<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>10. 双晶体管电路·多级放大电路</title>
    <link href="/2021/11/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/10.%20IC_buildingblocks/"/>
    <url>/2021/11/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/10.%20IC_buildingblocks/</url>
    
    <content type="html"><![CDATA[<h1 id="双晶体管电路"><a href="#双晶体管电路" class="headerlink" title="双晶体管电路"></a>双晶体管电路</h1><p>所有模拟电路都是通过使用数量非常有限的基本结构模块来构建的，因此，对这些简单模块的透彻了解对于深入了解更复杂的电路原理至关重要，这就是为什么将它们分别考虑并进行详细分析的原因。我们已经对单晶体管电路有了全面的了解，接下来我们将专注于电流镜和差分对的探讨，这些构成了所有模拟设计的基石。<br>基本的双晶体管配置有：电流镜(Current Mirror)和差分对(Difference Pair)两种。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128134829.png width=50%>  </p><p>大部分模拟电路在集成电路设计中都可以通过数个多级的如上所示的两个基本电路而构成。  </p><blockquote><p>参考资料:<a href="https://www.icfedu.cn/archives/13594">https://www.icfedu.cn/archives/13594</a></p></blockquote><h2 id="电流镜"><a href="#电流镜" class="headerlink" title="电流镜"></a>电流镜</h2><p>电流镜电路的基本设计如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128134946.png width=40%>  </p><p>这个电路中，左边的晶体管$Q_1$将输入电流转为电压$V_{BE}$输出，右边的晶体管$Q_2$将$V_{BE}$视为输入，进而转为电流$I_O$输出。  </p><h3 id="电流分析"><a href="#电流分析" class="headerlink" title="电流分析"></a>电流分析</h3><p>对电流镜电路，假设图中AB两点间的电流为$2\frac{I_C}{β}$：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128135641.png width=50%>  </p><p>那么可以发现：  </p><script type="math/tex; mode=display">I_{REF}=I_C+2\frac{I_C}{β}</script><script type="math/tex; mode=display">I_O=I_C</script><p>因此:  </p><script type="math/tex; mode=display">\frac{I_O}{I_{REF}}=\frac{1}{1+\frac{2}{β}}</script><p>当$β→∞$时，$\frac{I_O}{I_{REF}}→1$。<br>通常认为$I_O=I_{REF}$。  </p><h3 id="带基极电流补偿的电流镜"><a href="#带基极电流补偿的电流镜" class="headerlink" title="带基极电流补偿的电流镜"></a>带基极电流补偿的电流镜</h3><p>在电流镜电路中的AB两点增加一个晶体管：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211129204508.png width=50%>  </p><p>由于晶体管的存在，此时：  </p><script type="math/tex; mode=display">I_{REF}=I_C+I_{B3}</script><script type="math/tex; mode=display">I_{B3}=\frac{I_{E3}}{β+1}=\frac{2I_C}{β(β+1)}</script><p>因此：  </p><script type="math/tex; mode=display">I_O=I_{C}=\frac{I_{REF}}{1+\frac{2}{β(β+1)}}</script><p>相比于原来的电流镜电路，输出的电流大小对β的依赖性更低，更加稳定。  </p><h3 id="基本增益单元"><a href="#基本增益单元" class="headerlink" title="基本增益单元"></a>基本增益单元</h3><p>$I_{REF}$的产生方式有两种：第一种是通过给电压，使用电阻将电压转换为电流。另一种是直接给一个电流源。<br>在集成电路设计中第一种方法无法精准控制电流的大小，因此通常采用第二种方法来获得$I_{REF}$。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130133505.png width=70%>  </p><p>在小信号模型中对其进行分析，其开环增益应该为：  </p><script type="math/tex; mode=display">A_{vo}=-g_mr_o</script><p><strong>电流镜在集成电路中可以为其他晶体管电路提供稳定的直流电流，在集成电路中常作为直流电流源使用。在小信号模型分析中，电流镜电路和直流电流源一样，被视为开路。</strong>  </p><h2 id="达灵顿对"><a href="#达灵顿对" class="headerlink" title="达灵顿对"></a>达灵顿对</h2><p>达灵顿对（Darlington pair）是由两个（甚至多个）双极性晶体管组成的复合结构，通过这样的结构，经第一个双极性晶体管放大的电流可以进一步被放大。这样的结构可以提供一个比其中任意一个双极性晶体管高得多的电流增益。在使用集成电流芯片的情况里，达灵顿晶体管可以使得芯片比使用两个分立晶体管元件占用更少的空间，因为两个晶体管可以共用一个集极。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130134014.png width=30%>   </p><p>达灵顿对的电流增益可以表示为：  </p><script type="math/tex; mode=display">β=β_1×β_2</script><p>现在，达灵顿晶体管产品的典型电流增益可以达到1000甚至更高，因此只需要很小的基极电流就可以让晶体管导通。然而，这样高的电流增益也带来了一些缺点。<br>达灵顿对的问题在于通常$I_{B2}$非常小，因此$I_{E1}$很小，容易造成$I_{C1}$减小，影响$β_1$，使得$Q_1$进入截止工作状态而无法正常工作。  </p><blockquote><p>下图表示了$β$随$I_C$的变化曲线，可以发现如果$I_C$非常小的话，$β$无限趋近于0，晶体管进入截止状态。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130141945.png width=50%>  </p></blockquote><p>解决方法是在$Q_1$的发射极区增加一个恒定的电流源，使$I_{E1}=I_{B2}+I$，以维持$I_{E1}$的电流水平，使$I_{C1}$不至于过小。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130142236.png width=30%>  </p><h2 id="差分对"><a href="#差分对" class="headerlink" title="差分对"></a>差分对</h2><p>差分对是另一种常见于集成电路设计的基本结构，由于差分电路输出的结果是两个输入信号的差值，两个输入信号中携带的噪音在做差时很容易减小甚至是被除去，因此差分电路对于噪音和干扰的鲁棒性强，在集成电路中得到广泛的应用。<br>最基本的差分对结构如下图所示，差分对电路由两个完全相同的晶体管$Q_1$和$Q_2$组成。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130142858.png width=50%>  </p><p>差分对电路中的两基极电压$v_{B1}$和$v_{B2}$用于设置两个晶体管状态处于放大模式或截止模式。$i_C$可以用电压$V_{CC}$加电阻$R_C$产生，也可以使用电流源直接产生。  </p><h3 id="差分对的正常模式"><a href="#差分对的正常模式" class="headerlink" title="差分对的正常模式"></a>差分对的正常模式</h3><p>当$v_{B1}=v_{B2}=V_{CM}$时，晶体管处于正常模式。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130143312.png width=50%>  </p><p>在正常模式下，</p><script type="math/tex; mode=display">i_{E1}=i_{E2}=\frac{I}{2}</script><script type="math/tex; mode=display">V_{C1}=V_{C2}=V_{CC}-\frac{1}{2}αIR_C</script><p>可以发现，$Q_1$和$Q_2$均处于放大模式，此时输出的电压$V_{C1}$和$V_{C2}$与$V_{CM}$没有任何关系。  </p><h3 id="差分对的差分模式"><a href="#差分对的差分模式" class="headerlink" title="差分对的差分模式"></a>差分对的差分模式</h3><p><strong>当用于设置晶体管工作状态的$v_{B1}$和$v_{B2}$不相同时，$Q_1$和$Q_2$两个晶体管中一个晶体管处于正常模式，另一个晶体管处于截止模式。</strong><br>此时需要对两个晶体管的工作状态进行假设，然后观察两个晶体管的$V_{BE}&gt;0.7V$的条件是否成立，且是否与假设冲突，进而确定两个晶体管的工作状态。  </p><p>在差分模式下，其中处于截止状态的晶体管的输出电压：  </p><script type="math/tex; mode=display">V_{C}=V_{CC}</script><p>处于放大状态的晶体管的输出电压：  </p><script type="math/tex; mode=display">V_{C}=V_{CC}-αIR_C</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130144602.png width=30%>  </p><h2 id="差分放大电路"><a href="#差分放大电路" class="headerlink" title="差分放大电路"></a>差分放大电路</h2><p>差分放大电路是利用差分对性质构成的放大电路，其输入电压为两个晶体管的基极电压信号，输出两个晶体管集电极电压的差值。  </p><h3 id="大信号模型"><a href="#大信号模型" class="headerlink" title="大信号模型"></a>大信号模型</h3><p>在大信号模型下，输入的电压信号既有交流信号，也有直流信号。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130144839.png width=50%><br>此时：  </p><script type="math/tex; mode=display">i_{E1}=\frac{I_S}{α}e^{(v_{B1}-v_E)/V_T}</script><script type="math/tex; mode=display">i_{E2}=\frac{I_S}{α}e^{(v_{B2}-v_E)/V_T}</script><p>两式子相除：  </p><script type="math/tex; mode=display">\frac{i_{E1}}{i_{E2}}=e^{v_{id}/V_T}</script><p>其中$v_{id}$是输入电压信号的差值：$v_{id}=v_{B1}-v_{B2}$。<br>令$I=i_{E1}+i_{E2}$，等式两边同时加$1$以带入$I$，得到：  </p><script type="math/tex; mode=display">i_{E2}=\frac{I}{1+e^{v_{id}/V_T}}≈i_{C2}</script><script type="math/tex; mode=display">i_{E1}=\frac{I}{1+e^{-v_{id}/V_T}}≈i_{C1}</script><p>绘制出$i_C$关于$v_{id}$的图像，即差分放大电路的大信号模型特性曲线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130152811.png width=60%>  </p><p>在大信号模型中找到$v_{id}=0$（即$v_{B1}=v_{B2}=V_{CM}$）附近的线性区，在这个区域中，两个晶体管可以视作是在直流工作状态的放大模式下。  </p><h3 id="小信号模型"><a href="#小信号模型" class="headerlink" title="小信号模型"></a>小信号模型</h3><p>小信号模型基于大信号模型中的线性区域进行分析，根据大信号模型中得出的结论：  </p><script type="math/tex; mode=display">i_{C1}=\frac{αI}{1+e^{v_{-id}/V_T}}</script><script type="math/tex; mode=display">i_{C2}=\frac{αI}{1+e^{v_{id}/V_T}}</script><p>对于$i_{C1}$，分子分母同时乘以$e^{v_{id}/V_T}$：  </p><script type="math/tex; mode=display">i_{C1}=\frac{αIe^{v_{id}/2V_T}}{e^{v_{id}/V_T}+e^{v_{-id}/V_T}}</script><p>利用泰勒展开式展开，并保留前两项，化简得到：  </p><script type="math/tex; mode=display">i_{C1}=\frac{αI}{2}+\frac{αI}{2V_T}\frac{v_{id}}{2}</script><script type="math/tex; mode=display">i_{C1}=I_C-g_m\frac{v_{id}}{2}</script><p>由于$i_{C1}$由直流分量和交流分量组成，而$I_C$为纯粹的直流分量，因此$i_{C1}$的交流分量：  </p><script type="math/tex; mode=display">i_{c1}=g_m\frac{v_{id}}{2}</script><p>同理可得：  </p><script type="math/tex; mode=display">i_{c2}=-g_m\frac{v_{id}}{2}</script><h3 id="差分增益"><a href="#差分增益" class="headerlink" title="差分增益"></a>差分增益</h3><p>通过之前的分析可以得到两个输出电压：  </p><script type="math/tex; mode=display">v_{C1}=V_{CC}-I_CR_C-i_{C1}R_C</script><script type="math/tex; mode=display">v_{C2}=V_{CC}-I_CR_C+i_{C2}R_C</script><p>定义差分电路的差分增益为输出电压信号的差值和输入电压信号的差值$v_{id}$之比：  </p><script type="math/tex; mode=display">A_d=\frac{v_{C2}-v_{C1}}{v_{id}}=g_mR_C</script><h4 id="小信号模型的差分增益"><a href="#小信号模型的差分增益" class="headerlink" title="小信号模型的差分增益"></a>小信号模型的差分增益</h4><p>对两个晶体管在小信号模型下使用T模型进行分析：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211130154322.png width=50%>  </p><p>其输入电阻为：  </p><script type="math/tex; mode=display">R_{id}=\frac{v_{id}}{i_b}=2(β+1)r_e=2r_π</script><p>有:  </p><script type="math/tex; mode=display">i_e=\frac{v_{id}}{2r_e}≈i_c</script><script type="math/tex; mode=display">v_{c1}=-\frac{αv_{id}}{2r_e}R_C</script><script type="math/tex; mode=display">v_{c2}=\frac{αv_{id}}{2r_e}R_C</script><p>小信号模型下的差分增益：  </p><script type="math/tex; mode=display">A_d=\frac{v_{c2}-v_{c1}}{v_{id}}=\frac{2αR_C}{2r_e}≈\frac{R_C}{r_e}</script><h3 id="共模抑制比"><a href="#共模抑制比" class="headerlink" title="共模抑制比"></a>共模抑制比</h3><p>事实上，差分对的两个集电极区会有噪声和干扰，这些噪声和干扰最终归结于电路中$R_C$的阻值，因此在实际电路中，等效的两个$R_C$阻值并不完全相等，而是由细微的差异。<br>实际上差分对在正常模式下的两边的输出电压由于$R_C$细小的差异而不再相等：  </p><script type="math/tex; mode=display">v_{o1}=-\frac{αR_C}{r_e+2R_{EE}}v_{icm}</script><script type="math/tex; mode=display">v_{o2}=-\frac{α(R_C+ΔR_C)}{r_e+2R_{EE}}v_{icm}</script><p>此时整个电路相当于一个差分放大器，其在输出端存在一个差分电压：  </p><script type="math/tex; mode=display">v_{od}=v_{o2}-v_{o1}=-\frac{αΔR_C}{r_e+2R_{EE}}v_{icm}</script><p>定义共模增益为差分电压和输入电压之比：  </p><script type="math/tex; mode=display">A_{cm}=\frac{v_{od}}{v_{icm}}=-\frac{αΔR_C}{r_e+2R_{EE}}</script><p>定义共模抑制比为其差分增益与共模增益之比：  </p><script type="math/tex; mode=display">CMRR=\frac{A_d}{A_{cm}}</script><h2 id="多极放大器"><a href="#多极放大器" class="headerlink" title="多极放大器"></a>多极放大器</h2><p>为了尽可能的减少电阻、电容带来的不稳定性，在集成电路设计中通常使用多级的电流镜、差分对组成的电路实现电流信号的多级放大。<br>下图所示的是一个多级电流放大电路：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211201133023.png width=60%><br>在上图的电路中，<br>第一级由$Q_1$、$Q_2$、$Q_3$、$Q_9$ 四个晶体管组成。通过设置$V_{EE}$,在$Q_9$处产生$I_{REF}$。$I_{REF}$通过$Q_3$、$Q_9$ 组成的电流镜将电流信号传入$Q_1$、$Q_2$组成的差分对中，差分对将电流信号转换为电压信号，电压信号成为下一级差分对电路的输入信号。  </p><p>第二级由$Q_4$、$Q_5$、$Q_6$三个晶体管组成。上一级输出的电压信号作为$Q_4$、$Q_5$组成的差分对电路的输入电压（控制电压），同时$Q_6$对第一级的电流$I_{REF}$进行放大，并为$Q_4$、$Q_5$组成的差分对电路提供稳定的发射极电流$I_E$。差分对一端输出的电压信号传入下一级，为下一级的晶体管设置工作状态。  </p><p>第三级由$Q_7$组成，上一级差分对电路的输出电压为$Q_7$设置静态工作点，并通过$R_5$控制输入进下一级的电压信号的直流分量正好为0.7V。  </p><p>第四级由$Q_8$组成，通过$Q_8$基极和发射极之间的压降将上一级电压信号的直流分量完全消除，最终输出直流分量为0的交流电压信号。同时$R_6$将电压信号转为电流信号，可以发现，输出端的电流信号$I_o$正好是$I_{REF}$的十倍。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211201134351.png width=70%>  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9. 晶体管单级放大电路</title>
    <link href="/2021/11/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/9.%20ICamplifier/"/>
    <url>/2021/11/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/9.%20ICamplifier/</url>
    
    <content type="html"><![CDATA[<h1 id="晶体管单级放大电路"><a href="#晶体管单级放大电路" class="headerlink" title="晶体管单级放大电路"></a>晶体管单级放大电路</h1><p>集成电路中的运算放大器是由晶体管组成的，最基本的三种用晶体管构成的单级放大电路为：  </p><ul><li>共射极放大电路(Common Emitter)</li><li>共基极放大电路(Common Base)</li><li>共集极放大电路(Common Collector)  </li></ul><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128140544.png width=60%>   </p><p>总体上来说，晶体管的哪个集被共用，电路中晶体管的哪个极就接地。<br>三种放大电路的特性不尽相同，用途也不相同，本节主要介绍这三种放大电路的电路分析和特性。  </p><h2 id="共射极（CE）放大电路"><a href="#共射极（CE）放大电路" class="headerlink" title="共射极（CE）放大电路"></a>共射极（CE）放大电路</h2><p>共射极放大电路如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128140810.png width=50%></p><p>电压信号由基极输入、集电极输出。  </p><h3 id="π模型的电路分析"><a href="#π模型的电路分析" class="headerlink" title="π模型的电路分析"></a>π模型的电路分析</h3><p>当发射极没有额外的电阻时，因此使用π模型进行等效处理：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128151846.png width=60%>  </p><p>在该电路中，放大电路部分（图中蓝色框）的输入电阻：  </p><script type="math/tex; mode=display">R_{in}=\frac{v_i}{i_b}=r_π</script><p>而$r_π=\frac{β}{g_m}$，$g_m=\frac{I_C}{V_T}$，通常来说放大电路内部的输入电阻较小，但是数量级仍然在几千欧姆。<br>当$v_{sig}=0$时，从输出端看电路电阻，可以得到放大电路部分的输出电阻：  </p><script type="math/tex; mode=display">R_o=R_C</script><p>可见放大电路部分的输出电阻由$R_C$的阻值决定，通常$R_C$的阻值都比较大，数量级在几千欧姆左右。<br>放大器的电压增益就可以表示为：  </p><script type="math/tex; mode=display">A_v=\frac{v_o}{v_{sig}}</script><script type="math/tex; mode=display">v_o=-g_mv_π×R_C</script><script type="math/tex; mode=display">v_π=v_{sig}\frac{r_π}{r_π+R_{sig}}</script><script type="math/tex; mode=display">A_v=-g_m\frac{r_π}{r_π+R_{sig}}R_C</script><p>由于放大电路的开环增益与电压增益的关系为:$A_v=A_{vo}\frac{R_{in}}{R_{in}+R_{sig}}$，因此电路的开环增益表示为：  </p><script type="math/tex; mode=display">A_{vo}=-g_mR_C</script><h3 id="T模型电路分析"><a href="#T模型电路分析" class="headerlink" title="T模型电路分析"></a>T模型电路分析</h3><p>当发射极存在额外的电阻$R_e$时，采用T模型对电路进行分析：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128160412.png width=50%>  </p><p>由于发射极接地，不便于电阻分析，因此采用电阻投射定理将发射极的电阻转到基极上进行计算。<br>那么输入电阻：  </p><script type="math/tex; mode=display">R_{in}=(r_e+R_e)(β+1)=r_π</script><p>输出电阻：  </p><script type="math/tex; mode=display">R_o=R_C</script><p>那么电压增益可以表示为：  </p><script type="math/tex; mode=display">A_v=\frac{v_o}{v_{sig}}</script><p>应用电阻投射定理将$R_{sig}$转到发射极以求出$i_e$：  </p><script type="math/tex; mode=display">i_e=\frac{v_{sig}}{(r_e+R_e)+\frac{R_{sig}}{β+1}}</script><script type="math/tex; mode=display">v_o=-i_cR_C=-αi_eR_C=-\frac{αv_{sig}R_C}{(r_e+R_e)+\frac{R_{sig}}{β+1}}</script><script type="math/tex; mode=display">A_v=-\frac{αR_C}{(r_e+R_e)+\frac{R_{sig}}{β+1}}</script><p>由$α=\frac{β}{\beta+1}$:  </p><script type="math/tex; mode=display">A_v=-β\frac{R_C}{(r_e+R_e)(β+1)+R_{sig}}</script><p>由$r_π=(r_e+R_e)(β+1)=\frac{β}{g_m}$:  </p><script type="math/tex; mode=display">A_v=-g_m\frac{r_π}{r_π+R_{sig}}R_C</script><p>电路的开环增益同样为：  </p><script type="math/tex; mode=display">A_{vo}=-g_mR_C</script><h3 id="共射极放大电路的特性"><a href="#共射极放大电路的特性" class="headerlink" title="共射极放大电路的特性"></a>共射极放大电路的特性</h3><p>由开环增益的表达式可以发现，输入电阻$R_{in}=r_π$增大，$g_m$下降，$|A_{vo}|$减小。根据反馈电路中对开环增益与稳定性的分析：<strong>开环增益越小，系统越稳定。</strong><br>因此，输入电阻应该尽量地大，而输出电阻$R_C$也应当尽量地小才能保证系统的稳定性。<br>在实际中，可以在输入段之前加入一个缓冲器/跟随器，以提高输入电阻的阻值。  </p><h2 id="共基极-CB-放大电路"><a href="#共基极-CB-放大电路" class="headerlink" title="共基极(CB)放大电路"></a>共基极(CB)放大电路</h2><p>共基极放大电路如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128162524.png width=40%><br>电压信号$v_{sig}$在发射极作为输入信号，集电极处$R_C$上的电压作为输出电压。  </p><h3 id="T模型电路分析-1"><a href="#T模型电路分析-1" class="headerlink" title="T模型电路分析"></a>T模型电路分析</h3><p>由于发射极存在电阻，因此采用T模型进行分析：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128162806.png width=50%>  </p><p>T模型中放大电路的输入电阻：  </p><script type="math/tex; mode=display">R_{in}=-\frac{v_i}{i_e}=r_e</script><p>由于$r_e=\frac{α}{g_m}$，因此放大电路内部的输入电阻比较好，在几十欧姆左右。  </p><p>假设输入电压为0，从输出端看电阻，则输出电阻为：  </p><script type="math/tex; mode=display">R_o=R_C</script><p>可见放大电路部分的输出电阻由$R_C$的阻值决定，通常$R_C$的阻值都比较大，数量级在几千欧姆左右。<br>则放大电路的电压增益表示为：  </p><script type="math/tex; mode=display">A_v=\frac{v_o}{v_{sig}}</script><script type="math/tex; mode=display">\begin{aligned}    v_o&=i_cR_C \\    &=-αi_eR_C \\    &=-α(-\frac{v_{sig}}{v_{sig}+r_e})R_C\\\end{aligned}</script><script type="math/tex; mode=display">A_v=\frac{v_o}{v_{sig}}=α\frac{R_C}{R_{sig}+r_e}</script><p>其开环增益：  </p><script type="math/tex; mode=display">A_{vo}=α</script><p>由于$α≈1$，因此共基极放大器的电压增益与晶体管电流增益$β$无关。同时$R_{sig}$、$R_C$的阻值常处于同一数量级，因此共基极放大电路的电压增益很小。  </p><h3 id="共基极放大电路的特性"><a href="#共基极放大电路的特性" class="headerlink" title="共基极放大电路的特性"></a>共基极放大电路的特性</h3><p>由于输入阻抗/阻值过于低，与理想放大器要求的“输入阻抗无穷大”矛盾，因此绝大多数情况下不适合作为放大电路工作。<br>但是，由于其开环增益相对独立，因此共基极放大电路不容易受到频率的影响，在高频部分表现较为稳定。<br>此外，其输入阻值的数量级正好和同轴线缆的阻值差不多，因此可以在使用同轴线缆的高频电路中使用，实现和线缆的阻抗匹配，以减小信号的能量反射损失。  </p><h2 id="共集极-CC-放大电路-发射极跟随器"><a href="#共集极-CC-放大电路-发射极跟随器" class="headerlink" title="共集极(CC)放大电路/发射极跟随器"></a>共集极(CC)放大电路/发射极跟随器</h2><p>共集极放大电路的结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128170501.png width=40%>  </p><p>共集极以基极作为输入信号源，同时在发射极连接一个负载电阻$R_L$作为电路的输出。 </p><h3 id="T模型电路分析-2"><a href="#T模型电路分析-2" class="headerlink" title="T模型电路分析"></a>T模型电路分析</h3><p>由于发射极存在电阻，因此采用T模型进行分析：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128173612.png width=40%>  </p><p>输入电阻：  </p><script type="math/tex; mode=display">i_b=\frac{v_i}{(β+1)(r_e+R_L)}</script><script type="math/tex; mode=display">R_{in}=(r_e+R_L)(1+β)</script><p>输出电阻：<br>如果$v_{sig}=0$，那么从放大电路的输出端看电阻：  </p><script type="math/tex; mode=display">R_o=r_e</script><p>电路的电压增益为：  </p><script type="math/tex; mode=display">v_{in}=\frac{R_{in}}{R_{in}+R_{sig}}v_{sig}</script><script type="math/tex; mode=display">v_o=v_{in}\frac{R_L}{R_L+r_e}</script><p>其中$v_{in}$和$v_{o}$表示放大电路部分（对应晶体管）的输入电压和输出电压。  </p><script type="math/tex; mode=display">A_v=\frac{v_o}{v_{sig}}=\frac{R_L}{R_L+r_e}\frac{R_{in}}{R_{in}+R_{sig}}</script><p>带入$R_{in}$,得到：  </p><script type="math/tex; mode=display">\begin{aligned}    A_v&=\frac{R_L}{R_L+r_e}\frac{(r_e+R_L)(1+β)}{(r_e+R_L)(1+β)+R_{sig}}\\    &=\frac{(β+1)R_L}{(β+1)(r_e+R_L)+R_{sig}}\end{aligned}</script><p>电路的开环增益由$R_L→∞$给出：  </p><script type="math/tex; mode=display">A_{vo}=\lim_{R_L→∞}\frac{v_o}{v_{in}}=\lim_{R_L→∞}\frac{R_L}{R_L+r_e}=1</script><script type="math/tex; mode=display">A_{vo}=1</script><p>因此，电路的开环增益等于1。  </p><h3 id="共集极放大电路的特性"><a href="#共集极放大电路的特性" class="headerlink" title="共集极放大电路的特性"></a>共集极放大电路的特性</h3><p>共集极放大电路的开环增益恒等于1，因此在电路中常常作为缓冲器/跟随器使用。  </p><h2 id="完整的晶体管放大电路"><a href="#完整的晶体管放大电路" class="headerlink" title="完整的晶体管放大电路"></a>完整的晶体管放大电路</h2><p>上述的电路分析都是基于小信号模型，在小信号模型中只考虑的交流信号所带来的影响。现在回到大信号模型，同时考虑输入信号的直流分量。此时电路需要在晶体管的三极各设置一个耦合电容以隔绝直流的影响，其余部分保持不变。电路的特性和增益等交流分析的结论仍然适用。  </p><h3 id="完整的放大电路结构"><a href="#完整的放大电路结构" class="headerlink" title="完整的放大电路结构"></a>完整的放大电路结构</h3><ul><li><p>共发射极放大电路<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128185514.png width=30%>  </p></li><li><p>共基极放大电路<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128191118.png width=30%>  </p></li><li><p>共集极放大电路<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128192601.png width=30%>  </p></li></ul><h3 id="放大电路的频率响应"><a href="#放大电路的频率响应" class="headerlink" title="放大电路的频率响应"></a>放大电路的频率响应</h3><p>由于完整的放大电路中存在电容，当输入的电压信号频率较低时，这些电容的容抗无法在电路分析中忽略，因此放大电路的增益在输入信号为低频信号时有所损失。<br>下图表示了晶体管放大电路的频率响应特性曲线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211201134850.png width=80%></p><blockquote><p>集成放大器中（比如第10讲的多级放大电路）不存在电容，因此其性能不会受到输入信号中低频分量的影响。但是高频时晶体管内部的类似电容的表现特性也会使得其性能在高频时存在损失。  </p></blockquote><p>在低频输入下，电路中电容不再视为短路。整个电路的低频截止频率$f_L$可以是电路中的每一个电容的截止频率的线性叠加：  </p><script type="math/tex; mode=display">f_L=\frac{1}{2π}∑_i\frac{1}{C_iR_{Ci}}</script><p>其中$R_{Ci}$为单看其中一个电容，其他电容视为短路时，电容电阻构成的滤波器电路中的等效电阻。  </p><blockquote><p>求电路的低频截止频率：  </p><ol><li>单看其中一个电容，剩下电容视为短路。  </li><li>画出等效的滤波器电路模型，找到等效电阻。  </li><li>所有的电容对应的等效电阻都被找到，求每个电容的截止频率，再线性叠加。  </li></ol></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">放大电路类型</th><th style="text-align:center">$R_{in}$</th><th style="text-align:center">$R_{o}$</th><th style="text-align:center">$A_v$</th><th style="text-align:center">$A_{vo}$</th><th style="text-align:left">特性</th></tr></thead><tbody><tr><td style="text-align:center">CE</td><td style="text-align:center">$r_π$ <br> 越大越好</td><td style="text-align:center">$R_C$ <br> 越小越好</td><td style="text-align:center">$-g_m\frac{r_π}{r_π+R_{sig}}R_C$</td><td style="text-align:center">$-g_mR_C$</td><td style="text-align:left">内部的输入和输出阻值都在几千欧姆<br>相比之下输入阻值较小。</td></tr><tr><td style="text-align:center">CB</td><td style="text-align:center">$r_e$</td><td style="text-align:center">$R_C$</td><td style="text-align:center">$α\frac{R_C}{R_{sig}+r_e}$</td><td style="text-align:center">$α$</td><td style="text-align:left">输入阻值过小<br>电压增益很小<br>开环增益独立</td></tr><tr><td style="text-align:center">CC</td><td style="text-align:center">$(r_e+R_L)(1+β)$</td><td style="text-align:center">$r_e$</td><td style="text-align:center">$\frac{(β+1)R_L}{(β+1)(r_e+R_L)+R_{sig}}$</td><td style="text-align:center">$1$</td><td style="text-align:left">开环增益恒等于1</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13. 数字带通系统的抗噪性分析</title>
    <link href="/2021/11/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/13.%20%E6%95%B0%E5%AD%97%E5%B8%A6%E9%80%9A%E4%BC%A0%E8%BE%93%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%97%E5%99%AA%E6%80%A7%E5%88%86%E6%9E%90/"/>
    <url>/2021/11/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/13.%20%E6%95%B0%E5%AD%97%E5%B8%A6%E9%80%9A%E4%BC%A0%E8%BE%93%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%8A%97%E5%99%AA%E6%80%A7%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="数字带通系统的抗噪性分析"><a href="#数字带通系统的抗噪性分析" class="headerlink" title="数字带通系统的抗噪性分析"></a>数字带通系统的抗噪性分析</h1><h2 id="ASK的抗噪性分析"><a href="#ASK的抗噪性分析" class="headerlink" title="ASK的抗噪性分析"></a>ASK的抗噪性分析</h2><p>在调制端，输入信号可以由ASK信号和窄带高斯白噪声组成：  </p><script type="math/tex; mode=display">y_i(t)=u_i(t)+n_i(t)</script><p>其中:$u_i(t)=\begin{cases}<br>    acosω_ct,表示“1”\\<br>    0, 表示“0”<br>\end{cases}$<br>输入噪声可以通过正交分解表示为: $n_i(t)=n_c(t)cosω_ct-n_s(t)sinω_ct$。  </p><p>那么通过带通滤波器后的信号：  </p><script type="math/tex; mode=display">y(t)=\begin{cases}    [a+n_c(t)]cosω_ct-n_ssinω_ct,\text{ 表示“1”}\\    n_c(t)cosω_ct-n_s(t)sinω_ct,\text{ 表示“0”}\end{cases}</script><h3 id="相干调制的误码率分析"><a href="#相干调制的误码率分析" class="headerlink" title="相干调制的误码率分析"></a>相干调制的误码率分析</h3><p>在相干调制中，信号与载波信号相乘得到：  </p><script type="math/tex; mode=display">z(t)=y(t)cosω_ct=\begin{cases}    [a+n_c(t)]cos^2ω_ct-n_ssinω_ctcosω_ct,\text{ 表示“1”}\\    n_c(t)cos^2ω_ct-n_s(t)sinω_ctcosω_ct,\text{ 表示“0”}\end{cases}</script><p>其中，由于低通滤波器只允许低频分量和直流分量通过，在无线传输中，一般认为载波频率很高，因此含有$t$的所有项无法通过滤波器，最终得到：  </p><script type="math/tex; mode=display">x(t)=\begin{cases}    \frac{1}{2}[a+n_c(t)],\text{ 表示“1”}\\    \frac{1}{2}n_c(t),\text{ 表示“0”}\end{cases}</script><p>其中幅值$\frac{1}{2}$可以通过放大器消除。<br>同数字基带系统的抗噪性分析，计算码元为“0”时判别为“1”的概率和码元为“1”时判别为“0”的概率，得到在$P(0)=P(1)=0.5$时的误码率：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(\frac{\sqrt{SNR}}{2})</script><h3 id="非相干信号的误码率分析"><a href="#非相干信号的误码率分析" class="headerlink" title="非相干信号的误码率分析"></a>非相干信号的误码率分析</h3><p>通过带通滤波器的信号进行包络检波：  </p><script type="math/tex; mode=display">V(t)=\begin{cases}    \sqrt{([a+n_c(t)]^2+n_s^2(t))},\text{ 表示“1”}\\    \sqrt{(n_c^2(t)+n_s^2(t))}, \text{ 表示“0”}\\\end{cases}</script><p>通过计算得到：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}e^{-\frac{SNR}{4}}=\frac{1}{2}e^{-\frac{SNR}{4}}</script><h3 id="ASK信号的信噪比"><a href="#ASK信号的信噪比" class="headerlink" title="ASK信号的信噪比"></a>ASK信号的信噪比</h3><p>对于ASK信号，信噪比为：  </p><script type="math/tex; mode=display">SNR_{ASK}=\frac{\frac{a^2}{2}}{n_0B_{ASK}}=\frac{\frac{a^2}{2}}{2n_0B_s}</script><h2 id="FSK的抗噪性分析"><a href="#FSK的抗噪性分析" class="headerlink" title="FSK的抗噪性分析"></a>FSK的抗噪性分析</h2><h3 id="FSK信号的误码率"><a href="#FSK信号的误码率" class="headerlink" title="FSK信号的误码率"></a>FSK信号的误码率</h3><p>FSK信号的误码率可以表示为：<br>采用相干解调时：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(\sqrt{\frac{SNR_{FSK}}{2}})</script><p>采用非相干解调时：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}e^{-\frac{SNR_{FSK}}{2}}</script><h3 id="FSK信号的信噪比"><a href="#FSK信号的信噪比" class="headerlink" title="FSK信号的信噪比"></a>FSK信号的信噪比</h3><p>FSK信号的解调过程实际上是两路信号做ASK解调，因此：  </p><script type="math/tex; mode=display">SNR_{FSK}=\frac{\frac{a^2}{2}}{n_0B_{ASK}}=\frac{\frac{a^2}{2}}{2n_0B_{S}}</script><h2 id="PSK信号的抗噪性分析"><a href="#PSK信号的抗噪性分析" class="headerlink" title="PSK信号的抗噪性分析"></a>PSK信号的抗噪性分析</h2><h3 id="PSK信号的误码率"><a href="#PSK信号的误码率" class="headerlink" title="PSK信号的误码率"></a>PSK信号的误码率</h3><p>PSK信号的误码率可以表示为：<br>采用相干解调时：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(\sqrt{SNR_{PSK}})</script><p>采用差分解调时：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}e^{-SNR_{PSK}}</script><h3 id="PSK信号的信噪比"><a href="#PSK信号的信噪比" class="headerlink" title="PSK信号的信噪比"></a>PSK信号的信噪比</h3><p>PSK信号的信噪比和ASK信号相同：  </p><script type="math/tex; mode=display">SNR_{PSK}=\frac{\frac{a^2}{2}}{n_0B_{PSK}}=\frac{\frac{a^2}{2}}{2n_0B_{S}}</script><h2 id="ASK-FSK-PSK抗噪性比较"><a href="#ASK-FSK-PSK抗噪性比较" class="headerlink" title="ASK/FSK/PSK抗噪性比较"></a>ASK/FSK/PSK抗噪性比较</h2><p>通过公式得出ASK/FSK/PSK抗噪性、采用相干/非相干解调方法时的抗噪性曲线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127160641.png width=60%>  </p><p>可以从上图总结出如下结论：  </p><ol><li>抗噪性：<strong>PSK&gt;DPSK&gt;FSK&gt;ASK</strong></li><li>抗噪性： <strong>相干解调&gt;非相干解调</strong>  </li><li>系统的误码率下降时，系统的信噪比上升。  </li></ol><p>此外，ASK/PSK和DPSK的带宽相同，FSK的带宽大于前三者，因此FSK的频谱利用效率最低。  </p><h2 id="总结：ASK-FSK-PSK的参数性能"><a href="#总结：ASK-FSK-PSK的参数性能" class="headerlink" title="总结：ASK/FSK/PSK的参数性能"></a>总结：ASK/FSK/PSK的参数性能</h2><p>ASK是一种应用最早的基本调制方式。其优点是设备简单，频带利用率较高；缺点是抗噪声性能差，并且对信道特性变化敏感，不易是抽样判决器工作在最佳判决门限状态。<br>FSK是数字通信中不可或缺的一种调制方式。其优点是抗干扰能力较强，不受信道参数变化的影响，因此FSK特别适合应用于衰落信道；缺点是占用频带较宽，尤其是MFSK，频带利用率较低。目前，调频体制主要应用于中，低速数据传输与接入中。<br>PSK和DPSK是一种高传输效率的调制方式，其抗噪声能力比ASK和FSK都强，且不易受信道特性变化的影响，因此在高、中速数据传输中得到了广泛的应用。绝对相移（PSK）在相干解调时存在载波相位模糊的问题，在实际中很少采用于直接传输，MDPSK应用更为广泛。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">调制方式</th><th style="text-align:center">受调信号的码型</th><th style="text-align:center">受调信号的带宽</th><th style="text-align:center">解调方法</th><th style="text-align:center">解调的最佳判决门限</th><th style="text-align:center">最大频谱利用效率</th><th style="text-align:center">误码率</th></tr></thead><tbody><tr><td style="text-align:center">ASK</td><td style="text-align:center">单极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调<br>包络检波法</td><td style="text-align:center">$\frac{a}{2}$</td><td style="text-align:center">$\frac{1}{2}$</td><td style="text-align:center">$\frac{1}{2}erfc(\frac{\sqrt{SNR}}{2})$<br> $\frac{1}{2}e^{-\frac{SNR}{4}}$</td></tr><tr><td style="text-align:center">FSK</td><td style="text-align:center">单极性码</td><td style="text-align:center">$\lvert f_1-f_2\rvert +2B_s$</td><td style="text-align:center">相干解调<br>包络检波法<br>过零检波法<br></td><td style="text-align:center">无<br>无<br>$\frac{a}{2}$</td><td style="text-align:center">$\frac{R_B}{\lvert f_1-f_2\rvert +2R_B}$</td><td style="text-align:center">$\frac{1}{2}erfc(\sqrt{\frac{SNR_{FSK}}{2}})$ <br> $\frac{1}{2}e^{-\frac{SNR_{FSK}}{2}}$</td></tr><tr><td style="text-align:center">PSK</td><td style="text-align:center">双极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调</td><td style="text-align:center">0</td><td style="text-align:center">$\frac{1}{2}$</td><td style="text-align:center">$\frac{1}{2}erfc(\sqrt{SNR_{PSK}})$</td></tr><tr><td style="text-align:center">DPSK</td><td style="text-align:center">双极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调<br>相位比较法</td><td style="text-align:center">0</td><td style="text-align:center">$\frac{1}{2}$</td><td style="text-align:center">$\frac{1}{2}e^{-SNR_{PSK}}$</td></tr></tbody></table></div><p>所有调制方法的信噪比均为： $SNR=\frac{\frac{a^2}{2}}{2n_0B_{S}}$。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9. 线性相位滤波器·FIR滤波器设计概述</title>
    <link href="/2021/11/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/9.%20%E7%BA%BF%E6%80%A7%E7%9B%B8%E4%BD%8D%E6%BB%A4%E6%B3%A2%E5%99%A8/"/>
    <url>/2021/11/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/9.%20%E7%BA%BF%E6%80%A7%E7%9B%B8%E4%BD%8D%E6%BB%A4%E6%B3%A2%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="线性相位滤波器·FIR滤波器设计概述"><a href="#线性相位滤波器·FIR滤波器设计概述" class="headerlink" title="线性相位滤波器·FIR滤波器设计概述"></a>线性相位滤波器·FIR滤波器设计概述</h1><blockquote><p>本节中需要格外注意公式的角标  </p></blockquote><h2 id="线性相位滤波器"><a href="#线性相位滤波器" class="headerlink" title="线性相位滤波器"></a>线性相位滤波器</h2><p>由于滤波器系统方程是一个复数函数方程，因此可以将滤波器系统方程表示为幅度和相位相乘的形式：  </p><script type="math/tex; mode=display">H(e^{jω})=|H(e^{jω})|e^{j∠H(e^{jω})}</script><p>其中$∠H(e^{jω})$是滤波器的相频响应(Phase Response)，$H_r(e^{jω})=|H(e^{jω})|$是滤波器的幅度值响应(Maganitude Response)，是幅度相应(Amplitude Response)的绝对值。<br>线性相位能保证信号通过系统后其中各频率成分的相对相位关系不改变，因此不容易出现在滤波器系统中因为发生码间串扰而信号失真。<br>线性相位滤波器的系统方程中，其相位可以表示为：  </p><script type="math/tex; mode=display">∠H(e^{jω})=β-αω,-π<ω<π</script><p><strong>在时域上，线性相位滤波器的冲激响应具有对称性或者反对称性</strong>：  </p><script type="math/tex; mode=display">h[n]=h[M-1-n],0≤n≤M-1</script><blockquote><p>例如：$h[n]=\{-1,2,0,2,-1\}$  </p></blockquote><script type="math/tex; mode=display">h[n]=-h[M-1-n],0≤n≤M-1</script><blockquote><p>例如：$h[n]=\{-1,2,0,-2,1\}$  </p></blockquote><p>由于线性相位系统不会改变信号相位，从而减小码间串扰的特点，在滤波器设计时基本都会保证滤波器是线性相位的。  </p><h2 id="FIR-滤波器的优点"><a href="#FIR-滤波器的优点" class="headerlink" title="FIR 滤波器的优点"></a>FIR 滤波器的优点</h2><p>FIR滤波器的系统方程可以由：  </p><script type="math/tex; mode=display">H(z)=∑_{n=N_1}^{N_2}h[n]z^{-n}</script><p>FIR 滤波器具有以下主要优点：</p><ul><li>它们可以具有精确的线性相位。</li><li>由于$∑_{k=N_1}^{N_2}|h[n]|&lt;∞$，它们始终稳定。</li><li>设计方法通常是线性的。</li><li>它们可以在硬件中高效实现。</li></ul><blockquote><p>FIR 滤波器的主要缺点是，要达到同样的性能水平，其所需阶数远高于 IIR 滤波器。相应地，这些滤波器的延迟通常比同等性能的 IIR 滤波器大得多。</p></blockquote><p>最重要的原因是FIR滤波器是线性相位滤波器，因此实际设计中，通常更倾向于设计FIR滤波器。  </p><h2 id="线性相位FIR滤波器的类型"><a href="#线性相位FIR滤波器的类型" class="headerlink" title="线性相位FIR滤波器的类型"></a>线性相位FIR滤波器的类型</h2><p>按照系统方程的冲激响应序列是对称/反对称的，以及整个序列的长度$M$的奇偶性，可以将线性相位的FIR滤波器分为四类。下面来求这四种系统类型的相频响应。  </p><h3 id="第一类：冲激响应对称、序列长度为奇数"><a href="#第一类：冲激响应对称、序列长度为奇数" class="headerlink" title="第一类：冲激响应对称、序列长度为奇数"></a>第一类：冲激响应对称、序列长度为奇数</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211207150420.png width=40%>  </p><p>此时的冲激响应表示为：  </p><script type="math/tex; mode=display">h[n]=h[M-1-n],\frac{M-1}{2}\text{是整数。}</script><p>由于序列中以中间项为分割线，前一半序列和后一半序列完全相同。<br>那么系统的频率响应序列可以表示为：前一半序列的离散时间傅里叶变换的二倍与中间项的离散时间傅里叶变换之和：  </p><script type="math/tex; mode=display">\begin{aligned}    H(e^{jω})&=∑_{n=0}^{M-1}h(n)e^{-jωn}\\    &=∑_{n=0}^{(M-3)/2}h(n)e^{-jωn}+h(\frac{M-1}{2})e^{-j(M-1)ω/2}+∑_{n=(M+1)/2}^{M-1}h(n)e^{-jωn}\\\end{aligned}</script><p>对于每一个对称项，有：  </p><script type="math/tex; mode=display">h(0+n)e^{-jω(0+n)}+h(\frac{M-1}{2}-n)e^{-jω(\frac{M-1}{2}-n)}=2h(\frac{M-1}{2})cos(ωn)</script><p>令：$a[n]=2h[\frac{M-1}{2}-n]$，带入$a[n]$，得到：  </p><script type="math/tex; mode=display">H(e^{jω})=\left(∑_{n=0}^{(M-1)/2}a[n]cos(ωn)\right)e^{-jω(M-1)/2}</script><p>根据上述式子可以得到其相频响应为：  </p><script type="math/tex; mode=display">∠H(e^{jω})=-\frac{(M-1)ω}{2}</script><p>即$β=0$,$α=\frac{M-1}{2}$。  </p><h3 id="第二类：冲激响应对称、序列长度为偶数"><a href="#第二类：冲激响应对称、序列长度为偶数" class="headerlink" title="第二类：冲激响应对称、序列长度为偶数"></a>第二类：冲激响应对称、序列长度为偶数</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211207151600.png width=40%>  </p><p>此时的冲激响应表示为：  </p><script type="math/tex; mode=display">h[n]=h[M-1-n],\frac{M-1}{2}\text{非整数。}</script><p>由于不存在中间项，相比于第一类，其系统方程中不存在中间项：  </p><script type="math/tex; mode=display">\begin{aligned}    H(e^{jω})&=∑_{n=0}^{M-1}h(n)e^{-jωn}\\    &=∑_{n=0}^{(M-2)/2}h(n)e^{-jωn}+∑_{n=M/2}^{M-1}h(n)e^{-jωn}\\\end{aligned}</script><p>将序列改写，并把相同项进行合并，注意前半部分和后半部分对应项的奇偶性正好相反：  </p><script type="math/tex; mode=display">b[n]=2h[\frac{M}{2}-n]</script><p>同理运用欧拉公式可得：  </p><script type="math/tex; mode=display">H(e^{jω})=\left(∑_{n=0}^{M/2}b[n]cos(ω(n-\frac{1}{2}))\right)e^{-jω(M-1)/2}</script><p>其相频响应为：  </p><script type="math/tex; mode=display">∠H(e^{jω})=-\frac{(M-1)ω}{2}</script><p>即$β=0$,$α=\frac{M-1}{2}$。  </p><h3 id="第三类：冲激响应反对称、序列长度为奇数"><a href="#第三类：冲激响应反对称、序列长度为奇数" class="headerlink" title="第三类：冲激响应反对称、序列长度为奇数"></a>第三类：冲激响应反对称、序列长度为奇数</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211207152015.png width=40%>  </p><p>同理可得其系统方程的化简结果为：  </p><script type="math/tex; mode=display">H(e^{jω})=\left(\sum_{n=1}^{(M-1)/2}c[n]sin(ωn)\right)e^{j[\frac{π}{2}-\frac{ω(M-1)}{2}]}</script><script type="math/tex; mode=display">c[n]=2h[\frac{M-1}{2}-n]</script><p>其相频响应为：  </p><script type="math/tex; mode=display">∠H(e^{jω})=\frac{π}{2}-\frac{(M-1)ω}{2}</script><p>即$β=\frac{π}{2}$,$α=\frac{M-1}{2}$。  </p><h3 id="第四类：冲激响应反对称、序列长度为偶数"><a href="#第四类：冲激响应反对称、序列长度为偶数" class="headerlink" title="第四类：冲激响应反对称、序列长度为偶数"></a>第四类：冲激响应反对称、序列长度为偶数</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211207151838.png width=40%>  </p><p>同理可得其系统方程的化简结果为：  </p><script type="math/tex; mode=display">H(e^{jω})=\left(\sum_{n=1}^{M/2}d[n]sin(ω(n-\frac{1}{2}))\right)e^{j[\frac{π}{2}-\frac{ω(M-1)}{2}]}</script><script type="math/tex; mode=display">d[n]=\frac{M-1}{2}</script><p>其相频响应为：  </p><script type="math/tex; mode=display">∠H(e^{jω})=\frac{π}{2}-\frac{(M-1)ω}{2}</script><p>即$β=\frac{π}{2}$,$α=\frac{M-1}{2}$。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8. 数字滤波器的结构设计</title>
    <link href="/2021/11/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/8.%20%E6%95%B0%E5%AD%97%E6%BB%A4%E6%B3%A2%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/"/>
    <url>/2021/11/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/8.%20%E6%95%B0%E5%AD%97%E6%BB%A4%E6%B3%A2%E5%99%A8%E7%9A%84%E5%AE%9E%E7%8E%B0%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="数字滤波器的结构设计"><a href="#数字滤波器的结构设计" class="headerlink" title="数字滤波器的结构设计"></a>数字滤波器的结构设计</h1><p>数字滤波器设计的核心是通过给定的时域或频域系统方程，在时域设计出对应的滤波器。<br>数字系统的差分方程表示为：  </p><script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=∑_{k=0}^Mb_kx[n-k]</script><p>从中提取出$y[n]$，并简单变换后得到关于现态输出$y[n]$的差分方程：  </p><script type="math/tex; mode=display">y[n]=\frac{1}{a_0}(∑_{k=0}^Mb_kx[n-k]-∑_{k=1}^Na_ky[n-k]),a_0≠0</script><p>这个方程是数字滤波器设计的主要依据。<br>根据加法的性质，这个差分方程中求和运算中的内部和外部的各部分可以调换计算次序，进而根据计算过程中每个部分计算次序的先后、滤波器的结构也随之不同。  </p><h2 id="滤波器设计图的画法"><a href="#滤波器设计图的画法" class="headerlink" title="滤波器设计图的画法"></a>滤波器设计图的画法</h2><p>滤波器设计图的画法有两种：信号框图和信号流图。差分方程中的计算以加法、乘法、和时延为主，本小节也主要关注这两种画法中三种模块的表示方法。  </p><h3 id="信号框图"><a href="#信号框图" class="headerlink" title="信号框图"></a>信号框图</h3><p>信号框图中加法器、乘法器和延迟器的画法如下图所示：  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125160512.png width=70%>  </p><h3 id="信号流图"><a href="#信号流图" class="headerlink" title="信号流图"></a>信号流图</h3><p>信号流图中加法器、乘法器和延迟器的画法如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125160644.png width=70%>  </p><blockquote><p>需要注意的是，无论是信号流图还是信号框图，加法器只允许不超过两个的输入信号存在。  </p></blockquote><h2 id="FIR系统的物理结构类型"><a href="#FIR系统的物理结构类型" class="headerlink" title="FIR系统的物理结构类型"></a>FIR系统的物理结构类型</h2><p>FIR系统的差分方程由于不含有除了$y[n]$的其他含$y$项，因此FIR系统中没有反馈。FIR系统的差分方程可以写作：    </p><script type="math/tex; mode=display">y[n]=∑_{k=0}^Mb_kx[n-k]</script><p>FIR系统的冲激响应即为系统差分方程的系数：  </p><script type="math/tex; mode=display">h[n]=\begin{cases}    b_n,0≤n≤M\\    0,otherwise\\\end{cases}</script><p>FIR系统的物理结构可以分为直接型（Direct form）和级联型（Cascade form）两种。  </p><h3 id="直接型"><a href="#直接型" class="headerlink" title="直接型"></a>直接型</h3><p>将FIR系统的差分方程中的求和直接拆开，有：  </p><script type="math/tex; mode=display">y[n]=b_1x[n-1]+b_2x[n-2]+..+b_Mx[n-M]</script><p>替换系统的冲激响应：  </p><script type="math/tex; mode=display">y[n]=h[1]x[n-1]+h[x][n-2]+..+h[M]x[n-M]</script><p>系统的直接型结构为：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125161657.png width=80%>  </p><p>如上图所示，在直接型结构中，$x[n]$分别做$M$次时延，每一次时延后的信号与对应系数相乘后，与前面的序列相加。  </p><h4 id="硬件消耗"><a href="#硬件消耗" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>因此，直接型需要：  </p><ul><li>M个时延单元(也称为存储单元，用于存放之前的输入)</li><li>M+1个乘法单元</li><li>M个加法单元</li></ul><p>直接型虽然容易搭建，但是消耗器件较多。此外，由于加法器和延迟器都处于系统干路上，如果任何一个延迟器或者加法器出现故障，则整个滤波器系统将无法正常工作。  </p><h3 id="级联型"><a href="#级联型" class="headerlink" title="级联型"></a>级联型</h3><p>系统方程（z域）和系统的冲激响应之间存在如下关系：  </p><script type="math/tex; mode=display">H(z)=∑_{n=0}^Mh[n]z^{-n}</script><p>可以考虑构造若干个关于$z^{-n}$的多项式$(b_{0k}+b_{1k}z^{-1}+b_{2k}z^{-2})$，通过若干个多项式相乘构造$∑_{n=0}^Mh[n]z^{-n}$，即：  </p><script type="math/tex; mode=display">H(z)=∑_{n=}^Mh[n]z^{-n}=∏_{k=1}^{M_s}(b_{0k}+b_{1k}z^{-1}+b_{2k}z^{-2})</script><p>其中$M_s=[(M+1)/2]$,向下取整。$b_{1k}$表示第$k$个多项式的第1项系数，以此类推。<br>那么有Z域下系统输入输出关系为：  </p><script type="math/tex; mode=display">Y(z)=(b_{01}+b_{11}z^{-1}+b_{21}z^{-2})...(b_{0M_s}+b_{1M_s}z^{-1}+b_{2M_s}z^{-2})X(z)</script><p>回到时域，得到此时系统的差分方程为：  </p><script type="math/tex; mode=display">y[n]=(b_{01}x[n]+b_{11}x[n-1]+b_{21}x[n-2])*...*(b_{0M_s}x[n]+b_{1M_s}x[n-1]+b_{2M_s}x[n-2])</script><p>差分方程中卷积的实际意义是当前的节点（指某个卷积号）上携带此前所有节点的信息：<br>令$w_1[n]=b_{01}x[n]+b_{11}x[n-1]+b_{21}x[n-2]$为初始节点，有：  </p><script type="math/tex; mode=display">w_2=b_{02}w_1[n]+b_{12}w_1[n-1]+b_{22}w_1[n-2]</script><script type="math/tex; mode=display">w_3=b_{03}w_2[n]+b_{13}w_2[n-1]+b_{23}w_2[n-2]</script><script type="math/tex; mode=display">...</script><p>以此类推。<br>级联型结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125170748.png width=80%></p><h4 id="硬件消耗-1"><a href="#硬件消耗-1" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>在这个模块中，需要：  </p><ul><li>M个时延单元</li><li>$\frac{3}{2}M$个乘法单元</li><li>M个加法单元</li></ul><p>如果将$b_0k$做归一化处理，此时系统方程为：  </p><script type="math/tex; mode=display">y[n]=(1+b'_{01}x[n]+b'_{11}x[n-1]+b'_{21}x[n-2])*...*(1+b'_{0M_s}x[n]+b'_{1M_s}x[n-1]+b'_{2M_s}x[n-2])</script><p>那么每一个模块的第一项不再需要做乘法：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125172005.png width=80%>  </p><p>乘法单元数将减少到M+1.  </p><p>该结构的优点是便于控制零点，缺点是所需系数较多，因此所需的乘法单元竖线较多。  </p><h2 id="IIR系统的物理结构类型"><a href="#IIR系统的物理结构类型" class="headerlink" title="IIR系统的物理结构类型"></a>IIR系统的物理结构类型</h2><p>描述IIR系统的差分方程可以表示为：  </p><script type="math/tex; mode=display">y[n]=∑_{k=0}^Mb_kx[n-k]+∑_{k=1}^Na_ky[n-k]</script><p>描述IIR系统的差分方程中除了$y[n]$外还有其他的含$y$项，即$y[n-m]$。因此IIR系统的物理结构中含有反馈信号。  </p><h3 id="直接型-直接型I"><a href="#直接型-直接型I" class="headerlink" title="直接型/直接型I"></a>直接型/直接型I</h3><p>描述IIR系统的差分方程在z域上可以表示为：  </p><script type="math/tex; mode=display">Y(z)=H(z)X(z)=(∑_{k=0}^Mb_kz^{-k})\frac{1}{1-∑_{k=1}^Na_kz^{-k}}X(z)</script><p>设$H_1(z)=∑_{k=0}^Mb_kz^{-k}$,$H_2=\frac{1}{1-∑_{k=1}^Na_kz^{-k}}$。<br>可以发现$H_1(z)$没有极点，是FIR系统，$H_2(z)$是IIR系统。<br>在直接型I中，$X(z)$首先与$H_1(z)$结合，有：  </p><script type="math/tex; mode=display">V(z)=H_1(z)X(z)</script><script type="math/tex; mode=display">Y(z)=V(z)H_2(z)</script><p>在时域中，直接型I将系统的差分方程分解为了两部分：  </p><script type="math/tex; mode=display">y[n]=v[n]+∑_{k=1}^Na_ky[n-k]</script><script type="math/tex; mode=display">v[n]=∑_{k=0}^Mb_kx[n-k]</script><blockquote><p>可以看出$y[n]$是IIR系统，$v[n]$是一个FIR系统。  </p></blockquote><p>直接型I的结构如下图所示，输入信号$x[n]$在通过若干个延迟器后的结果赋权相加，然后将此结果与输出信号$y[n]$的反馈信号通过若干个延迟器后的结果赋权相加，得到现态输出$y[n]$的结果。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127131242.png width=50%>  </p><h4 id="硬件消耗-2"><a href="#硬件消耗-2" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>直接型I需要：  </p><ul><li>M+N个加法单元</li><li>M+N+1个乘法单元</li><li>M+N+1个时延单元</li></ul><p>直接型I的优点是搭建简单，整个信号流图基本按照公式原本的样子即可搭建。缺点是所需要的硬件消耗较大。  </p><h3 id="标准型-直接型II"><a href="#标准型-直接型II" class="headerlink" title="标准型/直接型II"></a>标准型/直接型II</h3><p>由，</p><script type="math/tex; mode=display">Y(z)=H_1(z)H_2(z)X(z)=(∑_{k=0}^Mb_kz^{-k})\frac{1}{1-∑_{k=1}^Na_kz^{-k}}X(z)</script><p>在直接型II中，$X(z)$首先与$H_2(z)$结合：  </p><script type="math/tex; mode=display">W(z)=X(z)H_2(z)</script><script type="math/tex; mode=display">Y(z)=W(z)H_1(z)</script><p>在时域中表示为：  </p><script type="math/tex; mode=display">w[n]=∑_{k=1}^Na_kw[n-k]+x[n]</script><script type="math/tex; mode=display">y[n]=∑_{k=0}^Mb_kw[n-k]</script><p>因此，虽然同直接型I，$x[n]$信号也是通过若干延迟器后赋权相加，但是此时的权重不再是$b_N$而应当为$a_N$。赋权后的信号进入另一组延迟器后赋权$b_N$相加。<br>下图表示了$M=N$时标准型II的结构：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127134905.png width=70%>  </p><p>进一步化简，由于两组延迟器存储的内容都是$w[n-k]$，因此两路信号可以共用一组延迟器，进而大幅度减小延迟器的消耗：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127135151.png width=70%>  </p><h4 id="硬件消耗-3"><a href="#硬件消耗-3" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>直接型II需要：</p><ul><li>M+N个加法单元</li><li>M+N+1个乘法单元</li><li>max(M,N)个时延单元</li></ul><p>相比于直接型I，直接型II大幅度减少了时延单元的消耗。   </p><h3 id="级联型-1"><a href="#级联型-1" class="headerlink" title="级联型"></a>级联型</h3><p>IIR系统的级联型原理与FIR系统的级联型原理相同，都是在Z域内把一个多项式分解为多个多项式的乘积。</p><script type="math/tex; mode=display">H(z)=G∏_{k=1}^{N_s}\frac{1+b'_{1k}z^{-1}+b'_{2k}z^{-2}}{1-a'_{1k}z^{-1}-a'_{2k}z^{-2}}</script><p>其中$N_s=\frac{N+1}{2}$<br>但是IIR系统中每一个二级多项式单元$\frac{1+b’_{1k}z^{-1}+b’_{2k}z^{-2}}{1-a’_{1k}z^{-1}-a’_{2k}z^{-2}}$可以选择用直接型I或者直接型II实现，但是通常仍然选择使用直接型II以节省时延单元的使用个数。  </p><p>级联型的结构图如下所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127141419.png width=70%></p><h4 id="硬件消耗-4"><a href="#硬件消耗-4" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>当$M=N$时，级联型需要：  </p><ul><li>$4\frac{(N+1)}{2}$个加法单元</li><li>$4\frac{(N+1)}{2}+1$个乘法单元</li><li>$2N_s$个时延单元</li></ul><p>相比于直接型，级联型结构中每一个子系统单元都是独立运行的，因此系统鲁棒性优于普通型。  </p><h3 id="并联型"><a href="#并联型" class="headerlink" title="并联型"></a>并联型</h3><p>由z域下系统频率响应可以通过提取常数改写为：  </p><script type="math/tex; mode=display">H(z)=∑_{k=0}^{N_p}C_kz^{-k}+∑_{k=1}^{N_s}\frac{e_{0k}+e_{1k}z^{-1}}{1-a_{1k}z^{-1}-a_{2k}z^{-2}}</script><p>其中$M≥N$时（即$H(z)$是假分数时）存在第一项，$C_k$为常数，$N_p=M-N$。$N_S=\frac{N+1}{2}$。<br>由于其后的求和符号，每一个二级多项式分式都可以独立计算，从而实现并行化。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127143607.png width=60%>  </p><h4 id="硬件消耗-5"><a href="#硬件消耗-5" class="headerlink" title="硬件消耗"></a>硬件消耗</h4><p>当$M=N$时，级联型需要：  </p><ul><li>$4\frac{(N+1)}{2}$个加法单元</li><li>$3\frac{(N+1)}{2}+1$个乘法单元</li><li>$2N_s$个时延单元</li></ul><h2 id="FIR和IIR的物理结构类型的特点"><a href="#FIR和IIR的物理结构类型的特点" class="headerlink" title="FIR和IIR的物理结构类型的特点"></a>FIR和IIR的物理结构类型的特点</h2><ul><li>当$h[n]$是一个对称或者反对称序列时，直接型的计算复杂度可以被减少。  </li><li>级联型和并联型系统的鲁棒性高于直接型。  </li><li>相比于FIR滤波器，IIR滤波器对量化噪声更敏感。  </li><li>级联型和并联型系统中的每一个子系统的运行情况相比于直接型更容易被观察。  </li></ul><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211127150608.png width=80%></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12. 数字带通系统的调制解调方法</title>
    <link href="/2021/11/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/12.%20%E6%95%B0%E5%AD%97%E5%B8%A6%E9%80%9A%E4%BF%A1%E5%8F%B7%E4%BC%A0%E8%BE%93/"/>
    <url>/2021/11/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/12.%20%E6%95%B0%E5%AD%97%E5%B8%A6%E9%80%9A%E4%BF%A1%E5%8F%B7%E4%BC%A0%E8%BE%93/</url>
    
    <content type="html"><![CDATA[<h1 id="数字带通系统的调制解调方法"><a href="#数字带通系统的调制解调方法" class="headerlink" title="数字带通系统的调制解调方法"></a>数字带通系统的调制解调方法</h1><h2 id="数字带通系统简述"><a href="#数字带通系统简述" class="headerlink" title="数字带通系统简述"></a>数字带通系统简述</h2><p>数字带通传输系统是将数字基带信号通过载波调制，进入信道，最后在发射端解调，然后通过抽样判决器还原数字信号的过程。数字带通系统主要应用于无线传输，其结构如下图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211118084917.png width=60%>  </p><p>PCM信号在经过数字基带系统之后生成数字基带系统的输入信号$S(t)$，输入信号与载波$c(t)$相乘进行调制。在信道中，存在加性高斯白噪声$n(t)$。在接收端，经过带通滤波器后，噪声的频谱收到限制，转变为窄带噪声$n_R(t)$。信号进行相干解调或者非相干解调（包络检波法），通过低通滤波器过滤出高频分量，最后在抽样判决器处还原为数字信号$m(t)$。  </p><h2 id="2ASK"><a href="#2ASK" class="headerlink" title="2ASK"></a>2ASK</h2><p>2ASK(Binary amplitude shift keying)是一种针对数字信号的调幅方法。  </p><h3 id="调制方法"><a href="#调制方法" class="headerlink" title="调制方法"></a>调制方法</h3><p>进入调制模块的输入信号由两部分组成：周期方波脉冲信号$g(t-nT_s)$和需要传输的信息$a_n=\begin{cases}<br>    1,以概率P\\<br>    0,以概率1-P\\<br>\end{cases}$整个信号表达为：$S(t)=∑_na_ng(t-nT_s)$。<br>该信号与载波$cosω_ct$相乘，得到$S_{2ASK}(t)=[∑_na_ng(t-nT_s)]cosω_ct$，其等价表达为：  </p><script type="math/tex; mode=display">S_{2ASK}(t)=\begin{cases}    cosω_ct,以概率P\\    0,以概率1-P\\\end{cases}</script><h3 id="物理实现"><a href="#物理实现" class="headerlink" title="物理实现"></a>物理实现</h3><p>2ASK调制的实现有两种:  </p><ol><li>模拟调制，载波和信号通过乘法器实现。  </li><li>键控法：原来的数字信号作为数字开关的控制信号，控制数字开关的开闭时间。数字开关的两个输入信号一个接地，即零信号，另一个输入接入载波信号$cosω_0t$。在原信号为“1”的时刻，数字开关打开，输出载波波形，在原信号为“0”的时刻，数字开关关闭，不输出任何信号。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211118091332.png width=50%></li></ol><h3 id="波形分析和频谱分析"><a href="#波形分析和频谱分析" class="headerlink" title="波形分析和频谱分析"></a>波形分析和频谱分析</h3><p>整个调制过程的波形如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211118090537.png width=60%>  </p><p>波形中每一个码元中载波的数量$N_c$与载波周期与码元周期之比有关：  </p><script type="math/tex; mode=display">N_c=\frac{T_s}{T_c}=\frac{f_s}{R_B}</script><p>对$S(t)$和载波信号的功率时间表达做傅里叶变换后相乘，得到2ASK信号的频谱表达式：  </p><script type="math/tex; mode=display">P_{2ASK}(f)=\frac{T_S}{16}\{Sa^2[π(f+f_c)T_s]+Sa^2[(f-f_c)T_s]\}+\frac{1}{16}[δ(f+f_c)+δ(f-f_c)]</script><p>其中：  </p><ul><li>$\frac{T_S}{16}\{Sa^2[π(f+f_c)T_s]+Sa^2[(f-f_c)T_s]\}$:连续信号，根据$cosω_ct$的采样性质，2ASK的频谱实际上是$s(t)$的频谱频域左右侧各复制一次，且幅度减半之后的结果。  </li><li>$\frac{1}{16}[δ(f+f_c)+δ(f-f_c)]$：离散信号，用于提取定时脉冲。  </li></ul><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211118100000.png width=60%>  </p><p>由于$cosω_ct$的采样性质，同时观察频谱可以得到，2ASK的频谱带宽是基带信号带宽的2倍：  </p><script type="math/tex; mode=display">B_{2ASK}=2B_s</script><p>带宽利用效率为：  </p><script type="math/tex; mode=display">η=\frac{R_B}{B_{2ASK}}</script><p>当基带信号为不归零码、没有码间串扰、且基带系统中使用理想低通滤波器时：$B_s=2R_B=2f_s$。<br>此时带宽利用效率为$η=\frac{R_B}{B_{2ASK}}=0.5b/s.Hz$。  </p><h3 id="解调方法"><a href="#解调方法" class="headerlink" title="解调方法"></a>解调方法</h3><p>2ASK的解调可以有两种方法：相干解调和非相干解调（包络检波法）。  </p><h4 id="相干解调"><a href="#相干解调" class="headerlink" title="相干解调"></a>相干解调</h4><p>同模拟信号调幅的解调，在接收端信号与另个同频同相的载波信号$cosω_ct$相乘得到：  </p><script type="math/tex; mode=display">S(t)cos^2ω_ct=S(t)\frac{1}{2}(1+cos2ω_ct)</script><p>由上述式子可以发现：  </p><ol><li>在与相干波形相乘后，原信号的极性被移除。  </li><li>相乘后的波形由直流分量和时变波形两部分组成。  </li></ol><p>因此，使用低通滤波器只保留直流分量，最终通过抽样判决器输出数字信号。<br>抽样判决器的最佳判决门限应该为$\frac{a}{2}$。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122205046.png width=50%>  </p><h4 id="非相干解调（包络检波法）"><a href="#非相干解调（包络检波法）" class="headerlink" title="非相干解调（包络检波法）"></a>非相干解调（包络检波法）</h4><p>另一种去除信号极性的方式是使用全波整流器输出信号的绝对值波形，然后使用低通滤波器过滤高频分量，最终通过抽样判决器输出数字信号。<br>非相干解调过程如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122205159.png width=50%></p><h2 id="FSK"><a href="#FSK" class="headerlink" title="FSK"></a>FSK</h2><h3 id="调制方法-1"><a href="#调制方法-1" class="headerlink" title="调制方法"></a>调制方法</h3><p>FSK使用两个不同频率的载波$cos(ω_1t)$、$cos(ω_2t)$来表示数字信号“1”和“0”。<br>假设原信号以$a_n$表示（表达式和之前的相同），$\overline{a_n}$表示其取反后的数字信号，那么原信号经过调制后的波形表示为：  </p><script type="math/tex; mode=display">S_{FSK}=[∑_na_ng(t-nT_s)]cos(ω_1t)+[∑_n\overline{a_n}g(t-nT_s)]cos(ω_2t)</script><p>从上式可以看出FSK其实是两个频率不同的ASK信号的叠加。  </p><h3 id="物理实现-1"><a href="#物理实现-1" class="headerlink" title="物理实现"></a>物理实现</h3><p>FSK调制的实现有两种:  </p><ol><li><p>模拟调制：两个波形完全相反的信号各通过模拟调制乘上不同频率的载波后相加。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122210724.png width=50%>  </p></li><li><p>键控法：原信号作为一个数字开关的控制信号的同时，其反相信号作为另一个数字开关的控制信号，两个数字开关在打开时分别输出$cosω_1t$与$cosω_2t$的波形。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122211148.png width=50%>  </p></li></ol><h3 id="波形和频谱分析"><a href="#波形和频谱分析" class="headerlink" title="波形和频谱分析"></a>波形和频谱分析</h3><p>整个调制过程的波形如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122211340.png width=50%>  </p><p>其频谱函数表达为：  </p><script type="math/tex; mode=display">P_{2FSK}(f)=\frac{T_s}{16}[Sa^2[π(f+f_1)T_s]+Sa^2[π(f-f_1)T_s]+Sa^2[π(f+f_2)T_s]+Sa^2[π(f-f_2)T_s]]+\frac{1}{16}[δ(f+f_1)+δ(f-f_1)+δ(f+f_2)+δ(f-f_2)]</script><p>其中：  </p><ul><li>$Sa^2[π(f+f_1)T_s]+Sa^2[π(f-f_1)T_s]$：以$f_1$为中心的连续谱分量，根据$cosω_ct$的采样性质, 其带宽为$B_s$。</li><li>$Sa^2[π(f+f_2)T_s]+Sa^2[π(f-f_2)T_s]$：以$f_2$为中心的连续谱分量,其带宽为$B_s$。</li><li>$δ(f+f_1)+δ(f-f_1)$：以$f_1$为中心的冲激分量</li><li>$δ(f+f_2)+δ(f-f_2)$：以$f_2$为中心的冲激分量</li></ul><p>可以发现，受调信号的频谱与$f_1$和$f_2$的大小有关,当且仅当$|f_2-f_1|≥2f_s$时，两个连续谱分量能够完全分离。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211122212634.png width=50%><br>受调信号的带宽表示为：  </p><script type="math/tex; mode=display">B_{2FSK}=2B_S+|f_2-f_1|</script><h3 id="解调方法-1"><a href="#解调方法-1" class="headerlink" title="解调方法"></a>解调方法</h3><h4 id="相干解调-1"><a href="#相干解调-1" class="headerlink" title="相干解调"></a>相干解调</h4><p>在接收端，FSK信号$S_{2FSK}(t)$分为两路，各通过一个带通滤波器，只过滤出$f_1$或者$f_2$的频谱分量，每一路信号在通过带通滤波器之后与对应的同频同向的载波信号相乘去除极性，通过低通滤波器过滤掉高频分量后，送入抽样判决器进行判决。<br>只有在$f_1$和$f_2$的连续谱分量完全分离时，带通滤波器才能准确提取出对应频率的分量，因此相干解调只适用于$|f_1-f_2|≥2f_s$的情况。<br>抽样判决器的判决标准是两路信号在同一个码元周期$T_s$内的电平大小进行比较，哪路信号的电平高，则数字信号的值就为这一路所代表的逻辑值。因此，相干解调不需要设置判决门限。  </p><blockquote><p>虽然对2FSK信号仍然可以通过带通滤波器提取其中一个频率的连续谱分量，使用ASK的解调方式进行解调。但是在M-FSK（即进制数不再为二进制时）信号的解调中无法单独使用某一路信号来还原全部数字信号，因此这种方法并不通用。  </p></blockquote><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211123130813.png width=70%>  </p><h4 id="非相干解调（包络检波法）-1"><a href="#非相干解调（包络检波法）-1" class="headerlink" title="非相干解调（包络检波法）"></a>非相干解调（包络检波法）</h4><p>非相干解调的过程和相干解调基本相同，只不过每一路信号采用包络检波法取代与载波相乘。<br>由于仍然需要带通滤波器分别提取两路信号的频谱分量，因此非相干解调也只适用于$|f_1-f_2|≥2f_s$的情况。<br>抽样判决的过程和相干解调相同，也不需要设置判决门限。  </p><h4 id="过零检波法"><a href="#过零检波法" class="headerlink" title="过零检波法"></a>过零检波法</h4><p>非相干解调和相干解调都只适用于$|f_1-f_2|≥2f_s$的情况，而过零检波法没有这样的条件限制。<br>在波形图上波形过0的次数越多代表码元周期内的频率越高，过零检波法的基本思路是用码元周期内平均幅度的大小来表示频率的高低。<br>过零检波法的具体过程是：FSK信号首先通过限制幅度将正弦波转变为方波，方波通过微分器后变为脉冲信号，经过整流器去除极性后，再用宽脉冲发生器依据脉冲信号重新生成无极性的方波信号。  </p><blockquote><p>宽脉冲发生器的作用是扩大码元周期之间符号持续时间的差异，这个差异在信号通过低通滤波器后会转变成直流分量幅值的差异。  </p></blockquote><p>方波信号会通过低通滤波器，低通滤波器只会允许低频分量（在此看做只有直流分量可以通过）通过滤波器，在单个码元周期中，方波脉冲的个数越多，代表其平均幅度越大，根据直流分量代表波形中的平均幅度可知，其直流分量也会更大。因此原波形中高频的部分通过低通滤波器之后的直流分量更大，低频部分通过低通滤波器后的直流分量更小。  </p><blockquote><p>方波脉冲信号的直流分量：$\frac{1}{T_s}∑τ_iA_i,τ_i$为周期内第$i$个方波脉冲的持续时间。  </p></blockquote><p>最后信号通过抽样判决器，抽样判决器的最佳判决门限为$\frac{a}{2}$。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211123133627.png width=50%>  </p><h2 id="PSK"><a href="#PSK" class="headerlink" title="PSK"></a>PSK</h2><h3 id="调制方法-2"><a href="#调制方法-2" class="headerlink" title="调制方法"></a>调制方法</h3><p>PSK对数字信号的相位进行调制，其使用两个相位不同的载波（通常相位差为$π$）$Acosω_Ct$、$Acos(ω_ct+π)$来表达逻辑“1”和“0”。  </p><script type="math/tex; mode=display">S_{2PSK}=\begin{cases}   Acosω_Ct \text{ 表示"1"}\\   Acos(ω_Ct+π) \text{ 表示"0"}\end{cases}=\begin{cases}   Acosω_Ct \text{ 表示"1"}\\   -Acos(ω_Ct) \text{ 表示"0"}\end{cases}</script><p>从表达式上可以看出，PSK将原信息$a_n$由单极性码转变为双极性码：$a_n=\begin{cases}<br>   +1 \text{ 以概率P表示“1”}\\<br>   -1 \text{ 以概率P表示“0”}<br>\end{cases}$，再与载波相乘。因此可以将PSK看做是双极性码的ASK。  </p><h3 id="物理实现-2"><a href="#物理实现-2" class="headerlink" title="物理实现"></a>物理实现</h3><p>物理实现的方法有两种：  </p><ol><li>模拟调制：将单极性码通过码型变换模块转为双极性码，再与载波相乘。  </li><li>键控法：数字开关的两个输入端一个为$cosω_ct$，其通过相移模块相移$π$后成为数字开关的第二个输入信号，数字开关以$S(t)$作为控制信号。  </li></ol><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125132110.png width=30%>  </p><h3 id="波形和频谱分析-1"><a href="#波形和频谱分析-1" class="headerlink" title="波形和频谱分析"></a>波形和频谱分析</h3><p>PSK信号的波形可以表示为：</p><script type="math/tex; mode=display">S_{2PSK}(t)=∑_na_ng(t-nT_s)cosω_ct</script><p>其中$a_n$是双极性码。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125133034.png width=50%>  </p><p>PSK的功率谱表达式为：  </p><script type="math/tex; mode=display">P_{2PSK}(f)=\frac{T_s}{4}\{Sa^2[π(f+f_c)T_s]+Sa^2[π(f-f_c)T_s]\}</script><p>可以发现，PSK的功率谱表达式实则为ASK功率谱中的连续分量。由于$a_n$是双极性码，因此功率谱中不含有离散的冲激分量。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125134908.png width=70%>  </p><p>PSK信号的带宽：  </p><script type="math/tex; mode=display">B_{2PSK}=2B_s</script><h3 id="解调方法-2"><a href="#解调方法-2" class="headerlink" title="解调方法"></a>解调方法</h3><h4 id="相干解调-2"><a href="#相干解调-2" class="headerlink" title="相干解调"></a>相干解调</h4><p>由于PSK信号通过全波整流器后各个码元周期内的信号完全相同，无法辨认“0”或“1”，因此PSK信号不能使用非相干解调，只能使用相干解调。<br>在相干解调中，PSK信号通过带通滤波器后和同频同向的载波相乘，表示“-1”的波形与载波相乘，得到的波形会完全在小于0的一侧，表示“1”的波形与载波相乘，得到的波形会完全在大于0的一侧。信号通过低通滤波器消除高频分量后送入抽样判决器进行判别。抽样判决器的最佳判决门限为0。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125141819.png width=60%></p><h2 id="DPSK"><a href="#DPSK" class="headerlink" title="DPSK"></a>DPSK</h2><h3 id="调制方法-3"><a href="#调制方法-3" class="headerlink" title="调制方法"></a>调制方法</h3><p>传统的PSK在解调过程中需要依赖未调制载波$cosω_ct$的相位，如果载波相位发生，则反转，调制结果会随之发生反转，这种现象称为倒π现象。为了解决倒π现象，DPSK（相对相移键控）选择使用相对码来取代PSK中使用的绝对码，以使得解调结果不依赖$cosω_ct$的相位。<br>DPSK的具体做法是:假设$b_n$为$a_n$的差分码，有：</p><script type="math/tex; mode=display">b_n=a_n⊕b_{n-1}</script><p>即当前差分码$b_n$是前一个差分码$b_{n-1}$与当前绝对码$a_n$的模二加法（异或）结果。<br>再将差分码做PSK调制即可。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125144556.png width=50%></p><h3 id="物理实现-3"><a href="#物理实现-3" class="headerlink" title="物理实现"></a>物理实现</h3><p>DPSK中差分和PSK调制的顺序可以倒换：  </p><ol><li>先求得码型的差分码$b_n$，再做PSK调制。  </li><li>先对码型做PSK调制，再将波形进行差分处理。<br>生成波形也同样可以采用键控和模拟调制两种方法。  </li></ol><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125144704.png width=60%></p><h3 id="解调方法-3"><a href="#解调方法-3" class="headerlink" title="解调方法"></a>解调方法</h3><h4 id="相干解调-3"><a href="#相干解调-3" class="headerlink" title="相干解调"></a>相干解调</h4><p>同PSK相干解调</p><h4 id="非相干解调（相位比较法-差分相干解调）"><a href="#非相干解调（相位比较法-差分相干解调）" class="headerlink" title="非相干解调（相位比较法/差分相干解调）"></a>非相干解调（相位比较法/差分相干解调）</h4><p>除了使用同频同相的载波与DPSK信号相乘外，还可以使用延时一个码元周期的原DPSK信号与自身信号相乘，两者都能够达到“表示-1的波形与载波相乘，得到的波形会完全在小于0的一侧，表示1的波形与载波相乘，得到的波形会完全在大于0的一侧。”的效果。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211125145153.png width=50%>  </p><p>由于延迟模块比产生载波的振荡器价格更便宜，因此相位比较法在实际中的应用更为广泛。但是相位比较法的误码率高于相干解调。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">调制方式</th><th style="text-align:center">受调信号的码型</th><th style="text-align:center">受调信号的带宽</th><th style="text-align:center">解调方法</th><th style="text-align:center">解调的最佳判决门限</th></tr></thead><tbody><tr><td style="text-align:center">ASK</td><td style="text-align:center">单极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调<br>包络检波法</td><td style="text-align:center">$\frac{a}{2}$</td></tr><tr><td style="text-align:center">FSK</td><td style="text-align:center">单极性码</td><td style="text-align:center">$\lvert f_1-f_2\rvert +2B_s$</td><td style="text-align:center">相干解调<br>包络检波法<br>过零检波法<br></td><td style="text-align:center">无<br>无<br>$\frac{a}{2}$</td></tr><tr><td style="text-align:center">PSK</td><td style="text-align:center">双极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调</td><td style="text-align:center">0</td></tr><tr><td style="text-align:center">DPSK</td><td style="text-align:center">双极性码</td><td style="text-align:center">$2B_s$</td><td style="text-align:center">相干解调<br>相位比较法</td><td style="text-align:center">0</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8. 晶体管的交流工作分析</title>
    <link href="/2021/11/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/8.%20BJT%20models/"/>
    <url>/2021/11/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/8.%20BJT%20models/</url>
    
    <content type="html"><![CDATA[<h1 id="晶体管的交流工作分析"><a href="#晶体管的交流工作分析" class="headerlink" title="晶体管的交流工作分析"></a>晶体管的交流工作分析</h1><h2 id="交流工作下的基极偏置"><a href="#交流工作下的基极偏置" class="headerlink" title="交流工作下的基极偏置"></a>交流工作下的基极偏置</h2><h3 id="耦合电容"><a href="#耦合电容" class="headerlink" title="耦合电容"></a>耦合电容</h3><p>在交流状态下工作的电容器称为耦合电容，耦合电容的特性可以用一句话总结：耦合电容会阻碍直流分量并允许交流分量通过，即“隔直流，通交流”。<br>根据电容的容抗计算公式：$X_c=\frac{1}{2πfc}$<br>当直流分量通过电容时，电容的容抗会非常的大，电容视为断路。<br>当交流分量通过电容时，如果频率非常的高，则电容视为短路。一般认为$X_c&lt;0.1R$（$R$为电路中的总电阻值）时，电容就视为短路。<br>在晶体管电路中，耦合电容的作用是阻止交流源电压源和输出电阻改变晶体管的静态工作点。</p><h3 id="基极偏置电路分析"><a href="#基极偏置电路分析" class="headerlink" title="基极偏置电路分析"></a>基极偏置电路分析</h3><p>交流下的基极偏置电路如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113163113.png width=60%>  </p><p>电路特点：</p><ul><li>在输入端（基极）和输出端（集电极）各有一个耦合电容。   </li><li>输入电压（即基极处的电源）$v_{bb}$是一个交流信号，不含有直流分量。  </li><li>供电电压$V_{CC}$是一个直流信号，不含有交流分量。  </li></ul><p>当晶体管的基极和集电极存在耦合电容时，基极端的交流电源和输出端的输出电阻对晶体管的工作状态不会有任何的影响。<br>电路中所有的电流都可以分解为直流分量和交流分量两部分：  </p><script type="math/tex; mode=display">i_B=I_B+i_b</script><p><strong>晶体管只会改变电路中电流的直流分量，交流分量保持不变。</strong><br>因此，交流状态下的基极偏置<strong>只需要按照对应静态工作点计算出直流分量的值，在加上或减去交流分量即可。</strong>  </p><blockquote><p>需要注意的是由于$v_C=V_{CC}-i_CR_c-V_{CE}$，因此$v_C$的波形与$i_C$应当是<strong>反相</strong>的。由于$i_C=βi_B$，因此$i_B$的波形与$i_C$<strong>同相</strong>。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113162613.png width=50%>  </p></blockquote><p>同时，由于耦合电容的特性，输出端的耦合电容会将直流分量完全去除，<strong>最终在输出电阻$R_L$上的电压/电流没有直流分量</strong>。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113162834.png width=60%>  </p><h2 id="大信号模型"><a href="#大信号模型" class="headerlink" title="大信号模型"></a>大信号模型</h2><p>晶体管的大小信号模型针对基极的输入电压含有直流分量和交流分量时的电路进行分析。基极输入电压信号幅值较大时的电路分析模型称为大信号模型。<br>在大信号模型下，$v_{BE}$与$i_C$是非线性关系，两者之间满足：  </p><script type="math/tex; mode=display">i_C=I_Se^{\frac{v_{BE}}{V_T}}</script><p>其中$I_S$是$I_C$的饱和电流，$V_T$是晶体管在CB两点间存在温差而出现的电位差（热电压），在室温下约为25.9mV。<br>根据上述关系，可以将集电极的等效二极管近似看做是一个电压控制电流源，发射极的等效二极管保持不变：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113164129.png width=30%>  </p><p>同时，希望在CE出导出输出电压，得到一个电压放大器（小的输出电压$v_{BE}$放大为$v_{CE}$），因此在集电极处加入一个电阻$R_C$。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113164622.png width=30%>  </p><p>那么，在大信号模型电路中输出电压$v_{CE}$与输入电压$v_{BE}$的关系如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113164828.png width=50%>  </p><p>在大信号模型下，$v_{BE}$很容易超出激活模式区域，进入饱和工作状态，导致电路出现非线性失真。  </p><h2 id="小信号模型"><a href="#小信号模型" class="headerlink" title="小信号模型"></a>小信号模型</h2><p>基极输入电压的$v_{BE}$比较小，正好处于激活模式下时电路分析模型称为小信号模型。在小信号模型中，可以近似将$v_{BE}$与$v_{CE}$的关系视为线性，即将整个晶体管的工作状态视作直流工作状态。<br>小信号模型可以看做是大信号模型在激活模式下的表现。  </p><h3 id="电压变换特性"><a href="#电压变换特性" class="headerlink" title="电压变换特性"></a>电压变换特性</h3><p>输入电压$v_{BE}$必须控制在一个小电压范围内，才能使晶体管的工作状态处于激活模式。在激活模式下：</p><script type="math/tex; mode=display">\begin{aligned}v_{CE}=&V_{CC}-R_Ci_C\\    =&V_{CC}-R_CI_Se^{\frac{v_{BE}}{V_T}}\end{aligned}</script><p>通过上述公式可知，$v_{CE}$的波形与$v_{BE}$<strong>反相</strong>。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113165310.png width=50%>  </p><p>当$v_{BE}=V_{BE}$时，说明输入电压仅含直流分量，此时晶体管处于静态工作点。在该点对其求斜率得到（等效电压放大器的）直流电压增益：  </p><script type="math/tex; mode=display">A_v=\frac{dv_{CE}}{dv_{BE}}|_{v_{BE}=V_{BE}}</script><p>带入$i_C$的表达式，有：  </p><script type="math/tex; mode=display">A_v=-\frac{I_C}{V_T}R_C=-\frac{V_{CC}-V_{CE}}{V_T}</script><p>可以发现，在激活模式下，$V_{CE}$越低，直流电压增益越大。  </p><h3 id="小信号模型的电流分析"><a href="#小信号模型的电流分析" class="headerlink" title="小信号模型的电流分析"></a>小信号模型的电流分析</h3><p>在小信号模型下，如果将$v_{BE}$视为输入信号、$i_C$视为输出信号，那么放大的结果是将小电压放大为大电流，这样的放大器称为跨导放大器。<br>那么对输出$i_C$引入输入$v_{BE}$进行分析：<br>由于小信号模型是大信号模型的一部分，因此$i_C$的导出式不变：  </p><script type="math/tex; mode=display">i_c=I_Se^{\frac{v_{BE}}{V_T}}</script><p>带入$v_{BE}=V_{BE}+v_{be}$</p><script type="math/tex; mode=display">\begin{aligned}    i_c&=I_Se^{\frac{V_{BE}+v_{be}}{V_T}}\\    &=I_Se^{\frac{V_{BE}}{V_T}}e^{\frac{v_{be}}{V_T}}\end{aligned}</script><p>根据$I_C=I_Se^{\frac{V_{BE}}{V_T}}$，有：  </p><script type="math/tex; mode=display">i_c=I_Ce^{\frac{v_{be}}{V_T}}</script><p>根据泰勒展开式，有：  </p><script type="math/tex; mode=display">i_c=I_C(1+∑_k(\frac{v_{be}}{V_T})^k\frac{1}{k!})</script><p>根据小信号模型的条件，$v_{be}$应当很小，$b_{be}&lt;&lt;V_T$，此时泰勒展开式的高阶项可以全部被忽略，有：  </p><script type="math/tex; mode=display">i_C≈I_C(1+\frac{v_{be}}{V_T})</script><p>带入$i_C=I_C+i_c$:  </p><script type="math/tex; mode=display">i_C=\frac{I_C}{V_T}v_{be}</script><h4 id="跨导"><a href="#跨导" class="headerlink" title="跨导"></a>跨导</h4><p>定义$g_m$为跨导（Transconductance）：  </p><script type="math/tex; mode=display">g_m=\frac{I_C}{V_T}</script><p>有：  </p><script type="math/tex; mode=display">i_C=g_mv_{be}</script><p>跨导也是$i_C-v_{BE}$图中当$i_C=I_C$时的斜率：  </p><script type="math/tex; mode=display">g_m=\frac{di_C}{dv_{BE}}|_{i_C=I_C}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114115547.png width=40%>  </p><h3 id="小信号模型中的直流分量和交流分量"><a href="#小信号模型中的直流分量和交流分量" class="headerlink" title="小信号模型中的直流分量和交流分量"></a>小信号模型中的直流分量和交流分量</h3><p>由于小信号模型满足线性条件，因此电路中的直流分量和交流分量可以完全独立分别计算，然后将计算直流分量的结果与计算交流分量的结果相加。<br>小信号模型中，<strong>直流分量的作用是确定晶体管所处的静态工作点。</strong><br>交流分量的作用是携带信息，因此在小信号模型中更关注交流分量的变化。  </p><h3 id="小信号模型的交流参数"><a href="#小信号模型的交流参数" class="headerlink" title="小信号模型的交流参数"></a>小信号模型的交流参数</h3><p>小信号模型中直流分量的来源为集电极供电$V_{CC}$和基极供电$V_{BE}$，令它们为0（接地）后进行交流分量的等效模型分析。  </p><h4 id="基极电流"><a href="#基极电流" class="headerlink" title="基极电流"></a>基极电流</h4><p>由$i_B=\frac{1}{β}i_C,i_C=g_mv_{be}$:  </p><script type="math/tex; mode=display">i_B=\frac{I_C}{β}+\frac{g_m}{β}v_{be}</script><script type="math/tex; mode=display">i_b=\frac{g_m}{β}v_{be}</script><h4 id="输入阻抗"><a href="#输入阻抗" class="headerlink" title="输入阻抗"></a>输入阻抗</h4><p>定义输入阻抗为输入端电压与电流之比。<br>当发射极接地，信号从基极输入时：</p><script type="math/tex; mode=display">r_π=\frac{v_{be}}{i_b}</script><p>带入$v_{be}$和$i_b$，得到：  </p><script type="math/tex; mode=display">r_π=\frac{V_T}{I_B}=\frac{β}{g_m}</script><p>当基极接地，信号从发射极输入时：  </p><script type="math/tex; mode=display">r_π=\frac{v_{be}}{i_e}</script><p>带入$v_{be}$和$αi_e=i_c$，得到：  </p><script type="math/tex; mode=display">r_e=\frac{V_T}{I_E}=\frac{α}{g_m}</script><p>可以发现输入阻抗$r_π$或$r_e$都不含有交流分量，是一个等效电阻。  </p><h4 id="厄利效应"><a href="#厄利效应" class="headerlink" title="厄利效应"></a>厄利效应</h4><p>厄利效应/基区宽度调制效应(Early Effect)，是指晶体管的$V_{CE}$改变，基极－集电极耗尽层宽度也会跟着改变。集电极电压升高，会使基极层变窄，使集电区或晶体管的输出电流增大。特性曲线中电压较大时的切线进行反向外推，其延长线与电压轴相交，在电压轴上截得的负截距称为厄利电压。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114123021.png width=50%>  </p><p><strong>厄利效应可以等效为一个横跨在$CE$两极、与输出电阻$R_C$并联的电阻。</strong>  </p><script type="math/tex; mode=display">r_o=\frac{V_A}{I_C}</script><h3 id="等效小信号模型"><a href="#等效小信号模型" class="headerlink" title="等效小信号模型"></a>等效小信号模型</h3><h4 id="π模型"><a href="#π模型" class="headerlink" title="π模型"></a>π模型</h4><p><strong>当发射极接地时，信号从基极输入。</strong><br>通过对交流参数的分析，由$r_π=\frac{v_{be}}{i_b}$，可以将基极等效为一个阻值为$r_π$的电阻。而由：$i_C=g_mv_{be}=βi_b$发射极等效为一个电流控制电压源或者$i_b$的电流控制电流源，得到π模型。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114121839.png width=70%><br>考虑厄利效应，有：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114123326.png width=70%>  </p><h4 id="T模型"><a href="#T模型" class="headerlink" title="T模型"></a>T模型</h4><p><strong>当基极接地时，信号从发射极输入。</strong><br>由$r_e=\frac{v_{be}}{i_e}$，可以将发射极等效为一个阻值为$r_e$的电阻。<br>由$i_C=g_mv_{be}=αi_e$可以将发射极等效为一个电流控制电压源或者$i_e$的电流控制电流源，得到T模型。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114124640.png width=50%><br>考虑厄利效应：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211114124920.png width=50%>  </p><p><strong>当E极在等效后没有电阻时，使用π模型进行分析。在等效后有电阻时，使用T模型进行分析。</strong>  </p><h4 id="电阻投射定理-Resistance-Reflection-Rule"><a href="#电阻投射定理-Resistance-Reflection-Rule" class="headerlink" title="电阻投射定理(Resistance Reflection Rule)"></a>电阻投射定理(Resistance Reflection Rule)</h4><p>T模型中发射极的电阻可以通过投射定理与π模型中基极的电阻相互转换。<br>由于：</p><script type="math/tex; mode=display">r_π=r_e(β+1)</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211128160204.png width=50%>  </p><p>因此，发射极的所有电阻值可以乘上$β+1$转为基极的输入电阻的阻值。  </p><script type="math/tex; mode=display">R_B=(β+1)R_E</script><p>应用该定理可以更加灵活地判断电路中放大电路部分输入电阻的阻值。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11. 数字基带系统的抗噪性分析</title>
    <link href="/2021/11/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/11.%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/"/>
    <url>/2021/11/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/11.%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="数字基带系统的抗噪性分析"><a href="#数字基带系统的抗噪性分析" class="headerlink" title="数字基带系统的抗噪性分析"></a>数字基带系统的抗噪性分析</h1><h2 id="抽样判决器"><a href="#抽样判决器" class="headerlink" title="抽样判决器"></a>抽样判决器</h2><p>在接收端，设通过接收端滤波器的信号为$x(t)$，它由传输信息$s(t)$和窄带高斯白噪声$n_R(t)$两部分构成。接下来，信号$x(t)$将通过抽样判决器，抽样判决器以$f_s$的抽样频率对其进行抽样，并对每一个抽样结果进行判断，决定抽样结果为数字逻辑“1”还是逻辑“0”。抽样判决器的工作原理可以表示为：  </p><script type="math/tex; mode=display">m'(kT_s)=\begin{cases}   1, x(kT_s)>V_d\\   0,x(kT_s)<V_d\end{cases}</script><p>$V_d$称为判决阈值。  </p><h2 id="误码率"><a href="#误码率" class="headerlink" title="误码率"></a>误码率</h2><p>数字基带系统在抽样判决器处的判决错误是产生误码率的重要原因，误码率$P_e$可以表示为两个条件概率之和：  </p><script type="math/tex; mode=display">P_e=P(0)P(\frac{1}{0})+P(1)P(\frac{0}{1})</script><p>$P(0)P(\frac{1}{0})$:原本的电平为0，误判为1的概率。<br>$P(1)P(\frac{0}{1})$：原本的电平为1，误判为0的概率。  </p><p>抽样判决器判决错误的主要原因是$x(t)$中包含的窄带高斯白噪声$n_R(t)$对判决结果产生了影响。<br>设$n_R(t)$的方差为$σ_n^2$、均值为0，则其概率密度函数为：  </p><script type="math/tex; mode=display">f(n)=\frac{1}{√(2π)σ_n}e^{-\frac{n^2}{2σ_n^2}}</script><p>并假设$s(t)$在为逻辑“0”的时刻电平为0，在为逻辑“1”的时刻电平对应其幅值$A$，那么$x(kT_s)$可以表示为：  </p><script type="math/tex; mode=display">x(kT_s)=\begin{cases}    A+n_R(kT_s),logic-1\\    n_R(kT_s),logic-0\end{cases}</script><p>那么，在发送逻辑“0”的时刻，$x(kT_s)$只包含$n_R(t)$，发送“0”的概率密度函数为：  </p><script type="math/tex; mode=display">f_0(x)=\frac{1}{√(2π)σ_n}e^{-\frac{n^2}{2σ_n^2}}</script><p>当$x(kT_s)$的值大于$V_d$时，抽样判决器将原本为0的电平$x(kT_s)$误判为1，该概率可以表示为：  </p><script type="math/tex; mode=display">P_{e0}=∫_{V_d}^∞f_0(x)dx=∫_{V_d}^∞\frac{1}{√(2π)σ_n}e^{-\frac{n^2}{2σ_n^2}}dx</script><p>同理可以得到，当$x(kT_s)$的值小于$V_d$时原本抽样判决器原本为1的电平$x(kT_s)$误判为0，该概率可以表示为：  </p><script type="math/tex; mode=display">P_{e1}=∫_∞^{V_d}f_0(x)dx=∫_∞^{V_d}\frac{1}{√(2π)σ_n}e^{-\frac{n^2}{2σ_n^2}}dx</script><p>那么总的误码率就可以表示为：  </p><script type="math/tex; mode=display">P_e=P(0)P_{e0}+P(1)P_{e1}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211112191352.png width=70%>  </p><p>图示中的涂色部分表示误码率的两个条件概率，可以发现，只有当$V_d=\frac{A}{2}$时，“额外的概率”（图中红色部分所示）才能被抵消为0，此时误码率最小，$V_d=\frac{A}{2}$称为优化阈值。<br>在优化阈值下重新计算误码率，可以得到：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(\frac{A}{2√2σ_n})</script><p>$A$与信号的功率有关，$σ_n$与噪声的功率有关。可以发现，在优化阈值下，<strong>影响误码率的唯一因素为信噪比。</strong><br>对于单极性信号，其平均功率为$S=\frac{A^2}{2}$，因此单极性信号的信噪比为：  </p><script type="math/tex; mode=display">SNR_u=\frac{A^2}{2σ^2}</script><p>此时误码率为：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(\frac{√SNR_u}{2})</script><p>对于双极性信号，其平均功率为$S={A^2}$，因此双极性信号的信噪比为：  </p><script type="math/tex; mode=display">SNR_b=\frac{A^2}{σ^2}</script><p>此时误码率为：  </p><script type="math/tex; mode=display">P_e=\frac{1}{2}erfc(√({\frac{SNR_u}{2}}))</script><p>比较两者的误码率，可以发现双极性信号的误码率总是优于单极性信号的误码率。  </p><h2 id="眼图"><a href="#眼图" class="headerlink" title="眼图"></a>眼图</h2><p>眼图是一种能够表现数字基带系统噪声和码间串扰的图像，它由示波器的余晖效应使得若干个$T_s$内的波形在示波器屏幕上叠加得到。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113102645.png width=30%><br>直观通过眼图判断系统抗噪性的指标为：</p><ol><li>眼图是否清晰<ul><li>系统的信噪比越高，眼图越清晰。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113103039.png width=50%></li></ul></li><li>“眼睛”的开闭程度<ul><li>系统的滚降系数越大，“眼睛”张开程度越大。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113103137.png width=50%>  </li></ul></li></ol>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10. 无码间串扰的数字基带系统</title>
    <link href="/2021/11/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/10.%20%E7%A0%81%E9%97%B4%E4%B8%B2%E6%89%B0/"/>
    <url>/2021/11/09/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/10.%20%E7%A0%81%E9%97%B4%E4%B8%B2%E6%89%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="无码间串扰的数字基带系统"><a href="#无码间串扰的数字基带系统" class="headerlink" title="无码间串扰的数字基带系统"></a>无码间串扰的数字基带系统</h1><h2 id="码间串扰的产生"><a href="#码间串扰的产生" class="headerlink" title="码间串扰的产生"></a>码间串扰的产生</h2><p>由于系统的带宽有限，单个字符信号的脉冲发生了失真，使得波形发生延展、含有拖尾，波形延展到其他码元时间间隔中时，会对其他字符的抽样产生干扰，称为码间串扰。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109115908.png width=60%><br>码间串扰与系统的带宽有关，系统的带宽越小，字符脉冲的拖尾就会越长越严重，发生码间串扰的可能性越大。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109120140.png width=80%>  </p><h3 id="码间串扰的数学分析"><a href="#码间串扰的数学分析" class="headerlink" title="码间串扰的数学分析"></a>码间串扰的数学分析</h3><p>数字信号$d(t)=∑a(b)δ(t-nT)$通过信道和接受滤波器后表示为：  </p><script type="math/tex; mode=display">y(t)=d(t)*h(t)+n_R(t)=∑a_nh(t-nT_s)+n_R(t)</script><p>其中$n_R(t)$表示窄带噪声。<br>经过采样周期为$T_s$的采样后：  </p><script type="math/tex; mode=display">y(kT_s+t_0)=∑a_nh(kT_s+t_0-nT_s)+n_R(kT_s+t_0)+a_kh(t_0)</script><p>其中：<br>$a_kh(t_0)$是第$k$个字符采样后波形的主瓣。<br>$a_nh(kT_s+t_0-nT_s)$是采样后波形的拖尾。<br>$n_R(kT_s+t_0)$是采样后的窄带噪声。<br>可以发现，要想消除码间串扰，就要让采样后的波形中不含有$a_nh(kT_s+t_0-nT_s)$一项，即系统的时域方程满足下列等式：  </p><script type="math/tex; mode=display">h(kT_s)=\begin{cases}    Const, k=0 \\    0, k≠0 \text{  除了采样时刻，其余时间波形的采样值为0}\end{cases}</script><p>有两种方式可以使得系统波形满足$a_nh(kT_s+t_0-nT_s)=0$：  </p><ol><li>系统波形正好在$t_0+T_s$时戛然而止  </li><li>系统波形虽然有拖尾，但是拖尾在每一个$t_0+kT_S,k≠0$的时刻为0。  </li></ol><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109133725.png width=80%>  </p><p>方案1无法在现实的电路中完成，因此现实中基本采用方法2来设计无码间串扰的系统。<br>下面推导符合上述条件的系统方程$H(ω)$：<br>根据傅里叶反变换：$h(kT_s)=\frac{1}{2π}∫H(ω)e^{jωkT_s}dω$<br>由于一个采样周期只有一个字符被抽样，因此修改积分上限，提取出一个抽样周期内的频谱函数(称为剪切)：  </p><script type="math/tex; mode=display">h(kT_s)=\frac{1}{2π}∑_i∫_{(2i-1)π/T_s}^{(2i+1)π/T_s}H(ω)e^{jωkT_s}dω</script><p>令$ω’=ω-\frac{2iπ}{T}$（称为时移）,  </p><script type="math/tex; mode=display">\begin{aligned}    h(kT_s)&=\frac{1}{2π}∑_i∫_{-π/T_s}^{π/T_s}H(ω'+\frac{2iπ}{T})e^{jω'kT_s}e^{2πikj}dω'\\    &=\frac{1}{2π}∑_i∫_{-π/T_s}^{π/T_s}H(ω'+\frac{2iπ}{T})e^{jω'kT_s}dω'\\    &=\frac{1}{2π}∫_{-π/T_s}^{π/T_s}∑_iH(ω'+\frac{2iπ}{T})e^{jω'kT_s}dω'\end{aligned}</script><p>剪切、时移、叠加的物理意义如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109150814.png width=70%></p><p>那么就得到了$H(ω)$的等效替代式子：  </p><script type="math/tex; mode=display">H_{eq}(ω)=∑_iH(ω'+\frac{2iπ}{T}),|ω|≤\frac{π}{T_s}</script><p>$H_{eq}(ω)$的物理意义是将切断的各部分平移到$|ω|≤\frac{π}{T_s}$内对应叠加求和，简称切断叠加。<br>那么将该式子带入$h(kT_s)$需要满足的条件中，得到频域中，系统方程等价为：  </p><script type="math/tex; mode=display">H(ω)=\begin{cases}    ∑H(ω+\frac{2πi}{T_s})=T_s, |ω|≤\frac{π}{T_s} \\    0, |ω|>\frac{π}{T_s} \text{  除了采样时刻，其余时间波形的采样值为0}\end{cases}</script><p>即，<strong>当且仅当系统的等效频谱在为一个在$±\frac{π}{T_s}$上的门函数时，这个系统可以满足没有码间串扰，该定律称为奈奎斯特第一定律。</strong>  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109143853.png width=20%>  </p><h3 id="导出结论"><a href="#导出结论" class="headerlink" title="导出结论"></a>导出结论</h3><ul><li>满足奈奎斯特第一定律时，频谱图的带宽称为奈奎斯特带宽$B_N$,$B_N=\frac{1}{2T_s}Hz$。  </li><li>奈奎斯特间隔为：$T_s=\frac{1}{2B_N}$。  </li><li>当采样周期为奈奎斯特间隔的整数倍（$T_s=\frac{Const}{2B_N}$）时，可以使得每次采样时信号拖尾的采样值都为，系统无码间串扰。对应的数据传输速率为：$R_B=\frac{1}{nT_s}$。  </li><li>系统支持的最大的传输速率为$R_{B|max}=\frac{1}{T_s}=2B_N$，当且仅当： <script type="math/tex; mode=display">\frac{R_{B|max}}{R_B}=Const</script>时，系统无码间串扰。  </li><li>由频谱利用率$η=\frac{R_B}{B}$，系统最大的频谱利用率为$η=\frac{2B_N}{B_n}=2$。</li></ul><h2 id="无码间串扰系统"><a href="#无码间串扰系统" class="headerlink" title="无码间串扰系统"></a>无码间串扰系统</h2><p>在频域中，要想使得系统频谱图为一个门函数，有两种方法：  </p><ol><li>理想低通滤波器</li><li>滚降滤波器</li><li>部分响应系统</li></ol><h3 id="理想低通滤波器"><a href="#理想低通滤波器" class="headerlink" title="理想低通滤波器"></a>理想低通滤波器</h3><p>理想低通滤波器的频谱正好是一个门函数：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211112173008.png width=60%>  </p><p>但是，可以从理想低通滤波器系统的频谱和波形图看出：理想低通滤波器有边界陡峭、难以实现、且时域中Sa函数收敛较慢的特点，因此考虑采用其他方法模拟等效理想低通滤波器的频谱。  </p><h3 id="滚降滤波器"><a href="#滚降滤波器" class="headerlink" title="滚降滤波器"></a>滚降滤波器</h3><p>滚降滤波器的基本思路是在理想低通滤波器频谱后加入一段奇对称的频谱，使得被剪切、时移、叠加后的等效频谱中奇对称的一半正好可以填充另一半，得到一个门函数的频谱，这种方法称为滚降。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109153130.png width=30%><br>常常被选用的奇函数为反比例函数和升余弦函数（即余弦函数+常数）：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109153809.png width=50%>  </p><p>设奇对称信号的带宽为$B_2$,那么滚降后的系统带宽为$B_N+B_2$。<br>滚降滤波器的系统方程可以表示为：</p><script type="math/tex; mode=display">H(ω)=\begin{cases}    Const, 0≤ω≤B_N\\    f(ω), B_N≤ω≤B_N+B_2\\    0,ω≥B_N+B_2\end{cases}</script><blockquote><p>根据系统方程可以将滚降系统的频谱分为：非滚降区、滚降区和截止区。  </p></blockquote><p>定义滚降系数$α=\frac{B_2}{B_N}$，那么系统带宽又可以写作：  </p><script type="math/tex; mode=display">B=(1+α)B_N,0≤α≤1</script><p>频谱利用效率为:$η=\frac{2}{1+α}$<br>系统所支持的无码间串扰的最大速率为:$R_{B|max}=2B_N$<br>可以发现，$α$越大，系统带宽就越大，系统有效性下降，但是从频谱图上来看，$α$越大，系统波形拖尾越小，可靠性上升。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109154450.png width=50%>  </p><h4 id="全滚降滤波器"><a href="#全滚降滤波器" class="headerlink" title="全滚降滤波器"></a>全滚降滤波器</h4><p>$α=1$时的滤波器称为全滚降滤波器，全滚降滤波器没有非滚降段，系统方程表示为：  </p><script type="math/tex; mode=display">H(ω)=\begin{cases}    f(ω), 0≤ω≤2B_N\\    0,ω≥2B_N\end{cases}</script><p>此时系统的带宽为$B=2B_N$。  </p><h3 id="部分响应系统"><a href="#部分响应系统" class="headerlink" title="部分响应系统*"></a>部分响应系统*</h3><p>滚降滤波器虽然可以解决理想低通滤波器在实际系统设计中无法应用的问题，但是其频谱效率只有$\frac{2}{1+α}$，不能达到理想低通滤波器$η=2$的效果。部分响应系统通过人为地引入码间串扰来改善这一问题。<br>部分响应系统的基本设想是使用两个波形相同，但是各自时移$\frac{T_s}{2}$的脉冲信号传输一个码元：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211112183659.png width=60%><br>虽然部分响应系统在每一个采样时刻都存在码间串扰，但是这个码间串扰仅由表达一个码元的相邻两个脉冲引起，这个特性使得在接收端可以消除码间串扰。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">系统类型</th><th style="text-align:center">$R_{Bmax}$</th><th style="text-align:center">$B$</th><th style="text-align:center">$η$</th></tr></thead><tbody><tr><td style="text-align:center">理想低通滤波器</td><td style="text-align:center">$2B_N$</td><td style="text-align:center">$B_N$</td><td style="text-align:center">$2$</td></tr><tr><td style="text-align:center">滚降滤波器</td><td style="text-align:center">$2B_N$</td><td style="text-align:center">$(1+α)B_N$</td><td style="text-align:center">$\frac{2}{1+α}$</td></tr><tr><td style="text-align:center">全滚降滤波器</td><td style="text-align:center">$2B_N$</td><td style="text-align:center">$2B_N$</td><td style="text-align:center">$1$</td></tr><tr><td style="text-align:center">部分响应系统</td><td style="text-align:center">$\frac{1}{T_s}$</td><td style="text-align:center">$\frac{1}{2T_s}$</td><td style="text-align:center">$2$</td></tr></tbody></table></div><h2 id="时域均衡"><a href="#时域均衡" class="headerlink" title="时域均衡*"></a>时域均衡*</h2><p>由于信道是时变系统，信道总会使得信号产生码间串扰。解决这一问题的方法是在接收机与接收滤波器之间增加一个均衡器$E_x$，通过均衡使得波形满足奈奎斯特第一定律进而消除码间串扰。均衡的方式有两种：时域均衡和频域均衡。本课只介绍时域均衡。<br>时域均衡的基本思想是在$t+n,n≠0$的时刻对采样信号叠加一个完全相反的冲激信号以抵消原本在采样时刻存在的非零电平，迫使$x(t+nT_s)=0$。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113104051.png width=70%>  </p><p>时域均衡器由若干个延迟器和自动调整权重的抽头以及相加器组成。延迟器的作用是确保获取$x(t)$在每一个$nT_s$上的抽样值，由自动调整权重的抽头赋予冲激信号一个与抽样值完全相反的权重、并与抽样值抵消，得到抽头信号。理论上，抽头信号只会在$x(t)$时有值。最后相加器将所有抽头信号相加，得到满足奈奎斯特第一定律的输出信号。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211113104527.png width=70%></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7. 数字滤波器·数字系统的表示</title>
    <link href="/2021/11/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/7.%20%E6%95%B0%E5%AD%97%E6%BB%A4%E6%B3%A2%E5%99%A8/"/>
    <url>/2021/11/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/7.%20%E6%95%B0%E5%AD%97%E6%BB%A4%E6%B3%A2%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="数字滤波器·数字系统的表示"><a href="#数字滤波器·数字系统的表示" class="headerlink" title="数字滤波器·数字系统的表示"></a>数字滤波器·数字系统的表示</h1><h2 id="数字系统的响应"><a href="#数字系统的响应" class="headerlink" title="数字系统的响应"></a>数字系统的响应</h2><p>数字滤波器是一种处理离散时间信号的系统。数字信号$x[n]$输入数字滤波器进行处理后生成输出信号$y[n]$。这个过程可以用卷积定理表示为：  </p><script type="math/tex; mode=display">y[n]=x[n]⊗h[n]=∑x[m]h[n-m] \tag{1}</script><p>$h[n]$是数字系统在时域上的表示，称为<strong>冲激响应</strong>，也是系统输入信号为冲激序列时系统的输出结果。<br>对(1)做离散时间傅里叶变换，可以得到：  </p><script type="math/tex; mode=display">Y(e^{jω})=X(e^{jω})H(e^{jω}) \tag{2}</script><p>$H(e^{jω})$是$h[n]$做离散时间傅里叶变换的结果，称为系统的<strong>频率响应</strong>。  </p><blockquote><p>可以发现(2)成立的条件中包含$h[n]$收敛的条件，如果$h[n]$不收敛，则不存在其离散时间傅里叶变换的结果$H(e^{jω})$。  </p></blockquote><h2 id="数字系统的表示"><a href="#数字系统的表示" class="headerlink" title="数字系统的表示"></a>数字系统的表示</h2><p>除了上述两个表达式可以描述一个特定的数字系统外，一个特定的数字系统还可以使用如下两种方法进行表达：差分方程和转换方程。<br>系统可以表示为线性常系数差分方程：    </p><script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=∑_{k=0}^Mb_kx[n-k],a_0≠0,b_0≠0</script><p>对上式做Z变换，两边相比，得到系统的转换方程：  </p><script type="math/tex; mode=display">H(z)=\frac{Y(z)}{X(z)}=\frac{∑_{k=0}^Mb_kz^{-k}}{∑_{k=0}^Na_kz^{-k}}</script><p>但是由于z变换成立的条件是要给出收敛域RoC，因此在未给出转换方程的前提下，其对应的差分方程可能有两个：</p><ul><li>右边序列：<script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=∑_{k=0}^Mb_kx[n-k]</script>此时数字系统是因果系统。  </li><li>左边序列:<script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=-∑_{k=-M}^{-1}b_kx[n+k]</script>此时数字系统是非因果系统。  </li></ul><h2 id="转换方程的特征"><a href="#转换方程的特征" class="headerlink" title="转换方程的特征"></a>转换方程的特征</h2><h3 id="与冲激响应"><a href="#与冲激响应" class="headerlink" title="与冲激响应"></a>与冲激响应</h3><p>系统转换方程可以写作两个多项式的比：  </p><script type="math/tex; mode=display">H(z)=\frac{b_0}{a_0}\frac{Π_{k=1}^M(1-c_kz^{-1})}{Π_{k=1}^N(1-b_kz^{-1})}</script><p>其中$M$对应差分方程右侧除去$x[n]$外含有$x$项的个数，$N$对应差分方程左侧除去$y[n]$外含有$y$项的个数，$c_k$表示零点，$d_k$表示极点。<br>化简上式得到如下结构：  </p><script type="math/tex; mode=display">H(z)=∑_{r=0}^{M-N}B_rZ^{-r}+∑_{k=1}^N\frac{A_k}{1-d_kz^{-1}}</script><p>对其做Z反变换：  </p><script type="math/tex; mode=display">h[n]=∑_{r=0}^{M-N}B_rδ[n-r]+∑_{k=1}^NA_k(d_k)^nu[n]</script><p>对上述反变换结果进行讨论：<br>当$N&gt;0$时，差分方程左边有除了$y[n]$的其他含$y$项$y[n-k]$，即此时系统方程当前输出由$x$项、系统以前的输出$y[n-k]$共同决定，系统含有反馈，此时系统方程为：  </p><script type="math/tex; mode=display">h[n]=∑_{r=0}^{M-N}B_rδ[n-r]+∑_{k=1}^NA_k(d_k)^nu[n]</script><p>由于$u[n]$是一个无限长度的序列，因此系统的冲激响应也是无限长度的，称这样的系统为无限冲激响应系统（IIR System）。<br>当$N=0$时，差分方程左边只含有$y[n]$，系统方程的当前输出只由输入$x$决定，系统不含有反馈，此时系统方程为：  </p><script type="math/tex; mode=display">h[n]=∑_{r=0}^{M}B_rδ[n-r]</script><p>由于$δ[n-r]$长度有限，整个系统的冲激响应的长度是有限的，称这样的系统为有限冲激响应系统（FIR System）。  </p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">N</th><th style="text-align:center">差分方程左侧</th><th style="text-align:center">有无反馈</th><th style="text-align:center">冲激响应长度</th></tr></thead><tbody><tr><td style="text-align:center">IIR</td><td style="text-align:center">N&gt;0</td><td style="text-align:center">含有$y[n-k]$</td><td style="text-align:center">有</td><td style="text-align:center">无限</td></tr><tr><td style="text-align:center">FIR</td><td style="text-align:center">N=0</td><td style="text-align:center">只有$y[n]$</td><td style="text-align:center">无</td><td style="text-align:center">有限</td></tr></tbody></table></div><h3 id="与频率响应"><a href="#与频率响应" class="headerlink" title="与频率响应"></a>与频率响应</h3><p>根据Z变换和离散时间傅里叶的定义式，可以推出：  </p><script type="math/tex; mode=display">H(e^{jω})=H(z)|_{z=exp(jω)}</script><p>因此系统的频率响应也可以写作多项式分式：  </p><script type="math/tex; mode=display">H(e^{jω})=\frac{b_0}{a_0}\frac{Π_{k=1}^M(1-c_ke^{-jω})}{Π_{k=1}^N(1-b_ke^{-jω})}</script><h4 id="使用MATLAB®绘制系统的频率响应"><a href="#使用MATLAB®绘制系统的频率响应" class="headerlink" title="使用MATLAB®绘制系统的频率响应"></a>使用MATLAB®绘制系统的频率响应</h4><p>在$[0,2\pi]$上生成若干个采样点，作为作图的$x$轴。<br>使用函数<code>fft()</code>可以生成指定序列的离散傅里叶变换结果。<code>abs()</code>函数能够给出指定序列在每个采样点上的绝对值，即幅度。<code>angle()</code>函数可以生成指定序列在每个采样点上的相位。  </p><p>下面的示例程序展示了如何绘制$h[n]=Sa(0.1(n-50)),0≤n≤100$的幅频和相频响应曲线：<br><figure class="highlight m"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs M">N<span class="hljs-built_in">=</span><span class="hljs-number">100</span>;<br>n<span class="hljs-built_in">=</span><span class="hljs-number">0</span>:N;<br>x<span class="hljs-built_in">=</span>sinc(<span class="hljs-number">0.1</span>*(n-<span class="hljs-number">50</span>));<br>x<span class="hljs-built_in">=</span>[x,zeros(<span class="hljs-number">1</span>,<span class="hljs-number">1000</span>)];<br>X<span class="hljs-built_in">=</span>fft(x);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>);<br>w<span class="hljs-built_in">=</span>[<span class="hljs-number">0</span>:(N+<span class="hljs-number">1000</span>)]*<span class="hljs-number">2</span>*pi/(N+<span class="hljs-number">1001</span>);<br>plot(w./pi,abs(X));<br>title(<span class="hljs-string">&#x27;Magnitude Response&#x27;</span>);<br>axis ([<span class="hljs-number">0</span> <span class="hljs-number">2</span> <span class="hljs-number">0</span> <span class="hljs-number">12</span>]);<br>xlabel(<span class="hljs-string">&#x27;\omega/\pi&#x27;</span>);<br>subplot(<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>);<br>plot(w./pi,angle(X));<br>title(<span class="hljs-string">&#x27;Phase Response&#x27;</span>);<br>axis ([<span class="hljs-number">0</span> <span class="hljs-number">2</span> -<span class="hljs-number">4</span> <span class="hljs-number">4</span>]);<br>xlabel(<span class="hljs-string">&#x27;\omega/\pi&#x27;</span>);<br></code></pre></div></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9. 数字信号的码型、波形和频谱</title>
    <link href="/2021/11/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/9.%20%E7%A0%81%E5%9E%8B%E5%92%8C%E6%B3%A2%E5%BD%A2%E5%88%86%E6%9E%90/"/>
    <url>/2021/11/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/9.%20%E7%A0%81%E5%9E%8B%E5%92%8C%E6%B3%A2%E5%BD%A2%E5%88%86%E6%9E%90/</url>
    
    <content type="html"><![CDATA[<h1 id="数字信号的码型、波形和频谱"><a href="#数字信号的码型、波形和频谱" class="headerlink" title="数字信号的码型、波形和频谱"></a>数字信号的码型、波形和频谱</h1><h2 id="数字基带传输系统简述"><a href="#数字基带传输系统简述" class="headerlink" title="数字基带传输系统简述"></a>数字基带传输系统简述</h2><p>数字基带传输系统的模型如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105164556.png width=80%><br>经过脉冲编码调制的PCM编码成为数字信号(a)，通过脉冲形成器由单极性码变成双极性码(b)，并提供定时脉冲(f)。生成的双极性码信号通过发送端的低通滤波器过滤掉高频分量后，成为升余弦波形(c)。  </p><blockquote><p>由0/1组成的编码称为单极性码。单极性码含有直流分量，无法通过由逻辑门电路构成的判决器。双极性码含有负电平（逻辑中以-1表示）。  </p><p>定时脉冲是周期为$T_s$的冲激序列，目的是为了让接收端知道每个字符（0/1/-1）的持续时间和出现时间间隔。  </p></blockquote><p>数字基带传输系统的信道常采用线缆、明线。在信道中存在加性噪声，使信号发生失真等现象(d)。<br>发送的模拟信号在接收端通过低通滤波器过滤掉信道中的加性噪声(e)，在同步提取模块中提取出信号的定时脉冲(f)，接收信号和这个定时脉冲被送入抽样判决器：抽样判决器会在每一个定时脉冲时判断接收信号的电平大小对应数字信号的1还是0，抽样判决器生成信号如(g)所示。最终，接收信号被复原为数字信号(h)。<br>数字传输系统中各阶段的波形如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105164652.png width=60%>  </p><h2 id="码间串扰"><a href="#码间串扰" class="headerlink" title="码间串扰"></a>码间串扰</h2><p>通过上图可以看出，原来的PCM信号在传输过程中产生了失真，使得原有的两个字符信号发生重叠而无法被判决器识别，最终导致误码。这样的两个字符重叠而产生的干扰称为码间串扰（Inter Symbol Interferance, ISI）。如何减少传输过程中的码间串扰是数字通信中的一个重点问题。  </p><h2 id="码型设计"><a href="#码型设计" class="headerlink" title="码型设计"></a>码型设计</h2><h3 id="码型设计标准"><a href="#码型设计标准" class="headerlink" title="码型设计标准"></a>码型设计标准</h3><p>原始信息编码为方便基带数字信号传输系统传输的编码方式（称为码型）。通常认为，对码型的要求包含如下几点：  </p><ol><li>在编码阶段不能包含直流分量，且低频分量少。  </li><li>码型要便于提取出定时脉冲。  </li><li>具备纠错、检错能力。  </li><li>高频分量尽量少，以减小码间串扰。  </li><li>传输和变换设备简单，便于实现。  </li></ol><h3 id="码型选择"><a href="#码型选择" class="headerlink" title="码型选择"></a>码型选择</h3><p>根据有无极性和是否归零可以将可能的编码大致分成四类：单极性归零码、单极性不归零码、双极性归零码、双极性不归零码。其频域内频谱图如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105194506.png width=80%>  </p><p>无直流分量在频域内的直接体现为0频时没有冲激信号，单极性不归零码(a)和单极性归零码(b)都存在直流分量，因此不适合用于传输。但是单极性归零码存在一个周期性的冲激序列，可以直接作为定时脉冲使用。<br>对双极性不归零码而言，不能直接提取定时脉冲，分离出定时脉冲的过程也比较复杂，因此不适用于传输。对双极性归零码而言，虽然不能直接提取定时脉冲，但可以通过使用一个整流器转换为单极性归零码，从而提取出定时脉冲，且无直流分量，因此<strong>双极性不归零码在数字基带传输中得到广泛应用</strong>。  </p><p>除了上述四类码型外，还有差分码，时钟脉冲和输入单极性数字信号做异或运算/模二加法，得到输入信号的差分码。<br>差分码在接收端收到的极性与发送端完全相反时，也能够正确的判决。在此不详述。  </p><h2 id="AMI码和HDB3编码"><a href="#AMI码和HDB3编码" class="headerlink" title="AMI码和HDB3编码"></a>AMI码和HDB<sub>3</sub>编码</h2><h3 id="AMI码"><a href="#AMI码" class="headerlink" title="AMI码"></a>AMI码</h3><p>AMI码是传号交替反转码的缩写，AMI码是一种双极不归零码，其编码规则如下：  </p><ul><li>消息编码中的0保持不变  </li><li>消息编码中的1在AMI码中为1或-1，1和-1交替出现  </li></ul><p>例如：<br>消息编码： 1.0.0.1.1.1<br>其AMI码： +1.0.0.-1.1.-1</p><p>因此AMI码可以通过交替出现的极性观察传输过程中是否出现误码。<br>但是，当消息编码中含有过长的连0信号时（如：0000000），会给定时脉冲的提取造成困难，为了改进AMI码在长0信号下的传输问题，HDB<sub>3</sub>码应运而生。  </p><h3 id="HDB3-码"><a href="#HDB3-码" class="headerlink" title="HDB3 码"></a>HDB<sub>3</sub> 码</h3><p>HDB<sub>3</sub>的编码规则基本和AMI码相同，但相比于AMI码，其规定在连续三个0信号出现时加入一个破坏脉冲V以防止过长0信号导致定时脉冲难以提取的问题。HDB<sub>3</sub>码的编码规则如下：  </p><ul><li>给定一个初始符号以指定消息编码中起始1的极性，使用AMI编码方式对消息进行编码。<strong>起始1的极性与初始符号的极性相反。</strong>  </li><li>当有连续4个0信号出现时，第四个0信号改为破坏脉冲V，对破坏脉冲的极性有如下规定：  <ol><li>V的极性交替反转（高优先级）</li><li>破坏脉冲的极性与前一个“1”的极性相同（V视作1）</li></ol></li><li><strong>在V的极性不满足条件2时</strong>，连0信号的第一个0变为补性码B’，B’的极性与其后一个V的极性相同。<strong>B’后的1全部反转极性</strong>。  </li><li>V和B’都为逻辑1。  </li></ul><p>例如：指定符号位为“+”：<br>消息编码：10000 0000 0000 0000 1<br>AMI编码： -10000 0000 0000 0000 1<br>加入破坏脉冲：-1000-V 000V 000-V 000V 1<br>加入补性码：-1000-V B’00V -B’00-V B’00V -1<br>HDB<sub>3</sub>编码： -1000-1 1001 -100-1 1001 -1  </p><p>HDB<sub>3</sub>在解码时只需要找到连0信号两端极性相同的部分，替换为0即可：<br>HDB<sub>3</sub>解码：-10000 0000 0000 0000 -1  </p><h2 id="曼彻斯特码"><a href="#曼彻斯特码" class="headerlink" title="曼彻斯特码"></a>曼彻斯特码</h2><h3 id="曼彻斯特码-双向码"><a href="#曼彻斯特码-双向码" class="headerlink" title="曼彻斯特码/双向码"></a>曼彻斯特码/双向码</h3><p>曼彻斯特码是一种双极性不归零码，其01编码为脉冲信号的上升沿和下降沿，巧妙地解决了长连0信号由于电平不发生变化而导致的定时脉冲提取困难的问题。其编码规则为：<br>脉冲波形在同步脉冲间隔周期50%时：  </p><ul><li>脉冲上升沿表示逻辑1  </li><li>脉冲下降沿表示逻辑0  </li></ul><p>例如：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105205712.png width=70%><br>但是曼彻斯特码在极性发生反转时容易发生译码错误，为了解决这个问题，引入了差分码的概念。  </p><h3 id="差分曼彻斯特码"><a href="#差分曼彻斯特码" class="headerlink" title="差分曼彻斯特码"></a>差分曼彻斯特码</h3><p>差分曼彻斯特码的编码规则为：<br>脉冲间隔开始时：  </p><ul><li>脉冲电平不发生变化（无触发沿）表示逻辑1</li><li>脉冲电平发生变化（有触发沿）表示逻辑0</li></ul><p>例如：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105210411.png width=70%>  </p><h2 id="基带波形的选择"><a href="#基带波形的选择" class="headerlink" title="基带波形的选择"></a>基带波形的选择</h2><p>除了考虑合适的码型外，还需要考虑使用什么形状的波形来表示选择的码型。<br>对波形的选择标准要求频谱图上的主瓣（即信号的有用带宽）后杂波的带宽越小越好，换言之，频谱函数收敛速度越快越好。<br>在方波脉冲、三角脉冲、升余弦脉冲中，升余弦脉冲的收敛速度最快，意味着杂波的带宽通常比较小，因此在数字基带通信中常选择升余弦脉冲作为基带波形。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211105211419.png width=80%>  </p><h2 id="频谱分析"><a href="#频谱分析" class="headerlink" title="频谱分析"></a>频谱分析</h2><p>设脉冲信号$g_1(t-nT_s)$表示逻辑0，$g_2(t-nT_s)$表示逻辑1，假设随机脉冲序列在码元时间间隔$T_s$内逻辑1和0的出现是相互独立的，那么对任何一个数字信号$s(t)$都可以表示为：  </p><script type="math/tex; mode=display">s(t)=∑s_n(t)</script><p>其中:</p><script type="math/tex; mode=display">s_n(t)=\begin{cases}  g_1(t-nT_s),\text{概率为}P\\  g_2(t-nT_s),\text{概率为}1-P\\\end{cases}</script><p>$s(t)$的图示如下：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109111353.png width=50%>  </p><p>由于任何波形都可以分解为两个波形的叠加，考虑要知道基带信号中是否存在可以提供频谱分量的周期同步信息，因此将$s(t)$分解为能够提取同步信息的周期波形$v(t)$和随机信号$u(t)$：  </p><script type="math/tex; mode=display">s(t)=v(t)+u(t)</script><p>经过数学运算可知，$v(t)$的功率谱表示为：  </p><script type="math/tex; mode=display">P_v(f)=∑|f_s[PG_1(mf_s)+(1-P)G_2(mf_s)]|^2δ(f-mf_s)</script><p>$u(t)$的功率谱表示为：  </p><script type="math/tex; mode=display">P_u(f)=f_sP(1-P)|G_1(f)-G_2(f)|^2</script><p>那么数字信号$s(t)$的频谱可以表示为：  </p><script type="math/tex; mode=display">\begin{aligned}  P_s(f)&=P_u(f)+P_v(f)\\  &=∑|f_s[PG_1(mf_s)+(1-P)G_2(mf_s)]|^2δ(f-mf_s)+f_sP(1-P)|G_1(f)-G_2(f)|^2\end{aligned}</script><p>化简为单边谱：  </p><script type="math/tex; mode=display">P_s(f)=2f_sP(1-P)|G_1(f)-G_2(f)|^2+f^2_s|PG_1(0)+(1-P)G_2(0)|^2δ(f)+2f_s^2∑|[PG_1(mf_s)+(1-P)G_2(mf_s)]|^2δ(f-mf_s)</script><p>可以发现这个单边谱公式由三部分组成：<br>$f^2_s|PG_1(0)+(1-P)G_2(0)|^2δ(f)$：在零频时的冲激信号，即信号的<strong>直流分量</strong>。<br>$2f_s^2∑|[PG_1(mf_s)+(1-P)G_2(mf_s)]|^2δ(f-mf_s)$：周期冲激序列，即可以提取用于同步的<strong>定时脉冲</strong>。<br>$2f_sP(1-P)|G_1(f)-G_2(f)|^2$:连续谱分量，由随机信号产生，极大地影响频谱效率。<br>下图表示了符号持续时间$τ$和对应频谱带宽的关系：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211109114653.png width=60%><br>可以发现，<strong>符号持续时间越长，占用带宽越小</strong>。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7. 晶体管的直流偏置状态</title>
    <link href="/2021/11/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/7.%20BJT_Biasing/"/>
    <url>/2021/11/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/7.%20BJT_Biasing/</url>
    
    <content type="html"><![CDATA[<h1 id="晶体管的直流偏置状态"><a href="#晶体管的直流偏置状态" class="headerlink" title="晶体管的直流偏置状态"></a>晶体管的直流偏置状态</h1><h2 id="晶体管的偏置类型"><a href="#晶体管的偏置类型" class="headerlink" title="晶体管的偏置类型"></a>晶体管的偏置类型</h2><p>BJT晶体管只有在直流工作状态下，才能作为放大器或者开关正常工作。在实际设计中，有两种方式来控制静态工作点（$I_C$和$V_{CE}$）的值：  </p><ul><li>基极偏置<br>在基极偏置下，保持$I_B$始终不变来设置$I_C$和$V_{CE}$的值。<br>基极偏置通常用于晶体管作为开关时。  </li><li>发射极偏置<br>在发射极偏置下，保持$I_E$始终不变来设置$I_C$和$V_{CE}$的值。<br>发射极偏置通常用于晶体管作为放大器时。  </li></ul><h2 id="基极偏置"><a href="#基极偏置" class="headerlink" title="基极偏置"></a>基极偏置</h2><p>基极偏置的电路图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104153700.png width=50%>  </p><p>基极偏置下，发射极接地，基极接入一个直流电压$V_{BB}$。<strong>当$V_{BB}$和$R_B$固定时（这两个值已知），$I_B$固定。</strong><br>通过对基极环路和集电极环路应用基尔霍夫电流/电压定律计算出$I_C$和$V_{CE}$。  </p><script type="math/tex; mode=display">\begin{aligned}    I_B&=\frac{V_{BB}-V_{BE}}{R_B}\\    I_C&=βI_B\\    V_{CE}&=V_{CC}-I_CR_C\\\end{aligned}</script><p>可以发现这个计算过程中要用到电流增益$β$，因此静态工作点的选取和$β$有关。<br>由于静态工作点对$β$极为敏感，因此静态工作点很容易出现在饱和和截止区域，因此基极偏置通常用于晶体管作为开关时。  </p><blockquote><p>饱和状态下可以通过计算$I_{CSat}$反求$I_B$。  </p></blockquote><h2 id="反馈偏置"><a href="#反馈偏置" class="headerlink" title="反馈偏置*"></a>反馈偏置*</h2><p>由于电流增益$β$的大小与温度、器件本身等诸多因素有关，在电路设计时应当尽量避免$β$对电路的输出产生影响，导致不稳定的结果。反馈偏置就是一类利用负反馈对$β$变化而导致的静态工作点变化进行抑制的电路。  </p><h3 id="发射极反馈偏置"><a href="#发射极反馈偏置" class="headerlink" title="发射极反馈偏置"></a>发射极反馈偏置</h3><p>由于基极偏置的静态工作点对$β$极为敏感，考虑使用负反馈让$I_C$不会产生过多变化。发射极反馈偏置就是采用这样一种思路的电路，其结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104192421.png width=30%>  </p><p>在这个电路中：<br>如果$I_C$增大，由$I_C≈I_E,V_E=I_ER_E$可知$V_E$会增大；<br>由$V_{BE}=V_{B}-V_E=0.7V$可知$V_B$增大；<br>由$V_B=V_{BB}-I_BR_B$可知$I_B$减小；<br>由$I_C=βI_B$可知$I_C$最终会减小。<br>反之亦然。<br>但是相比于静态工作点不随$β$发生任何变化的发射极偏置而言，$β$仍然对发射极反馈偏置存在影响：虽然存在负反馈限制$I_C$的变化，但是在实际过程中$I_C$的变化仍可能不满足设计需求，因此发射极反馈偏置电路不常用。  </p><h3 id="集电极反馈偏置"><a href="#集电极反馈偏置" class="headerlink" title="集电极反馈偏置"></a>集电极反馈偏置</h3><p>集电极反馈是另一种尝试负反馈来抑制$I_C$发生变化的电路，其结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104195052.png width=30%>  </p><p>在这个电路中：<br>如果$I_C$增大，由$V_C=V_{CC}-I_CR_C$可知$V_C$减小；<br>由$V_B=V_{BE}=V_{C}-I_BR_B=0.7V$可知$I_B$减小；<br>由$I_C=βI_B$可知$I_C$最终会减小。<br>反之亦然。<br>在实际应用中，由于比发射极反馈偏置电路图更简单，集电极反馈偏置的负反馈更容易抑制$I_C$的变化，但是也对$β$很敏感。  </p><h3 id="集电极-发射极反馈偏置"><a href="#集电极-发射极反馈偏置" class="headerlink" title="集电极-发射极反馈偏置*"></a>集电极-发射极反馈偏置*</h3><p>集电极-发射极反馈偏置试图综合上述两种反馈偏置的负反馈效果，来达到更好抑制效果的目的。但是事实上，集电极-发射极反馈偏置虽然优于前两者的反馈抑制效果，但是很难大规模生产，因此不常应用，其电路图如下图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104195335.png width=30%>  </p><h2 id="发射极偏置"><a href="#发射极偏置" class="headerlink" title="发射极偏置"></a>发射极偏置</h2><p>发射极偏置的电路如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104174419.png width=50%>  </p><p>发射极偏置下，发射极接入一个电阻$R_E$，在$V_{BB}$和$V_{BE}$的作用下，发射极产生一个发射极电流$I_E$。<strong>当给定$R_E$和$V_{BB}$时，$I_E$固定不发生变化</strong>。<br>通过对基极环路和集电极环路应用基尔霍夫电流/电压定律计算出$I_C$和$V_{CE}$。<br>在这种情况下</p><script type="math/tex; mode=display">\begin{aligned} I_E&=\frac{V_{BB}-V_{BE}}{R_E}\\I_E&≈I_C\\V_{CE}&=V_C-V_E\\&=V_{CC}-I_CR_C-I_ER_E\end{aligned}</script><p>可以发现，此处计算$I_C$时不会用到$β$，即静态工作点的选取与$β$无关。这种情况下的静态工作点较为稳定，处于放大区域内，因此发射极偏置常用于晶体管作为放大器时。  </p><h3 id="发射极偏置的变形"><a href="#发射极偏置的变形" class="headerlink" title="发射极偏置的变形"></a>发射极偏置的变形</h3><h4 id="分压偏置"><a href="#分压偏置" class="headerlink" title="分压偏置"></a>分压偏置</h4><p>分压偏置（Voltage Divider Bias，VDB）的电路图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104185532.png width=30%>  </p><p>分压偏置其实是发射极偏置的改装：与发射极偏置的唯一不同点在于基极供电$V_{BB}$直接由$V_{CC}$和分压器提供：  </p><script type="math/tex; mode=display">V_{BB}=\frac{R_2}{R_1+R_2}V_{CC}</script><p>其余计算与分压偏置相同。  </p><h4 id="双电源发射极偏置"><a href="#双电源发射极偏置" class="headerlink" title="双电源发射极偏置"></a>双电源发射极偏置</h4><p>双电源发射极偏置（Two supply Emitter Bias，TSEB）结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104190922.png width=30%>  </p><p>在这种情况下，发射极有两个直流电压源$V_{BE}$和$V_{EE}$。由于<strong>基极连接电阻后直接接地，$I_B$非常小，可以认为$V_{B}=0$。</strong><br>因此对于发射极：  </p><script type="math/tex; mode=display">V_E=0-V_{BE}=-0.7V</script><script type="math/tex; mode=display">I_E=\frac{V_E-V_{EE}}{R_E}</script><p>其余计算同发射极偏置。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">偏置类型</th><th style="text-align:center">恒定量</th><th style="text-align:center">电路特征</th><th style="text-align:center">静态工作点与$β$独立？</th></tr></thead><tbody><tr><td style="text-align:center">基极偏置</td><td style="text-align:center">$I_B$</td><td style="text-align:center">基极端有电阻$R_B$</td><td style="text-align:center">否</td></tr><tr><td style="text-align:center">发射极偏置</td><td style="text-align:center">$I_E$</td><td style="text-align:center">发射极端有有电阻$R_E$</td><td style="text-align:center">是</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 快速傅里叶变换</title>
    <link href="/2021/10/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/6.%20%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/10/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/6.%20%E5%BF%AB%E9%80%9F%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="快速傅里叶变换"><a href="#快速傅里叶变换" class="headerlink" title="快速傅里叶变换"></a>快速傅里叶变换</h1><p>快速傅里叶变换（FFT）是一种计算离散傅里叶变换的算法，其独有的计算方式能够大幅度减小离散傅里叶变换的计算量，使得离散傅里叶变换在计算机上具有可实现性。  </p><h2 id="离散傅里叶变换的计算量"><a href="#离散傅里叶变换的计算量" class="headerlink" title="离散傅里叶变换的计算量"></a>离散傅里叶变换的计算量</h2><p>回顾离散傅里叶变换：  </p><script type="math/tex; mode=display">X[k]=\sum_{n=0}^{N-1}x[n]W^{kn}_N</script><p>可以发现，计算一个离散傅里叶变换需要计算：  </p><ol><li>N个$x[n]W$，即N次复数乘法</li><li>N-1次$x[i]W+x[i+1]W$，即(N-1)次复数加法</li></ol><p>根据复数乘法原则$(a+jb)(c+jd)=(ac-bd)+j(ad+bc)$，和复数加法原则$(a+jb)+(c+jd)=(a+c)+j(b+d)$，可以发现：1次复数乘法与4个实数乘法和2个实数加法等价；1次复数加法和2次实数加法等价。<br>因此计算一次离散傅里叶变换需要计算：  </p><ol><li>$4N^2$次实数乘法</li><li>$4N^2-2N$次实数加法  </li></ol><p>其中实数乘法对计算资源的消耗非常的大，因此考虑使用别的算法以简化实数乘法的次数。  </p><h2 id="时域抽取的快速傅里叶变换"><a href="#时域抽取的快速傅里叶变换" class="headerlink" title="时域抽取的快速傅里叶变换"></a>时域抽取的快速傅里叶变换</h2><p>将离散傅里叶变换分为奇数和偶数两个段落：  </p><script type="math/tex; mode=display">\begin{aligned}    X[k]&=\sum_{r=0}^{\frac{N}{2}-1}x[2r]W^{2rk}_N+\sum_{r=0}^{\frac{N}{2}-1}x[2r+1]W^{(2r+1)k}_N\\    &=\sum_{r=0}^{\frac{N}{2}-1}x[2r]W^{2rk}_N+W_N^{k}\sum_{r=0}^{\frac{N}{2}-1}x[2r+1]W^{2rk}_N\end{aligned}</script><p>根据复数的共轭对称性质：$W_N^{k(N-n)}=W_N^{kN}W^{-kn}_N=W^{-kn}_N$，前半段（$0-N/2$）的表达式可以写作：  </p><script type="math/tex; mode=display">X[k]=\sum_{r=0}^{\frac{N}{2}-1}x[2r]W^{rk}_{N/2}+W_N^k\sum_{r=0}^{\frac{N}{2}-1}x[2r+1]W^{rk}_{N/2}</script><p>令$G[k]=\sum_{r=0}^{\frac{N}{2}-1}x[2r]W^{rk}_{N/2}$，$H[k]=\sum_{r=0}^{\frac{N}{2}-1}x[2r+1]W^{rk}_{N/2}$:  </p><script type="math/tex; mode=display">X[k]=G[k]+W^k_NH[k],k=0,1,..,N-1</script><p>将前半段式子的下标加上$N/2$考虑后半段式子的和，由于$W_N^{k+N/2}=-1$，因此：  </p><script type="math/tex; mode=display">X[k+N/2]=G[k]-W^k_NH[k],k=0,1,..,N-1</script><p>综合两段，得到时域抽取的快速傅里叶变换：  </p><script type="math/tex; mode=display">X[k]=G[k]+W^k_NH[k],k=0,1,..,N/2-1</script><script type="math/tex; mode=display">X[k+N/2]=G[k]-W^k_NH[k],k=0,1,..,N/2-1</script><p>上述式子称为蝶式结构，用图示可以表示为：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030143805.png width=40%> </p><p>可以将整个序列继续折中细分成多个小部分，每个部分计算蝶形结构。在$N$为2的次方数时，使用折中法正好可以使得最终细分到相邻的奇偶两项做蝶形结构运算：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030144247.png width=30%>  </p><p>比如$N=8$时就可以通过折中法多次两两分组，每组内部进行蝶形运算后的结果再进行蝶形运算：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030144446.png width=80%><br>其中最低一级的分组通过如下方式进行：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030144544.png width=50%>  </p><h3 id="蝶形结构运算"><a href="#蝶形结构运算" class="headerlink" title="蝶形结构运算"></a>蝶形结构运算</h3><p>观察整个快速傅里叶变换的结构：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030144723.png width=80%></p><p>可以得出如下结论：  </p><ol><li>对于$N=2^m$，需要$m$级次蝶形结构的运算。  </li><li>对于第$m$级运算，组数为$2^N-m-1$。每一组的$q$总是被赋予$-1$和权重，权重表示为：  <script type="math/tex; mode=display">W_{2^{m+1}}^r,r=0,1,2,..,2^m-1</script><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030145708.png width=40%></li></ol><blockquote><p>注意计算之前首先得按照比特反转的方法对序列进行重排序。  </p></blockquote><h3 id="快速傅里叶变换的计算量"><a href="#快速傅里叶变换的计算量" class="headerlink" title="快速傅里叶变换的计算量"></a>快速傅里叶变换的计算量</h3><p>由于一点蝶形运算中不包含乘法，快速傅里叶变换通过应用这样的蝶形结构来削减乘法计算的次数。当长度$N=2^m$时，简单分析可得快速傅里叶变换的计算量：  </p><script type="math/tex; mode=display">\frac{N^2}{2^m}+m\frac{N}{2}=N+\frac{N}{2}log_2N</script><h2 id="频域抽取的快速傅里叶变换"><a href="#频域抽取的快速傅里叶变换" class="headerlink" title="频域抽取的快速傅里叶变换"></a>频域抽取的快速傅里叶变换</h2><p>在频域内对离散傅里叶变换进行拆分，可以得到：  </p><script type="math/tex; mode=display">\begin{aligned}    X[2r]=&∑_{n=0}^{N/2-1}x[n]W_N^{2nr}+∑_{n=0}^{N/2-1}x[n+N/2]W^{2r(n+N/2)}_N\\    =&∑_{n=0}^{N/2-1}[x[n]+x[n+N/2]]W^{rn}_{N/2},r=0,1,..,N/2-1\end{aligned}</script><p>同理对于频域内的奇数序列有：  </p><script type="math/tex; mode=display">X[2r+1]=[x[n]-x[n+N/2]]W^{rn}_{N/2},r=0,1,..,N/2-1</script><p>令$g[n]=x[n]+x[n+N/2]$,$h[n]=x[n]-x[n+N/2]$，得到频域抽取的快速傅里叶变换：  </p><script type="math/tex; mode=display">X[2r]=∑_{n=0}^{N/2-1}g[n]W_{N/2}^{rn}</script><script type="math/tex; mode=display">X[2r+1]=W_N^n∑_{n=0}^{N/2-1}h[n]W_{N/2}^{rn},r=0,1,..,N/2-1</script><p>同样符合蝶形结构：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030150736.png width=60%>  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 晶体管的结构和直流工作状态</title>
    <link href="/2021/10/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/6.%20foundamentals%20of%20BJT/"/>
    <url>/2021/10/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/6.%20foundamentals%20of%20BJT/</url>
    
    <content type="html"><![CDATA[<h1 id="晶体管的结构和直流工作状态"><a href="#晶体管的结构和直流工作状态" class="headerlink" title="晶体管的结构和直流工作状态"></a>晶体管的结构和直流工作状态</h1><h2 id="基本结构"><a href="#基本结构" class="headerlink" title="基本结构"></a>基本结构</h2><p>半导体有两种：N型半导体和P型半导体，两种半导体内部有多余的负电荷或者是正电荷。制造半导体的主要工艺为掺杂：掺杂有两种类型： p 型掺杂（具有额外的空穴，带正电）和 n 型掺杂（具有额外的电子，带负电）。此外不同半导体的掺杂程度也可以不同，掺杂程度越高（称为重掺杂），半导体导电性能越强。<br>BJT晶体管/三极管是广泛运用于电子设计中的电路元件，它由三个N型或者P型半导体结合组成，三个半导体既可以是P-N-P，也可以是N-P-N，结合的部分称为PN结。本课主要讲N-P-N型三极管，其结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211027153932.png width=30%><br>三极管有三个输入端，分别为：集电极、基极和发射极，NPN三极管中三者半导体类型如下：   </p><div class="table-container"><table><thead><tr><th style="text-align:center">集电极</th><th style="text-align:center">基极</th><th style="text-align:center">发射极</th></tr></thead><tbody><tr><td style="text-align:center">N型</td><td style="text-align:center">P型</td><td style="text-align:center">N型</td></tr><tr><td style="text-align:center">中度掺杂</td><td style="text-align:center">轻度掺杂</td><td style="text-align:center">重度掺杂</td></tr><tr><td style="text-align:center">自由电子</td><td style="text-align:center">空穴</td><td style="text-align:center">自由电子</td></tr></tbody></table></div><p>由于这样的设计，自由电子只能从集电极/发射极流向基极，而无法从基极流向两边，<br>因此可以将NPN三极管等效为两个背靠背的二极管：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211027155507.png width=30%>  </p><h3 id="偏置状态"><a href="#偏置状态" class="headerlink" title="偏置状态"></a>偏置状态</h3><p>在外接电源的情况（称为偏置）下，自由电子受到电场的作用从而定向移动：从两端的N型半导体移动到中心的P型半导体。其中的一部分自由电子在基极内部的两侧与空穴结合，从而形成两个枯竭层阻挡自由电子继续前进。硅半导体枯竭层的两侧在25℃条件下具有0.7V的电压差。但是基极通常很薄，且为轻度掺杂，因此大部分的电子仍然可以穿过基极，流向两端。这一过程中，由于发射极为重度掺杂，导电性大于集电极，因此<strong>绝大多数电子的流向是从发射极经过基极流向集电极。</strong><br>自由电子到达集电极后会受到$V_{cc}$的吸引，最终流向$V_{cc}$的正极。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028212658.png width=50%>  </p><p>该过程转化为电流的流向，NPN三极管内部的电流流向如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028212033.png width=20%><br>在这样的电流流动情况下，集电极处的等效二极管处于反向偏置状态，发射极处的等效二极管处于正向偏置状态。  </p><p>三极管的等效电路图如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028222936.png width=50%></p><h2 id="共发射极电路中三极管的电流变化"><a href="#共发射极电路中三极管的电流变化" class="headerlink" title="共发射极电路中三极管的电流变化"></a>共发射极电路中三极管的电流变化</h2><p>根据三极管不同的端接地分为不同的连接方式，其中最常见的是发射极接地的情况，称为共发射极电路（Common Emitter connection）：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028214554.png width=50%>  </p><p>如果如果信号由晶体管基极输入，从集电极输出。下面在共发射极的电路中讨论基极和集电极的电流变化。  </p><h3 id="基极的电流变化曲线"><a href="#基极的电流变化曲线" class="headerlink" title="基极的电流变化曲线"></a>基极的电流变化曲线</h3><p>探究$V_{BE}$对基极电流$I_B$的影响：<br>根据电流图示，基极和发射极之间的等效二极管处于正向偏置状态，可以将$I_B$和$V_{BE}$之间的关系看做是一个二极管的电压-电流曲线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028215817.png width=20%><br>通过图像可以看出：这个等效二极管只需要0.7V就可以完全导通。<br>同时，晶体管在正常工作($I_B$并非非常小)时，基极和发射极之间始终存在压降$V_{BE}$。<br><strong>对于理想三极管$V_{BE}=0V$（称为一级近似），对于非理想三极管$V_{BE}=0.7V$</strong>（称为二级近似）。<br>根据欧姆定律可以得到基极侧的电流电压关系：  </p><script type="math/tex; mode=display">I_B=\frac{V_{BB}-V_{BE}}{R_B}</script><h3 id="集电极的电流变化曲线"><a href="#集电极的电流变化曲线" class="headerlink" title="集电极的电流变化曲线"></a>集电极的电流变化曲线</h3><p>探究$V_{CE}$对基极电流$I_C$的影响：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211028220139.png width=50%><br>根据之前的电流图示，可以得到：  </p><script type="math/tex; mode=display">I_E=I_C+I_B</script><p>根据上述特性曲线，可以将工作状态分为：<strong>饱和、放大、截止</strong>三种。此外还有称为击穿的异常工作状态。  </p><h4 id="放大-线性"><a href="#放大-线性" class="headerlink" title="放大/线性"></a>放大/线性</h4><p>放大状态是三极管的正常工作状态，在这种工作状态下，几乎所有的电子都已经流向了集电极。发射极的等效二极管处于前向偏置状态。<strong>无论$V_{CC}$和$V_{CE}$如何变化，集电极的电流$I_C$始终只与$I_B$有关。</strong><br>在放大状态下，输入一个较小的$I_B$可以输出一个较大的电流信号：$I_C$。此时晶体管可以用做放大器。  </p><p>定义三极管的<strong>电流增益</strong>:</p><script type="math/tex; mode=display">β=\frac{I_C}{I_B}</script><p>电流增益会随着<strong>三极管型号</strong>、<strong>温度</strong>和<strong>集电极电流$I_C$</strong><br>的不同而变化，在设计放大电路时应当尽量避免$β$对电路输出产生影响。    </p><p>同时定义晶体管的修正系数$α$为集电极电流和发射极电流之比:  </p><script type="math/tex; mode=display">α=\frac{I_C}{I_E}=\frac{β}{β+1}</script><p>通常认为在$β&gt;100$的情况下，$α≈1$。  </p><h4 id="饱和"><a href="#饱和" class="headerlink" title="饱和"></a>饱和</h4><p>在饱和工作状态下，几乎所有的自由电子都从发射极流向基极。$I_B$大于放大状态的电流。此时$CE$间相当于短路，是晶体管用做开关时的导通状态。<br>由于$CE$间相当于短路，饱和状态下集电极环路的电流为：  </p><script type="math/tex; mode=display">I_{CSat}=\frac{V_{CC}}{R_C}</script><p>此电流为集电极环路中的最大电流。  </p><blockquote><p>由于$β$与$I_C$有关，在饱和状态下，无法使用$I_C=βI_B$进行计算。  </p></blockquote><h4 id="截止"><a href="#截止" class="headerlink" title="截止"></a>截止</h4><p>在截止状态下，$I_B=0$，此时$CE$之间相当于断路，是是晶体管用做开关时的关断状态。<br>此时$V_{CE}$与供电电压$V_{CC}$相等：  </p><script type="math/tex; mode=display">V_{CEcutoff}=V_{CC}</script><h4 id="击穿"><a href="#击穿" class="headerlink" title="击穿"></a>击穿</h4><p>当$V_{CE}$相当大时，晶体管被击穿，晶体管处于永久短路状态，此时的$I_C$迅速增大。  </p><h2 id="直流工作状态"><a href="#直流工作状态" class="headerlink" title="直流工作状态"></a>直流工作状态</h2><p>要想使三极管处于开关或者放大器的工作模式，三极管必须处于直流工作状态（即三极管静态工作点就是交流输入信号为零时），在直流工作状态下，对集电极环路进行分析：  </p><script type="math/tex; mode=display">V_{CE}=V_{CC}-I_CR_C</script><script type="math/tex; mode=display">I_C=-\frac{1}{R_C}V_{CE}+\frac{V_{CC}}{R_C}</script><p>可以发现当$V_{CC}$和$R_C$固定时，$V_{CE}$和$I_C$需要设置为某些特定的值下，才能使得三极管满足直流工作状态，且在直流工作状态下两者成线性关系。这条线称为<strong>直流负载曲线</strong>，也是三极管在直流工作状态下的特性曲线。<br>这条曲线的<strong>斜率为$-\frac{1}{R_C}$，截距为集电极饱和电流$\frac{V_{CC}}{R_C}$，零点为集电极的截止电压</strong>。随着$V_{CE}$的增大，$I_C$逐渐减小。  </p><h3 id="静态工作点"><a href="#静态工作点" class="headerlink" title="静态工作点"></a>静态工作点</h3><p>在直流工作状态下，随着基极电阻的增大，基极电流$I_B$会相应的发生变化，不同的$I_B$会导致集电极环路中$V_{CE}$和$I_C$的关系发生变化：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030123051.png width=50%>  </p><p>要得到$I_B$一定时，三极管处于直流工作状态下对应的$I_C$和$V_{CE}$，应当在此图上作出直流负载曲线，与$V_{CE}$和$I_C$的关系曲线的交点即为所求。该交点称为三极管的<strong>静态工作点</strong>（Q Point），表示三极管处于直流工作状态下，$I_B$为某个固定值时$I_C$和$V_{CE}$的值。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211030123451.png width=50%>  </p><p>从图上可以看出，当基极的电流增益$β$非常大时，$I_B$不变的情况下（称为Base-Biasing），$I_C$随之升高，可能会使$V_{CE}$非常小，甚至接近短路，使得静态工作点位于饱和区域。同理，当基极的电流增益$β$非常小时，$V_{CE}$非常大，甚至接近断路，使得静态工作点位于截止区域。  </p><p>在三极管用做放大器时，静态工作点位于放大区域。在此状态下，三极管可以生成非常稳定的电流增益，防止电路产生非线性失真。<br>在三极管用做开关时，静态工作点在饱和和截止区域之间切换。此状态方便用数字信号进行表达：当静态工作点处于饱和区域时，数字信号为1，处于截止区域时，代表的数字信号为0。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8. 模拟信号的数字化</title>
    <link href="/2021/10/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/8.%20%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%BC%A0%E8%BE%93/"/>
    <url>/2021/10/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/8.%20%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E4%BC%A0%E8%BE%93/</url>
    
    <content type="html"><![CDATA[<h1 id="模拟信号的数字化"><a href="#模拟信号的数字化" class="headerlink" title="模拟信号的数字化"></a>模拟信号的数字化</h1><p>在现代通信中，更经常用到的是将模拟信号在发送端进行数字化处理后进行传输，信号在接收端进行解码还原。整个过程如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023130519.png width=80%>  </p><p>原信号经过抽样、量化后由模拟信号变成数字信号，再经过编码使得信号的幅值由无限（注意$δ(t)$的幅值是无限大的）变为有限描述，传输至信道，在接收端，首先通过定时规定信号的起始点和周期，再经过译码还原为量化信号（PAM，仍然是数字信号），最后通过低通滤波器过滤高频信号后在接收端还原为模拟信号$f_o(t)$。  </p><blockquote><p>$f_o(t)$和$f(t)$实际上是不同的两个信号，原因有三：  </p><ol><li>采样结果受到采样频率和信号变化频率的影响，不同的采样频率对同一个信号变化频率采集到的结果不同，甚至得到的采样信号可能是和原信号完全相反的波形。  </li><li>量化过程受到精度限制，极有可能获得原信号在某时间点上幅值的近似值而非准确值，这两个值之间的差距称为量化噪声。量化噪声产生后无法被消除。  </li><li>传输过程中信道的噪声和干扰。  </li></ol></blockquote><h2 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h2><p>由奈奎斯特采样定理可知：采样的实质是原信号与周期冲激序列相乘:  </p><script type="math/tex; mode=display">m_s(t)=m(t)δ_T(t)</script><p>现实中很难获得一个周期冲激序列，因此改用一个周期方波序列作为抽样使用的信号。在自然采样中(Natural sampling)，采样后的每一个信号分量的幅值是随着时间变化的：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023131900.png width=50%><br>平顶抽样（Ceiling sampling）在自然采样后加入了一个保持器，可以使得信号的每一个分量的幅值被采集到后保留一段时间：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023132058.png width=50%>  </p><p>由奈奎斯特采样定理可得：  </p><script type="math/tex; mode=display">\begin{aligned}    m_s(t)&=m(t)δ_T(t)\\    =&∑m(nT_s)δ(t-nT_s)\\\end{aligned}</script><p>在频域中可得到采样后的信号频谱：  </p><script type="math/tex; mode=display">M_s(f)=\frac{1}{T}∑M(f-nf_s)</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023132549.png width=50%></p><p>采样后频谱的每一个分量都包含原信号的完整信息，因此可以设计低通滤波器滤出一个频域周期内($f_s$)的信号。这种做法的前提条件是频谱分量间不能有任何的重叠，否则滤出的信号会由于重叠而产生混叠误差。（Aliasing error）<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023132927.png width=50%>  </p><p>因此规定采样频率必须至少高于原信号带宽：  </p><script type="math/tex; mode=display">f_s≥2f_H</script><p>但是采样频率越高，整个频谱的带宽越大，频谱利用率越低，最好的采样频率为两者相等时：$f_s=2f_H$，称为奈奎斯特采样频率。  </p><h3 id="带通信号采样"><a href="#带通信号采样" class="headerlink" title="带通信号采样"></a>带通信号采样</h3><p>这样的采样方式对低通信号（原信号频谱$f_L=0$）固然是可行的，对于带通信号（原信号$f_L≠0$），这样的采样使得频谱中出现很多无信号部分，称为频谱空洞，导致频谱利用效率降低。因此需要在上述方法上进行改进。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023133539.png width=50%>  </p><p>对于带通信号，其采样频率$f_s$应当满足如下条件：  </p><script type="math/tex; mode=display">f_s≥2B(1+\frac{M}{N})</script><p>其中$M$为$|\frac{f_H}{B}|$的整数部分（向下取整），$N$为$|\frac{f_H}{B}|$的小数部分。<br>满足$f_s=2B(1+\frac{M}{N})$的采样结果不会出现频谱空洞。<br>对于上式，当$f_L$非常大时，$f_s≈2B$。  </p><h2 id="量化"><a href="#量化" class="headerlink" title="量化"></a>量化</h2><h3 id="均匀量化"><a href="#均匀量化" class="headerlink" title="均匀量化"></a>均匀量化</h3><p>量化过程简述如下：将信号的幅值划分成若干个区间，某时刻原信号幅值落在该区间时，量化信号在此时刻的幅值为这个区间的中值。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023135157.png width=80%>  </p><p>该过程可以用数学表示为：  </p><script type="math/tex; mode=display">m_q(kT_S)=q_i,\text{if }m_{i-1}≤m(kT_s)≤m_i</script><p>这个过程中的每个区间称为量化间隔，在均匀量化中，这个间隔是均等的：$Δ=\frac{V_m}{N}$，$N$为用于描述信号的比特数，与量化精度相关。每个区间的上界是下一个区间的下界，每个界限以$m_i$表示。当原信号落入某区间时，用于描述/替代原信号幅值的值称为量化电平$q_i$，量化电平通常是该区间的中值，以减小总体的量化误差：  </p><script type="math/tex; mode=display">q_i=\frac{m_i+m_{i-1}}{2}</script><h4 id="均匀量化的信噪比"><a href="#均匀量化的信噪比" class="headerlink" title="均匀量化的信噪比"></a>均匀量化的信噪比</h4><p>输入信号的平均功率：  </p><script type="math/tex; mode=display">S=E[(m_k)^2]=∫x^2f(x)dx</script><p>$m_k$表示采样值，$m_q$表示量化值。<br>量化值与实际值之间的误差称为量化误差/量化噪声，量化噪声的功率在数学上表示为：  </p><script type="math/tex; mode=display">N_q=E[(m_k-m_q)^2]=∫_a^b(x-m_q)^2f(x)dx</script><p>$f(x)$是原信号的概率密度函数，原信号需要符合均匀分布才能使用均匀量化。<br>带入$m_i=a+iΔ$，$q_i=a+iΔ+i\frac{Δ}{2}$后化简计算，可以发现<strong>量化噪声的功率只与量化间隔有关。</strong><br>定义量化信噪比为输入的采样信号功率与量化噪声的功率之比：  </p><script type="math/tex; mode=display">\frac{S}{N_q}=\frac{E[(m_k)^2]}{E[(m_k-m_q)^2]}</script><p>从上述结论可以发现，量化噪声与输入信号的功率大小无关，因此小的输入信号功率会导致非常小的量化信噪比。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023140452.png width=50%>  </p><h3 id="非均匀量化"><a href="#非均匀量化" class="headerlink" title="非均匀量化"></a>非均匀量化</h3><p>解决“小的输入信号功率会导致量化信噪比小”这一问题的基本思路是使用一个函数对信号的幅值进行重映射，使其能够扩大小功率时的幅值，缩小大功率时的幅值。这个函数称为压缩律。输入信号经过压缩器使用压扩器增大小功率信号的幅值后，再使用均匀量化就能减小量化信噪比。在接收处，通过压缩率的反函数可以对压缩信号进行还原。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023140905.png width=80%>  </p><p>国际电信联盟（ITU）所采用的两种压缩律分别为A压缩律和μ压缩律，A压缩律在中国和欧盟国家使用，μ压缩律在美国、日本、韩国使用，国际通信时使用A压缩律作为标准。本章只介绍A压缩律。<br>A压缩律可以用如下公式表示：  </p><script type="math/tex; mode=display">y=\begin{cases}    \frac{Ax}{1+lnA},0≤x≤\frac{1}{A}\\    \frac{1+ln(Ax)}{1+lnA},\frac{1}{A}≤x≤1\end{cases}</script><p>其中$x$,$y$分别表示最大值归一化后压扩器的输入和输入信号。  </p><h3 id="A压缩律的数字化"><a href="#A压缩律的数字化" class="headerlink" title="A压缩律的数字化"></a>A压缩律的数字化</h3><p>在数字系统中，压缩律通过折线对模拟压缩律进行近似，ITU规定数字化的A压缩律以13折折线近似，μ压缩律以15折折线近似。对A压缩律，具体的表示方法如下：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023142704.png width=80%>  </p><ol><li><p>将最大值归一化后的$x$轴采用折中法反复折中，划分为8段落（$0-\frac{1}{128}$到$\frac{1}{2}-1$），称为量化段。对于每一个段落，分为16个小区间，称为量化级。最小的区间长度出现在$0-\frac{1}{128}$段，定义$Δ=\frac{1}{128×16}=\frac{1}{2048}$。每一量化段的量化间隔如下表所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023143157.png width=50%>  </p><p>需要注意，声音信号的幅值分布在I象限和III象限，因此量化折线还需要镜像对称到第III象限。由于-2，-1，1，2四个量化段的斜率相等，是同一条线，因此一共使用了13条折线来描述A压缩律（I象限、III象限）。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211023143939.png width=50%></p><p>那么$x$轴一共有256个量化级，可以用8bit进行表示：  </p><script type="math/tex; mode=display">M=2×8×16=2^8</script></li><li>$y$轴平分为8段，每一段间隔相等。  </li><li>连线。  </li></ol><h2 id="编码"><a href="#编码" class="headerlink" title="编码"></a>编码</h2><p>通信系统中常用的编码有三种：  </p><ol><li>自然二进制编码（NBC）</li><li>格雷码</li><li>折叠码（FBC）</li></ol><h3 id="折叠码"><a href="#折叠码" class="headerlink" title="折叠码"></a>折叠码</h3><p>本节着重介绍折叠码，折叠码化需要选取折叠的位置，取折叠码第一位表示极性，即是折叠位置以上（正，1）还是折叠位置以下（负，0），然后出去极性，将值到折叠位置的距离二进制化，得到该值对应的折叠码。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211025180629.png width=80%>  </p><p>折叠码的优势在于，对相同的点平/值，折叠码表示所用的比特数要少于自然二进制编码。此外，折叠码对小信号（0附近的信号）比较友好，当表示极性的比特位发生错误时，对应的电平误差只有1。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211025180940.png width=50%>  </p><h3 id="脉冲编码调制（PCM）"><a href="#脉冲编码调制（PCM）" class="headerlink" title="脉冲编码调制（PCM）"></a>脉冲编码调制（PCM）</h3><p>脉冲编码调制是基于A压缩律的非均匀调制的一种编码方法，是一种折叠码。但是由于声音格式有负幅值，因此其折线位于0处。PCM采用了如下格式进行编码：  </p><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">极性码</th><th style="text-align:center">段落码</th><th style="text-align:center">段内码</th></tr></thead><tbody><tr><td style="text-align:center"></td><td style="text-align:center">$C_1$</td><td style="text-align:center">$C_2C_3C_4$</td><td style="text-align:center">$C_5C_6C_7C_8$</td></tr><tr><td style="text-align:center">意义</td><td style="text-align:center">极性</td><td style="text-align:center">对应8个段落</td><td style="text-align:center">对应每一个段落中的16个量化级</td></tr></tbody></table></div><p>PCM编码与数字化的13折A压缩律对应如下：  </p><div class="table-container"><table><thead><tr><th style="text-align:center">段落编号</th><th style="text-align:center">电平区间</th><th style="text-align:center">段落码</th><th style="text-align:center">量化间隔Δ</th></tr></thead><tbody><tr><td style="text-align:center">1</td><td style="text-align:center">0-16</td><td style="text-align:center">000</td><td style="text-align:center">$1=2^0$</td></tr><tr><td style="text-align:center">2</td><td style="text-align:center">16-32</td><td style="text-align:center">001</td><td style="text-align:center">$1=2^0$</td></tr><tr><td style="text-align:center">3</td><td style="text-align:center">32-64</td><td style="text-align:center">010</td><td style="text-align:center">$2=2^1$</td></tr><tr><td style="text-align:center">4</td><td style="text-align:center">64-128</td><td style="text-align:center">011</td><td style="text-align:center">$4=2^2$</td></tr><tr><td style="text-align:center">5</td><td style="text-align:center">128-256</td><td style="text-align:center">100</td><td style="text-align:center">$8=2^3$</td></tr><tr><td style="text-align:center">6</td><td style="text-align:center">256-512</td><td style="text-align:center">101</td><td style="text-align:center">$16=2^4$</td></tr><tr><td style="text-align:center">7</td><td style="text-align:center">512-1024</td><td style="text-align:center">110</td><td style="text-align:center">$32=2^5$</td></tr><tr><td style="text-align:center">8</td><td style="text-align:center">1024-2048</td><td style="text-align:center">111</td><td style="text-align:center">$64=2^6$</td></tr></tbody></table></div><h3 id="脉冲调制编码过程"><a href="#脉冲调制编码过程" class="headerlink" title="脉冲调制编码过程"></a>脉冲调制编码过程</h3><p>量化后的电平值转化为脉冲调制编码的步骤为：  </p><ol><li><p>判断电平的正负，如果是正：$C_1=1$，如果为负，$C_1=0$。</p><blockquote><p>注意“1正0负”</p></blockquote></li><li><p>根据电平值和电平区间，判断电平落在了哪一个段落，决定段落码$C_2C_3C_4$。  </p></li><li>将电平值减去段落的起始值，与量化间隔相除，结果转化为8421码即为$C_5C_6C_7C_8$。  </li></ol><p>与量化间隔相除结果的余数部分无法通过编码表示，称为编码噪声。<br>由于这样的转换方式比较低效，实际上的通信系统通常采用逐位进行比较的逐次比较法，过程如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211025183903.png width=80%>  </p><h4 id="PCM与NBC的关系"><a href="#PCM与NBC的关系" class="headerlink" title="PCM与NBC的关系"></a>PCM与NBC的关系</h4><p>PCM基于非均匀脉冲，是一种非线性编码。由于之后的通信电路中含有仅支持线性输入的逻辑电路，因此还需要将7bit的PCM转化为11bit的自然二进制编码（NBC），两者之间满足：  </p><script type="math/tex; mode=display">I_{PCM}=I_{NBC}</script><p>即两者编码转化为10进制的结果是相同的。<br>因此PCM编码转为10进制后再转为自然二进制即可得到NBC。  </p><h4 id="PCM的解码"><a href="#PCM的解码" class="headerlink" title="PCM的解码"></a>PCM的解码</h4><p>由于PCM编码只考虑到了每个量化区间内的起始值$m_{i-1}$而并非量化电平$p_i$，在解码过程中需要补充每个量化段的半个量化区间$\frac{Δ_i}{2}$，由于最小的$\frac{Δ_i}{2}=0.5$，因此需要额外补充一个bit来弥补增加的精度。  </p><h3 id="PCM的抗噪性分析"><a href="#PCM的抗噪性分析" class="headerlink" title="PCM的抗噪性分析"></a>PCM的抗噪性分析</h3><h4 id="传输速率"><a href="#传输速率" class="headerlink" title="传输速率"></a>传输速率</h4><p>PCM的传输速率为：  </p><script type="math/tex; mode=display">TransmitionRate=f_s×log_2^M</script><p>其中$f_s$为采样速率，$M$为比特数，A律13折PCM中$M=8$。  </p><h4 id="信噪比"><a href="#信噪比" class="headerlink" title="信噪比"></a>信噪比</h4><p>解码器端解码后的信号可以表示为：  </p><script type="math/tex; mode=display">\hat{m}(t)=m_0(t)+n_q(t)+n_e(t)</script><p>$n_q(t)$为量化噪声，$n_e(t)$为传输过程中的高斯白噪声。<br>因此整个过程的信噪比表示为：  </p><script type="math/tex; mode=display">\frac{S_o}{N_o}_{PCM}=\frac{\overline{m^2(t)}}{N_q+N_e}</script><p>通过计算可以发现，当$m(t)$服从均匀分布时，量化信噪比表示为：  </p><script type="math/tex; mode=display">\frac{S}{N_q}=M^2</script><h2 id="时分复用"><a href="#时分复用" class="headerlink" title="时分复用"></a>时分复用</h2><p>时分复用（TDM）可以达到在一个小时间段内同时传输多条信号的目的。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211101182433.png width=80%>  </p><p>如上图所示，多路信号作为输入，每一路的输入信号都要通过一个低通滤波器以保证信号的最高频小于$f_H$(对于声音信号是3400Hz)，保证采样时可以抽取到所有的信息。此后，多路信号汇合，通过一个抽样转盘，该抽样转盘会在一个周期内均匀地抽取每一路信号的一部分，对于声音信号，抽样转盘的采样频率为$f_s=8000Hz$。<br>在解码端也存在一个与发送端频率完全相同的抽样转盘，该转盘在一个周期内会将经过时分复用后的信号还原分配给每一路信号。  </p><p>对于每一路信号，抽样转盘能够提取这路信号的时间段称为一个路时隙$T_a$（Time slot），每一路信号的一个路时隙组成一帧（Frame），即抽样转盘的采样周期$T_s$，二者存在如下关系：  </p><script type="math/tex; mode=display">T_a=\frac{T_s}{n}</script><p>$n$表示信号的路数。<br>对于PCM信号，每一路信号的一个路时隙信息量为8bit，即一个路时隙的字长$l=8bit$，因此对于TDM-PCM信息传输速率可以表示为：  </p><script type="math/tex; mode=display">R_B=R_b=nlf_s</script><p>$f_s$为转盘的抽样频率。  </p><h3 id="占空比"><a href="#占空比" class="headerlink" title="占空比"></a>占空比</h3><p>对每一帧而言，其中电平不为0的时间段（即信息传输的时间）称为符号持续时间$τ$（Symbol duration），定义占空比（Duty Cycle）表示符号持续时间和一个周期时间之比：  </p><script type="math/tex; mode=display">Duty.Cycle=\frac{τ}{T_s}×100\%</script><p>当$τ=T_s$时，表示一个周期内所有时间都在发送符号，称为归零码（RZ Code），$τ≠T_s$时，称为不归零码（NRZ Code）。  </p><h3 id="30-32-PCM-基群结构"><a href="#30-32-PCM-基群结构" class="headerlink" title="30/32 PCM 基群结构"></a>30/32 PCM 基群结构</h3><p>30/32 PCM 基群结构是我国普遍使用的TDM-PCM方式，一帧有32个路时隙，其中有2个路时隙用于传输同步信号，剩余的30个路时隙用于传输信息。<br>其中TS0用于传输同步码、监视码、对端告警码组（简称对告码）；TS16用于传输信令码；TS1—TS15传前15个话路的话音数字码，TS17—TS31传输后15个话路的话音数字码。<br>此外还有16个复帧（Multi-frame）用于特殊用途（如定位信号，CRC校验码，信令传输等等）。  </p><blockquote><p>信令是用来表示通话状态的一系列信息，如：摘机、挂机信号、拨号、忙音等。  </p></blockquote><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211101184749.png width=80%>  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 定时器</title>
    <link href="/2021/10/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/5.%20timers/"/>
    <url>/2021/10/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/5.%20timers/</url>
    
    <content type="html"><![CDATA[<h1 id="定时器"><a href="#定时器" class="headerlink" title="定时器"></a>定时器</h1><h2 id="电容器的充放电特性"><a href="#电容器的充放电特性" class="headerlink" title="电容器的充放电特性"></a>电容器的充放电特性</h2><p>在RC电路中，当电容与电压源连通时电容会进行充电，而断开连接后电容器会放电，充电和放电的过程电容器的电压和电流都随着时间的变化而变化。设时间常数$τ=RC$，分析电容器充放电过程的特性。  </p><h3 id="电容器的充电特性"><a href="#电容器的充电特性" class="headerlink" title="电容器的充电特性"></a>电容器的充电特性</h3><p>充电时电容器上的电压会随着时间增大：  </p><script type="math/tex; mode=display">V=V_0(1-e^{-\frac{t}{τ}})</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022194059.png width=50%>  </p><p>经过$1τ$，电容器电压达到最大值的62%，经过$5τ$时可以认为电容器已经充满电。<br>电流随着时间逐渐变为0:  </p><script type="math/tex; mode=display">I=I_0e^{-\frac{t}{τ}}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022193952.png width=50%>  </p><p>同样地，经过$1τ$，电容器电流流失到原来的37%，经过$5τ$时可以认为没有电流通过电容器。  </p><h3 id="电容器的放电特性"><a href="#电容器的放电特性" class="headerlink" title="电容器的放电特性"></a>电容器的放电特性</h3><p>放电时，电容器的电压变化与充电时相反，随着时间的推移，电压逐渐流失：  </p><script type="math/tex; mode=display">V=V_0e^{-\frac{t}{τ}}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022194713.png width=50%>  </p><p>经过$1τ$，电容器电流流失到原来的37%，经过$5τ$时可以认为没有电流通过电容器。<br>同时，电流也随着时间逐渐流失，与充电过程不同的是，电流流失的方向是相反的：  </p><script type="math/tex; mode=display">I=-I_0e^{-\frac{t}{τ}}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022194804.png width=50%>  </p><p>与电压流失相同，经过$1τ$，电容器电流流失到原来的37%，经过$5τ$时可以认为没有电流通过电容器。  </p><h3 id="三角波发生器"><a href="#三角波发生器" class="headerlink" title="三角波发生器"></a>三角波发生器</h3><p>利用电容器的充放电性质，可以让输入电压周期性地打开和关闭与电容的连接，电容器会不断地进行充放电，形成三角波形。事实上“周期性地打开和关闭”的效果与输入信号为方波时相同。<br>理想条件下，可以由此设计三角波发生器，其电路完全等同于低通滤波器。<br>需要注意的是，考虑到电容器的完全充放电是需要时间的，输入信号的频率应该比较低，以给予电容器合适的充放电时间。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022195421.png width=50%>  </p><p>将上述的电路进一步改进，得到如下的电路：<br>该电路由两部分组成：  </p><ol><li>由直流电压源、电阻和电容组成的三角波发生器电路，该电路在电容和电压源附近各有一个开关，如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022200001.png width=50%>  <ul><li>当$S_1$闭合、$S_2$打开时，电压源会向电容器充电。  </li><li>当$S_1$打开、$S_2$闭合时，电容器会放电到$R_2$。<br>因此该电路通过控制$S_1$、$S_2$的开闭来控制电容器的充放电。  </li></ul></li><li>$S_1$、$S_2$开关连接至RS触发器电路，RS触发器的R端和S端分别连接两个比较器，如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022200338.png width=50%>  <ul><li>当输入电压$V_{in}&gt;V_1$时，上方的比较器向触发器的S端发送高电平，而下方比较器由于$V_2&gt;V_{in}$则不会向R端发送高电平，此时RS触发器的输入逻辑：$S=1,R=0$，根据RS触发器的真值表可以得到$Q=1,\overline{Q}=0$，$S_1$闭合、$S_2$打开时，电压源会向电容器充电。  </li><li>当输入电压$V_{in}&lt;V_1$时，下方的比较器向触发器的R端发送高电平，而上方比较器由于$V_{in}&lt;V_1$则不会向S端发送高电平，此时RS触发器的输入逻辑：$S=0,R=1$，根据RS触发器的真值表可以得到$Q=0,\overline{Q}=1$，$S_1$打开、$S_2$闭合，使电容器放电。  </li></ul></li></ol><blockquote><p>RS 触发器真值表：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022205217.png width=50%>  </p></blockquote><p>当输入$V_{in}$是一个正弦波或者方波时，与$V_1$、$V_2$的大小关系会被自动触发，从而形成稳定而连续的三角波波形，其波形如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022201022.png width=50%>  </p><h2 id="555定时器"><a href="#555定时器" class="headerlink" title="555定时器"></a>555定时器</h2><p>555定时器是一种利用电容器充放电性质的电路元件，它可以通过直流电压输出稳定的方波。其元件内部结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022201421.png width=80%>  </p><p>其中的NPN晶体管作用类似于开关。上方三个$5kΩ$的分压器将输入电压$V_{cc}$分割成$\frac{2}{3}V_{cc}$和$\frac{1}{3}V_{cc}$并分别送入比较器2、1。其中比较器2将$\frac{2}{3}V_{cc}$与外接电压Threshold进行比较，比较器1将$\frac{1}{3}V_{cc}$与外接电压Trigger进行比较，以控制SR触发器的输入。<br>同时，555定时器还支持使用ControlVoltage替代$\frac{2}{3}V_{cc}$作为比较电压。SR触发器的输出为Ouput和Reset。<br>555定时器有三种工作状态（电路连接方式）：非稳态、单稳态和多稳态，这三种连接分别可以产生三种不同的方波波形。  </p><h3 id="非稳态模式"><a href="#非稳态模式" class="headerlink" title="非稳态模式"></a>非稳态模式</h3><p>非稳态模式(Astable)下555定时器的连接图如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022210029.png width=80%></p><p>如图，VCC分别作为内部和外部电路的电压源，外部电路是一个基本的RC电路。而外部电路的输出端与Threshold和Trigger连接，从而起到自我触发的效果。<br>开始时电容器充电，当$Threshold&gt;\frac{2}{3}V_{cc}$时，SR触发器输入逻辑为：$R=1,S=0$，输出为低电平，同时由于$\overline{Q}=1$，NPN晶体管被导通，电容器开始放电。<br>当$Threshold&lt;\frac{2}{3}V_{cc}$时，SR触发器输入逻辑为：$R=0,S=1$，输出为高电平，同时由于$\overline{Q}=0$，NPN晶体管关断，电容器充电。<br>此后，由于Threshold/Trigger电压的变化，电容器会不断地进行充放电，从而在输出端产生稳定的高低电平方波，而电容器处产生稳定的锯齿波三角波，且周期占空比与输出的方波信号完全相同:<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022210401.png width=50%>  </p><p>可以发现锯齿波/三角波的上下限为$\frac{2}{3}V_{CC}$和$\frac{1}{3}V_{CC}$。  </p><p>在电路连接时往往还会增加另一个电容$C_2$以提高电路的稳定性。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104164835.png width=50%>  </p><h4 id="有关计算"><a href="#有关计算" class="headerlink" title="有关计算"></a>有关计算</h4><p>在电容器充电过程，电流实际上流过了外部的两个电阻$R_1、R_2$，因此充电过程的时间常数：$τ_1=(R_1+R_2)C_1$。<br>放电过程中电流只流过了$R_2$,因此放电过程的时间常数：$τ_2=R_2C_1$。<br>根据数学推导得到充电时间：   </p><script type="math/tex; mode=display">t_{char}=ln2(R_1+R_2)C_1</script><p>放电时间：  </p><script type="math/tex; mode=display">t_{Discr}=ln2R_2C_1</script><p>周期：  </p><script type="math/tex; mode=display">T=t_{char}+t_{Discr}=ln2(R_1+2R_2)C_1</script><p>振荡频率：  </p><script type="math/tex; mode=display">f_r=\frac{1}{T}=\frac{1.44}{(R_1+2R_2)C_1}</script><p>定义输出波形一周期内的高电平出现时间占整个周期时间的比例为占空比，有：  </p><script type="math/tex; mode=display">Duty Cyecle=\frac{R_1+R_2}{R_1+2R_2}× 100\%</script><p><strong>因此，非稳态的555定时器输出的方波可以通过改变$R_1$和$R_2$的值改变占空比。</strong><br>可以发现这种基本的非稳态555振荡器配置的问题在于占空比，因为电阻$R_2$的存在使得占空比永远大于50%。<br>换句话说，该电路不能使输出“ON”时间短于“OFF”时间，因为$(R_1 + R_2)C$ 总是大于$R_1C$的值。  </p><blockquote><p>当$R_2$远大于$R_1$时，$Duty Cyecle=50\%$。  </p></blockquote><p><strong>$V_{Control}$对输出波形的影响</strong>：<br>充放电时间中的参数$ln2$实际上是由$\frac{1}{3}V_{CC}$和$\frac{2}{3}V_{CC}$进行决定的：  </p><script type="math/tex; mode=display">Const=ln\frac{V_{CC}-0.5V_{Control}}{V_{CC}-V_{Control}}</script><p>当$V_{CC}=15V,V_{Control}=\frac{2}{3}V_{CC}$时，$Const=ln2$。<br>如果Pin5：Control-Voltage接入直流电压，则$V_{Control}≠\frac{2}{3}V_{CC}$。<br>此时产生的三角波的上下限应该为：$\frac{1}{3}V_{CC}-V_{Control}$。<br>输出的方波周期发生变化，高电平和低电平的持续时间同比例增加或者减小，占空比仍然保持不变。  </p><h4 id="50-占空比555稳定器"><a href="#50-占空比555稳定器" class="headerlink" title="50%占空比555稳定器*"></a>50%占空比555稳定器*</h4><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104165149.png width=50%>   </p><p>555振荡器现在产生50％的占空比作为定时电容， $C_1$ 现在通过相同的电阻器充电和放电， $R_2$ 而不是如前所述通过定时器放电引脚7放电。当555振荡器的输出为高电平时，电容器通过 $R_2$ 充电，当输出为低电平时，它通过 $R_2$ 放电。电阻器 $R_1$ 用于确保电容器完全充电至与电源电压相同的值。</p><h3 id="单稳态模式"><a href="#单稳态模式" class="headerlink" title="单稳态模式*"></a>单稳态模式*</h3><p>单稳态模式由于振荡电容器$C_1$直接接地，因此电容器在充电后直接放电至接地，所以在单稳态模式下，555定时器的输出只会产生一个方波信号，其电路图如下所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211022211852.png width=80%><br>方波信号的持续时间：  </p><script type="math/tex; mode=display">τ=1.1R_1C_1</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7. 非线性调制和解调方法</title>
    <link href="/2021/10/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/7.%20%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%B0%83%E5%88%B6%C2%B7%E8%A7%A3%E8%B0%83/"/>
    <url>/2021/10/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/7.%20%E9%9D%9E%E7%BA%BF%E6%80%A7%E8%B0%83%E5%88%B6%C2%B7%E8%A7%A3%E8%B0%83/</url>
    
    <content type="html"><![CDATA[<h1 id="非线性调制和解调方法"><a href="#非线性调制和解调方法" class="headerlink" title="非线性调制和解调方法"></a>非线性调制和解调方法</h1><p>载波信号：  </p><script type="math/tex; mode=display">C(t)=Acos(ω_ct+φ_0)</script><p>除了可以用载波信号的幅度携带基带信号之外，还可以用基带信号的角频率和相位携带基带信号，这两种方法都是非线性调制。<br>非线性调制的后信号的频谱会有额外增加的频率成分。<br>通常非线性调制的带宽远远大于线性调制的带宽，因此非线性调制通过牺牲其有效性增加可靠性。  </p><h2 id="调相"><a href="#调相" class="headerlink" title="调相"></a>调相</h2><p>设载波可以表示为：$φ(t)=K_pm(t)$<br>其中$K_p$称为相位敏感度（Phase Sensitivity）。  </p><script type="math/tex; mode=display">S_{PM}=Acos(ω_ct+K_pm(t))</script><p>当$m(t)=A_mcosω_mt$时：  </p><script type="math/tex; mode=display">S_{PM}(t)=Acos(ω_ct+K_pA_mcosω_mt)</script><p>称$m_P=K_pA_m$为调相指数：  </p><script type="math/tex; mode=display">S_{PM}(t)=Acos(ω_ct+m_Pcosω_mt)</script><h2 id="调频"><a href="#调频" class="headerlink" title="调频"></a>调频</h2><p>调频将基带信号携带到相位分量的微分形式上：$\frac{dφ(t)}{dt}=K_fm(t)$。<br>其中$K_f$称为频率敏感度（Frequency Sensitivity）。  </p><script type="math/tex; mode=display">S_{FM}=Acos[ω_ct+K_f∫m(t)dt]</script><p>当$m(t)=A_mcosω_mt$时：  </p><script type="math/tex; mode=display">S_{FM}=Acos[ω_ct+\frac{K_fA_m}{ω_m}sinω_mt]</script><p>称$m_f=\frac{K_fA_m}{ω_m}$为调相指数：  </p><script type="math/tex; mode=display">S_{FM}(t)=Acos(ω_ct+m_fsinω_mt)</script><h3 id="调频的非相干解调"><a href="#调频的非相干解调" class="headerlink" title="调频的非相干解调"></a>调频的非相干解调</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211018184136.png width=50%>  </p><p>调频可以通过非相干解调进行，输出的信号为：  </p><script type="math/tex; mode=display">s_o(t)=K_d[ω_c+K_fm(t)]</script><p>通过低通滤波器：   </p><script type="math/tex; mode=display">s_o(t)=K_dK_fm(t)</script><h3 id="调频的相干解调（窄带信号）"><a href="#调频的相干解调（窄带信号）" class="headerlink" title="调频的相干解调（窄带信号）"></a>调频的相干解调（窄带信号）</h3><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211018184413.png width=50%>  </p><p>窄带信号的调频输出信号为：  </p><script type="math/tex; mode=display">m_o(t)=\frac{A}{2}K_fm(t)</script><h3 id="宽带调频参数"><a href="#宽带调频参数" class="headerlink" title="宽带调频参数"></a>宽带调频参数</h3><p>宽带调频时，其带宽存在如下关系：  </p><script type="math/tex; mode=display">B_{FM}≈2(Δf+f_H)=2(m_f+1)f_H</script><p>其中$Δf$是最大频率分量。<br>调频后的能量：  </p><script type="math/tex; mode=display">P_{FM}=\frac{A^2}{2}</script><p>调频的信噪比增益：  </p><script type="math/tex; mode=display">G=3m_f^2(m_f+1)</script><h2 id="调频和调相的关系"><a href="#调频和调相的关系" class="headerlink" title="调频和调相的关系"></a>调频和调相的关系</h2><p>$f(t)$积分后的信号通过积分器后调相的结果是其调频结果。<br>$f(t)$微分后的信号通过微分器后调频的结果是其调相结果。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211018183409.png width=50%>  </p><p>所有调制方法的信噪比增益如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211018184536.png width=50%></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. 振荡器</title>
    <link href="/2021/10/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/4.%20Osillator/"/>
    <url>/2021/10/17/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/4.%20Osillator/</url>
    
    <content type="html"><![CDATA[<h1 id="振荡器"><a href="#振荡器" class="headerlink" title="振荡器"></a>振荡器</h1><h2 id="巴克豪森稳定性准则"><a href="#巴克豪森稳定性准则" class="headerlink" title="巴克豪森稳定性准则"></a>巴克豪森稳定性准则</h2><p>反馈放大器在提升增益的同时降低了放大器的稳定性，可以利用反馈放大器在高增益下低稳定性的特点制作振荡器，使得输入的直流信号能够被振荡从而产生交流信号。<br>振荡器电路的框图如下：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211017143453.png width=50%>  </p><p>要形成稳定的振荡波形，反馈电路中不能有外源输入存在，或者说外源输入对其无影响，根据反馈的$G=\frac{V_{o}}{V_{in}}=\frac{A}{1+AB}$可知，当$|AB|=1$时可以满足这一条件。<br>此外，反馈信号的相位和输入信号的相位相同，否则在叠加时产生的相移会使振荡不均匀。<br>因此，制造稳定振荡的两个条件：</p><ol><li><p>对于反馈：$G=\frac{A_v}{1+A_vB}$，$|AB|=1$：   </p><ul><li>当$|AB|&gt;1$时，每一次反馈都会加强信号，无法产生稳定的振荡波形：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104144246.png width=30%>  </li><li>当$|AB|<1$时，每一次反馈都会削弱信号，无法产生稳定的振荡波形：  <img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104144334.png width=30%>  </li><li>当$|AB|=1$时，每一次的反馈信号和输入信号相同，可以产生稳定的振荡波形：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211104144501.png width=30%>  </li></ul></li><li><p>反馈信号的相位与放大电路输入信号的相位相同。</p><ul><li>对于正反馈放大器，其反馈信号的相位和输入信号的相位相同。</li><li>对于负反馈放大器，反馈信号的相位和输入信号的相位相差180°，因此需要人为添加相移器对相移进行复位。    </li></ul></li></ol><p>这两个条件称为<strong>巴克豪森稳定性准则</strong>。满足这两个条件的反馈电路才可以产生稳定的正弦波。  </p><h2 id="文氏电桥振荡器"><a href="#文氏电桥振荡器" class="headerlink" title="文氏电桥振荡器"></a>文氏电桥振荡器</h2><p>由于正反馈放大器可以带来振荡，负反馈放大器可以带来稳定性，文氏电桥振荡器结合了上述两种反馈放大器的优点，其电路如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211101214746.png width=50%><br>文氏电桥振荡器的 正相输入端连接的是一个由RC组成的带通滤波器电路，与正相输入端构成振荡电路，产生振荡。 其中带通滤波器的电路如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211017140810.png width=50%><br>这个带通滤波器的作用是选择特定频率的信号传入正反馈放大器，从而产生振荡。<br>其频率响应特性曲线如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211017141408.png width=50%>  </p><p>可以发现，当信号频率为:  </p><script type="math/tex; mode=display">f_r=\frac{1}{2πRC}</script><p>时，带通滤波器的相移为0，满足条件2。<br>反相输入端与$R_1$、$R_2$构成一个负反馈放大器电路，通过控制反馈电阻可以使得$|AB|=1$，满足条件1。<br>通过数学计算$|AB|=1$可以发现，这个结果取决于放大器的电压增益$A_v$，当电压增益$A_v=1+\frac{R_f}{R_g}≥3$时才能满足这一条件。  </p><blockquote><p>这一部分的数学推导：<a href="https://blog.csdn.net/weixin_43996900/article/details/106189102">https://blog.csdn.net/weixin_43996900/article/details/106189102</a>  </p></blockquote><h2 id="相移振荡器"><a href="#相移振荡器" class="headerlink" title="相移振荡器"></a>相移振荡器</h2><p>由于负反馈放大器本身可以满足$|AB|=1$的条件，另一种满足相移条件的方式是将负反馈放大器连接到相移器电路上，当相移器能够实现信号相移180°时即可使电路输出稳定的正弦波。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211017150508.png width=50%>  </p><h3 id="相移器"><a href="#相移器" class="headerlink" title="相移器"></a>相移器</h3><p>相移器通过高通滤波器的并联实现，根据高通滤波器的频率响应关系和相移公式可知：  </p><script type="math/tex; mode=display">Δφ=arctan\frac{X_c}{R}</script><p>通过调整电路中RC的值即可使其在输入信号频率$f_r$固定的情况下产生特定的相移。<br>当高通滤波器并联时，要使相移平均到高通滤波器，有如下公式：  </p><script type="math/tex; mode=display">f_r=\frac{1}{2πRC\sqrt{2N}}</script><p>其中$N$代表高通滤波器的个数，它与相移之间满足如下关系:</p><script type="math/tex; mode=display">Δφ=\frac{N}{180°}</script><p>需要注意的是，$N$的值越大，所需要的器件越多，同时由于每个高通滤波器在$f_r$处的增益都小于0，对所连接的运算放大器电压增益的要求也更高：运算放大器的电压增益需要大于所有高通滤波器在$f_r$的增益之和，该电路才能正常工作。通常认为<strong>$A_v≥29$</strong>。<br>同时，根据高通滤波器的频率响应图可知，二阶90°相移器的</p><h2 id="松弛振荡器"><a href="#松弛振荡器" class="headerlink" title="松弛振荡器"></a>松弛振荡器</h2><p>松弛振荡器电路如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/312px-OpAmpHystereticOscillator.svg.png width=50%>  </p><p>其反相输入端可以看做是一个振荡电路，通过电容的充放电可以产生三角波，而同相输入端可以看做是一个同相放大器。<br>当所有电阻阻值、所有电容阻值都相等时，有电路的谐振频率：  </p><script type="math/tex; mode=display">f_r=\frac{1}{2.2RC}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211017151737.png width=50%></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 离散傅里叶级数·离散傅里叶变换</title>
    <link href="/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/5.%20%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%C2%B7%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/5.%20%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0%C2%B7%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="离散傅里叶级数·离散傅里叶变换"><a href="#离散傅里叶级数·离散傅里叶变换" class="headerlink" title="离散傅里叶级数·离散傅里叶变换"></a>离散傅里叶级数·离散傅里叶变换</h1><h2 id="复指数序列的周期性"><a href="#复指数序列的周期性" class="headerlink" title="复指数序列的周期性"></a>复指数序列的周期性</h2><p>$x[n]=e^{jω_0n}$，由于$ω_0∈[0,2π)$的周期性，因此有：$x[n]=e^{jω_0n}=e^{j(ω_0+2πk)n}$，令$ω_0N=2πk,k∈Z$，有：  </p><script type="math/tex; mode=display">x[n]=e^{jω_0n}=e^{j(ω_0+2πk)n}=x[n+N]</script><p>复指数序列$x[n]$具有周期性，称$N$为其周期。<br>由于$ω_k=\frac{2πk}{N}∈[0,2π)$，因此当序列周期为$N$时，当且仅当$k=0,1,2,…,N-1$时存在$N$个不同的$ω_k$。$N=\frac{2πk}{ω_0}$。  </p><h2 id="离散傅里叶级数（DFS）"><a href="#离散傅里叶级数（DFS）" class="headerlink" title="离散傅里叶级数（DFS）"></a>离散傅里叶级数（DFS）</h2><p>根据连续时间周期信号的傅里叶变换：  </p><script type="math/tex; mode=display">x(t)=∑_{k=-∞}^∞X(kΩ_0)e^{jkΩ_0t}</script><p>其中连续信号的角频率为：$Ω_0=\frac{2π}{T}$<br>类比连续时间周期信号，设周期序列$\tilde{x}[n]$:$\tilde{x}[n]=\tilde{x}[n+rN],r∈Z$，有：  </p><script type="math/tex; mode=display">\tilde{x}[n]=∑_{k=-∞}^∞X(kΩ_0)e^{j\frac{2π}{N}kn}</script><p>由于满足条件的频率分量$ω_k$只有$N$个：  </p><script type="math/tex; mode=display">\begin{aligned}    \tilde{x}[n]&=∑_{k=-∞}^∞X(kΩ_0)e^{j\frac{2π}{N}kn}\\    &=∑_{k=0}^{N-1}X(kΩ_0)e^{j\frac{2π}{N}kn}\\    &=\frac{1}{N}∑_{k=0}^{N-1}\tilde{X}[k]e^{j\frac{2π}{N}kn}\end{aligned}</script><p>其中$\tilde{X}[k]$为离散傅里叶级数系数，可反推得到：  </p><script type="math/tex; mode=display">\tilde{X}[k]=∑_{k=0}^{N-1}\tilde{x}[n]e^{-j\frac{2π}{N}kn}</script><p>定义$W_N^{kn}=e^{-j(\frac{2π}{N})kn}$，有离散傅里叶级数分析：  </p><script type="math/tex; mode=display">\tilde{X}[k]=∑_{k=0}^{N-1}\tilde{x}[n]W_N^{kn}</script><p>离散傅里叶级数合成：  </p><script type="math/tex; mode=display">\tilde{x}[n]=\frac{1}{N}∑_{k=0}^{N-1}\tilde{X}[k]W_N^{-kn}</script><blockquote><p>$W_N^{kn}$是复数的角度表示形式，一般计算时转化为z域中的坐标以方便计算。如:$W_4^2=e^{-j\frac{2π}{4}×2}=-1$  </p></blockquote><h3 id="离散傅里叶级数的意义"><a href="#离散傅里叶级数的意义" class="headerlink" title="离散傅里叶级数的意义"></a>离散傅里叶级数的意义</h3><p><strong>周期为$N$的序列可以表示为$N$个周期为$N$的复指数序列的线性组合</strong>。  </p><h4 id="离散傅里叶级数与离散时间傅里叶变换（DTFT）的关系"><a href="#离散傅里叶级数与离散时间傅里叶变换（DTFT）的关系" class="headerlink" title="离散傅里叶级数与离散时间傅里叶变换（DTFT）的关系"></a>离散傅里叶级数与离散时间傅里叶变换（DTFT）的关系</h4><p>事实上，可以将离散傅里叶级数看作是<strong>对离散时间傅里叶变换结果$X(e^{jω})$以周期为$N$做延拓后，对其进行采样的结果。</strong><br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211014165116.png width=50%>  </p><h4 id="离散傅里叶级数与Z变换的关系"><a href="#离散傅里叶级数与Z变换的关系" class="headerlink" title="离散傅里叶级数与Z变换的关系"></a>离散傅里叶级数与Z变换的关系</h4><p>给定Z变换：$X(z)|_{z=e^{jω}}=X(e^{jω})$，那么：  </p><script type="math/tex; mode=display">\tilde{X}[k]=X(z)|_{z=e^{j(2π/N)k}}=X(e^{j(2π/N)k}),k=0,1,...,N-1</script><p>即离散傅里叶级数可以看做是在Z变换的单位圆上做均匀采样的结果。  </p><h3 id="离散傅里叶级数的性质"><a href="#离散傅里叶级数的性质" class="headerlink" title="离散傅里叶级数的性质"></a>离散傅里叶级数的性质</h3><ol><li>周期性：如果$\tilde{x}[n]$的周期为$N$，$\tilde{X}[k]$的周期同样为$N$。  </li><li>线性：$a\tilde{x_1}[n]+b\tilde{x_2}[n]↔a\tilde{X_1}[k]+b\tilde{X_2}[k]$  </li><li>时移：$\tilde{x}[n-m]↔W^{km}_N\tilde{X}[k]$  </li><li>频移：$\tilde{X}[k-l]↔W^{-nl}_N\tilde{x}[n]$  </li><li>对偶性：如果$\tilde{x}[n]↔\tilde{X}[k]$，那么$\tilde{X}[n]↔N\tilde{x}[-k]$</li></ol><h4 id="周期卷积定理"><a href="#周期卷积定理" class="headerlink" title="周期卷积定理"></a>周期卷积定理</h4><p>如果两个序列$\tilde{x_1}[n]$、$\tilde{x_2}[n]$有相同的周期$N$，有:</p><script type="math/tex; mode=display">\tilde{x_1}[n]\tilde{⊕}\tilde{x_2}[n]=∑_{m=0}^{N-1}\tilde{x_1}[m]\tilde{x_2}[n-m]↔\tilde{X_1}[k]\tilde{X_2}[k]</script><p>周期卷积定理可以被矩阵化为：  </p><script type="math/tex; mode=display">\tilde{x}[n]\tilde{⊕}\tilde{y}[n]=\left[\begin{matrix}    \tilde{z}[0] \\    \tilde{z}[1] \\    ...\\    \tilde{z}[N-2] \\    \tilde{z}[N-1]\end{matrix}\right]|_{periodic}=\left[\begin{matrix}    \tilde{y}[0] & \tilde{y}[N-1] & ...& \tilde{y}[2] & \tilde{y}[1]\\    \tilde{y}[1] & \tilde{y}[0] & ...& \tilde{y}[3] & \tilde{y}[2]\\    ...&...&...&...&...\\    \tilde{y}[N-2] & \tilde{y}[N-1] & ...& \tilde{y}[0] & \tilde{y}[N-1]\\    \tilde{y}[N-1] & \tilde{y}[N-2] & ...& \tilde{y}[1] & \tilde{y}[0]\\\end{matrix}\right]\left[\begin{matrix}    \tilde{x}[0] \\    \tilde{x}[1] \\    ...\\    \tilde{x}[N-2] \\    \tilde{x}[N-1]\end{matrix}\right]</script><p>可以发现矩阵$Y$内部每一列的元素在进行周期新的位置轮换。<br>周期卷积计算可以在MATLAB®中使用命令<code>toeplitz(x,y)</code>得到，其中<code>x</code>,<code>y</code>为两个周期序列单周期内所有元素组成的向量，两个向量长度相同。  </p><blockquote><p>当两向量长度不等时，使用0进行补齐。  </p></blockquote><h2 id="离散傅里叶变换（DFT）"><a href="#离散傅里叶变换（DFT）" class="headerlink" title="离散傅里叶变换（DFT）"></a>离散傅里叶变换（DFT）</h2><p>当离散傅里叶序列变换的对象变成非周期有限长度序列时，此时的变换称为离散傅里叶变换（DFT）：  </p><script type="math/tex; mode=display">X[k]=∑_{k=0}^{N-1}x[n]W_N^{kn},0≤n≤N-1</script><p>其反变换为：  </p><script type="math/tex; mode=display">x[n]=\frac{1}{N}∑_{k=0}^{N-1}X[k]W_N^{-kn},0≤n≤N-1</script><h3 id="离散傅里叶变换-DFT-、离散傅里叶级数（DFS）、离散时间傅里叶变换（DTFT）的关系"><a href="#离散傅里叶变换-DFT-、离散傅里叶级数（DFS）、离散时间傅里叶变换（DTFT）的关系" class="headerlink" title="离散傅里叶变换(DFT)、离散傅里叶级数（DFS）、离散时间傅里叶变换（DTFT）的关系"></a>离散傅里叶变换(DFT)、离散傅里叶级数（DFS）、离散时间傅里叶变换（DTFT）的关系</h3><p>不难看出周期序列$\tilde{x}[n]$做傅里叶级数分析后一周期内（$0≤n≤N-1$）的结果与$x[n]$做离散傅里叶变换的结果完全一致。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211016143431.png width=50%></p><p>可以发现：<strong>离散傅里叶级数是对离散时间傅里叶变换的结果进行采样，而一周期内的采样结果则为离散傅里叶变换的结果。</strong>  </p><h3 id="离散傅里叶变换的性质"><a href="#离散傅里叶变换的性质" class="headerlink" title="离散傅里叶变换的性质"></a>离散傅里叶变换的性质</h3><ol><li>线性：$a{x_1}[n]+b{x_2}[n]↔a{X_1}[k]+b{X_2}[k],0≤k≤N-1$  </li><li>对偶性:如果${x}[n]↔{X}[k]$，那么$\tilde{X}[n]↔N{x}[(-k)mod(N)],0≤k≤N-1$</li><li>循环时移：$x[(n-m)mod(N)]↔W^{km}_NX[k],0≤k≤N-1$</li></ol><blockquote><p>$(n+m)modN$运算的含义是取序列的$0-N$部分以$N$为周期进行延拓，延拓后的序列向左平移$m$个单位，取现在序列$0-N$的结果。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211016144821.png width=50%></p></blockquote><h4 id="循环卷积定理"><a href="#循环卷积定理" class="headerlink" title="循环卷积定理"></a>循环卷积定理</h4><p>如果$\tilde{x_1}[n]$、$\tilde{x_2}[n]$分别对应是$x_1[n]$、$x_2[n]$以周期为$N$的延拓，有：  </p><script type="math/tex; mode=display">x_1[n]⊕_Nx_2[n]=\tilde{x_1}[n]\tilde{⊕}\tilde{x_2}[n]</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 线性调制的解调方法·抗噪性</title>
    <link href="/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/6.%20%E7%BA%BF%E6%80%A7%E8%A7%A3%E8%B0%83/"/>
    <url>/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/6.%20%E7%BA%BF%E6%80%A7%E8%A7%A3%E8%B0%83/</url>
    
    <content type="html"><![CDATA[<h1 id="线性调制的解调方法·抗噪性"><a href="#线性调制的解调方法·抗噪性" class="headerlink" title="线性调制的解调方法·抗噪性"></a>线性调制的解调方法·抗噪性</h1><p>线性调制的解调方法分为两种，其一为相干解调，适用于所有线性调制方法。其二为非相干解调（包络解波法），仅适用于调幅。  </p><h2 id="相干解调"><a href="#相干解调" class="headerlink" title="相干解调"></a>相干解调</h2><p>相干解调法适用于所有的线性调制，其过程如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211016153554.png width=50%>  </p><p>如图，当信号传入解调端后，信号与另一个同频同相的载波相乘，通过低通滤波器过滤出直流分量即可得到复原后的信号$m_o(t)$。</p><h3 id="调幅、双边带调制的相干解调"><a href="#调幅、双边带调制的相干解调" class="headerlink" title="调幅、双边带调制的相干解调"></a>调幅、双边带调制的相干解调</h3><p>对于调幅（AM）：<br>输入进解调部分的信号:$S_{AM}(t)=[A_0+m(t)]cos(ω_ct+φ_0)$。<br>这个信号将与一个同频同相的载波相乘：  </p><script type="math/tex; mode=display">\begin{aligned}    ρ(t)&=[A_0+m(t)]cos(ω_ct+φ_0)cos(ω_ct+φ_0)\\    &=\frac{1}{2}[A_0+m(t)][cos(φ_0-φ_0)+cos(2ω_ct+2φ_0)]\end{aligned}</script><p>由于通常载波频率$ω_c$非常的高，因此通过低通滤波器时$cos(2ω_ct+2φ_0)$一项被过滤掉，只留下直流分量：  </p><script type="math/tex; mode=display">m_0=\frac{1}{2}[A_0+m(t)]</script><p>接下来信号进入减法器，减去直流$\frac{1}{2}A_0$后得到最终的输出：  </p><script type="math/tex; mode=display">m_0=\frac{1}{2}m(t)</script><p>对于双边带调制（DSB）其过程与上述过程基本相同，由于双边带调制后的信号不存在直流分量$\frac{1}{2}A_0$，因此无需通过减法器。  </p><p>可以得到解调后信号的能量：  </p><script type="math/tex; mode=display">S_o|_{AM}=S_o|_{DSB}=\frac{\overline{m^2(t)}}{4}</script><p>非相干解调在$A_0+m(t)&gt;&gt;n_i(t)$时的结果和相干解调的各项值完全相同。  </p><h3 id="单边带调制的相干解调"><a href="#单边带调制的相干解调" class="headerlink" title="单边带调制的相干解调"></a>单边带调制的相干解调</h3><p>进入解调部分的信号：$S_{SSB}=\frac{1}{2}m(t)cosω_ct∓\frac{1}{2}\hat{m(t)sinω_ct}$，与同频同相位的载波相乘：  </p><script type="math/tex; mode=display">ρ(t)=\frac{1}{4}[m(t)cos(φ_0-φ_0)∓\hat{m}(t)sin(φ_0-φ_0)]+\frac{1}{4}[m(t)cos(2\omega_ct+2φ_0)∓\hat{m}(t)sin(2ω_c t+2φ_0)]</script><p>通过低通滤波器过滤掉含有$ω_c$的部分：  </p><script type="math/tex; mode=display">m_o(t)=\frac{1}{4}[m(t)cos(φ_0-φ_0)∓\hat{m}(t)sin(φ_0-φ_0)]</script><p>通过时协同步器，可以得到：</p><script type="math/tex; mode=display">m_o(t)=\frac{1}{4}m(t)</script><p>可以得到解调后信号的能量：  </p><script type="math/tex; mode=display">S_o|_{SSB}=\frac{\overline{m^2(t)}}{16}</script><h2 id="非相干解调（包络解波法）"><a href="#非相干解调（包络解波法）" class="headerlink" title="非相干解调（包络解波法）"></a>非相干解调（包络解波法）</h2><p>非相干解调（包络解波法）仅适用于调幅，对于$|m(t)|_{max}≤A_0$的调制信号，其通过如下图所示的包络线检测电路（本质上是低通滤波器的改装）后，即可消除保留波形图中幅度变化较大的部分，从而保留包络线。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211016155523.png width=50%>  </p><h2 id="相干解调过程的噪声"><a href="#相干解调过程的噪声" class="headerlink" title="相干解调过程的噪声"></a>相干解调过程的噪声</h2><p>对于解调过程，假设输入进解调模组的加性高斯白噪声为$n_p$，其可以分为同相分量和正交分量两部分：$n_p(t)=n_ccosω_ct-n_s(t)sinω_ct$。<br>这两部分与载波相乘：  </p><script type="math/tex; mode=display">\begin{aligned}    n_p(t)&=[n_ccosω_ct-n_s(t)sinω_ct]cosω_ct\\    &=\frac{1}{2}n_c(t)+\frac{1}{2}[n_c(t)cos2ω_ct--n_s(t)sin2ω_ct]\end{aligned}</script><p>通过低通滤波器过滤掉含有$ω_c$的部分：  </p><script type="math/tex; mode=display">n_o(t)=\frac{1}{2}n_c(t)</script><p>那么输出噪声的能量为：</p><script type="math/tex; mode=display">N_o=\frac{1}{4}N_i</script><p>由于DSB、AM与SSB的输入噪声能量不相同，有：  </p><script type="math/tex; mode=display">N_o|_{AM}=N_o|_{DSB}=\frac{n_0f_H}{2}</script><script type="math/tex; mode=display">N_o|_{SSB}=\frac{n_0f_H}{4}</script><p>可以得到三种调制模式在输出端的信噪比：  </p><script type="math/tex; mode=display">SNR_o|_{AM}=SNR_o|_{DSB}=\frac{\overline{m^2(t)}}{\frac{n_0f_H}{2}}</script><script type="math/tex; mode=display">SNR_o|_{SSB}=\frac{\overline{m^2(t)}}{\frac{n_0f_H}{4}}</script><h2 id="信噪比增益"><a href="#信噪比增益" class="headerlink" title="信噪比增益"></a>信噪比增益</h2><p>定义信噪比增益：  </p><script type="math/tex; mode=display">G=\frac{SNR_o}{SNR_i}</script><p>可求得三种调制模式的信噪比增益为：  </p><script type="math/tex; mode=display">G=\begin{cases}    \frac{2\overline{m^2(t)}}{A_0^2+\overline{m^2(t)}}≤\frac{2}{3}...AM \\    2...DSB\\    1...SSB\\\end{cases}</script><blockquote><p>在不能直接通过信噪比增益衡量调制效果的好坏，事实上，当输入信号相同时，DSB和SSB的抗噪性能理论上是相等的。  </p></blockquote><h2 id="总结：线性调制的解调的输出参数"><a href="#总结：线性调制的解调的输出参数" class="headerlink" title="总结：线性调制的解调的输出参数"></a>总结：线性调制的解调的输出参数</h2><div class="table-container"><table><thead><tr><th style="text-align:center">线性调制方法</th><th style="text-align:center">输出信号</th><th style="text-align:center">输出能量</th><th style="text-align:center">噪声</th><th style="text-align:center">信噪比</th><th style="text-align:center">信噪比增益</th></tr></thead><tbody><tr><td style="text-align:center">调幅</td><td style="text-align:center">$\frac{1}{2}m(t)$</td><td style="text-align:center">$\frac{1}{4}\overline{m^2(t)}$</td><td style="text-align:center">$\frac{n_0f_H}{2}$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{2n_0f_H}$</td><td style="text-align:center">$\frac{2\overline{m^2(t)}}{A_0^2+\overline{m^2(t)}}≤\frac{2}{3}$</td></tr><tr><td style="text-align:center">双边带调制</td><td style="text-align:center">$\frac{1}{2}m(t)$</td><td style="text-align:center">$\frac{1}{4}\overline{m^2(t)}$</td><td style="text-align:center">$\frac{n_0f_H}{2}$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{2n_0f_H}$</td><td style="text-align:center">$2$</td></tr><tr><td style="text-align:center">单边带调制</td><td style="text-align:center">$\frac{1}{4}m(t)$</td><td style="text-align:center">$\frac{1}{16}\overline{m^2(t)}$</td><td style="text-align:center">$\frac{n_0f_H}{4}$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{4n_0f_H}$</td><td style="text-align:center">$1$</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 反馈放大器</title>
    <link href="/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/3.%20Feedbacks/"/>
    <url>/2021/10/14/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/3.%20Feedbacks/</url>
    
    <content type="html"><![CDATA[<h1 id="反馈放大器"><a href="#反馈放大器" class="headerlink" title="反馈放大器"></a>反馈放大器</h1><p>反馈电路指将系统输出经过处理后加入输入信号的电路，基本的反馈结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211014132513.png width=50%>  </p><p>反馈电路由两部分组成：正向系统（输入→输出方向），其增益称为<strong>开环增益</strong>（Open-loop Gain），系统方程（S域）以$A(s)$或者$G(s)$表示；反馈系统（输出→输入方向），其增益称为反馈因子，系统方程（S域）以$B(s)$或者$H(s)$表示。<br>根据加法器的符号正负，可以分为正反馈系统和负反馈系统。<br>整个系统的<strong>闭环增益</strong>（Close-loop Gain）表示为：  </p><script type="math/tex; mode=display">Gain_{cl}=\frac{θ_o}{θ_i}=\frac{G(s)}{1±G(s)H(s)}</script><blockquote><p>“-“表示正反馈电路，”+”表示负反馈电路</p></blockquote><p>当反馈因子为0时（物理意义为不连接反馈电路），闭环增益退化为开环增益。  </p><h2 id="反馈放大器类型"><a href="#反馈放大器类型" class="headerlink" title="反馈放大器类型"></a>反馈放大器类型</h2><p>放大器引入反馈电路的目的是为了便于控制放大器的频率响应特性，使其变得稳定或者是不稳定。<br>运算放大器通过反馈电路连接输入端的正相/反相端口分为正反馈和负反馈放大器电路。  </p><h3 id="反馈放大器的稳定性"><a href="#反馈放大器的稳定性" class="headerlink" title="反馈放大器的稳定性"></a>反馈放大器的稳定性</h3><p>对于反馈放大器电路，电路中的反馈部分可以是非线性元件：LC，此时反馈因子的方程同样与频率有关：  </p><script type="math/tex; mode=display">A_f(ω)=\frac{A(ω)}{1∓A(ω)B(ω)}</script><p>因此，反馈放大器的增益是随着频率而变化的。<br>运算放大器增益随带宽（频率）的变化如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/ddfdfsdf.png width=50%>  </p><p>由上图总结出：  </p><ol><li>在低频时，放大器的增益事实上是开环增益，在$|AB|=1$处之后，反馈放大器的增益变成闭环增益。  </li><li>带宽越大，放大器的稳定性能越好，但是同时放大器的增益越小。事实上，反馈放大器的开环带宽和闭环带宽之间存在着如下关系：  <script type="math/tex; mode=display">B_{cl}=\frac{B_{ol}}{A_v}</script>其中$A_v$是运算放大器的电压增益。   </li></ol><h3 id="正反馈放大器（振荡器）"><a href="#正反馈放大器（振荡器）" class="headerlink" title="正反馈放大器（振荡器）"></a>正反馈放大器（振荡器）</h3><p>对正反馈放大器电路，其放大器增益（即系统的闭环增益）可以表示为：  </p><script type="math/tex; mode=display">Gain=\frac{G}{1-GH}</script><p>正反馈虽然能够提高放大倍数，但会使电路工作变得不稳定。当$GH=1$时，系统增益为无穷，此时系统变得不稳定，产生正弦波<strong>振荡</strong>的电压信号。利用同相放大器的这一特性可以制作振荡器电路，将输入的直流信号变为交流信号，当$Gain$非常大时，输出电压会受到放大器工作电压的限制，最终输出的信号接近于方波。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211014141623.png width=50%>  </p><h3 id="负反馈放大器"><a href="#负反馈放大器" class="headerlink" title="负反馈放大器"></a>负反馈放大器</h3><p>对于负反馈放大器电路，其放大器增益（即系统的闭环增益）可以表示为：  </p><script type="math/tex; mode=display">Gain=\frac{G}{1+GH}</script><p>在放大电路中引入负反馈，虽然会导致闭环增益的下降，但能使放大电路的许多性能得到改善。例如，可以提高增益的<strong>稳定性</strong>，扩展通频带，减小非线性失真，改变输入电阻和输出电阻等。</p><blockquote><p>给出了负反馈增益的具体推导，以及频率响应为什么和低通滤波器如此相似的原因：<a href="https://alan.ece.gatech.edu/ECE3040/Lectures/Lecture29-OP%20Amp%20Frequency%20Response.pdf">https://alan.ece.gatech.edu/ECE3040/Lectures/Lecture29-OP%20Amp%20Frequency%20Response.pdf</a></p></blockquote><h2 id="负反馈放大器的类型"><a href="#负反馈放大器的类型" class="headerlink" title="负反馈放大器的类型"></a>负反馈放大器的类型</h2><p>根据基本放大电路和反馈网络之间的端口连接方式可分为四类负反馈电路：</p><ol><li><p>输入端（Mixer）：</p><ul><li>串联反馈：串联连接（输入电压信号）</li><li>并联反馈：并联连接（输入电流信号）</li></ul></li><li><p>输出端（Sensing）：</p><ul><li>电压反馈：采样电压信号</li><li>电流反馈：采样电流信号  </li></ul></li></ol><p>输出端和输入端组合后有四种负反馈方式：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211014152046.png width=60%></p><blockquote><p>负反馈放大器，上海交通大学：<a href="https://nuedc-sh.sjtu.edu.cn/analog/kejian/chapter-5.pdf">https://nuedc-sh.sjtu.edu.cn/analog/kejian/chapter-5.pdf</a></p></blockquote><p>最简单的判断电路属于哪种反馈类型的方式为看电路中反馈部分两端是否存在额外的接地电阻，如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211014152437.png width=80%>  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Unit 16~18</title>
    <link href="/2021/10/03/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%2016~19/"/>
    <url>/2021/10/03/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%2016~19/</url>
    
    <content type="html"><![CDATA[<h1 id="Unit-16-18-ま行・や行・わ行"><a href="#Unit-16-18-ま行・や行・わ行" class="headerlink" title="Unit 16~18 ま行・や行・わ行"></a>Unit 16~18 ま行・や行・わ行</h1><h2 id="Unit-16-ま・も"><a href="#Unit-16-ま・も" class="headerlink" title="Unit 16 ま・も"></a>Unit 16 ま・も</h2><ul><li>まま（に）  <ul><li>動詞辞書形・名詞～の＋まま（に）  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【任凭……】</span>  </span></li><li>動詞普通形・い形容詞・な形容詞・名詞～の＋まま（に）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【保持……的样子】</span>  </span></li><li>動詞受身形＋まま   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【任人……】，消极地任人摆布</span>  </span></li></ul></li><li>も当然だ  <ul><li>動詞普通形～の・い形容詞～の・な形容詞～の・名詞＋も当然だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……也是理所当然的】</span>  </span></li></ul></li><li>～も～ば～も・～も～なら～も <ul><li>名詞＋も＋動詞ば形・い形容詞ば形＋名詞＋も </li><li>名詞＋も＋な形容詞・名詞＋なら＋名詞＋も   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【既……又……】</span>  </span></li></ul></li><li>ものか・もんか<br>動詞普通形・な形容詞・い形容詞＋ものか・もんか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【再也不会……】，强烈的否定意志，口语</span>  </span></li><li>もかまわず<br>動詞普通形～の・名詞＋もかまわず   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不顾……】</span>  </span></li><li>ものがある<br>動詞普通形・い形容詞・な形容詞＋ものがある   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【的确很……】，表示评价和感受</span>  </span></li><li>ものだ  <ul><li>動詞普通形・い形容詞・な形容詞＋ものだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【理应……】</span>  </span></li><li>動詞た形＋ものだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">语气，表示对过去的感慨</span>  </span></li><li>動詞普通形・い形容詞・な形容詞＋ものだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">语气，表示强烈的感情</span>  </span></li><li>動詞ます形～たい＋ものだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【真想……】，强烈的愿望</span>  </span></li></ul></li><li>ものだから<br>動詞普通形・い形容詞・な形容詞・名詞～な＋ものだから   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【因为……】</span>  </span></li><li>ものではない<br>動詞辞書形＋ものではない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不要……】，从常识性的角度给出忠告</span>  </span></li><li>ものなら  <ul><li>動詞可能形＋ものなら   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果能……的话】，描述几乎无法实现的事情</span>  </span></li><li>動詞意向形＋ものなら   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果要……的话】，后项为严重的事情，且能被预料到</span>  </span>  </li></ul></li></ul><h2 id="Unit-17-も・や・よ・わ"><a href="#Unit-17-も・や・よ・わ" class="headerlink" title="Unit 17 も・や・よ・わ"></a>Unit 17 も・や・よ・わ</h2><ul><li>ものの　　<br>動詞普通形・い形容詞・な形容詞～な・名詞～である＋ものの　  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然……但是……】</span>  </span>  </li><li>矢先に  <ul><li>動詞た形＋矢先に  </li><li>動詞意向形＋とする・とした＋矢先に    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正要……的时候】</span>  </span></li></ul></li><li>やら～やら<br>動詞辞書形・い形容詞・名詞＋やら＋動詞辞書形・い形容詞・名詞＋やら    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一边……一边/是……又是……】</span>  </span>  </li><li>ようがない・ようもない<br>動詞ます形＋ようがない・ようもない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【没有办法……】，想要做也无济于事</span>  </span>  </li><li>ようで<br>動詞普通形・い形容詞・な形容詞～な・名詞～の＋ようで   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【看上去像……，但……】，实际与想象不符合</span>  </span></li><li>ようでは<br>動詞辞書形・ない形～ない＋ようでは   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果是……的话，那就……】，后面是负面的事件</span>  </span></li><li>ようならば・ようだったら<br>動詞辞書形・ない形・い形容詞・な形容詞～な＋ようならば・ようだったら   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果是……的话】</span>  </span></li><li>わけがない・わけはない<br>動詞普通形・い形容詞・な形容詞～な＋わけがない・わけはない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不可能……】，强烈的、确信的判断</span>  </span></li><li>わけだ<br>動詞普通形・い形容詞・な形容詞～な＋わけだ <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就是……】，解释说明</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【因为……】</span>  </span></li></ol></li><li>わけではない・わけでもない<br>動詞普通形・い形容詞・な形容詞～な＋わけではない・わけでもない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">并不是……</span>  </span></li></ul><h2 id="Unit-18-わ・を"><a href="#Unit-18-わ・を" class="headerlink" title="Unit 18 わ・を"></a>Unit 18 わ・を</h2><ul><li>わけにはいかない・わけにもいかない  <ul><li>動詞辞書形＋わけにはいかない・わけにもいかない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不做……】，出于责任义务等不能做</span>  </span></li><li>動詞ない形～ない＋わけにはいかない・わけにもいかない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不能不做……】，出于责任义务等必须要做……</span>  </span></li></ul></li><li>わりに（は）<br>動詞普通形・い形容詞・な形容詞～な＋割には   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【相反地……】，后项的行为违背由前项得出理所应当的结论</span>  </span></li><li>を中心に・を中心にして・を中心として<br>名詞＋を中心に・を中心にして・を中心として   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【以……为中心/重点】</span>  </span></li><li>を通して・を通じて<br>名詞＋を通して・を通じて <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……的期间/内的范围】，常与时间名词连用</span>  </span>  </li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【通过……】，后面是积极的结果</span>  </span></li></ol></li><li>を問わず・は問わず<br>名詞＋を問わず・は問わず   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不论……】</span>  </span></li><li>を除いて（は）<br>名詞＋を除いて（は）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【除了……之外】</span>  </span></li><li>をはじめ・をはじめとして・をはじめとする<br>名詞＋をはじめ・をはじめとして・をはじめとする   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【以……为代表的】</span>  </span></li><li>を踏まえて・を踏まえ・をふまえた<br>名詞＋を踏まえて・を踏まえ・をふまえた   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……基础上】</span>  </span></li><li>をめぐって・をめぐり・をめぐる<br>名詞＋をめぐって・をめぐり・をめぐる   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【围绕……】，常与讨论、争论等动词连用</span>  </span></li><li>をもとに（して）<br>名詞＋をもとに（して）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【基于……】</span>  </span></li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>N2备考文法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. Z变换</title>
    <link href="/2021/10/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/4.%20Z%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/10/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/4.%20Z%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Z变换"><a href="#Z变换" class="headerlink" title="Z变换"></a>Z变换</h1><h2 id="离散傅里叶变换的局限性"><a href="#离散傅里叶变换的局限性" class="headerlink" title="离散傅里叶变换的局限性"></a>离散傅里叶变换的局限性</h2><p>对于离散傅里叶变换$X(e^{jω})=∑x[n]e^{-jωn}$，要求原离散信号$x(n)$满足狄利克雷条件，即要求变换中的求和项收敛：  </p><script type="math/tex; mode=display">∑|x[n]|<∞</script><p>有大量的信号不能满足这一条件。  </p><h2 id="Z变换原理"><a href="#Z变换原理" class="headerlink" title="Z变换原理"></a>Z变换原理</h2><p>解决办法是在变换时添加一项$r^{-n}$，以在保留原信号特征的同时改善原信号的收敛性。</p><script type="math/tex; mode=display">X_r(e^{jω})=∑x[n]r^{-n}e^{-jωn}=∑x[n](re^{jω})^{-n}</script><p>将：$re^{jω}$简记为$z$，得到Z变换的变换公式：  </p><script type="math/tex; mode=display">X(z)=∑x[n]z^{-n}</script><p>Z变换可以将输入序列转变为以指数序列构成的线性组合。  </p><h3 id="收敛域"><a href="#收敛域" class="headerlink" title="收敛域"></a>收敛域</h3><p>此时要求改善后的信号满足狄利克雷条件，有：  </p><script type="math/tex; mode=display">∑|x[n]z^{-n}|<∞</script><p>满足这个条件的$z$的取值称为这个Z变换对的收敛域。<br>可以发现$|z|$的取值决定了整个线性组合是否满足狄利克雷条件。<br>当$|z|=1$时，Z变换退化为离散傅里叶变换，满足这一条件的所有$ω$的取值在傅里叶平面内构成一个单位圆：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001141750.png width=30%>  </p><h4 id="收敛特性"><a href="#收敛特性" class="headerlink" title="收敛特性"></a>收敛特性</h4><p>序列的Z变换是否存在与收敛域有关，下面讨论不同类型序列的收敛域特征：  </p><div class="table-container"><table><thead><tr><th style="text-align:center">序列类型</th><th style="text-align:center">收敛域</th><th style="text-align:center">图示</th></tr></thead><tbody><tr><td style="text-align:center">右边序列：$x[n]=a^nu[n]$</td><td style="text-align:center">$‖z‖&gt;‖a‖$</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001142544.png width=50%></td></tr><tr><td style="text-align:center">左边序列：$x[n]=-a^nu[-n-1]$</td><td style="text-align:center">$‖z‖&lt;‖a‖$</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001142726.png width=50%></td></tr><tr><td style="text-align:center">双边序列:$x[n]=a^nu[n]-b^nu[-n-1]$</td><td style="text-align:center">$‖a‖&lt;‖z‖&lt;‖b‖$</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001142950.png width=50%></td></tr></tbody></table></div><p>由上表可以总结出Z变换的三条性质：</p><ol><li>当且仅当收敛域包括单位圆时，原信号才能同时满足稳定性和因果性，其离散傅里叶变换存在。  </li><li>收敛域以极点（指数序列的基底）、0、无穷划分边界。  </li><li>在收敛域内不存在任何极点。  </li></ol><h3 id="Z反变换"><a href="#Z反变换" class="headerlink" title="Z反变换"></a>Z反变换</h3><h4 id="定义式"><a href="#定义式" class="headerlink" title="定义式"></a>定义式</h4><p>定义Z反变换为：  </p><script type="math/tex; mode=display">x[n]=\frac{1}{2πj}∮_{ROC}X(z)z^{n-1}dz</script><p>反变换的定义式涉及到曲线积分、计算比较困难，由于LIT系统的系统方程都能够写作多项式分数的形式，因此对LIT系统方程而言通常不采用求解定义式的方式来求解反变换，而更多地采用如下方法求解反变换式：  </p><h4 id="Z变换式的一般形式"><a href="#Z变换式的一般形式" class="headerlink" title="Z变换式的一般形式"></a>Z变换式的一般形式</h4><p>序列$x(n)$的z变换式$X(z)$的一般形式可以写作由两个多项式组成的分式：  </p><script type="math/tex; mode=display">X(z)=\frac{N(z)}{D(z)}=\frac{∑b_mz^m}{∑a_nz^n}</script><p>其中$b_m$称为方程的零点，$a_m$称为方程的极点。<br>当极点为一阶时,对等式两边同时除以$z$以提取常系数$A$：  </p><script type="math/tex; mode=display">\frac{X(z)}{z}=∑_{i=1}^N\frac{A_i}{z-z_i}</script><p>其中$A_i=(z-z_i)\frac{X(z)}{z}|_{z=z_i}$。<br>再乘上$z$：  </p><script type="math/tex; mode=display">X(z)=∑_{i=1}^N\frac{A_iz}{z-z_i}</script><p>其中$A_i$为$x(n)$的常系数，$z_i$为底数。<br>对应的$x(n)$：</p><script type="math/tex; mode=display">x(n)=∑_{i=0}^∞A_i(z_i)^nu[n],n≥0</script><p>需要注意的是，需要根据$z-z_i$的正负对Z变换的收敛域进行讨论:  </p><ul><li>当$z&lt;z_i$时，对应分式项$\frac{A_iz}{z-z_i}$应写作$-\frac{A_iz}{z-z_i}$以保证$z-z_i$恒正。该项对应的指数序列为左边序列$-A_i(z_i)^nu[-n-1]$  </li><li>当$z&lt;z_i$时，对应分式项应写作$\frac{A_iz}{z-z_i}$以保证$z-z_i$恒正。该项对应的指数序列为右边序列$A_i(z_i)^nu[n]$  </li></ul><h2 id="离散系统的差分方程"><a href="#离散系统的差分方程" class="headerlink" title="离散系统的差分方程"></a>离散系统的差分方程</h2><p>离散系统的差分方程可以写作：  </p><script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=∑_{k=0}^Mb_kx[n-k]</script><p>求得系统的转换方程为：  </p><script type="math/tex; mode=display">H(z)=\frac{Y(z)}{X(z)}=\frac{∑b_mz^m}{∑a_nz^n}=\frac{b_0}{a_0}\frac{e^{jω(N-M)}Π_{k=1}^M(e^{jω}-b_k)}{Π_{k=1}^N(e^{jω}-a_k)}</script><p>可以发现$e^{jω}-b_k$和$e^{jω}-a_k$都表示从点$(b_k,0)$或$(a_k,0)$到单位圆上一点的向量。<br>将系统方程转化为角度表示，可以得出结论：  </p><ul><li>系统方程的模长：  <script type="math/tex; mode=display">|H(e^{jω})|=\frac{Π零向量的模长}{Π极向量的模长}</script></li><li>系统方程的角度：  <script type="math/tex; mode=display">∠H(e^{jω})=∑零向量的角度-∑极向量的角度</script></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 滤波器</title>
    <link href="/2021/10/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/2.%20Filter/"/>
    <url>/2021/10/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/2.%20Filter/</url>
    
    <content type="html"><![CDATA[<h1 id="滤波器"><a href="#滤波器" class="headerlink" title="滤波器"></a>滤波器</h1><p>滤波器按照滤波器本身是否消耗额外的能量（由于需要额外提供能量的组件多为运算放大器，因此也可按照有无运算放大器参与滤波分类）分为无源滤波器（额外不消耗能量、无运算放大器）和有源滤波器（额外消耗能量、有运算放大器）。<br>滤波器的阶数由滤波元件（L.C）的个数决定，在实际电路中，由于电感的体积较大，在集成电路设计中通常使用电容作为滤波元件。  </p><h2 id="无源滤波器"><a href="#无源滤波器" class="headerlink" title="无源滤波器"></a>无源滤波器</h2><p>无源滤波器的截止频率由$X_c=R$给出：  </p><script type="math/tex; mode=display">f_c=\frac{1}{2πRC}</script><h3 id="一阶低通滤波器"><a href="#一阶低通滤波器" class="headerlink" title="一阶低通滤波器"></a>一阶低通滤波器</h3><p>电路图如下所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001134003.png width=60%>   </p><p>当电压信号频率增大时，电容容抗减小最终导致电容短路，$V_{out}=0$。<br>当电压信号频率减小时，电容容抗增大最终导致电容断路，此时$V_{out}$是有数值的。  </p><p>一阶低通滤波器的频率响应特性如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145727.png width=50%><br>相移规律如下：  </p><script type="math/tex; mode=display">φ=-arctan(\frac{R}{X_c})=-arctan(2πfRC)</script><p>当达到滤波器的截止频率时：$X_c=R$，因此相位移动为-45°。  </p><h4 id="二阶低通滤波器"><a href="#二阶低通滤波器" class="headerlink" title="二阶低通滤波器"></a>二阶低通滤波器</h4><p>由于无源滤波器都是线性滤波器，因此其特性实际上是一阶滤波器的线性叠加。<br>二阶无源低通滤波器的电路如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145038.png width=50%><br>二阶低通滤波器的截止频率：  </p><script type="math/tex; mode=display">f_c=\frac{1}{2π√(R_1R_2C_1C_2)}</script><p>其频率响应特性如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145535.png width=50%><br>其相移为两个一阶滤波器的相移之和，即:</p><script type="math/tex; mode=display">φ=φ_1+φ_2</script><p>因此当滤波器达到截止频率时，其相移为-90°。  </p><h3 id="一阶高通滤波器"><a href="#一阶高通滤波器" class="headerlink" title="一阶高通滤波器"></a>一阶高通滤波器</h3><p>一阶高通滤波器的电路图与一阶低通滤波器的电路图相同，只是被测目标由电容改为了电阻。因此截止频率与一阶低通滤波器相同。<br>一阶高通滤波器的频率响应特性如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145626.png width=50%><br>相移规律如下：  </p><script type="math/tex; mode=display">φ=arctan(\frac{R}{X_c})=arctan(2πfRC)</script><p>当达到滤波器的截止频率时：$X_c=R$，因此相位移动为45°。  </p><h4 id="二阶高通滤波器"><a href="#二阶高通滤波器" class="headerlink" title="二阶高通滤波器"></a>二阶高通滤波器</h4><p>二阶高通滤波器的电路图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008150715.png width=50%>  </p><p>其频率响应特性图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008150729.png width=50%><br>因此当滤波器达到截止频率时，其相移为90°  </p><h3 id="带通滤波器"><a href="#带通滤波器" class="headerlink" title="带通滤波器"></a>带通滤波器</h3><p>带通滤波器的电路图为一个高通滤波器与一个低通滤波器并联。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145829.png width=50%>  </p><p>其频率响应图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145910.png width=50%><br>对于带通滤波器，其拥有两个截止频率$f_H$和$f_L$，分别对应高通滤波器和低通滤波器的截止频率。  </p><script type="math/tex; mode=display">f_H=\frac{1}{2πR_1C_1},f_L=\frac{1}{2πR_2C_2}</script><blockquote><p>注意$f_H&lt;f_L$。  </p></blockquote><p>其中心响应频率(Central resonance frequency)是这两个截止频率乘积的平方根：  </p><script type="math/tex; mode=display">f_r=√f_L×f_H=\frac{1}{2π√(R_1R_2C_1C_2)}</script><p>带通滤波器的相移在达到中心响应频率时为0。<br>定义带通滤波器的品质因数$Q$:  </p><script type="math/tex; mode=display">Q=\frac{f_c}{BW}=\frac{f_c}{f_H-f_L}</script><p>有时候为了彻底阻隔高通滤波器和低通滤波器之间的相互影响，会在分流处放置一个缓冲器，如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145947.png width=50%>   </p><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">电路图</th><th style="text-align:center">被测目标</th><th style="text-align:center">截止频率</th><th style="text-align:center">下降/上升斜率</th><th style="text-align:center">达到截止频率时的相移</th></tr></thead><tbody><tr><td style="text-align:center">一阶低通滤波器</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211001134003.png width=60%></td><td style="text-align:center">C</td><td style="text-align:center">$\frac{1}{2πRC}$</td><td style="text-align:center">-20dB</td><td style="text-align:center">-45°</td></tr><tr><td style="text-align:center">一阶高通滤波器</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008150418.png width=50%></td><td style="text-align:center">R</td><td style="text-align:center">$\frac{1}{2πRC}$</td><td style="text-align:center">20dB</td><td style="text-align:center">45°</td></tr><tr><td style="text-align:center">二阶低通滤波器</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145038.png width=50%></td><td style="text-align:center">C</td><td style="text-align:center">$\frac{1}{2π√(R_1R_2C_1C_2)}$</td><td style="text-align:center">-40dB</td><td style="text-align:center">-90°</td></tr><tr><td style="text-align:center">二阶高通滤波器</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008150715.png width=50%></td><td style="text-align:center">R</td><td style="text-align:center">$\frac{1}{2π√(R_1R_2C_1C_2)}$</td><td style="text-align:center">40dB</td><td style="text-align:center">90°</td></tr><tr><td style="text-align:center">带通滤波器</td><td style="text-align:center"><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211008145829.png width=50%></td><td style="text-align:center">R、C</td><td style="text-align:center">$f_r=\frac{1}{2π√(R_1R_2C_1C_2)}$ <br> $f_H=\frac{1}{2πR_1C_1}$ <br> $f_L=\frac{1}{2πR_2C_2}$</td><td style="text-align:center"><br> 20dB <br>-20dB</td><td style="text-align:center">0° <br> 90° <br> -90°</td></tr></tbody></table></div><h2 id="有源滤波器"><a href="#有源滤波器" class="headerlink" title="有源滤波器"></a>有源滤波器</h2><p>有源滤波器中含有运算放大器，因此其最大增益必定大于0dB。<br>简单的有源滤波器电路实质是无源滤波器的输出端与运算放大器电路的输入端连接得到的电路，加入运算放大器的好处有两点：  </p><ol><li>由于理想运算放大器内部输入阻抗远大于输出阻抗，因此在输出端运算放大器可以提供低的输出阻抗。  </li><li>激励电压信号/电流，减少信号在传输过程中的损失。  </li></ol><p>由于无源滤波器电路和运算放大器电路相互独立，因此<strong>有源滤波器的截止频率，上升速率等性质仍然与无源滤波器相同</strong>。<br>与无源滤波器不同的是，此时的最大增益不再为0dB，而是按照正相/反相运算放大器提供的最大增益进行计算。  </p><h3 id="有源滤波器的电路分析要点"><a href="#有源滤波器的电路分析要点" class="headerlink" title="有源滤波器的电路分析要点"></a>有源滤波器的电路分析要点</h3><ol><li>对于高阶滤波器，从无源滤波器入手，观察电流的分流点。  </li><li>找到每个无源滤波器与放大器输入端连接的节点，假设信号频率升高或者降低，观察此点的电压变化，由此判断出滤波器的类型（高通/低通）和放大器（正相/反相）的类型。  </li><li>根据滤波器输出电压判断滤波器类型和放大器类型，进行相应的计算。  </li></ol><h3 id="有源带通滤波器"><a href="#有源带通滤波器" class="headerlink" title="有源带通滤波器"></a>有源带通滤波器</h3><p>有源带通滤波器的结构为一个高通滤波器和低通滤波器分别跨在一个放大器的两侧串联构成，如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010181634.png width=50%><br>简化后的有源带通滤波器电路：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010181757.png width=60%>  </p><h3 id="有源带阻滤波器"><a href="#有源带阻滤波器" class="headerlink" title="有源带阻滤波器"></a>有源带阻滤波器</h3><p>有源带阻滤波器由带通滤波器由低通和高通滤波器与放大器并联得到：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010182053.png width=50%>  </p><p>带阻滤波器的计算方法和带通滤波器完全相同，其各参数为各无源滤波器参数的线性叠加。带阻滤波器的中心响应频率为：  </p><script type="math/tex; mode=display">f_c=√f_L×f_H</script><p>达到中心响应频率时，同带通滤波器，其相移为0°。<br>带阻滤波器的品质因数计算方法和带通滤波器完全相同。  </p><h4 id="陷波滤波器"><a href="#陷波滤波器" class="headerlink" title="陷波滤波器"></a>陷波滤波器</h4><p>陷波滤波器（Notch Filter）是带阻滤波器的一种，由于陷波滤波器的$f_L$和$f_H$相隔很近，其阻带很窄，因此也称点阻滤波器。常常用于去除固定频率分量或阻带很窄的地方。如用于去除直流分量，去除某些特定频率分量。<br>陷波滤波器的电路图和带阻滤波器完全相同，其频率响应特性如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010183524.png width=50%>  </p><p>陷波器的中心响应频率记作$f_N$，计算方法同带阻滤波器。  </p><blockquote><p>陷波器的相关资料：<a href="https://zh-cn.lambdageeks.com/notch-filter-circuit/#def">https://zh-cn.lambdageeks.com/notch-filter-circuit/#def</a></p></blockquote><h2 id="Sallen-Key-滤波器结构（二阶高通滤波器）"><a href="#Sallen-Key-滤波器结构（二阶高通滤波器）" class="headerlink" title="Sallen-Key 滤波器结构（二阶高通滤波器）"></a>Sallen-Key 滤波器结构（二阶高通滤波器）</h2><p>Sallen-Key滤波器是一种滤波器的搭建结构。其二阶高通滤波器的基本结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010184723.png width=50%><br>这种构造的滤波器可以通过直接改变运算放大器的增益来改变整个滤波器的最大增益，滤波器的最大增益由如下公式给出：  </p><script type="math/tex; mode=display">Gain_{max}=A×Q</script><p>其中$A$表示运算放大器的增益。<br>该放大器的中心响应频率为：  </p><script type="math/tex; mode=display">f_C=\frac{1}{2π√R_AR_BC_AC_B}</script><p>通常所有电阻的阻值相等，所有电容的电容值相等：  </p><script type="math/tex; mode=display">f_C=\frac{1}{2πRC}</script><p>Sallen-Key 滤波器的品质因数由如下公式给出：  </p><script type="math/tex; mode=display">Q=\frac{1}{3-A}</script><blockquote><p>Sallen-Key滤波器的带宽为3dB。  </p></blockquote><p>其频率响应曲线由品质因数$Q$决定：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211010185310.png width=50%>  </p><p>按照$f = f_0$附近频率特性的特点，可将滤波器分为巴特沃斯（Butterworth）、切比雪夫（Chebyshev）和贝塞尔（Bessel）三种类型。</p><blockquote><p><a href="https://www.eet-china.com/mp/a25110.html">https://www.eet-china.com/mp/a25110.html</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 线性调制方法</title>
    <link href="/2021/09/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/5.%20%E7%BA%BF%E6%80%A7%E8%B0%83%E5%88%B6/"/>
    <url>/2021/09/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/5.%20%E7%BA%BF%E6%80%A7%E8%B0%83%E5%88%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="线性调制方法"><a href="#线性调制方法" class="headerlink" title="线性调制方法"></a>线性调制方法</h1><h2 id="调制"><a href="#调制" class="headerlink" title="调制"></a>调制</h2><p>简单来说调制是将原本的信号（称为基带信号）$m(t)$与另一个确知信号（称为载波）$c(t)$一同进入乘法器，输出信号的过程。  </p><script type="math/tex; mode=display">S_m(t)=m(t)c(t)</script><p>需要注意的是，由于载波是确知信号，因此调制过程不会发生任何信息的变化。<br>使用调制的目的有三个：  </p><ol><li>由于天线与传输信号的波长之间存在匹配关系，通常天线的尺寸在$\frac{λ}{10}$到$\frac{λ}{4}$之间，经过调制的信号波长会变小，因此对应的传输天线的尺寸会对应减小以便于传输。  </li><li>调制使得多频复用称为可能，多个基带信号可以与不同的载波结合，实现同时传输多个基带信号。  </li><li>扩展信号带宽，提高系统抗干扰能力。  </li></ol><h3 id="调制方法的分类"><a href="#调制方法的分类" class="headerlink" title="调制方法的分类"></a>调制方法的分类</h3><ul><li>按基带信号的类型分为：数字调制和模拟调制</li><li>按照载波信号的类型可分为：连续波调制和脉冲调制</li><li><p>当载波为正弦波时，按照正弦波的受调参量可分为：<br>| 调制参量 | 模拟信号调制方法 | 数字信号调制方法 |<br>|:—:|:—:|:—:|<br>|幅度(A)| AM,DSB,SSB,VSB | ASK |<br>|频率(ω/f)| FM | FSK |<br>|相位(ϕ)|PM|PSK,DPSK,QPSK,OQPSK|  </p></li><li><p>按已调信号的频谱结构可分为：线性调制和非线性调制  </p></li></ul><h3 id="线性调制·解调方法"><a href="#线性调制·解调方法" class="headerlink" title="线性调制·解调方法"></a>线性调制·解调方法</h3><p>线性调制后，不会有新的频率成分产生。因此线性调制只能在受调参量为幅度时使用。<br>线性调制的方法分为：调幅（AM），双边带调制（DSB），单边带调制（SSB），残留边带调制（VSB）。这几种线性调制方法简图如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210930185930.png width=90%>  </p><p>线性调制的解调方法分为两类：相干解调和非相干解调，两者的简图如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210930190243.png width=60%>  </p><h2 id="调幅"><a href="#调幅" class="headerlink" title="调幅"></a>调幅</h2><p>标准调幅系统的框图如下。基带信号与一个直流信号叠加后进行抬升，然后以正弦波为载波通过乘法器。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210930190538.png width=50%>  </p><p>标准调幅可以用数学公式表达为：  </p><script type="math/tex; mode=display">S_{AM}(t)=[A_0+m(t)]cosω_ct</script><p>已调信号可以被分解为不含信息的载波项$A_0cosω_ct$和含有信息的边带项$m(t)cosω_ct$。  </p><blockquote><p>上述公式成立暗含着$E(m(t))=0$，即基带信号本身不含直流信号这一条件。  </p></blockquote><p>在时域上表现为正弦信号的包络线实则为经过抬升后的基带信号。<br>在频域中:  </p><script type="math/tex; mode=display">S_{AM}(ω)=πA_0[δ(ω+ω_c)+δ(ω-ω_c)]+\frac{1}{2}[M(ω+ω_c)+M(ω-ω_c)]</script><p>其在频谱图上表示为两段对称的连续频谱和两个冲击频谱。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210930191355.png width=70%>  </p><h3 id="调幅后的信号参数"><a href="#调幅后的信号参数" class="headerlink" title="调幅后的信号参数"></a>调幅后的信号参数</h3><h4 id="带宽"><a href="#带宽" class="headerlink" title="带宽"></a>带宽</h4><p>由频谱可以看出,AM信号的频谱由载频分量、上边带（USB）、下边带(LSB)三部分组成。上边带的频谱结构与原调制信号的频谱结构相同,下边带是上边带的镜像。因此,AM信号是带有载波分量的双边带信号,它的带宽是基带信号带宽$f_H$的2倍,即:  </p><script type="math/tex; mode=display">B_{AM}=2f_H</script><h4 id="能量·调制效率"><a href="#能量·调制效率" class="headerlink" title="能量·调制效率"></a>能量·调制效率</h4><p>已调信号的平均功率可以表示为：  </p><script type="math/tex; mode=display">P_{AM}=\overline{S^2_{AM}}=\overline{A_0^2cos^2ω_ct}+\overline{m^2(t)cos^2ω_ct}+\overline{2A_0m(t)cos^2ω_0t}</script><p>经过化简可以得到：  </p><script type="math/tex; mode=display">P_{AM}=\frac{A_0^2}{2}+\frac{\overline{m^2(t)}}{2}</script><p>其中载波功率：$P_c=\frac{A_0^2}{2}$，边带功率：$P_s=\frac{\overline{m^2(t)}}{2}$<br>即<strong>调制后信号的平均功率为载波功率和边带功率之和。</strong><br>由于载波不携带任何信息，定义调制效率为边带功率与总功率之比以反映调制时信息的占比：  </p><script type="math/tex; mode=display">η_{AM}=\frac{P_s}{P_s+P_c}</script><h4 id="调幅指数"><a href="#调幅指数" class="headerlink" title="调幅指数"></a>调幅指数</h4><p>由于对标准调幅的解调实质上是求得其包络线函数，在波形图上观察，当$m(t)<A_0$时，波形图的上下包络线会发生重叠从而无法还原之前的包络线函数，导致失真。  <img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210930192908.png width=30%>  </p><p>因此要求:  </p><script type="math/tex; mode=display">|m(t)|_{max}≤A_0</script><p>定义调幅指数$β_{AM}$反映$|m(t)|_{max}$与$A_0$的关系：  </p><script type="math/tex; mode=display">β_{AM}=\frac{|m(t)|_{max}}{A_0}</script><ul><li>$β_{AM}&lt;1$： 正常调幅</li><li>$β_{AM}=1$： 满调幅</li><li>$β_{AM}&gt;1$： 过调幅</li></ul><p>当然$A_0$并不是越大越好，倘若$A_0$设置的过大，那么会导致信息含量下降，调幅效率降低。  </p><h3 id="随机信号的调幅"><a href="#随机信号的调幅" class="headerlink" title="随机信号的调幅"></a>随机信号的调幅</h3><p>当$m(t)$是一个高斯随机过程时，容易求得调幅过程的自相关函数：  </p><script type="math/tex; mode=display">R_{AM}=E[S_{AM}(t)S_{AM}(t+τ)]</script><p>其频谱仍然为：  </p><script type="math/tex; mode=display">P_{AM}(ω)=πA_0[δ(ω+ω_c)+δ(ω-ω_c)]+\frac{1}{2}[P_S(ω+ω_c)+P_S(ω-ω_c)]</script><p>对其进行积分，求得平均功率，可以发现上述有关平均功率的结论依然适用。  </p><h2 id="双边带调制-DSB"><a href="#双边带调制-DSB" class="headerlink" title="双边带调制(DSB)"></a>双边带调制(DSB)</h2><p>对于调幅，其调制效率的最大值在受调信号$m(t)$达到最大值$|m(t)|_{max}=A_m$时取得，此时的最大调制效率为：  </p><script type="math/tex; mode=display">η_{AM}=\frac{\frac{A_m^2}{2}}{A_0^2+\frac{A^2_m}{2}}=\frac{1}{3}</script><p>可以发现，$A_0$虽然抬高了受调信号，但是调制效率非常低下。<br>双边带调制改进了调幅办法，取消了用于抬高的直流信号$A_0$，其余部分与调幅相同，其调制过程框图如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211011174430.png width=50%>  </p><p>整个调制过程的输出信号$S_{DSB}(t)$可以表示为：  </p><script type="math/tex; mode=display">S_{DSB}(t)=m(t)cosω_ct</script><p>在频域上：  </p><script type="math/tex; mode=display">S_{DSB}(ω)=\frac{1}{2}[M(ω-ω_c)+M(ω+ω_c)]</script><p>其频谱分量中不再有冲击分量。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211011175017.png width=50%>  </p><p>同调幅，其带宽仍然是原信号带宽的两倍。  </p><script type="math/tex; mode=display">B_{DSB}=B_{AM}=2f_H</script><p>由于去掉了$A_0$，双边带调制的能量为：  </p><script type="math/tex; mode=display">P_{DSB}=P_f=\frac{1}{2}\overline{m^2(t)}</script><p>最大调制效率为：  </p><script type="math/tex; mode=display">η_{max}=\frac{P_s}{P_c}=1</script><h2 id="单边带调制-SSB"><a href="#单边带调制-SSB" class="headerlink" title="单边带调制(SSB)"></a>单边带调制(SSB)</h2><p>调制过程的有效性用带宽利用率进行衡量，双边带调制的带宽比较大，因此其带宽利用率较低。同时通过对双边带调制结果的频谱分析，可以发现每个频谱成分中的半个边带（称为上边带/下边带）已经携带了受调信号的所有信息，因此考虑使用滤波器或者数学方法使得调制结果只包含单边带，以提高带宽利用率。这样的调制方法称为单边带调制。  </p><h3 id="滤波法"><a href="#滤波法" class="headerlink" title="滤波法"></a>滤波法</h3><p>滤波法使用一个滤波器$H_{SSB}(ω)$过滤出LSB或USB，其调制过程如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211011180141.png width=50%>  </p><p>在实际运用中，由于LSB的峰值点和USB的峰值点非常接近，因此要求滤波器接近理想滤波情况，即要求滤波器在截止频率后的过滤频率剧烈变化。这样的滤波器设计在现实中是非常难实现的。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211011193413.png width=50%>  </p><h3 id="相移法"><a href="#相移法" class="headerlink" title="相移法"></a>相移法</h3><p>相移法通过数学上的希尔伯特变换使其能够将原信号变换为仅含有上边带或者下边带的部分。<br>对于正弦受调信号：$m(t)=A_mcosω_mt$，其受正弦双边带调制调制后的信号为：$S_{DSB}(t)=m(t)c(t)=A_mcosω_mtcosω_ct$。<br>利用积化和差公式可以得到：  </p><script type="math/tex; mode=display">S_{DSB}(t)=\frac{1}{2}cos(ω_c-ω_m)t+\frac{1}{2}A_mcos(ω_c+ω_m)t</script><p>其中加号连接的两项分别为上边带和下边带部分，因此下边带可以写作：   </p><script type="math/tex; mode=display">\begin{aligned}  S_{LSB}(t)&=\frac{1}{2}cos(ω_c-ω_m)t\\  &=\frac{1}{2}A_mcosω_mtcosω_ct+\frac{1}{2}A_msinω_mtsinω_ct \\  &=\frac{1}{2}m(t)cosω_ct+\frac{1}{2}\hat{m(t)}sinω_ct\end{aligned}</script><p>可以发现$sinω_mt$实际上是$cosω_mt$通过<strong>相移$-\frac{π}{2}$</strong>得来的。称将原信号$m(t)$在时域内相移$-\frac{π}{2}$的变换为希尔伯特变换，变换后的信号记为$\hat{m(t)}$。  </p><blockquote><p>希尔伯特变换表达式：$\hat{f(t)}=f(t)*\frac{1}{πt}$  </p></blockquote><p>同理，对上边带部分也有：  </p><script type="math/tex; mode=display">S_{USB}(t)=\frac{1}{2}m(t)cosω_ct-\frac{1}{2}\hat{m(t)}sinω_ct</script><p>因此相移法的调制结果可以表示为：  </p><script type="math/tex; mode=display">S_{SSB}=\frac{1}{2}m(t)cosω_ct ∓ \frac{1}{2}\hat{m(t)}sinω_ct</script><blockquote><p>注意上边带为“-”，下边带为“+”   </p></blockquote><p>无论哪一种调制方式，SSB结果的带宽都是DSB的一半：  </p><script type="math/tex; mode=display">B_{SSB}=\frac{1}{2}B_{DSB}=f_H</script><p>SSB调制后的能量可以表示为：  </p><script type="math/tex; mode=display">P_{SSB}=\frac{1}{2}\overline{\frac{1}{2}m^2(t)cos^2ω_ct}+\frac{1}{2}\overline{\frac{1}{2}\hat{m^2(t)}sin^2ω_ct}=\frac{1}{4}\overline{m^2(t)}</script><h2 id="残留边带调制（VSB）"><a href="#残留边带调制（VSB）" class="headerlink" title="残留边带调制（VSB）"></a>残留边带调制（VSB）</h2><p>残留边带调制VSB在双边带调制的基础上，通过设计滤波器，使信号一个边带的频谱成分原则上保留，另一个边带频谱成分只保留小部分（残留）。该调制方法既比双边带调制节省频谱，又比单边带易于解调。<br>可以理解为VSB利用过滤后残留的上边带和下边带部分拼凑出一个完整的信息。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20211013085148.png width=50%>  </p><h2 id="线性调制过程的噪声"><a href="#线性调制过程的噪声" class="headerlink" title="线性调制过程的噪声"></a>线性调制过程的噪声</h2><p>由于所有的调制过程都是线性调制，而本课内默认所有噪声为高斯白噪声，根据平稳高斯随机过程通过线性系统的特点，可以得出线性调制过后的噪声应该和系统原来的加性噪声能量相等：  </p><script type="math/tex; mode=display">N_o=N_i=n_0B</script><p>其中$n_0$表示噪声的功率谱密度，$B$表示调制后噪声的带宽。  </p><h2 id="总结：线性调制方法的输出参数"><a href="#总结：线性调制方法的输出参数" class="headerlink" title="总结：线性调制方法的输出参数"></a>总结：线性调制方法的输出参数</h2><div class="table-container"><table><thead><tr><th style="text-align:center">线性调制方法</th><th style="text-align:center">输出表达式</th><th style="text-align:center">带宽</th><th style="text-align:center">输出能量</th><th style="text-align:center">噪声</th><th style="text-align:center">信噪比</th></tr></thead><tbody><tr><td style="text-align:center">调幅(AM)</td><td style="text-align:center">$S_{AM}=(A_0+m(t))cosω_ct$</td><td style="text-align:center">$2f_H$</td><td style="text-align:center">$\frac{A_0^2}{2}+\frac{\overline{m^2(t)}}{2}$</td><td style="text-align:center">$2n_0f_H$</td><td style="text-align:center">$\frac{A_o^2+\overline{m^2(t)}}{4n_0f_H}$</td></tr><tr><td style="text-align:center">双边带调制(DSB)</td><td style="text-align:center">$S_{DSB}=m(t)cosω_ct$</td><td style="text-align:center">$2f_H$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{2}$</td><td style="text-align:center">$2n_0f_H$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{4n_0f_H}$</td></tr><tr><td style="text-align:center">单边带调制(SSB) <br> 残留边带调制(VSB)</td><td style="text-align:center">$S_{SSB}=\frac{1}{2}m(t)cosω_ct∓\frac{1}{2}\hat{m(t)sinω_ct}$</td><td style="text-align:center">$f_H$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{4}$</td><td style="text-align:center">$n_0f_H$</td><td style="text-align:center">$\frac{\overline{m^2(t)}}{4n_0f_H}$</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>讲义：什么是遗传算法？</title>
    <link href="/2021/09/30/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E8%AE%B2%E4%B9%89%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/"/>
    <url>/2021/09/30/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E8%AE%B2%E4%B9%89%EF%BC%9A%E4%BB%80%E4%B9%88%E6%98%AF%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="讲义：什么是遗传算法？"><a href="#讲义：什么是遗传算法？" class="headerlink" title="讲义：什么是遗传算法？"></a>讲义：什么是遗传算法？</h1><blockquote><p>参考资料：</p><ol><li><em>Flappy Learning</em>- <a href="https://xviniette.github.io/FlappyLearning">https://xviniette.github.io/FlappyLearning</a></li><li><em>北京大兴国际机场旅客航站楼和综合换乘中心</em>, 北京市建筑设计研究院有限公司</li><li><em>Technological overview of the next generation Shinkansen high-speed train Series N700</em>, Central Japan Railway Company, Tokyo, Japan</li><li><em>Towards Safe Evolutionary Optimization</em>, Chao Qian, Nanjing University</li><li><em>‘Genshin Impact’: Building a Scalable AI System</em>, Shou Xu, miHoYo Inc., 2021</li><li><em>遗传算法在游戏开发中的应用</em>，杨科选等，中科院软件研究所，2009⋆</li><li><em>遗传算法原理及应用</em>，周明等，国防工业出版社，1999⋆</li><li><em>A genetic algorithm tutorial</em>, Darrell Whitley, 1994⋆</li><li><em>自然与人工系统中的适应:理论分析及其在生物控制和人工智能中的应用</em>,John.H.Holland ,高等教育出版社，2008⋆</li><li><em>Adaptation in Nature and Artificial Systems</em>,John.H.Holland, A Bradford Book, 2008 （9的英文版）⋆</li></ol></blockquote><h2 id="引入"><a href="#引入" class="headerlink" title="引入"></a>引入</h2><h3 id="学习目标"><a href="#学习目标" class="headerlink" title="学习目标"></a>学习目标</h3><ol><li>了解一些遗传算法的应用案例</li><li>了解经典遗传算法的运行流程</li><li>使用数学方法证明经典遗传算法的有效性</li><li>对遗传算法进行评价：知晓其优点和缺点  </li></ol><h3 id="遗传算法的定义"><a href="#遗传算法的定义" class="headerlink" title="遗传算法的定义"></a>遗传算法的定义</h3><p>遗传算法是一类将特定问题潜在的解决方案编码，然后应用进化理论对解决方案进行优胜劣汰式的反复筛选的算法。   </p><h2 id="遗传算法的应用"><a href="#遗传算法的应用" class="headerlink" title="遗传算法的应用"></a>遗传算法的应用</h2><h3 id="Github-开源项目FlappyLearning"><a href="#Github-开源项目FlappyLearning" class="headerlink" title="Github 开源项目FlappyLearning"></a>Github 开源项目FlappyLearning</h3><p>项目地址：<a href="https://xviniette.github.io/FlappyLearning/">https://xviniette.github.io/FlappyLearning/</a><br>项目通过每一代生成50个flappy bird，每一只鸟由随机的操作进行控制，通过游戏对其进行淘汰，而能够活得久，获得高分的游戏策略会有高概率继承给下一代。<br>大约在第25-50代时的鸟能够稳定地存活下去。<br>在游戏设计中，有些怪物可以应用遗传算法随机切换攻击模式，并通过进化和玩家的对抗不断地筛选出不容易被玩家打败的攻击模式，从而提升游戏可持续的难度。  </p><h3 id="大兴机场穹顶力学结构设计"><a href="#大兴机场穹顶力学结构设计" class="headerlink" title="大兴机场穹顶力学结构设计"></a>大兴机场穹顶力学结构设计</h3><p>大兴机场的穹顶设计使用了遗传算法来符合力学要求。具体而言，大兴机场的穹顶在在设计时，穹顶的主划分线被赋予了88个控制点，遗传算法可以对这88个控制点的位置进行选择，使建造出的穹顶不会倒塌。  </p><h3 id="新干线N700系车头外形"><a href="#新干线N700系车头外形" class="headerlink" title="新干线N700系车头外形"></a>新干线N700系车头外形</h3><p>高速铁路列车在通过隧道时由于列车和隧道对空气的挤压发出巨大的响声，新干线N700系列车在设计时通过遗传算法对列车的外形进行选择，最终设计出抗噪性较好的列车外形。  </p><h2 id="遗传算法的概念"><a href="#遗传算法的概念" class="headerlink" title="遗传算法的概念"></a>遗传算法的概念</h2><h3 id="举例：遗传算法面对的问题"><a href="#举例：遗传算法面对的问题" class="headerlink" title="举例：遗传算法面对的问题"></a>举例：遗传算法面对的问题</h3><p>开始之前，我们需要明确几个概念。<br>思考如下的场景：我们需要从一口井中取水，井中水的水位是由一个水阀进行控制，这个水阀有8个档位，每一个档位对应了不同的水位高度，要想更方便地取水自然水位的高度越高越好，现在我们想要找到那个最适合我们取水的档位，就可以用遗传算法解决这个问题。<br>在遗传算法中，这个水阀的8个档位实际上就是系统的八种状态，这八种状态对应了系统不同的输出，像这样的，<strong>系统的某些或全部状态的集合称为一个种群（Population）。</strong> 称这个<strong>状态集合中的一个特定状态为个体（Individual）或者染色体（Chromosome）。</strong>  </p><blockquote><p>此处要注意与生物学上个体和染色体的数量关系进行区分，遗传算法领域认为一个个体只含有一条染色体。  </p></blockquote><h2 id="经典遗传算法的流程"><a href="#经典遗传算法的流程" class="headerlink" title="经典遗传算法的流程"></a>经典遗传算法的流程</h2><p>经典遗传算法通过对当前种群的<strong>评估（Evaluation）</strong>，<strong>选择（Selection）</strong>，<strong>重组（Recombination）</strong>和<strong>突变（Mutation）</strong>  后，能够在现有种群的基础上产生下一代种群。经过数次进化之后，遗传算法能够选择出对目标问题解决的最佳方案组合。    </p><h3 id="状态编码"><a href="#状态编码" class="headerlink" title="状态编码"></a>状态编码</h3><p>当然，计算机是无法直接读懂这些状态的意义，对数学运算而言，函数的自变量也必须是一个数，因此需要对系统的所有状态进行编码（Coding）。<strong>编码的过程就是将状态用数进行编号的过程。</strong> 遗传算法中采用的编码机制是二进制编码，如上面例子当中水阀的8个档位，就可以用3个比特位（称为<strong>位串</strong>（Strings））：从000 编码到111，对这个水阀的8个档位状态进行表达。<br><strong>种群中的每一个个体都可以用位串的形式进行表达。</strong><br>编码之后的个体就能够用函数去评估它是好的还是坏的了。  </p><h3 id="原始种群"><a href="#原始种群" class="headerlink" title="原始种群"></a>原始种群</h3><p>由于实际问题中遗传算法要面临的状态编码数量非常庞大，不可能一下子对所有的状态都进行评估，因此遗传算法需要从所有个体中随机地抓取一些个体生成<strong>原始种群</strong>（Initial population）。遗传算法最开始的操作都是对原始种群进行的。  </p><h3 id="评估和适应度"><a href="#评估和适应度" class="headerlink" title="评估和适应度"></a>评估和适应度</h3><p>原始种群被生成后，每一个个体会通过评估函数和适应度函数（Fitness funtion）生成其对种群的适应度（Fitness）。  </p><p>对适应度函数的直观理解：<br>我们想要从一个班的学生中选择出优等生，最简单的方法就是考试，每个学生通过考试会得到一个分数，以衡量他们的学习水平。在这里，考试就是适应度函数，而每个学生的分数就是适应度。  </p><p>种群中个体$i$的适应度定义为：  </p><script type="math/tex; mode=display">\frac{f_i}{\overline{f}}</script><p>其中，$f_i$表示评估函数对第$i$个个体的评估结果，$\overline{f}$表示种群的平均评估。<br>个体的适应度越高，表明这个状态对应的系统结果越能够符合我们的要求。  </p><h3 id="复制·选择（轮盘赌选择）"><a href="#复制·选择（轮盘赌选择）" class="headerlink" title="复制·选择（轮盘赌选择）"></a>复制·选择（轮盘赌选择）</h3><p>选择后的每个个体的适应度格式为x.xx，即有小数部分和整数部分。适应度的整数部分表示该个体会被复制多少次。<br>复制中的选择机制：<br>这样就能直接地让优秀的个体获得更多被复制的机会，而适应度整数部分为0的个体因为不会被复制而被淘汰。<br>但是，那些适应度比较低的个体中仍然可能有对系统有益的部分，为了尽可能地保留这些部分，遗传算法在选择阶段还规定：<br>对所有的个体，适应度的小数部分表示额外被复制的概率。<br>如此，每一个个体中对系统有益的部分都能够被尽可能地复制。<br>比如，适应度2.3的个体能够获得2次复制，并且有0.3的概率能获得第三次复制的机会。<br>这样的机制能够用数学表示为：   </p><script type="math/tex; mode=display">M(H,t+1)=M(H,t)\frac{f(H,t)}{\overline{f}}</script><p>其中M表示的是种群中的一个亚种(Sub-populations)。  </p><p>总结：<br>选择的过程即为有概率地对种群中的个体进行复制，可以发现，适应度越高的个体被复制的概率就越大。  </p><p>原始种群经过复制后形成<strong>中间种</strong>（Intermediate Generation）。  </p><h3 id="重组（单点交叉）"><a href="#重组（单点交叉）" class="headerlink" title="重组（单点交叉）"></a>重组（单点交叉）</h3><p><strong>遗传算法中重组的本质是杂交（Crossover）</strong>，其过程主要有两步： </p><ol><li>随机地使得个体间两两配对。  </li><li>随机地选取一对个体，两者在某个随机且相同的比特位处断开，前后的两段基因型进行交叉互换。  </li></ol><p><img src="https://img-blog.csdnimg.cn/20191202151959116.gif#pic_center" alt=""></p><p>新生成的两个个体称为后代（Offspring），后代能够插入到下一代的概率计作$p_c$。  </p><h3 id="突变（反转突变）"><a href="#突变（反转突变）" class="headerlink" title="突变（反转突变）"></a>突变（反转突变）</h3><p>重组之后利用突变算子对后代作突变处理，对于种群中的所有比特位，其有$p_m$的概率发生比特反转。同遗传学一样，突变概率一个非常小的概率，通常小于1%。<br>中间种经过重组和突变，最终能称为新的种群。</p><p><div align="center">  <img src=https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210718132905.png width=80% />  </div></p><center>▲ 经典遗传算法的选择和重组过程</center>  <h2 id="遗传算法的有效性证明"><a href="#遗传算法的有效性证明" class="headerlink" title="遗传算法的有效性证明"></a>遗传算法的有效性证明</h2><p>上述的过程中很难直观地让我们感受到重组和突变对算法带来的实际效果，也很难感受到遗传算法的有效性，下面从数学的角度说明这两点。  </p><h3 id="采样空间"><a href="#采样空间" class="headerlink" title="采样空间"></a>采样空间</h3><p>在几何学上，称n维空间的某一个小于n维的子空间为<strong>超平面</strong>（hyperplane）， 比如二维空间的超平面是一条线，三位空间的超平面是一个面。<br><strong>在位串长度固定位$L$的前提下，种群中所有可能的编码方式所构成的空间称为搜索空间（Search space）。</strong> 如果每一种特定的编码方式在L维搜索空间中对应了一个角（Corner），那么共超平面的几个角对应的编码中必定在相同的某几个比特位上的值是相同的，此时引入通配符（Don‘t care，以*记）的概念，那么搜索空间的一个超平面就可以表示为含有Don’t care（*）的位串（比如：0****，11*****），这样的位串称为<strong>模式</strong>（Schema），每一个模式对应了一个超平面。   </p><h3 id="模式定理"><a href="#模式定理" class="headerlink" title="模式定理"></a>模式定理</h3><h4 id="适应度选择"><a href="#适应度选择" class="headerlink" title="适应度选择"></a>适应度选择</h4><p>由之前提出的经过选择后超平面$H$留存的样本（个体）数目$M(H,t+1)$：  </p><script type="math/tex; mode=display">M(H,t+1)=M(H,t)\frac{f(H,t)}{\overline{f}}</script><h4 id="重组的作用·定义距"><a href="#重组的作用·定义距" class="headerlink" title="重组的作用·定义距"></a>重组的作用·定义距</h4><p>考虑重组对选择后超平面$H$中种群样本数目的影响：</p><ol><li>重组是有概率发生的，概率为$p_c$。  </li><li>对于发生重组的种群，交叉既有可能产生出现有空间内某个模式的副本（比如100和010交叉就可能产生000，使得000的副本增加一个）即为$gains$，单位为个数，同时也有可能使得原有的样本消失，这个消失的概率记为$losses$。    </li></ol><p>那么现在后代中落在超平面$H$的样本数目：  </p><script type="math/tex; mode=display">M(H,t+1)=(1-p_c)M(H,t) \frac{f(H,t)}{\overline{f}} +p_c [M(H,t)\frac{f(H,t)}{\overline{f}}(1-losses)+gains]</script><p>模式定理认为gain发生的概率要远远小于losses。为了简化计算，忽略gain，并且假设发生在Schema上有义部分的交叉必然导致染色体破坏，记破坏概率为$disruption$，那么有：  </p><script type="math/tex; mode=display">M(H,t+1) \geq (1-p_c)M(H,t) \frac{f(H,t)}{\overline{f}} +p_c [M(H,t)\frac{f(H,t)}{\overline{f}}(1-disruption)]</script><p>定义超平面$H$的采样率表示超平面$H$的样本数目与种群中样本数目的比，以$P(H,t)$记。  </p><p><strong>定义距</strong>$Δ(H)$表示超平面$H$对应模式中第一个确定字符的位置和最后一个确定字符的位置之间的距离。如：$Δ( 011 ∗ 1 ∗ ∗ )=4$。<br>按照我们对重组的理解：<strong>对原信息的破坏只可能发生在定义距的区间段内。</strong>  </p><p>此外，如果发生重组的位串都在平面$H$内，那么重组也不可能对原本信息造成破坏，因此要想让重组破坏原有的信息，亲本中的另一条位串必定来自于其他平面，另一个位串来自其他平面的概率为$1-P(H,t)$。<br>由这上述两点可以将破坏概率定义为：  </p><script type="math/tex; mode=display">\frac{\Delta(H)}{L-1}(1-P(H,t))</script><p>由破坏的定义可以得出如下结论：<br><strong>定义距$Δ(H)$越小，模式受到破坏的概率就越小</strong>。从直观上来说，定义距越小，交叉发生在定义距内（即一定能破坏信息）的概率也越小。<br>那么下一代超平面$H$的采样率可以表示为：</p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t))]</script><p>如果考虑亲代是基于适应度选择出来的：  </p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})]</script><h4 id="突变的作用·模式阶"><a href="#突变的作用·模式阶" class="headerlink" title="突变的作用·模式阶"></a>突变的作用·模式阶</h4><p>最后，考虑突变的影响：记突变发生的概率为$p_m$，超平面$H$的阶数为$o(H)$，<strong>阶数表示模式中确定字符的个数，当突变发生在这些字符上时，才会对原来的位串产生破坏。</strong><br>那么表示超平面$H$的Schema不会受到突变影响的概率为：  </p><script type="math/tex; mode=display">(1-p_m)^{o(H)}</script><p>可以得出结论：<br><strong>模式的阶数$o(H)$越小,模式不会受到突变影响的概率越大</strong>。从直观上来看，模式的阶数代表着有效字符的个数，有效字符越少，在交叉过程中越容易被保留下来。<br>最终，超平面$H$在下一代中被采样到的概率可以表示为：  </p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})] (1-p_m)^{o(H)}</script><h4 id="指数增长"><a href="#指数增长" class="headerlink" title="指数增长"></a>指数增长</h4><p>可以通过数学推算出，在适应度$\frac{f(H,t)}{\overline{f}}&gt;1$时：</p><script type="math/tex; mode=display">P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})]=P(H,t) \frac{f(H,t)}{\overline{f}}(1-p_c \frac{\Delta(H)}{L-1})+[P(H,t) \frac{f(H,t)}{\overline{f}} ]^2</script><p>用$t=0$代来推算$t$代时候的采样率：  </p><script type="math/tex; mode=display">P(H,t) ≥ \{P(H,0) \frac{f(H,0)}{\overline{f}}(1-p_c \frac{\Delta(H)}{L-1})+[P(H,0) \frac{f(H,0)}{\overline{f}} ]^2\}^t(1-p_m)^{o(H)}</script><p>可以发现：<strong>在适应度$\frac{f(H,t)}{\overline{f}}&gt;1$时，采样率呈现指数型上升。</strong><br>可以总结为：<br><strong>在选择，重组，突变算子的作用下，当某个超平面的适应度大于1时，模式的阶数$o(H)$越小，定义距$Δ(H)$越小的个体越能够被保留下来，且数目成指数型上升。</strong><br>定义距和模式阶都是染色体本身的参数，通过重组和突变这两个参数被引入到进化中，并对选择起到了关键的作用。  </p><h4 id="对模式定理结论的直观理解"><a href="#对模式定理结论的直观理解" class="headerlink" title="对模式定理结论的直观理解"></a>对模式定理结论的直观理解</h4><p>定义距相当于基因的长度，基因越长，在进化过程中被破坏概率就越大，因此定义距越短的个体越容易在进化中得到保留。<br>例子：兔子的性状<br>模式阶相当于个体携带性状的个数。单纯的红眼兔显然比裂唇长耳红眼兔更容易传递给后代。因此模式阶越小，个体越容易在进化中得到保留。  </p><p>模式定理在数学上证明了重组和突变的有效性，并给出了采样率的下界，是遗传算法中重要的理论基础之一。  </p><h2 id="其他进化算法"><a href="#其他进化算法" class="headerlink" title="其他进化算法"></a>其他进化算法</h2><h3 id="Genitor-算法"><a href="#Genitor-算法" class="headerlink" title="Genitor 算法"></a>Genitor 算法</h3><blockquote><p>进化策略中细分为两种类型：$(μ+λ)-ES$和$(μ,λ)-ES$。<br>在$(μ+λ)-ES$机制中，亲代$μ$产生后代$λ$后，种群还会对亲代和后代共同进行选择，选择其中表现出色的个体生成下一代。在这种选择机制下，亲代会被保留直到被比亲代表现更出色的个体替代。<br>在$(μ,λ)-ES$机制中，后代被产生后就直接替代亲代，选择在后代中执行。这种进化机制在选择阶段与经典遗传算法近似。但是在重组阶段所采用的算子与经典遗传算法不同。<br>$(μ+λ)-ES$机制相比于$(μ,λ)-ES$机制，其被优化的后代数目一定是单调增加的。  </p></blockquote><p>传统的进化算法在进行到最后时，由于留存的都是表现的比较好的个体，因此采用适应度淘汰个体（即选择过程）的压力会随着算法运行次数的增加而不断减弱，最后甚至根本不能对个体有任何选择。Gnitor算法可以加强选择的压力，一定程度上避免这种情况的发生。<br>Genitor算法是一种使用$(μ+λ)-ES$机制的算法，其与经典遗传算法中的进化模型不同点有三处。  </p><ol><li>选择在亲代中执行，选择后的亲代产生的后代被立即投放到下一代种群中。  </li><li>后代不会替代亲代，但是每一代中适应度最差的个体被直接移除以加强选择压力。  </li><li>适应度函数通过排名算法（Ranking）而非比值来表现。排名也同样能够保持选择压力的有效性。  </li></ol><h4 id="排名算法"><a href="#排名算法" class="headerlink" title="排名算法"></a>排名算法</h4><p>设三个个体的适应度评估为：$h_1,h_2,h_3$.<br>首先对所有个体按照适应度从小到大排序，比如：$h_2,h_1,h_3$;<br>按照上面的顺序重新赋予fitness，即$f(h_2)=1,f(h_1)=2,f(h_3)=3$<br>计算选择概率:$p(h_2)=\frac{1}{1+2+3}=\frac{1}{6},p(h_1)=\frac{2}{6},p(h_3)=\frac{3}{6}$<br>排名算法能够不受制于适应度的限制，选择压力不会因为总体适应度的上升而减小，保证了选择的有效性。<br>同时排名算法的运行机制也参考了适应度，保证了选择的可靠性。  </p><h3 id="锦标赛（Tournaments）算法"><a href="#锦标赛（Tournaments）算法" class="headerlink" title="锦标赛（Tournaments）算法"></a>锦标赛（Tournaments）算法</h3><ol><li>确定每次选择的个体数量N。（二元锦标赛选择即选择2个个体）</li><li>从种群中随机选择N个个体(每个个体被选择的概率相同) ，根据每个个体的适应度值，选择其中适应度值最好的个体进入下一代种群。</li><li>重复步骤(2)多次（重复次数为种群的大小），直到新的种群规模达到原来的种群规模。<br>锦标赛算法相当于是有噪声的排序算法。<br>由于2这一步可以同时选择若干个体数量为N的组，每一组内的选择是独立的，因此通过锦标赛算法可以将遗传算法进行并行化处理，大大地节省了运算时间。  </li></ol><h2 id="遗传算法的局限性"><a href="#遗传算法的局限性" class="headerlink" title="遗传算法的局限性"></a>遗传算法的局限性</h2><h3 id="计算量问题"><a href="#计算量问题" class="headerlink" title="计算量问题"></a>计算量问题</h3><p>对于遗传算法来说评估函数的计算速度和计算量是一个问题：首先，对于现有种群的评估计算量就比较大。不仅如此，种群的后代也需要进行评估——这会导致计算量的暴增。  </p><h3 id="信息表达问题"><a href="#信息表达问题" class="headerlink" title="信息表达问题"></a>信息表达问题</h3><p>遗传算法的每个个体用位串来表示，能够存储的信息量、用于描述单个个体的精度有限。  </p>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. 高斯噪声</title>
    <link href="/2021/09/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/4.%20%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0/"/>
    <url>/2021/09/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/4.%20%E9%AB%98%E6%96%AF%E5%99%AA%E5%A3%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="高斯噪声"><a href="#高斯噪声" class="headerlink" title="高斯噪声"></a>高斯噪声</h1><h2 id="白噪声"><a href="#白噪声" class="headerlink" title="白噪声"></a>白噪声</h2><p><strong>白噪声</strong>指噪声信号的功率谱密度函数在频域内符合均匀分布。事实上，完全意义上的白噪声是不可能存在的，因此如果噪声的功率谱密度在系统的工作频段内符合均匀分布，也认为是白噪声。  </p><h3 id="白噪声的统计特性"><a href="#白噪声的统计特性" class="headerlink" title="白噪声的统计特性"></a>白噪声的统计特性</h3><p>白噪声的谱密度函数（双边）可以表示为：  </p><script type="math/tex; mode=display">P_ξ(ω)=\frac{n_0}{2}(-∞<ω<∞)</script><p>其期望为：  </p><script type="math/tex; mode=display">E_ξ(ω)=∞</script><p>其自相关函数为：  </p><script type="math/tex; mode=display">R_ξ(τ)=\frac{1}{2π}∫_{-∞}^∞\frac{n_0}{2}e^{jωτ}dω=\frac{n_0}{2}δ(τ)</script><p>频谱中为负的部分没有任何的现实意义，因此定义白噪声的单边谱密度函数为：  </p><script type="math/tex; mode=display">P_ξ(ω)=n_0(-∞<ω<∞)</script><h2 id="高斯白噪声"><a href="#高斯白噪声" class="headerlink" title="高斯白噪声"></a>高斯白噪声</h2><p>高斯白噪声指信号的功率谱密度函数在频域内符合均匀分布、概率密度函数符合高斯分布的噪声。高斯白噪声是一种可加性噪声。    </p><h4 id="高斯白噪声的统计特性"><a href="#高斯白噪声的统计特性" class="headerlink" title="高斯白噪声的统计特性"></a>高斯白噪声的统计特性</h4><p>均值：$E_ξ(ω)=0$<br>方差：$D_ξ(ω)=0$<br>自相关函数：$R_n(τ)=\frac{n_0}{2}δ(τ)$  </p><h2 id="窄带高斯白噪声"><a href="#窄带高斯白噪声" class="headerlink" title="窄带高斯白噪声"></a>窄带高斯白噪声</h2><p>当高斯白噪声通过线性滤波器从而使得原有的谱密度函数说遵循的均匀分布被限制在了某一个频段$(-ω,ω)$，称此时的高斯白噪声为窄带高斯白噪声。  </p><h3 id="表达方式和统计性质"><a href="#表达方式和统计性质" class="headerlink" title="表达方式和统计性质"></a>表达方式和统计性质</h3><h4 id="包络相位形式"><a href="#包络相位形式" class="headerlink" title="包络相位形式"></a>包络相位形式</h4><p>窄带高斯白噪声的谱密度函数可以表示为：  </p><script type="math/tex; mode=display">n_i(t)=a(t)cos[ω_ct+ϕ(t)]</script><p>其中$a(t)$是随机包络函数，$ϕ(t)$是随机相位函数。  </p><p>随机包络和随机相位的统计特性：<br>随机包络$a(t)$：  </p><script type="math/tex; mode=display">f(a)=\frac{a}{σ^2}exp[-\frac{a^2}{2σ_n^2}],a≥0</script><p>其服从瑞利分布。<br>随机相位$ϕ(t)$：  </p><script type="math/tex; mode=display">f(ϕ)=\frac{1}{2π},0≤ϕ≤2π</script><p>其服从均匀分布，且与随机包络相互独立。  </p><h4 id="同相正交形式"><a href="#同相正交形式" class="headerlink" title="同相正交形式"></a>同相正交形式</h4><p>定义窄带高斯白噪声的<br>同相分量：$n_c(t)=a(t)cos[ϕ(t)]$<br>正交分量：$n_s(t)=a(t)sin[ϕ(t)]$<br>则窄带高斯白噪声可以分解为：  </p><script type="math/tex; mode=display">n_i(t)=n_ccosω_ct-n_s(t)sinω_ct</script><p>同相分量和正交分量的统计特性：<br><strong>一个均值为0的窄带平稳高斯过程，其同相分量和正交分量也是平稳高斯过程，且均值为0，方差和原信号相同。</strong>  </p><h3 id="高斯白噪声通过低通滤波器"><a href="#高斯白噪声通过低通滤波器" class="headerlink" title="高斯白噪声通过低通滤波器"></a>高斯白噪声通过低通滤波器</h3><p>低通滤波器的频谱是一个以$ω=0$为纵对称轴轴的门函数，其截止频率为$W$：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210926142613.png width=50%><br>按照第3讲中平稳随机过程通过线性系统的输出特性，可以得到当输入高斯白噪声到低通滤波器时，输出的窄带高斯白噪声的谱密度函数：  </p><script type="math/tex; mode=display">P_ξ(ω)=\frac{n_0}{2},-W≤ω≤W=\frac{n_0}{2}G_{2W}(ω)</script><p>其中$W$表示的是线性低通滤波器的截止频率。<br>此时的平均功率可以由谱密度函数的面积表示：  </p><script type="math/tex; mode=display">Avg.Power=\frac{n_0}{2}×2W=n_0W</script><p>其自相关函数可以通过傅里叶变换来获得：  </p><script type="math/tex; mode=display">R_n(τ)=\frac{n_0W}{2π}Sa(Wτ)</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210926142217.png width=80%>  </p><h3 id="高斯白噪声通过带滤波器"><a href="#高斯白噪声通过带滤波器" class="headerlink" title="高斯白噪声通过带滤波器"></a>高斯白噪声通过带滤波器</h3><p>带通滤波器的频谱是两个以$ω=ω_0$为纵对称轴轴的、且相互以$ω=0$对称的门函数，其截止频段为$W$：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210926143006.png width=50%><br>当高斯白噪声通过带通滤波器，其输出的窄带高斯白噪声的谱密度函数为：  </p><script type="math/tex; mode=display">P_n(ω)=\frac{n_0}{2}[G_W(ω+ω_0)+G_W(ω-ω_0)]</script><p>由傅里叶变换得到其自相关函数为：  </p><script type="math/tex; mode=display">R_n(τ)=\frac{n_0W}{2π}Sa(\frac{Wτ}{2})cos(ω_0τ)</script><p>其平均功率为：  </p><script type="math/tex; mode=display">Avg.Power=\frac{n_0}{2}×2×W=n_0W</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>TensorFlow 入门项目：训练一个VGG模型</title>
    <link href="/2021/09/25/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E4%BD%BF%E7%94%A8tensorflow/"/>
    <url>/2021/09/25/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E4%BD%BF%E7%94%A8tensorflow/</url>
    
    <content type="html"><![CDATA[<h1 id="TensorFlow-入门项目：训练一个VGG模型"><a href="#TensorFlow-入门项目：训练一个VGG模型" class="headerlink" title="TensorFlow 入门项目：训练一个VGG模型"></a>TensorFlow 入门项目：训练一个VGG模型</h1><blockquote><p>代码环境建议为：Python37/38/39 Tensorflow 2.3.0/2.6.0</p></blockquote><p>同NUS的交通标志分类器项目一样，搭建一个训练器的算法思路基本相同。基本步骤为：</p><ol><li>读取数据集，加载数据集中的图像和标签</li><li>划分训练集和测试集</li><li>定义分类器，此处需要定义使用的Google的VGG模型</li><li>将训练集放入分类器训练，并用测试集输出评价</li><li>输出设定的评价标准</li><li>保存模型</li></ol><p>整个过程需要的函数库如下所示：<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> tensorflow <span class="hljs-keyword">as</span> tf<br><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">from</span> cv2 <span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> tensorflow.keras <span class="hljs-keyword">import</span> Model, Sequential, layers, models<br><span class="hljs-keyword">from</span> tensorflow.keras.callbacks <span class="hljs-keyword">import</span> EarlyStopping, ReduceLROnPlateau<br><span class="hljs-keyword">from</span> tensorflow.keras.preprocessing.image <span class="hljs-keyword">import</span> ImageDataGenerator<br></code></pre></div></td></tr></table></figure><br>在正式进行训练之前，可以利用tf中的<code>tf.config.experimental.list_physical_devices(&#39;GPU&#39;)</code>查找并选择使用GPU，写法是固定的。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-comment">#调用GPU</span><br>gpus = tf.config.experimental.list_physical_devices(<span class="hljs-string">&#x27;GPU&#x27;</span>)<br><span class="hljs-keyword">if</span> gpus:<br>    <span class="hljs-keyword">for</span> gpu <span class="hljs-keyword">in</span> gpus:<br>        tf.config.experimental.set_memory_growth(gpu, <span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure></p><h2 id="加载数据集"><a href="#加载数据集" class="headerlink" title="加载数据集"></a>加载数据集</h2><p>这一部分的思路与NUS项目中使用Sklearn创建交通标志分类器的思路几乎完全相同：定义两个list用于分别存放图像集和标签集。遍历整个数据集。遍历数据集的方法使用<code>glob()</code>函数，数据集的文件夹层级为；<br>—dataset<br>..|-images<br>….|-cato1<br>….|-cato2<br>….|-cato3<br>….|-cato4<br>其中每一张图像以类似<code>001_photoname.jpg</code>命名，001是图像的类别标签。<br>对于图像，使用<code>cv2.imread()</code>将图像转为np.array格式后存放到list即可。对于图像所对应的标签，此处使用的是<code>split()</code>函数对文件路径、或者是文件名中含有的标签信息进行提取。如果标签在数据集中以<em>.csv或者</em>.exls的表格文件储存，则需要调用pandas函数库进行处理。<br>需要注意的是，图像需要用<code>cv2.resize()</code>保证每张图片的大小相同，即矩阵的大小是相等的。  </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 定义容器</span><br>x = []  <span class="hljs-comment"># 图像集</span><br>y = []  <span class="hljs-comment"># 标签集</span><br><br>ImgHight = <span class="hljs-number">64</span> <span class="hljs-comment"># 图片高度</span><br>ImgWidth = <span class="hljs-number">64</span> <span class="hljs-comment"># 图片宽度</span><br><br><span class="hljs-comment"># 加载数据集</span><br>dataset_root = <span class="hljs-string">&#x27;dataset/images/**/&#x27;</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> glob.glob(dataset_root + <span class="hljs-string">&#x27;*.jpg&#x27;</span>, recursive=<span class="hljs-literal">True</span>):<br>    img = cv2.imread(i)<br>    img_resize = cv2.resize(img, (ImgWidth, ImgHight))  <span class="hljs-comment"># 裁剪图像</span><br>    x.append(img_resize)<br>    label = i.split(<span class="hljs-string">&quot;\\&quot;</span>)[<span class="hljs-number">2</span>][<span class="hljs-number">0</span>:<span class="hljs-number">3</span>]  <span class="hljs-comment"># 分词找标签</span><br>    y.append(<span class="hljs-built_in">int</span>(label))<br><br><span class="hljs-comment"># 错误代码</span><br><span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(x) == <span class="hljs-number">0</span>:<br>    print(<span class="hljs-string">&#x27;Missing files&#x27;</span>)<br><span class="hljs-keyword">elif</span> <span class="hljs-built_in">len</span>(y) == <span class="hljs-number">0</span>:<br>    print(<span class="hljs-string">&quot;missing names&quot;</span>)<br><br>print(<span class="hljs-string">&quot;reading completed&quot;</span>)<br></code></pre></div></td></tr></table></figure><p>由于tf只支持标签和图像都为np.array格式，因此需要将标签和图像列表都转换为np.array格式。<br>此外还需要将图像列表转为一个长向量，以便输入分类器进行拟合。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 把标签和图像转为nparry格式</span><br>x = np.array(x).reshape(-<span class="hljs-number">1</span>, ImgHight, ImgWidth, <span class="hljs-number">3</span>)  <span class="hljs-comment"># 转为1维长向量</span><br>y = np.array(y)<br></code></pre></div></td></tr></table></figure><br>同样地，此处使用Sklearn中的<code>train_test_split()</code>函数对数据集进行随机划分，划分为测试集和训练集两部分。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 划分训练集和测试集</span><br>x_train, x_test, y_train, y_test = train_test_split(x,<br>                                                    y,<br>                                                    test_size=<span class="hljs-number">0.4</span>,<br>                                                    shuffle=<span class="hljs-literal">True</span>)<br></code></pre></div></td></tr></table></figure></p><h2 id="加载模型"><a href="#加载模型" class="headerlink" title="加载模型"></a>加载模型</h2><p>此处使用<code>tf.keras.applications.vgg16.VGG16()</code>来加载TensorFlow中预制的VGG算法模型。<br>由于数据集的量比较小，因此设置数据输入到最后的四层。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">&quot;Loading the model..&quot;</span>)<br><span class="hljs-comment"># VGG16预训练网络</span><br>covn_base = tf.keras.applications.vgg16.VGG16(weights=<span class="hljs-string">&#x27;imagenet&#x27;</span>,<br>                                              include_top=<span class="hljs-literal">False</span>)<br>covn_base.trainable = <span class="hljs-literal">True</span><br><span class="hljs-comment"># 冻结前面的层，训练最后四层</span><br><span class="hljs-keyword">for</span> layers <span class="hljs-keyword">in</span> covn_base.layers[:-<span class="hljs-number">4</span>]:<br>    layers.trainable = <span class="hljs-literal">False</span><br>    <br></code></pre></div></td></tr></table></figure><br>对每一层，都需要用<code>tf.keras.layers</code>中的函数指定每一层的用途和相关的参数（比如激活函数，池化方法等等）。由于采用的是预制的标准VGG16算法，因此最后4层每一层的设置遵循标准VGG16的结构。需要注意损失函数的定义，当标签以整实数形式存放时，应该使用<code>tf.keras.losses.SparseCategoricalCrossentropy()</code>，如果以二进制编码，如标签3为011，则应该使用<code>tf.keras.losses.CategoricalCrossentropy()</code>。<br>Logits表示网络的直接输出 。没经过sigmoid或者softmax的概率化。<code>from_logits=False</code>就表示把已经概率化了的输出，重新映射回原值。$log(p/(1-p))$。  当<code>from_logits=True</code>时损失函数会做softmax，并进行概率归一化操作。<br>由于有四类图像需要识别，此处<code>tf.keras.layers.Dense()</code>的第一个参数应该为4，表示样本空间的维度。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 构建模型</span><br>model = tf.keras.Sequential()<br>model.add(covn_base)<br>model.add(tf.keras.layers.GlobalAveragePooling2D())<br>model.add(tf.keras.layers.Dense(<span class="hljs-number">256</span>, activation=<span class="hljs-string">&#x27;relu&#x27;</span>))<br>model.add(tf.keras.layers.Dropout(<span class="hljs-number">0.2</span>))<br>model.add(tf.keras.layers.Dense(<span class="hljs-number">4</span>, activation=<span class="hljs-string">&#x27;softmax&#x27;</span>))<br>model.summary()<br><span class="hljs-comment"># 编译模型，初始学习率0.001</span><br><span class="hljs-comment"># 编译模型，初始学习率0.001</span><br>model.<span class="hljs-built_in">compile</span>(<br>    optimizer=tf.keras.optimizers.Adam(learning_rate=<span class="hljs-number">0.001</span>),<br>    loss=tf.keras.losses.SparseCategoricalCrossentropy(<br>        from_logits=<span class="hljs-literal">False</span>),  <span class="hljs-comment"># 标签为实数</span><br>    <span class="hljs-comment"># CategoricalCrossentropy(from_logits=False)，标签为二进制编码</span><br>    metrics=[<span class="hljs-string">&quot;accuracy&quot;</span>])<br></code></pre></div></td></tr></table></figure><br>对于大数据集，在训练后期，当loss不再明显时，减小学习率以加大学习的压力。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 监视&#x27;val_loss&#x27;，当两个epoch的loss不变时，学习率减小为1/10</span><br>reduce_lr = ReduceLROnPlateau(monitor=<span class="hljs-string">&#x27;val_loss&#x27;</span>,<br>                              factor=<span class="hljs-number">0.1</span>,<br>                              patience=<span class="hljs-number">2</span>,<br>                              verbose=<span class="hljs-number">1</span>)<br></code></pre></div></td></tr></table></figure><br>将训练集的图像和标签输入到分类器中拟合，拟合过程指定训练的轮数epochs，批数等等。使用TensorFlow2.0特性<code>validation_data()</code>导入测试集图像和标签，训练器在每一轮训练后会使用测试集进行测试，并返回准确率、loss到<code>history</code>中。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 开始训练</span><br>history = model.fit(<br>    x_train,<br>    y_train,<br>    batch_size=<span class="hljs-number">128</span>,<br>    epochs=<span class="hljs-number">15</span>,<br>    validation_data=(x_test, y_test),<br>)<br>print(<span class="hljs-string">&quot;train complieted&quot;</span>)<br></code></pre></div></td></tr></table></figure></p><h2 id="读取训练参数并保存模型"><a href="#读取训练参数并保存模型" class="headerlink" title="读取训练参数并保存模型"></a>读取训练参数并保存模型</h2><p>将记录到的loss、准确率进行读取，并使用pyPlot函数库对训练结果进行可视化处理。<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-comment"># 记录准确率和损失值</span><br>history_dict = history.history<br>train_loss = history_dict[<span class="hljs-string">&quot;loss&quot;</span>]<br>train_accuracy = history_dict[<span class="hljs-string">&quot;accuracy&quot;</span>]<br>val_loss = history_dict[<span class="hljs-string">&quot;val_loss&quot;</span>]<br>val_accuracy = history_dict[<span class="hljs-string">&quot;val_accuracy&quot;</span>]<br><br><span class="hljs-comment"># Generate predictions (probabilities -- the output of the last layer)</span><br><span class="hljs-comment"># on new data using `predict`</span><br>print(<span class="hljs-string">&quot;Generate predictions for 3 samples&quot;</span>)<br>predictions = model.predict(x_test[:<span class="hljs-number">3</span>])<br>print(<span class="hljs-string">&quot;predictions shape:&quot;</span>, predictions.shape)<br><br>print(<span class="hljs-string">&quot;ploting..&quot;</span>)<br><span class="hljs-comment"># 绘制损失值</span><br>plt.figure()<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), train_loss, label=<span class="hljs-string">&#x27;train_loss&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), val_loss, label=<span class="hljs-string">&#x27;val_loss&#x27;</span>)<br>plt.legend()<br>plt.xlabel(<span class="hljs-string">&#x27;epochs&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;loss&#x27;</span>)<br><br><span class="hljs-comment"># 绘制准确率</span><br>plt.figure()<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), train_accuracy, label=<span class="hljs-string">&#x27;train_accuracy&#x27;</span>)<br>plt.plot(<span class="hljs-built_in">range</span>(epochs), val_accuracy, label=<span class="hljs-string">&#x27;val_accuracy&#x27;</span>)<br>plt.legend()<br>plt.xlabel(<span class="hljs-string">&#x27;epochs&#x27;</span>)<br>plt.ylabel(<span class="hljs-string">&#x27;accuracy&#x27;</span>)<br>plt.show()<br></code></pre></div></td></tr></table></figure><br>使用<code>model.save()</code>函数保存训练模型，训练模型的格式有两种：  </p><ol><li>h5，生成的是一个*.h5文件，需要使用<code>keras</code>进行读取。  </li><li>tf，生成的是一个模型文件夹，比较容易读取。  </li></ol><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python">print(<span class="hljs-string">&quot;saving the model...&quot;</span>)<br><span class="hljs-comment"># 模型保存，注意：仅仅是多了一个save_format的参数而已</span><br><span class="hljs-comment"># 注意：这里的&#x27;path_to_saved_model&#x27;不再是模型名称，仅仅是一个文件夹，模型会保存在这个文件夹之下</span><br>model.save(<span class="hljs-string">&#x27;model/&#x27;</span>, save_format=<span class="hljs-string">&#x27;tf&#x27;</span>)<br>print(<span class="hljs-string">&quot;completed&quot;</span>)<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 离散傅里叶变换</title>
    <link href="/2021/09/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/3.%20%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/09/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/3.%20%E7%A6%BB%E6%95%A3%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="离散傅里叶变换"><a href="#离散傅里叶变换" class="headerlink" title="离散傅里叶变换"></a>离散傅里叶变换</h1><h2 id="傅里叶变换的意义"><a href="#傅里叶变换的意义" class="headerlink" title="傅里叶变换的意义"></a>傅里叶变换的意义</h2><p>对于一个线性时不变系统，系统任意的输入的信号可以表示为一系列特征函数的线性组合。而傅里叶变换的本质在于求出这个线性组合中每一项的系数和这个线性组合本身的表示。而连续时间域中的傅里叶变换是离散域中线性组合概念的拓展。<br>离散频域中的线性时不变系统的特征函数是指数函数（序列）:$e^{jω_kn}$，因此通过傅里叶变换，任何一个满足狄利克雷条件的离散时间域中的信号都可以表示为指数序列的线性组合：  </p><script type="math/tex; mode=display">x[n]=∑_ka_ke^{jω_kn}</script><p>通过傅里叶变换，这个线性组合可以表示为：</p><script type="math/tex; mode=display">x[n]=\frac{1}{2π}∫_{-π}^πX(e^{jω})e^{jωn}</script><p>其中$X(jω)$为这个线性组合的系数，有：   </p><script type="math/tex; mode=display">X(e^{jω})=∑_{n=-∞}^∞x[n]e^{-jωn}</script><p>上述式子称为离散傅里叶变换。 </p><blockquote><p>由于等比数列的求和性质，变换的结果是一个连续频谱。  </p></blockquote><p>其反变换即线性组合的表达式:  </p><script type="math/tex; mode=display">x[n]=\frac{1}{2π}∫_{-π}^πX(e^{jω})e^{jωn}</script><p>由傅里叶变换，这个线性组合的特征函数$e^{jωn}$在时域内表现为正弦函数$cosωn$，因此这个线性组合在时域上表征为正弦函数的线性组合，这表示<strong>一个信号可以被分解为若干个特性不同的正弦波。</strong>  </p><p>连续和离散傅里叶变换的对比如下表所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210925140243.png width=80%>  </p><h2 id="离散傅里叶变换的共轭性质"><a href="#离散傅里叶变换的共轭性质" class="headerlink" title="离散傅里叶变换的共轭性质"></a>离散傅里叶变换的共轭性质</h2><h3 id="序列的分解"><a href="#序列的分解" class="headerlink" title="序列的分解"></a>序列的分解</h3><h4 id="复分解"><a href="#复分解" class="headerlink" title="复分解"></a>复分解</h4><p>同连续傅里叶变换，离散傅里叶变换也可以做复分解：  </p><script type="math/tex; mode=display">X(e^{jω})=X_R(e^{jω})+jX_I(e^{jω})</script><h4 id="共轭分解"><a href="#共轭分解" class="headerlink" title="共轭分解"></a>共轭分解</h4><p>定义序列$x[n]$的共轭对称序列:  </p><script type="math/tex; mode=display">x_e[n]=\frac{1}{2}(x[n]+x^*[-n])</script><p>共轭对称序列的性质：$x_e[n]=x_e^*[-n]$<br>序列$x[n]$的共轭反对称序列:  </p><script type="math/tex; mode=display">x_o[n]=\frac{1}{2}(x[n]-x^*[-n])</script><p>共轭反对称序列的性质：$x_o[n]=-x_o^*[-n]$<br>任何一个序列$x[n]$可以表示为其共轭对称和共轭反对称序列的和：  </p><script type="math/tex; mode=display">x[n]=x_e[n]+x_o[n]</script><p>共轭分解对频域序列也同样适用。  </p><h3 id="共轭信号的性质"><a href="#共轭信号的性质" class="headerlink" title="共轭信号的性质"></a>共轭信号的性质</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域序列</th><th style="text-align:center">频域变换</th></tr></thead><tbody><tr><td style="text-align:center">反向</td><td style="text-align:center">$x^<em>[n]$ <br> $x^</em>[-n]$</td><td style="text-align:center">$X^<em>(e^{-jω})$ <br> $X^</em>(e^{jω})$</td></tr><tr><td style="text-align:center">幅度分量为偶函数</td><td style="text-align:center">$\</td><td style="text-align:center">X(e^{jω})\</td><td>$</td><td>$\</td><td>X(e^{-jω})\</td><td>$</td></tr><tr><td style="text-align:center">相位分量为奇函数</td><td style="text-align:center">$∠X(e^{jω})$</td><td style="text-align:center">$-∠X(e^{-jω})$</td></tr><tr><td style="text-align:center">实部分量为偶函数</td><td style="text-align:center">$X_R(e^{jω})$</td><td style="text-align:center">$X_R(e^{-jω})$</td></tr><tr><td style="text-align:center">虚部分量为奇函数</td><td style="text-align:center">$X_I(e^{jω})$</td><td style="text-align:center">$-X_I(e^{-jω})$</td></tr></tbody></table></div><h2 id="离散傅里叶变换的性质"><a href="#离散傅里叶变换的性质" class="headerlink" title="离散傅里叶变换的性质"></a>离散傅里叶变换的性质</h2><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域序列</th><th style="text-align:center">频域变换</th></tr></thead><tbody><tr><td style="text-align:center">线性</td><td style="text-align:center">$ax[n]+by[n]$</td><td style="text-align:center">$aX(e^{jω})+bY(e^{jω})$</td></tr><tr><td style="text-align:center">时移</td><td style="text-align:center">$x[n-n_0]$</td><td style="text-align:center">$e^{-jωn_0}X(e^{jω})$</td></tr><tr><td style="text-align:center">频移</td><td style="text-align:center">$e^{jω_0n}x[n]$</td><td style="text-align:center">$X(e^{j(ω-ω_0)})$</td></tr><tr><td style="text-align:center">反转</td><td style="text-align:center">$x[-n]$</td><td style="text-align:center">$X(e^{-jω})$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">频域微分</td><td style="text-align:center">$nx[n]$</td><td style="text-align:center">$j\frac{dX(e^{jω})}{dω}$</td></tr></tbody></table></div><h3 id="卷积特性"><a href="#卷积特性" class="headerlink" title="卷积特性"></a>卷积特性</h3><p>时域卷积：  </p><script type="math/tex; mode=display">x[n]*y[n]⇔X(e^{jω})Y(e^{jω})</script><p>频域卷积：  </p><script type="math/tex; mode=display">x[n]y[n]⇔\frac{1}{2π}X(e^{jω})*Y(e^{jω})=\frac{1}{2π}∫_{-π}^πX(e^{jθ})Y(e^{j(ω-θ)dθ})</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Unit 11~15</title>
    <link href="/2021/09/21/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%2011~15/"/>
    <url>/2021/09/21/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%2011~15/</url>
    
    <content type="html"><![CDATA[<h1 id="Unit-11-15-な行・は行"><a href="#Unit-11-15-な行・は行" class="headerlink" title="Unit 11~15 な行・は行"></a>Unit 11~15 な行・は行</h1><h2 id="Unit-11-な・に"><a href="#Unit-11-な・に" class="headerlink" title="Unit 11 な・に"></a>Unit 11 な・に</h2><ul><li>ないことにはない・ないこともない・ないではない・ないではない   <ul><li>動詞ない形・い形容詞ない形・な形容詞～で＋ないことにはない・ないこともない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不是不能……】消极</span>  </span></li><li>動詞ない形・い形容詞ない形・な形容詞～で＋ないではない・ないではない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【也不是不……】</span>  </span></li></ul></li><li>ながら（も）<br>動詞ます形・な形容詞・い形容詞・名詞＋ながら（も）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然……，但是……】</span>  </span></li><li>なくはない・なくもない<br>動詞ない形・い形容詞ない形・な形容詞～で・名詞～が・は＋なくはない・なくもない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不是不……】</span>  </span></li><li>ならともかく<br>動詞辞書形・な形容詞・い形容詞・名詞＋ならともかく   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果是……那么另当别论】</span>  </span></li><li>にあたって・にあたり<br>動詞辞書形・名詞＋にあたって・にあたり   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……之际（重要的时刻）】</span>  </span></li><li>において・における<br>名詞＋において・における   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……方面，时间、地点、状况】</span>  </span></li><li>に応じて・に応じ・に応じた<br>名詞＋に応じて・に応じ・に応じだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【按照/根据……而变】</span>  </span></li><li>に（は）かかわらず・に（は）かかわりず<br>動詞辞書形・ない形～ない・名詞・い形容詞・な形容詞＋に（は）かかわらず・に（は）かかわりず   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【无论是……，都】</span>  </span></li><li>に限って・に限り<br>名詞＋に限って・に限り   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只限于……】</span>  </span></li><li>に限って<br>名詞＋に限って   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【唯独……】</span>  </span></li></ul><h2 id="Unit-12-に"><a href="#Unit-12-に" class="headerlink" title="Unit 12 に"></a>Unit 12 に</h2><ul><li>にかぎる<br>動詞辞書形・ない形～ない＋に限る   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【最好是……】</span>  </span>  </li><li>にかけては・にかけても<br>名詞＋にかけては・にかけても   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……方面】</span>  </span>  </li><li>に決まっている<br>動詞辞書形・い形容詞・な形容詞・名詞＋に決まっている   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一定……】确切的推测</span>  </span>  </li><li>に加えて・に加え<br>名詞＋に加えて・に加え   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【加上……】</span>  </span>  </li><li>に越したことはない<br>動詞辞書形・い形容詞・な形容詞～である・名詞～である＋に越したことはない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【是……的话那再好不过了】</span>  </span>  </li><li>に応えて・に応え<br>名詞＋に応えて・に応え   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【应……】</span>  </span>  </li><li>に際して・に際し・に際しての<br>動詞辞書形・名詞＋に際して・に際し・に際しての   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【当……之际】</span>  </span>  </li><li>に先立って・に先立ち<br>名詞＋に先立って・に先立ち   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……之前】</span>  </span>  </li><li>に従って・に従い<br>動詞辞書形・名詞＋に従って・に従い <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【按照……】</span>  </span>  </li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【随着……】</span>  </span>  </li></ol></li><li>にしたら・にすれば・にしても<br>名詞＋にしたら・にすれば・にしても   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……的立场来看】</span>  </span>  </li></ul><h2 id="Unit-13-に"><a href="#Unit-13-に" class="headerlink" title="Unit 13 に"></a>Unit 13 に</h2><ul><li>にしては<br>動詞普通形・い形容詞・な形容詞・名詞＋にしては   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就……而言】</span>  </span></li><li>にしても・にせよ・にしろ  <ul><li>動詞普通形・い形容詞・な形容詞・名詞（～である）＋にしても・にせよ・にしろ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【即使是……】</span>  </span></li><li>两个にしても・にせよ・にしろ连用   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【无论是……还是……，都】，两个对立面的事物</span>  </span></li></ul></li><li>に過ぎない<br>動詞普通形・い形容詞・な形容詞（～である）・名詞（である）＋に過ぎない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不过是……而已】</span>  </span></li><li>に相違ない・に違いない<br>動詞普通形・い形容詞・な形容詞・名詞＋に相違ない・に違いない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一定是……】</span>  </span></li><li>に沿って・に沿った<br>名詞＋に沿って・に沿った   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【按照……】</span>  </span></li><li>につき<br>名詞＋につき <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【每……】，表示平均每几个分得到一个</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【因为……】，郑重地告知</span>  </span></li></ol></li><li>につけ・にしけては・につけても<br>動詞辞書形＋につけ・にしけては・につけても   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【每当……，就……】</span>  </span><br>動詞辞書形・い形容詞・名詞＋につけ＋動詞普通形・い形容詞・名詞＋につけ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不论……还是……都……】</span>  </span></li><li>に伴って・に伴う・に伴い<br>動詞辞書形・名詞＋に伴って・に伴う・に伴い   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【随着……】</span>  </span></li><li>に反する・に反して・に反し<br>名詞＋に反する・に反して・に反し   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【与……相反】</span>  </span></li></ul><h2 id="Unit-14-に・ぬ・の・は（ば）"><a href="#Unit-14-に・ぬ・の・は（ば）" class="headerlink" title="Unit 14　に・ぬ・の・は（ば）"></a>Unit 14　に・ぬ・の・は（ば）</h2><ul><li>にほかならない  <ul><li>名詞＋にほかならない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正是……】，强调没有其他</span>  </span></li><li>動詞普通形・い形容詞・な形容詞～である/だ・名詞～である/だ＋にほかならない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正是因为……】，强调没有其他原因</span>  </span></li></ul></li><li>にもかかわらず<br>動詞普通形・い形容詞・な形容詞・名詞（～である）＋にもかかわらず   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然……，但是……】</span>  </span> </li><li>に基づいて・に基づき・に基づく・に基づいた<br>名詞＋に基づいて・に基づき・に基づく・に基づいた   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【根据……】</span>  </span></li><li>にわたって・にわたり・にわたる・にわたった<br>名詞＋にわたって・にわたり・にわたる・にわたった   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【涉及……】，表示时间和空间的范围，强调时间之长、范围之广</span>  </span></li><li>抜きでは・抜きに（は）・抜きの・を抜きにして（は）・は抜きにして    <ul><li>名詞＋抜きでは・抜きに（は）・抜きの   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【省去……/如果没有……，就（不）……】</span>  </span></li><li>名詞＋を抜きにして（は）・は抜きにして   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【省去……/如果没有……，就（不）……】，除去一般情况下会有的东西</span>  </span></li></ul></li><li>抜く<br>動詞ます形＋抜く   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【终于……】，克服困难坚持最终做完了</span>  </span></li><li>のみならず<br>動詞普通形・い形容詞・な形容詞・名詞（～である）＋のみならず   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不仅……】</span>  </span></li><li>のもとで・のもとに  <ul><li>名詞＋のもとで・のもとに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……的影响下】</span>  </span></li><li>名詞＋名のもとに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【以……的名义】</span>  </span></li></ul></li><li>はおろか<br>動詞普通形～の・名詞＋はおろか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不要说……，就连……也……】</span>  </span>  </li><li>ばかりか<br>動詞普通形・い形容詞・な形容詞・名詞＋ばかりか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不只是……】</span>  </span><br>動詞ない形＋ばかりか　  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不只是不……】</span>  </span>  </li></ul><h2 id="Unit-15-は（ば）・へ（べ）・ほ・ま"><a href="#Unit-15-は（ば）・へ（べ）・ほ・ま" class="headerlink" title="Unit 15 は（ば）・へ（べ）・ほ・ま"></a>Unit 15 は（ば）・へ（べ）・ほ・ま</h2><ul><li>ばかりに<br>動詞普通形・な形容詞～な・い形容詞・名詞～な/である＋ばかりに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正是因为……】，表示由于不好的原因造成的意料之外的结果</span>  </span> </li><li>はともかく（として）<br>名詞＋はともかく（として）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【先不说……】</span>  </span> </li><li>は別として・は別にして<br>名詞＋は別として・は別にして<br>動詞普通形・な形容詞・い形容詞・名詞＋かどうか/か＋は別として・は別にして    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【先不说】</span>  </span>  </li><li>はもちろん・はもとより<br>名詞＋はもちろん・はもとより   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【连……的话，更不用说……】</span>  </span> </li><li>反面・半面<br>動詞普通形・い形容詞・な形容詞～な/である・名詞～である＋半面・反面   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【另一方面……】</span>  </span>  </li><li>べき・べきだ・べきではない<br>動詞辞書形＋べき・べきだ・べきではない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【应该……】，社会常识、义务的行为</span>  </span> </li><li>ほか（は）ない・よりほか（は）ない<br>動詞辞書形＋ほか（は）ない・よりほか（は）ない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只有……】，表示别无他法</span>  </span> </li><li>ほど・ほどだ・ほどの  <ul><li>ば～ほど<br>動詞ば形・い形容詞ば形＋動詞辞書形・い形容詞＋ほど<br>名詞＋であれば＋名詞＋である＋ほど<br>な形容詞＋であれば＋な形容詞＋である＋ほど    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【越……就越……】</span>  </span>  </li><li>動詞辞書形・ない形～ない・な形容詞～な・い形容詞・名詞＋ほど・ ほどだ・ほどの   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……的程度】</span>  </span>  </li><li>動詞辞書形・な形容詞～ない・な形容詞～な・い形容詞・名詞＋ほど   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【越……越……】</span>  </span></li></ul></li><li>まい・まいか<br>動詞辞書形＋まい・まいか＋動詞ない形＋まい・まいか  <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不想……】，否定的用法</span>  </span>  </li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不会……吧，也许不……】，否定的推测</span>  </span>  </li></ol></li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>N2备考文法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 数字系统</title>
    <link href="/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/2.%20%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F/"/>
    <url>/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/2.%20%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="数字系统"><a href="#数字系统" class="headerlink" title="数字系统"></a>数字系统</h1><h2 id="系统的特性"><a href="#系统的特性" class="headerlink" title="系统的特性"></a>系统的特性</h2><h3 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h3><p>线性系统满足两个特点：齐次性和可加性。  </p><h4 id="齐次性"><a href="#齐次性" class="headerlink" title="齐次性"></a>齐次性</h4><p>如果$x[n]→T→y[n]$，有：  </p><script type="math/tex; mode=display">Ax[n]→T→Ay[n]</script><p>称系统具有齐次性。  </p><h4 id="可加性"><a href="#可加性" class="headerlink" title="可加性"></a>可加性</h4><p>如果$x_1[n]→T→y_1[n]$、$x_2[n]→T→y_2[n]$，有：  </p><script type="math/tex; mode=display">x_1[n]+x_2[n]→T→y_1[n]+y_2[n]</script><p>称系统具有可加性。  </p><p>同时满足齐次性和可加性的系统称为线性系统。  </p><h3 id="时不变性"><a href="#时不变性" class="headerlink" title="时不变性"></a>时不变性</h3><p>系统中如果输入的时移会导致系统输出的同步时移，这样的系统称为时不变系统：<br>如果$x[n]→T→y[n]$，有：  </p><script type="math/tex; mode=display">x[n-n_0]→T→y[n-n_0]</script><h3 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h3><p>如果系统的输入和输出都有界，那么称系统是稳定的。  </p><script type="math/tex; mode=display">x[n]<∞,y[n]<∞</script><h3 id="无记忆性"><a href="#无记忆性" class="headerlink" title="无记忆性"></a>无记忆性</h3><p>当前系统的输出只依赖于当前的系统输入、而不依赖于之前的系统输入的系统称为无记忆系统。  </p><h3 id="因果性"><a href="#因果性" class="headerlink" title="因果性"></a>因果性</h3><p>当前系统的输出$y[n]$不会依赖于未来的系统输入:$x[n+n_0],n_0∈Z^*$，这样的系统称为因果系统。  </p><blockquote><p>无记忆系统一定是因果系统。  </p><p>非因果系统可以通过设置延时器转换为因果系统。  </p></blockquote><h2 id="卷积和"><a href="#卷积和" class="headerlink" title="卷积和"></a>卷积和</h2><p>定义离散信号的卷积称为卷积和：  </p><script type="math/tex; mode=display">∑x[k]h[n-k]=x[n]*h[n]</script><h3 id="单位采样响应"><a href="#单位采样响应" class="headerlink" title="单位采样响应"></a>单位采样响应</h3><p>对于给定的系统$T[·]$，当系统输入为单位冲击序列$δ[n]$时的系统输出$h[n]$称为单位采样响应。  </p><script type="math/tex; mode=display">h[n]=T[δ[n]]</script><p>对于线性系统：$x[n]→T→y[n]$，<br>由齐次性：$x[0]δ[n]→T→x[0]h[n]$<br>由时不变性：$x[k]δ[n-k]→T→x[k]h[n-k]$<br>由单位冲激序列的采样特性：$x[n]=∑x[k]δ[n-k]$<br>因此：  </p><script type="math/tex; mode=display">y[n]=∑x[k]h[n-k]=x[n]*h[n]</script><p>即<strong>系统输出$y[n]$可以表示为系统输入$x[n]$与单位采样响应$h[n]$的卷积</strong>。  </p><h3 id="卷积和的运算性质"><a href="#卷积和的运算性质" class="headerlink" title="卷积和的运算性质"></a>卷积和的运算性质</h3><ol><li><p>线性：$x[n]<em>(h_1[n]+h_2[n])=x[n]</em>h_1[n]+x[n]*h_2[n]$  </p><blockquote><p>线性揭示了卷积和运算可以被并行化处理  </p></blockquote></li><li><p>交换律：$x[n]<em>h_1[n]</em>h_2[n]=x[n]<em>h_2[n]</em>h_1[n]$  </p></li><li>结合律：$x[n]<em>h_1[n]</em>h_2[n]=x[n]<em>(h_1[n]</em>h_2[n])$</li></ol><h2 id="数字系统方程"><a href="#数字系统方程" class="headerlink" title="数字系统方程"></a>数字系统方程</h2><p>数字系统可以由差分方程进行描述：  </p><script type="math/tex; mode=display">∑_{k=0}^Na_ky[n-k]=∑_{k=0}^Mb_kx[n-k]</script><p>其中系统方程的阶$N$由系统最前输出$y[n-N]$决定。  </p><h3 id="数字系统的频率响应·离散傅里叶变换"><a href="#数字系统的频率响应·离散傅里叶变换" class="headerlink" title="数字系统的频率响应·离散傅里叶变换"></a>数字系统的频率响应·离散傅里叶变换</h3><p>类比于连续时间傅里叶变换，称$e^{jωn}$为特征函数（Eigenfuntion）。对于数字系统，当系统的输入为特征函数时：  </p><script type="math/tex; mode=display">y[n]=∑h[k]e^{jω(n-k)}=e^{jωn}∑h[k]e^{-jωk}</script><p>这个变换式称为<strong>离散傅里叶变换</strong>。<br>称$∑h[k]e^{-jωk}$为数字系统的频率响应：  </p><script type="math/tex; mode=display">H(e^{jω})=∑h[k]e^{-jωk}</script><p>其反变换：  </p><script type="math/tex; mode=display">h[n]=\frac{1}{2π}∫_{-π}^{π}H(e^{jω})e^{jωn}dω</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 数字信号</title>
    <link href="/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/1.%20%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7/"/>
    <url>/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/1.%20%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="数字信号"><a href="#数字信号" class="headerlink" title="数字信号"></a>数字信号</h1><p>数字信号是时间离散、幅值离散的信号。但是在本课中为了简化分析，认为时间离散、幅值连续的信号也是数字信号。<br>数字信号可以由序列进行表示：  </p><script type="math/tex; mode=display">...,x[-1],x[0],x[1],...</script><h2 id="采样"><a href="#采样" class="headerlink" title="采样"></a>采样</h2><p>模拟信号是时间连续、幅值连续的信号。使模拟信号转变为数字信号的过程称为采样。采样过程可由如下公式表示：  </p><script type="math/tex; mode=display">x[n]=x(t)|_{t=nT_s}=x(nT_s),n∈Z</script><p>其中$T_s$称为采样周期。  </p><h2 id="常见的数字信号"><a href="#常见的数字信号" class="headerlink" title="常见的数字信号"></a>常见的数字信号</h2><h3 id="单位冲激序列"><a href="#单位冲激序列" class="headerlink" title="单位冲激序列"></a>单位冲激序列</h3><script type="math/tex; mode=display">δ[n]=\begin{cases}    1,n=0 \\    0,others\end{cases}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919151509.png width=30%>  </p><h4 id="冲激序列的采样性质"><a href="#冲激序列的采样性质" class="headerlink" title="冲激序列的采样性质"></a>冲激序列的采样性质</h4><p>类比冲击信号的采样性质，可以发现任何的数字信号都可以表示为时移的单位冲激序列的线性组合。  </p><script type="math/tex; mode=display">x[n]=∑x[k]δ[n-k]</script><h3 id="单位阶跃序列"><a href="#单位阶跃序列" class="headerlink" title="单位阶跃序列"></a>单位阶跃序列</h3><script type="math/tex; mode=display">u[n]=\begin{cases}    1,n≥0 \\    0,others\end{cases}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919151704.png width=30%>  </p><h3 id="指数序列"><a href="#指数序列" class="headerlink" title="指数序列"></a>指数序列</h3><script type="math/tex; mode=display">x[n]=a^n</script><p>如果底数$a$是一个复数:$a=Ae^{jθ}$，此时可以表示为：  </p><script type="math/tex; mode=display">x[n]=A^n(cosθn+jsinθn)</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919154806.png width=50%>  </p><h3 id="三角序列"><a href="#三角序列" class="headerlink" title="三角序列"></a>三角序列</h3><p>连续的三角信号可以表示为：  </p><script type="math/tex; mode=display">x(t)=Asin(Ωt+φ)</script><p>此时的角频率$Ω$称为模拟角频率，单位为rad/s。<br>对连续的三角信号进行采样，从而得到数字域的三角信号：  </p><script type="math/tex; mode=display">x[n]=Asin(2πfn/f_s+φ)=Asin(ωn+φ)</script><p>其中$f_s$是采样频率，$ω=\frac{2πf}{f_s}$，称为数字角频率，单位为rad或者rad/sample。  </p><h4 id="数字角频率的理解"><a href="#数字角频率的理解" class="headerlink" title="数字角频率的理解"></a>数字角频率的理解</h4><p>由数字角频率：  </p><script type="math/tex; mode=display">ω=\frac{2πf}{f_s}=\frac{Ω}{f_s}</script><p>数字角频率可以看做是模拟角频率对其进行归一化的结果。<br>又有角频率公式：$ω=2πf_d$，$f_d$称为数字频率。  </p><script type="math/tex; mode=display">f_d=\frac{f}{f_s}</script><p>数字频率可以看做是对模拟频率$f$进行归一化的结果。  </p><h3 id="三角序列的周期性"><a href="#三角序列的周期性" class="headerlink" title="三角序列的周期性"></a>三角序列的周期性</h3><p>定义数字信号的周期性为：  </p><script type="math/tex; mode=display">x(n)=x(n+N)</script><p>对于数字三角信号（三角序列），有：  </p><script type="math/tex; mode=display">Acos(ω_0n+φ)=Acos(ω_0(n+N)+φ)=Acos(ω_0n+ω_0N+φ),0≤ω_0≤2π</script><p>可以发现当$ω_0N=2πk,k∈Z$时上述式子成立。<br>得到：</p><script type="math/tex; mode=display">ω_0=\frac{2πk}{N},k=0,1,...,N-1</script><p>也就是说，要想三角信号呈周期性：  </p><ol><li>$ω_0$必须是π的整数倍以保证数字周期$N$是一个自然数。  </li><li>只有N个不同的$ω_0$使得三角信号呈周期性。  </li></ol><h3 id="三角序列的振荡特性"><a href="#三角序列的振荡特性" class="headerlink" title="三角序列的振荡特性"></a>三角序列的振荡特性</h3><p>对于连续的三角信号：$Ω$越大，三角信号的周期越小，三角信号振荡越剧烈。<br>对于三角序列：</p><ul><li>$ω∈(0,π)$时，$ω$越大，三角序列振荡越剧烈。  </li><li>$ω∈(π,2π)$时，$ω$越大，三角序列振荡越平缓。  </li></ul><p>推理的过程如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919154402.png width=70%></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0. 课程简介</title>
    <link href="/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/"/>
    <url>/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E4%BF%A1%E5%8F%B7%E5%A4%84%E7%90%86/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>数字信号处理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 随机变量和随机过程</title>
    <link href="/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/3.%20%E6%A6%82%E7%8E%87%E4%B8%8E%E9%9A%8F%E6%9C%BA/"/>
    <url>/2021/09/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/3.%20%E6%A6%82%E7%8E%87%E4%B8%8E%E9%9A%8F%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="随机变量和随机过程"><a href="#随机变量和随机过程" class="headerlink" title="随机变量和随机过程"></a>随机变量和随机过程</h1><blockquote><p>由于通信原理所研究的信号是连续的模拟信号，因此本节主要复习连续随机变量/随机过程的性质。  </p></blockquote><h2 id="随机变量"><a href="#随机变量" class="headerlink" title="随机变量"></a>随机变量</h2><h3 id="概率密度和概率分布函数"><a href="#概率密度和概率分布函数" class="headerlink" title="概率密度和概率分布函数"></a>概率密度和概率分布函数</h3><p>对于随机变量$X$，<strong>概率密度函数</strong>(PDF)$f(x)$表示当$X=x$时候的概率：  </p><script type="math/tex; mode=display">f(x)=P(X=x)</script><p><strong>概率分布函数/积累分布函数</strong>（CDF）$F(x)$表示$X$小于$x$的概率，对于连续随机变量，积累分布函数可以表示为：  </p><script type="math/tex; mode=display">F(x)=P(X≤x)=∫_{-∞}^xf(u)du</script><p>积累分布函数和概率密度函数有如下关系：  </p><script type="math/tex; mode=display">f(x)=\frac{dF(x)}{dx}</script><h4 id="概率密度函数的性质"><a href="#概率密度函数的性质" class="headerlink" title="概率密度函数的性质"></a>概率密度函数的性质</h4><ul><li>正定性：$f(x)≥0$  </li><li>概率之和为1：$∫f(x)dx=1$</li><li>区间概率：$P(a&lt;X≤b)=∫_a^bf(x)dx$</li></ul><h3 id="随机变量的统计特征"><a href="#随机变量的统计特征" class="headerlink" title="随机变量的统计特征"></a>随机变量的统计特征</h3><h4 id="期望"><a href="#期望" class="headerlink" title="期望"></a>期望</h4><p>期望表示随机变量的均值：  </p><script type="math/tex; mode=display">E(x)=∫xf(x)dx</script><p>期望的计算性质：  </p><ul><li>$E(C)=C$</li><li>$E(X+Y)=E(X)+E(Y)$</li><li>当随机变量$X$,$Y$<strong>相互独立</strong>时，$E(XY)=E(X)E(Y)$</li></ul><h4 id="方差"><a href="#方差" class="headerlink" title="方差"></a>方差</h4><p>方差表示随机变量分布的离散程度:  </p><script type="math/tex; mode=display">D(X)=∫[x_i-E(X)]^2f(x)dx</script><p>更多时候，方差可由期望推导出： </p><script type="math/tex; mode=display">D(x)=E[X-E(X)]^2=E(X^2)-E^2(X)</script><blockquote><p>求方差的步骤： </p><ol><li>求出期望$E(X)$</li><li>求出均方值期望$E^2(X)$</li><li>带入公式求得$D(X)$</li></ol></blockquote><p>方差的计算性质：  </p><ul><li>$D(C)=0$</li><li>$D(X+C)=D(X)$</li><li>$D(CX)=C^2X$</li><li>当随机变量$X$,$Y$<strong>相互独立</strong>时，$D(X+Y)=D(X)+D(Y)$</li></ul><h2 id="通信原理中常见随机变量的分布"><a href="#通信原理中常见随机变量的分布" class="headerlink" title="通信原理中常见随机变量的分布"></a>通信原理中常见随机变量的分布</h2><h3 id="均匀分布"><a href="#均匀分布" class="headerlink" title="均匀分布"></a>均匀分布</h3><p>均匀分布（Uniform Distribution）指随机变量在某个区间$(a,b)$内取到某个值$x$的概率是相同的。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919131848.png width=50%>  </p><p>均匀分布的概率密度函数：  </p><script type="math/tex; mode=display">f(x)=\begin{cases}    \frac{1}{b-a},a≤x≤b \\    0,others\end{cases}</script><ul><li>期望：$E(x)=\frac{b+a}{2}$</li><li>方差：$D(x)=\frac{(b-a)^2}{12}$</li></ul><h3 id="高斯分布-正态分布"><a href="#高斯分布-正态分布" class="headerlink" title="高斯分布/正态分布"></a>高斯分布/正态分布</h3><p>随机变量在不任何束缚前提下的总体变化规律称为高斯分布/正态分布。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210919131811.png width=50%>  </p><p>高斯分布的概率密度函数：  </p><script type="math/tex; mode=display">f(x)=\frac{1}{√(2π)σ}exp[-\frac{(x-μ)^2}{2σ^2}]</script><p>其中$μ$是随机变量$X$的均值，它影响高斯分布曲线的轴的位置。<br>$σ^2$是随机变量$X$的方差，它影响高斯分布曲线中最大值点的位置。  </p><h3 id="瑞利分布"><a href="#瑞利分布" class="headerlink" title="瑞利分布"></a>瑞利分布</h3><p>当一个随机二维向量的两个分量呈独立的、有着相同的方差、均值为0的 正态分布 时，这个向量的模呈瑞利分布。<br>瑞利分布的概率密度函数：  </p><script type="math/tex; mode=display">f(x)=\begin{cases}    \frac{x}{σ^2}exp(-\frac{x^2}{2σ^2}),x≥0 \\    0,x≤0\end{cases}</script><p>$σ^2$是瑞利分布的方差。  </p><h2 id="随机过程"><a href="#随机过程" class="headerlink" title="随机过程"></a>随机过程</h2><p>与上文所述的确知过程不同的是，在每一个时间点上的概率都不能用一个或若干个时间函数进行描述的过程称为随机过程。<br>随机过程可以有两种理解方式：  </p><ol><li>在样本空间$S$中对每一个样本$s_i$采样得到的所有采样函数的集合。  </li><li>样本空间$S$中所有随机变量随着时间的推移。<br>简单来说，随机过程可以理解为是若干随机变量的集合。<br>随机过程的阶指随机过程中含有的随机变量的个数。阶数越大，对随机过程的统计特性描述就越充分。  </li></ol><h3 id="概率密度和概率分布函数-1"><a href="#概率密度和概率分布函数-1" class="headerlink" title="概率密度和概率分布函数"></a>概率密度和概率分布函数</h3><p>随机过程$ξ(t)$在某个固定的时间$t=t_1$时是一个随机变量$ξ(t_1)$，其一阶概率积累函数可以表示为：  </p><script type="math/tex; mode=display">F_1(x_1,t_1)=P(ξ(t_1)≤x_1)</script><p>同样地：  </p><script type="math/tex; mode=display">f(ξ(t_1))=\frac{∂F_1(x_1,t_1)}{∂x_1}</script><h3 id="描述随机过程的统计特征"><a href="#描述随机过程的统计特征" class="headerlink" title="描述随机过程的统计特征"></a>描述随机过程的统计特征</h3><h4 id="期望-1"><a href="#期望-1" class="headerlink" title="期望"></a>期望</h4><script type="math/tex; mode=display">E(ξ(t))=∫xf_1(x,t)dx=e(t)</script><p>此时随机过程的期望应该是一个关于时间的函数。表示的是随机过程值的摆动中心。  </p><h4 id="方差-1"><a href="#方差-1" class="headerlink" title="方差"></a>方差</h4><script type="math/tex; mode=display">D(ξ(t))=E(ξ^2(t))-e(t)^2</script><p>随机过程的方差表示随机过程值围绕期望的摆动幅度。  </p><h4 id="自相关函数"><a href="#自相关函数" class="headerlink" title="自相关函数"></a>自相关函数</h4><p>随机过程的自相关函数用于描述随机过程在不同时间点上的随机变量之间的关联程度。  </p><script type="math/tex; mode=display">R(t,t+τ)=E[ξ(t)ξ(t+τ)]</script><p>自相关函数在$τ=0$时取得最大值，易证$R(0)=E[ξ^2(t)]$。<br>自相关函数在通信领域的一个应用是用于判断多径效应产生的时移信号与原信号之间的相关性。  </p><h3 id="平稳随机过程"><a href="#平稳随机过程" class="headerlink" title="平稳随机过程"></a>平稳随机过程</h3><p>严平稳过程要求随机变量的变化与初始值无关，只与时间间隔有关的随机过程。  </p><script type="math/tex; mode=display">f_n(x_1,...,x_n;t_1,...,t_n)=f_n(x_1,...,x_n;t_1+τ,...,t_n+τ)</script><p>宽平稳过程要求：  </p><ol><li>随机过程的均值是一个常数：$E(ξ(t))=C$</li><li>自相关函数是一个只关于时间间隔$τ$的函数：$R(t,t+τ)=R(τ)$</li></ol><h4 id="功率信号"><a href="#功率信号" class="headerlink" title="功率信号"></a>功率信号</h4><p>在通信系统中，功率信号是一个宽平稳随机过程，下面使用自相关函数研究其性质。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">功率信号</th><th style="text-align:center">自相关函数</th><th style="text-align:center">注解</th></tr></thead><tbody><tr><td style="text-align:center">平均功率</td><td style="text-align:center">$R(0)=E(ξ^2(t))$</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">直流功率</td><td style="text-align:center">$R(∞)=E^2(ξ(t))$</td><td style="text-align:center">当τ→∞时，表示为两个不相关信号的自相关函数</td></tr><tr><td style="text-align:center">交流功率</td><td style="text-align:center">$R(0)-R(∞)=σ^2$</td><td style="text-align:center">平均功率=交流功率+直流功率</td></tr></tbody></table></div><blockquote><p>求解平均功率的方式：  </p><ol><li>$R(0)$</li><li>$E(ξ^2(t))$</li><li>谱密度函数的积分<ul><li>对于角频率谱密度函数：$\frac{1}{2π}∫P_ξ(ω)dω$</li><li>对于频率密度函数：$∫P_ξ(f)df$</li></ul></li></ol></blockquote><p>由于直流功率（功率的直流分量）是一个常数而不含有任何信息，对信号处理时常常使用自相关函数分解直流功率和交流功率。  </p><h3 id="遍历随机过程"><a href="#遍历随机过程" class="headerlink" title="遍历随机过程"></a>遍历随机过程</h3><p>如果一个随机过程的任何一个样本都经历了平稳随机过程所有的可能状态，称这个随机过程是遍历随机过程（Ergodic Random Process）。便利随机过程最大的特点是过程中的任意一个随机变量$x(t)$的在时间上的统计特性和这个随机过程$ξ(t)$的统计特性相等。<br>对于遍历随机过程的期望：  </p><script type="math/tex; mode=display">E[ξ(t)]=∫ξf(ξ,t)dt=\lim_{T→∞}\frac{1}{T}∫_{-\frac{T}{2}}^\frac{T}{2}x(t)dt=\overline{a}</script><p>遍历随机过程的自相关函数：  </p><script type="math/tex; mode=display">R(τ)=E[ξ(t)ξ(t+τ)]=\lim_{T→∞}\frac{1}{T}∫_{-\frac{T}{2}}^\frac{T}{2}x(t)x(t+τ)dt=\overline{R(τ)}</script><p>综合上述两点，遍历随机过程必然是平稳随机过程。   </p><h4 id="证明遍历性"><a href="#证明遍历性" class="headerlink" title="证明遍历性"></a>证明遍历性</h4><ol><li>计算过程中任意一个随机变量的期望：$E(X(t))=∫x(t)f(x,t)dt$  </li><li>计算随机过程的时间均值：$\lim_{T→∞}\frac{1}{T}∫_{-\frac{T}{2}}^\frac{T}{2}f(t)dt$</li><li>证明两者相等  </li></ol><blockquote><p>对于时间均值函数：</p><script type="math/tex; mode=display">Avg.=\lim_{T→∞}\frac{1}{T}∫_{-\frac{T}{2}}^\frac{T}{2}f(t)dt</script><p><strong>当$f(t)$是一个周期函数时，其时间均值为0。</strong></p></blockquote><h2 id="随机过程通过系统"><a href="#随机过程通过系统" class="headerlink" title="随机过程通过系统"></a>随机过程通过系统</h2><p>由于真实的信号和噪声都是随机过程，因此有必要知道对于给定的随机过程，通过系统后，系统的输出情况。  </p><h3 id="随机过程通过线性系统"><a href="#随机过程通过线性系统" class="headerlink" title="随机过程通过线性系统"></a>随机过程通过线性系统</h3><p>设系统的单位冲击响应$h(t)⇔H(ω)$，当随机过程$ξ_i(t)$通过系统后，系统的输出信号为$ξ_o(t)$，有：  </p><script type="math/tex; mode=display">ξ_o(t)=h(t)*ξ_i(t)=∫_0^∞h(τ)ξ_i(t-τ)dτ</script><h4 id="输出信号的期望"><a href="#输出信号的期望" class="headerlink" title="输出信号的期望"></a>输出信号的期望</h4><script type="math/tex; mode=display">\begin{aligned}    E[ξ_o(t)]&=E[∫_0^∞h(τ)ξ_i(t-τ)dτ]\\    &=∫_0^∞h(τ)dτE[ξ_i(t-τ)]\\    &=∫_0^∞h(τ)dτE[ξ_i(t)]\\    &=H(0)E[ξ_i(t)]\end{aligned}</script><p>因此当输入信号是一个平稳随机过程，其期望$E[ξ_i(t)]=a$时，输出信号的期望：  </p><script type="math/tex; mode=display">E[ξ_o(t)]=H(0)E[ξ_i(t)]=aH(0)</script><h4 id="输出信号的自相关函数"><a href="#输出信号的自相关函数" class="headerlink" title="输出信号的自相关函数"></a>输出信号的自相关函数</h4><script type="math/tex; mode=display">\begin{aligned}    R_o(t,t+τ)&=E[ξ_o(t)ξ_o(t+τ)]\\    &=E[∫_0^∞h(α)ξ_i(t-α)dα∫_0^∞h(β)ξ_i(t+τ-β)dβ]\\    &=∫_0^∞h(α)dα∫_0^∞h(β)dβE[ξ_i(t-α)ξ_i(t+τ-β)]\\    &=∫_0^∞h(α)dα∫_0^∞h(β)dβR_i(τ+α-β)\\\end{aligned}</script><p>因此，输出信号的自相关函数结果也必然是一个只与$τ$有关的函数：  </p><script type="math/tex; mode=display">R_o(t,t+τ)==∫_0^∞h(α)dα∫_0^∞h(β)dβR_i(τ+α-β)=R_o(τ)</script><p>综合自相关函数和期望，可以得出结论：<strong>如果线性系统的输入信号是一个平稳随机过程，那么输出信号也必然是一个平稳随机过程。</strong>  </p><h4 id="功率谱密度"><a href="#功率谱密度" class="headerlink" title="功率谱密度"></a>功率谱密度</h4><p>假设输入信号的功率谱密度为$P_{ξ_i}(ω)=∫R_i(τ)e^{-jωτ}dτ$，有：  </p><script type="math/tex; mode=display">\begin{aligned}    P_{ξ_o}(ω)&=∫R_o(τ)dτ\\    &=∫dτ∫_0^∞h(α)dα∫_0^∞h(β)dβR_i(τ+α-β)\\    &=∫_0^∞h(α)e^{jωα}dα∫_0^∞h(β)e^{-jωβ}dβ∫R_i(τ')e^{-jωτ'}dτ'\\    &=H^*(ω)H(ω)P_{ξ_i}(ω)\\    &=|H(ω)|^2P_{ξ_i}(ω)\end{aligned}</script><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210924134156.png width=60%>  </p><h3 id="随机过程通过调制系统"><a href="#随机过程通过调制系统" class="headerlink" title="随机过程通过调制系统"></a>随机过程通过调制系统</h3><p>在信号中，调制系统的实质是一个乘法器，将输入信号与一个正弦信号相乘，得到输出信号。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210924134432.png width=40%>  </p><p>调制系统的输出信号可以表示为：  </p><script type="math/tex; mode=display">ξ_o(t)=ξ_{i}(t)cosω_0t</script><p>调制系统是一个非线性系统。  </p><h4 id="输出信号的自相关函数-1"><a href="#输出信号的自相关函数-1" class="headerlink" title="输出信号的自相关函数"></a>输出信号的自相关函数</h4><script type="math/tex; mode=display">\begin{aligned}    R_o(t,t+τ)&=E[ξ_o(t)ξ_o(t+τ)]\\    &=E[ξ_i(t)ξ_i(t+τ)cosω_0tcosω_0(t+τ)]\\    &=\frac{1}{2}E[ξ_i(t)ξ_i(t+τ)][cosω_0t+cos(2ω_0t+ω_0τ)]\\    &=\frac{1}{2}R_i(τ)[cosω_0t+cos(2ω_0t+ω_0τ)]\\    &=\frac{1}{2}R_i(τ)cosω_0t+\frac{1}{2}R_i(τ)cos(2ω_0t+ω_0τ)\\\end{aligned}</script><h4 id="输出信号的功率谱密度"><a href="#输出信号的功率谱密度" class="headerlink" title="输出信号的功率谱密度"></a>输出信号的功率谱密度</h4><p>可以发现，由于$cos(2ω_0t+ω_0τ)$的存在，输出信号的自相关函数不再是一个只与$τ$相关的函数，此时如果要想通过傅里叶变换求到其频谱密度函数非常困难。<br>此时的方法是选用$cos(2ω_0t+ω_0τ)$的时间均值来近似代表其在整个时间上的变化规律。  </p><script type="math/tex; mode=display">\overline{R_o(t,t+τ)}=\frac{1}{2}R_i(τ)cosω_0t+\frac{1}{2}R_i(τ)\overline{cos(2ω_0t+ω_0τ)}</script><p>由于$cos(2ω_0t+ω_0τ)$是一个周期函数，其时间均值为0。<br>因此$\overline{R_o(t,t+τ)}=\frac{1}{2}R_i(τ)cosω_0t$。<br>对其做傅里叶变换得到输出信号的功率谱密度函数：  </p><script type="math/tex; mode=display">P_{ξ_o(ω)}=F[\frac{1}{2}R_i(τ)cosω_0t]=\frac{1}{4}[P_{ξ_i}(ω+ω_0)+P_{ξ_i}(ω-ω_0)]</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 信号</title>
    <link href="/2021/09/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/2.%20%E4%BF%A1%E5%8F%B7/"/>
    <url>/2021/09/13/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/2.%20%E4%BF%A1%E5%8F%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h1><h2 id="信号的分类"><a href="#信号的分类" class="headerlink" title="信号的分类"></a>信号的分类</h2><h3 id="直流信号和交流信号"><a href="#直流信号和交流信号" class="headerlink" title="直流信号和交流信号"></a>直流信号和交流信号</h3><p>任意信号可以分解为直流信号和交流信号：  </p><script type="math/tex; mode=display">S(t)=S_{ac}(t)+S_{dc}(t)</script><p>直流信号是信号在一周期内的平均值：  </p><script type="math/tex; mode=display">S_{dc}=\lim_{T→∞}∫_{-\frac{T}{2}}^{\frac{T}{2}}S(t)dt</script><p><strong>由于直流信号是一个常量，直流信号不包含任何信息。</strong></p><h3 id="确知信号和随机信号"><a href="#确知信号和随机信号" class="headerlink" title="确知信号和随机信号"></a>确知信号和随机信号</h3><p>在任意时间上的信号参数为已知的信号为确知信号，以$f(t)$表示。<br>信号参数无法被预测的信号称为随机信号，以$p(t)$表示。  </p><h3 id="能量信号和功率信号"><a href="#能量信号和功率信号" class="headerlink" title="能量信号和功率信号"></a>能量信号和功率信号</h3><p>已知确知信号的瞬时能量函数$f(t)$，其能量可以表示为：  </p><script type="math/tex; mode=display">E=∫|f(t)|^2dt</script><p>根据绝对可积性，并将式子中的其中一个$f*(t)$替换为傅里叶反变换表达，得到：  </p><script type="math/tex; mode=display">E=\frac{1}{2π}∫|F(ω)|^2dω</script><p>其中令$E_f(ω)=|F(ω)|^2$，定义为能量谱密度函数。<br>那么能量信号可以写作：  </p><script type="math/tex; mode=display">E=\frac{1}{2π}∫E_f(ω)dω</script><p>能量信号的自相关函数：  </p><script type="math/tex; mode=display">r(τ)=∫f(t)f(t+τ)dt</script><p>其功率信号可以表示为：  </p><script type="math/tex; mode=display">P=\lim_{T→∞}\frac{1}{T}∫_{-T/2}^{T/2}|f(t)|^2dt</script><p>同样地，定义功率谱密度函数为：  </p><script type="math/tex; mode=display">P_f(ω)=\lim_{T→∞}\frac{|F_T(ω)|^2}{T}</script><p>其中$F_T$为周期函数$f(t)$的重复单位$f_t(t)$的傅里叶变换。<br>那么平均功率可以写作：  </p><script type="math/tex; mode=display">P=\frac{1}{2π}∫P_f(ω)dω</script><p>功率信号的自相关函数：  </p><script type="math/tex; mode=display">r(τ)=\lim_{T→∞}\frac{1}{T}∫_{-\frac{T}{2}}^{\frac{T}{2}}f(t)f(t+τ)dt</script><h4 id="维纳——辛钦定理"><a href="#维纳——辛钦定理" class="headerlink" title="维纳——辛钦定理"></a>维纳——辛钦定理</h4><p><strong>能量信号的自相关函数和能量谱密度函数为傅里叶变换对。</strong>  </p><script type="math/tex; mode=display">E_f(t)=∫R(f_e(t))e^{-jωt}dt</script><p><strong>功率信号的自相关函数和功率谱密度函数为傅里叶变换对。</strong>  </p><script type="math/tex; mode=display">P_f(t)=∫R(f_p(t))e^{-jωt}dt</script><p>由维纳——辛钦定理可知，当已知能量信号和功率信号时，对其求自相关函数后做傅里叶变换即可得到对应的谱密度函数。  </p><h2 id="常见的两种信号"><a href="#常见的两种信号" class="headerlink" title="常见的两种信号"></a>常见的两种信号</h2><h3 id="单位冲激信号"><a href="#单位冲激信号" class="headerlink" title="单位冲激信号"></a>单位冲激信号</h3><p>单位冲激信号的表达式：  </p><script type="math/tex; mode=display">δ(t)=\begin{cases} ∞,t=0 \\ 0,t≠0 \\ \end{cases}</script><p>冲激信号的性质：  </p><ol><li>$∫δ(t)dt=1$</li><li>$∫s(t)δ(t-t_0)dt=s(t_0)$  </li></ol><h3 id="门信号"><a href="#门信号" class="headerlink" title="门信号"></a>门信号</h3><script type="math/tex; mode=display">g(t)=u(t+\frac{\tau}{2})-u(t-\frac{\tau}{2})</script><p>其中$τ$称为门函数的宽度。  </p><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><p>在信号与系统中定义傅里叶变换：  </p><script type="math/tex; mode=display">F[f(t)]=∫f(t)e^{-jω_1t}dt</script><p>傅里叶反变换：  </p><script type="math/tex; mode=display">f(t)=\frac{1}{2π}∫F(ω)e^{jωt}dω</script><h2 id="采样定理"><a href="#采样定理" class="headerlink" title="采样定理"></a>采样定理</h2><h3 id="模拟信号转数字信号"><a href="#模拟信号转数字信号" class="headerlink" title="模拟信号转数字信号"></a>模拟信号转数字信号</h3><p>模拟信号$f(t)$转换为数字信号经过三步：</p><ol><li>取样</li><li>量化</li><li>编码</li></ol><p>其中取样的本质是$f(t)$与一个周期信号$p(t)$相乘。</p><script type="math/tex; mode=display">f_s(t)=f(t)p(t)</script><p>在频域中：  </p><script type="math/tex; mode=display">F_s(ω)=F(ω)*P(t)</script><h3 id="理想取样"><a href="#理想取样" class="headerlink" title="理想取样"></a>理想取样</h3><p>$p(t)$是周期单位冲激信号$δ_T(t)=∑δ(t-nT_s)$。</p><script type="math/tex; mode=display">\begin{aligned}    P(ω)&=ω_s∑δ(ω-nω_s)\\    F_s(ω)&=\frac{1}{2π}F(ω)*P(t) \\    &=\frac{1}{T_s}∑F(ω-nω_s)\end{aligned}</script><p>如果取样频率$ω_s$（表现为冲激信号的间隔）非常的小，那么频域上取样后的信号可能会产生重叠。<br>如果取样频率非常的大，那么信号会丢失非常多的细节，导致失真。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Unit 6~10</title>
    <link href="/2021/09/11/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%206/"/>
    <url>/2021/09/11/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%206/</url>
    
    <content type="html"><![CDATA[<h1 id="Unit-6-10-さ行・た行・な行"><a href="#Unit-6-10-さ行・た行・な行" class="headerlink" title="Unit 6~10 さ行・た行・な行"></a>Unit 6~10 さ行・た行・な行</h1><h2 id="Unit-6-さ（ざ）・し（じ）・す（ず）・せ・た"><a href="#Unit-6-さ（ざ）・し（じ）・す（ず）・せ・た" class="headerlink" title="Unit 6 さ（ざ）・し（じ）・す（ず）・せ・た"></a>Unit 6 さ（ざ）・し（じ）・す（ず）・せ・た</h2><ul><li>際（は）・際に（は）<br>動詞辞書形・た形・名詞～の＋際（は）・際に（は）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……的时候/借着……的时机】</span>  </span></li><li>最中（に）・最中だ<br>動詞て形～ている・い形容詞・名詞～の＋最中（に）・最中だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正在……时突然发生了……】</span>  </span></li><li>ざるを得ない<br>動詞ない形＋ざるを得ない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不得不……】</span>  </span></li><li>次第・次第だ・次第で  <ul><li>動詞ます形＋次第   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【刚一……，就……】</span>  </span></li><li>普通形＋次第で・次第だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【由于……，书面语】</span>  </span></li><li>名詞＋次第で（は）・次第だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【取决于/根据……】</span>  </span></li></ul></li><li>上・上は・上も<br>名詞＋上・上は・上も   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从（公文、历史、法律、教育等）上来看】</span>  </span></li><li>末（に）・末の<br>動詞た形・名詞～の＋すえ（に）・すえの   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【经过……终于……，强调很长的过程】</span>  </span></li><li><p>ずにすむ・ないですむ・なくてすむ<br>動詞ない形＋ずにすむ・ないですむ・なくてすむ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不必要做……也可以/不用……就行】</span>  </span></p><blockquote><p>する→せ  </p></blockquote></li><li><p>ずにはいられない・ないではいられない<br>動詞ない形＋ずにはいられない・ないではいられない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【情不自禁地/不能不做……】</span>  </span></p><blockquote><p>する→せ  </p></blockquote></li><li><p>せいで・せか・せいだ・せいにする  </p><ul><li>普通形＋せいで・せか・せいだ・せいにする   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【都怪……】</span>  </span></li><li>普通形＋せいか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【可能因为……】</span>  </span></li></ul></li><li>たいばかりに・ほしいばかりに  <ul><li>動詞ます形＋たいばかりに </li><li>名詞～が＋ほしいばかりに    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就是因为太想要……了（而不辞辛劳地做……）】</span>  </span></li></ul></li></ul><h2 id="Unit-7-た（だ）・つ"><a href="#Unit-7-た（だ）・つ" class="headerlink" title="Unit 7 た（だ）・つ"></a>Unit 7 た（だ）・つ</h2><ul><li><p>だけあって・だけに・だけのことはある</p><ul><li>普通形＋だけあって・だけに・だけのことはある   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不愧是……，正面评价】</span>  </span></li><li>名詞・普通形＋だけに <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正因为……，更加……】</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正因为……，反倒是……】</span>  </span></li></ol></li></ul></li><li><p>たとえ～ても・としても・たところで</p><ul><li>たとえ＋動詞て形・い形容詞て形＋も・としても・たところで</li><li>たとえ＋な形容詞・名詞＋でも・としても・たところで  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【即便是……也……】</span>  </span></li></ul></li><li>たところ<br>動詞た形＋ところ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……之后就……】</span>  </span>  </li><li>たところが<br>動詞た形＋ところが   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【然而……】</span>  </span> </li><li>たとたん（に）<br>動詞た形＋とたん（に）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【刚……就……】*说话人自身过去的事情，客观事件</span>  </span></li><li>たばかりに<br>動詞た形＋ばかりに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……刚结束】</span>  </span></li><li>たびに<br>動詞辞書形・名詞～の＋ばかりに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【每次……】</span>  </span></li><li>だらけ<br>名詞＋だらけ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【满是/到处都是……（不好的事物）】</span>  </span><br>常用：泥だらけ　傷だらけ　間違いだらけ　血だらけ　借金だらけ  </li><li>ついでに<br>動詞辞書形・た形・名詞～の＋ついでに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【顺便……】</span>  </span>  </li><li>っこない<br>動詞ます形＋っこない    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不可能……】</span>  </span>  </li></ul><h2 id="Unit-8-つ・て"><a href="#Unit-8-つ・て" class="headerlink" title="Unit 8 つ・て"></a>Unit 8 つ・て</h2><ul><li>つつ・つつも  <ul><li>動詞ます形＋つつ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一边……】</span>  </span>  </li><li>動詞ます形＋つつ（も）  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然……，但是……】</span>  </span></li></ul></li><li>つつある<br>動詞ます形＋つつある   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正在……，表示不断发展】</span>  </span></li><li>っぽい<br>動詞ます形・名詞・い形容詞語幹＋っぽい   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【看上去……】</span>  </span></li><li>つもり・つもりだ  <ul><li>動詞辞書形・ない形～ない＋つもりだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【打算……】</span>  </span></li><li>動詞た形・て形～ている・な形容詞～な・い形容詞・名詞～の＋つもり   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【这样认为的……】</span>  </span></li></ul></li><li>つもりで  <ul><li>動詞た形＋つもりで   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就当是……】</span>  </span></li></ul></li><li>て以来<br>動詞て形＋て以来   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……之后就，状态一直持续】</span>  </span></li><li>てからでないと・てからでなければ<br>動詞て形＋てあらでないと・てからでなければ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果不先做……的话，就（不能）……，后项为否定】</span>  </span></li><li>てしょうがない・てしようがない<br>動詞て形・い形容詞て形・な形容詞～で＋てしょうがない・てしようがない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【特别……，用于说话人表示感情强烈】</span>  </span></li><li>てたまらない<br>動詞て形・い形容詞て形・な形容詞～で＋てたまらない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……得受不了/特别……，用于说话人表示感情强烈，只能他动词】</span>  </span></li><li>てでも<br>動詞て形＋てでも   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就算……，也要……，采取强硬的手段】</span>  </span></li></ul><h2 id="Unit-9-て・と"><a href="#Unit-9-て・と" class="headerlink" title="Unit 9　て・と"></a>Unit 9　て・と</h2><ul><li>てならない<br>動詞て形・い形容詞て形・な形容詞～で＋て（で）ならない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【非常……，程度很高，情不自禁……】</span>  </span>  </li><li>てはいられない<br>動詞て形＋てはいられない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不能……，由于某种情况不能做前项，危机感】</span>  </span></li><li>てはじめて<br>動詞て形＋はじめて   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……之后才……】</span>  </span></li><li>てばかりはいられない・ればかりもいられない<br>動詞て形＋てばかりはいられない・ればかりもいられない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【也不能总是……】</span>  </span></li><li>ということだ<br>普通形＋ということだ <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【也就是说……】</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【听说……】</span>  </span></li></ol></li><li>というものではない・というものでもない<br>普通形＋というものではない・というものでもない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【并非……，认为不全面】</span>  </span></li><li>というより<br>動詞普通形・な形容詞＋というより   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然说……】</span>  </span></li><li>といっても<br>動詞普通形・な形容詞～な・い形容詞・名詞＋といっても   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然说……】</span>  </span></li><li><p>とおり（に）・どおり（に）  </p><ul><li>動詞辞書形・た形・名詞～の＋とおり（に） </li><li>名詞＋どおりに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正如……那样】</span>  </span>  </li></ul></li><li><p>とか  </p><ul><li>普通形・名詞＋とか・とかいう   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【说是……什么的，不确定】</span>  </span></li><li>普通形＋とかいうことだ・とかいえ話だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【听说好像……】</span>  </span></li></ul></li><li>とかで<br>普通形＋とかで   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【说是因为……什么的，口语】</span>  </span></li></ul><h2 id="Unit-10-と（ど）・な"><a href="#Unit-10-と（ど）・な" class="headerlink" title="Unit 10 と（ど）・な"></a>Unit 10 と（ど）・な</h2><ul><li>どころが<br>普通形＋どころが   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">别说……，就连……也……</span>  </span> </li><li>ところだった<br>動詞辞書形＋ところだった   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【差点就……，不好的事】</span>  </span> </li><li>どころではない・どころではなく<br>動詞辞書形・て形～ている＋どころではない・どころではなく   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【不是做……的时候】</span>  </span></li><li>ところに・ところへ<br>動詞辞書形・た形・て形～ている＋ところに・ところへ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正当……的时候（发生了出乎意料的事情）】</span>  </span></li><li>とことを<br>動詞辞書形・た形・て形～ている＋ところを   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正当……的时候（被阻拦了）】</span>  </span></li><li>とことを見ると<br>動詞た形・て形～ている＋とことを見ると   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……上来看】</span>  </span></li><li>としか言いようがない<br>普通形＋としか言いようがない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只能说是……】</span>  </span></li><li>としたら・とすると・とすれば<br>普通形＋としたら・とすると・とすれば   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果……，后为自然而然的结果】</span>  </span></li><li>とともに<br>動詞辞書形・い形容詞・名詞（～である）・な形容詞～である＋とともに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【随着……的同时】</span>  </span></li><li>とは限らない<br>普通形＋とは限らない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【未必……】</span>  </span></li><li>ないことには  <ul><li>動詞ない形・い形容詞ない形＋ないことには</li><li>な形容詞・名詞＋でないことには  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【如果不……就（不）……】</span>  </span></li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>N2备考文法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 通信系统·信息</title>
    <link href="/2021/09/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/1.%20%E9%80%9A%E4%BF%A1%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E3%80%81%E4%BF%A1%E6%81%AF/"/>
    <url>/2021/09/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E9%80%9A%E4%BF%A1%E5%8E%9F%E7%90%86/1.%20%E9%80%9A%E4%BF%A1%E7%B3%BB%E7%BB%9F%E5%8F%82%E6%95%B0%E3%80%81%E4%BF%A1%E6%81%AF/</url>
    
    <content type="html"><![CDATA[<h1 id="通信系统·信息"><a href="#通信系统·信息" class="headerlink" title="通信系统·信息"></a>通信系统·信息</h1><h2 id="信号"><a href="#信号" class="headerlink" title="信号"></a>信号</h2><h3 id="模拟信号"><a href="#模拟信号" class="headerlink" title="模拟信号"></a>模拟信号</h3><p>模拟信号指时间连续，幅值连续的信号。  </p><h3 id="数字信号"><a href="#数字信号" class="headerlink" title="数字信号"></a>数字信号</h3><p>数字信号指时间连续/离散，幅值离散的信号。  </p><p>数字信号的优势：  </p><ul><li>抗噪性高：只要幅值高于某个阈值则即为1，对幅值的精度要求不如模拟信号。  </li><li>便于加密、存储、处理、传输<br>数字信号的劣势：  </li><li>需要更大的带宽需求</li><li>需要高的时协同步要求</li></ul><h2 id="信息"><a href="#信息" class="headerlink" title="信息"></a>信息</h2><p>信息分为连续信息（比如声音）和离散信息（比如文字）。<br><strong>以消息中包含的未确定事件的概率来衡量信息的大小，称为信息量</strong>。记信息量为：  </p><script type="math/tex; mode=display">I=log_a\frac{1}{P(x)}=-log_aP(x)</script><p>其中$P(x)$表示事件发生的概率。<br>信息量的单位取决于不同底数$a$：  </p><ul><li>$a=2$,bit  </li><li>$a=e$,nit  </li><li>$a=10$,Hartley  </li></ul><h3 id="信息熵"><a href="#信息熵" class="headerlink" title="信息熵"></a>信息熵</h3><p>信息熵是用来衡量消息有效率的指标，信息熵表示消息中平均含有的信息量：  </p><script type="math/tex; mode=display">H=∑_{i=1}^MP(x_i)log_2\frac{1}{P(x_i)}</script><p>对于连续信息：  </p><script type="math/tex; mode=display">H=∫P(x_i)log_2\frac{1}{P(x_i)}dx</script><p>其中$M$表示消息中的字符数量。<br>信息熵的单位是bit/符号。  </p><p>在概率相等的情况下，含有$M$个字符的最大信息熵为：  </p><script type="math/tex; mode=display">H_{max}=log_2M</script><h2 id="通信系统"><a href="#通信系统" class="headerlink" title="通信系统"></a>通信系统</h2><p>通信系统的组成大致上分为三部分：  </p><ul><li>发射机（Transmitter）：将信息转换为信号并发送</li><li>信道（Channel）：信号传输所经过的介质</li><li>接收机（Receiver）：对信号进行解调、解码、解密后复原信息  </li></ul><p>具体而言：可由如下流程大概表示：<br>信源-&gt;信源编码-&gt;信道编码-&gt;调制-&gt;时钟同步-&gt;解调-&gt;解码  </p><ul><li>信源编码：将模拟信号转化为数字信号，减少冗余以增加系统有效性  </li><li>信道编码：增加额外的冗余（例如重复的部分、校验码）以增加系统可靠性  </li><li>调制：调制过程将原信号（称为基带信号）$S(t)$与载波$C(t)$结合转为高频波$S(t)C(t)$以方便传输。这个过程中不会有新信息加入。其中载波的形式可以是正弦波$cos(ω_ct+θ)$和脉冲波$δ(t)$。当载波是正弦波时，通过载波参数中的幅度、频率、相位的变化将数字信号加入其中，具体如下表所示。  </li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">载波参数</th><th style="text-align:center">方法</th><th style="text-align:center">二进制表达</th></tr></thead><tbody><tr><td style="text-align:center">幅度</td><td style="text-align:center">ASK</td><td style="text-align:center">0-&gt;”0”<br>A-&gt;”1”</td></tr><tr><td style="text-align:center">频率</td><td style="text-align:center">FSK</td><td style="text-align:center">$f_1$-&gt;”0”<br>$f_2$-&gt;”1”<br>$f_2$=$2f_1$</td></tr><tr><td style="text-align:center">相位</td><td style="text-align:center">PSK</td><td style="text-align:center">0-&gt;”0”<br>π-&gt;”1”</td></tr></tbody></table></div><p>  上述调制方法针对的是数字信号，对于模拟信号也同样有调制方法，分为：幅度调制和角度调制，在此不展开。  </p><h3 id="通信系统的分类"><a href="#通信系统的分类" class="headerlink" title="通信系统的分类"></a>通信系统的分类</h3><p>按传输方向分类：  </p><ul><li>单工：信号只能从发射机到接收机。举例：卫星电视</li><li>半双工：信号既可以从发射机到接收机，也能从接收机到发射机，但这两个过程不能同时进行。举例：对讲机</li><li>双工：信号既可以从发射机到接收机，也能从接收机到发射机，但这两个过程可以同时进行。举例：手机  </li></ul><p>按传输序列来分：  </p><ul><li>并行传输</li><li>串行传输</li></ul><h3 id="通信系统的参数"><a href="#通信系统的参数" class="headerlink" title="通信系统的参数"></a>通信系统的参数</h3><h4 id="传输速率"><a href="#传输速率" class="headerlink" title="传输速率"></a>传输速率</h4><p>传输速率是衡量系统有效性的关键指标。传输速率既可以单位时间内的以字符计，也可以单位时间内的以信息量计。  </p><ul><li>以字符计时的速率称为符号速率，以$R_B$或者$R_S$表示，单位为Baud或者字符/s。  </li><li>以信息量计时的速率称为比特率/码率，以$R_b$计，单位为bit/s，简记为bps。  <script type="math/tex; mode=display">R_b=R_Blog_2M</script></li></ul><h4 id="频谱效率"><a href="#频谱效率" class="headerlink" title="频谱效率"></a>频谱效率</h4><p>频谱效率用于表示频谱中每一个频率能够传输的信息大小，同样也以字符或信息量计。  </p><ul><li>以字符计时的频谱效率，以$η$表示，$η=\frac{R_B}{B}$，单位为Baud/Hz。  </li><li>以信息量计时的频谱效率，以$η_b$表示，$η_b=\frac{R_b}{B}$，单位为bit/(s Hz)。  <script type="math/tex; mode=display">η_b=ηlog_2M</script></li></ul><h4 id="误码率"><a href="#误码率" class="headerlink" title="误码率"></a>误码率</h4><p>误码率（BER）是衡量系统可靠性的关键指标。误码率表示错误信息占传输信息的比值，同样也以字符或信息量计。  </p><ul><li>以字符计时：$P_e=\frac{Error symbol}{Total Symbol}$</li><li>以信息量计时：$P_b=\frac{Errorbit}{Total bit}$</li></ul><blockquote><p>通常来说通信系统的有效性和可靠性是反比关系，当传输速率快时，通信系统的有效性高，此时信号间的保护带间隔时间小，由于噪声和干扰的存在，保护带很容易消失而导致信号在接收端混淆，此时系统的误码率高，通信系统的可靠性低。反之亦然。  </p></blockquote><h4 id="干扰·信噪比·香农公式"><a href="#干扰·信噪比·香农公式" class="headerlink" title="干扰·信噪比·香农公式"></a>干扰·信噪比·香农公式</h4><p>由于传输过程中的路径损失、多径效应、和阴影效应，信号会在传输过程中受到干扰和损失。对传输信号产生干扰的信号称为噪声（Noise），噪声分为两种：  </p><ul><li>加性噪声：强度与原信号无关，原信号消失，噪声依然存在。  </li><li>乘性噪声：强度与原信号有关，原信号消失，噪声消失。  </li></ul><p>在通信系统中使用信噪比（SNR），即系统传输信号能量与噪声能量的比值来表示传输过程的强壮性：  </p><script type="math/tex; mode=display">SNR=\frac{P_{signal}}{P_{noise}}</script><h4 id="香农容量"><a href="#香农容量" class="headerlink" title="香农容量"></a>香农容量</h4><p>科学家香农给出了信息系统传输信息有效性的上限，称为香农容量/香农上限，简称容量。在误码率为0的情况下，信息系统的最大速率称为香农容量，它由香农公式给出：  </p><script type="math/tex; mode=display">C=Blog_2(1+\frac{S}{N})=Blog_2(1+SNR)</script><p>香农容量的单位为bps。<br>定义频谱中单位带宽内的噪声能量为$n_0$，噪声能量为$N=n_0B$。<br>此时香农公式可以改写为：  </p><script type="math/tex; mode=display">C=Blog_2(1+\frac{S}{N})=Blog_2(1+\frac{S}{n_0B})</script><p>可以看出当带宽趋近于无穷时：  </p><script type="math/tex; mode=display">\lim_{B→∞}C=\lim_{B→∞}Blog_2(1+\frac{S}{n_0B})≈1.44\frac{S}{n_0}</script><p>同时，频谱效率也可以由容量和带宽给出：  </p><script type="math/tex; mode=display">η_b=\frac{C}{B}=log_2(1+SNR)</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>通信原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 运算放大器</title>
    <link href="/2021/09/08/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/1.%20OpAmp/"/>
    <url>/2021/09/08/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E5%AD%90%E7%B3%BB%E7%BB%9F/1.%20OpAmp/</url>
    
    <content type="html"><![CDATA[<h1 id="运算放大器"><a href="#运算放大器" class="headerlink" title="运算放大器"></a>运算放大器</h1><h2 id="结构和特性"><a href="#结构和特性" class="headerlink" title="结构和特性"></a>结构和特性</h2><p>一个运算放大器的结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908201643.png width=80%>  </p><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><h4 id="输入和输出"><a href="#输入和输出" class="headerlink" title="输入和输出"></a>输入和输出</h4><p>2.反相输入端$V_{(-)}$<br>3.正相输入端$V_{(+)}$<br>6.输出$V_{out}$<br>运算放大器的输入电压$V_{(in)}$可以表示为：  </p><script type="math/tex; mode=display">V_{(in)}=V_{(+)}-V_{(-)}</script><h4 id="供电"><a href="#供电" class="headerlink" title="供电"></a>供电</h4><p>4.7.为两个供电接口，一般来说运算放大器的供电电压在⨦5v~⨦15v之间。  </p><h3 id="特性"><a href="#特性" class="headerlink" title="特性"></a>特性</h3><h4 id="增益"><a href="#增益" class="headerlink" title="增益"></a>增益</h4><p>一般来说，运算放大器内部输入端的阻抗非常的大；而内部输出端的阻抗非常的小；同时运算放大器的增益非常大。<br>运算放大器的（电压）增益：  </p><script type="math/tex; mode=display">A=\frac{V_{out}}{V_{in}}</script><p>由于运算放大器的增益常常到了上万级别，而运算放大器本质上是放大两个输入端之间的差异，因此如果两个输入端之间的电压差值过大可能会导致烧坏电路。一般输入端的$V_{(-)}$和$V_{(+)}$要求：  </p><script type="math/tex; mode=display">V_{(+)}≈V_{(-)}</script><p>在理想状态下，运算放大器输入端的阻抗无限大，输出端的阻抗为0，且增益为无限大。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908203246.png width=50%>  </p><h4 id="频率响应特性"><a href="#频率响应特性" class="headerlink" title="频率响应特性"></a>频率响应特性</h4><p>对于运算放大器而言，<strong>随着频率的升高，运算放大器的电压增益会逐渐减小</strong>，如下图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908203630.png width=50%><br>定义在某一频率时的带宽与增益的乘积为<strong>增益带宽积（GBP）</strong>：  </p><script type="math/tex; mode=display">GBP=Gain × Bandwidth</script><h4 id="理想放大器的特性"><a href="#理想放大器的特性" class="headerlink" title="理想放大器的特性"></a>理想放大器的特性</h4><p>一般认为理想放大器在反相输入端和同相输入端之间存在两个特性，方便进行电路分析：  </p><ol><li><strong>理想放大器的反相输入端和同相输入端之间的电压是相等的，称为“虚短路”。</strong>  </li><li><strong>理想放大器的反相输入端和同相输入端之间的电压是为“0”的，称为“虚接地”。</strong>  </li></ol><h2 id="基本电路"><a href="#基本电路" class="headerlink" title="基本电路"></a>基本电路</h2><h3 id="反相放大器"><a href="#反相放大器" class="headerlink" title="反相放大器"></a>反相放大器</h3><p>反相放大器的电路连接如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908204038.png width=50%>  </p><h4 id="增益-1"><a href="#增益-1" class="headerlink" title="增益"></a>增益</h4><blockquote><p>运算放大器的推导建立在两个基本条件之上：  </p><ol><li>由于$V_{(+)}≈V_{(-)}$，因此输入端的+-输入间可以视为通路，即$V_{(+)}=V_{(-)}$。  </li><li>人为地使得电阻$R_1$和$R_2$的阻值非常大（在千欧姆级别），因此通过-输入端与$R_1$之间的电流非常小，这部分电流可以视为0。  </li></ol></blockquote><p>反相放大器的增益：  </p><script type="math/tex; mode=display">A=-\frac{R_2}{R_1}</script><p>其推导过程简写如下：  </p><script type="math/tex; mode=display">\begin{aligned}    ∵&V_{(+)}≈V_{(-)},V_{(+)}=0 \\    ∴&V_{(+)}=V_{(-)}=0 \\    ∵&I_1=I_2,I_1=\frac{V_{in}-0}{R_1},I_2=\frac{0-V_{out}}{R_2}\\    ∴&\frac{V_{in}-0}{R_1}=-\frac{V_{out}}{R_2}\\    ∴&A=\frac{V_{out}}{V_{in}}=-\frac{R_2}{R_1}\end{aligned}</script><h3 id="同相放大器"><a href="#同相放大器" class="headerlink" title="同相放大器"></a>同相放大器</h3><p>同相放大器的电路连接如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908205726.png width=50%>  </p><h4 id="增益-2"><a href="#增益-2" class="headerlink" title="增益"></a>增益</h4><p>同相放大器的增益：  </p><script type="math/tex; mode=display">A=1+\frac{R_2}{R_1}</script><p>其推导过程简写如下：  </p><script type="math/tex; mode=display">\begin{aligned}    ∵&V_{(+)}≈V_{(-)},V_{(+)}=V_{in}\\    ∴&V_{(-)}=V_{(+)}=V_{in}\\    ∵&I_1=I_2,I_1=\frac{V_{in}-0}{R_1},I_2=\frac{V_{out}-V_{in}}{R_2}\\    ∴&\frac{V_{in}}{R_1}=\frac{V_{out}-V_{in}}{R_2}\\    ∴&A=\frac{V_{out}}{V_{in}}=1+\frac{R_2}{R_1}\end{aligned}</script><h3 id="缓冲器"><a href="#缓冲器" class="headerlink" title="缓冲器"></a>缓冲器</h3><p>缓冲器结构如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210908210811.png width=50%>  </p><p>其增益始终为1。<br>设置缓冲器的目的是为了在不改变电压大小的前提下，对信号的电流进行操作，以补充衰减。</p><blockquote><p>信息以电压的形式传输，而电流表征的是携带信息的信号强度  </p></blockquote><h2 id="基本电路的应用"><a href="#基本电路的应用" class="headerlink" title="基本电路的应用"></a>基本电路的应用</h2><h3 id="加法放大器（反相输入）"><a href="#加法放大器（反相输入）" class="headerlink" title="加法放大器（反相输入）"></a>加法放大器（反相输入）</h3><p>加法放大器（Summing Amplifier）的结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210909122946.png width=60%><br>有输入端的各支路电流总和大小等于输出端的电流大小，考虑到虚接地，有：  </p><script type="math/tex; mode=display">∑\frac{V_{in}}{R_{in}}=-\frac{V_{out}}{R_F}</script><p>推出：  </p><script type="math/tex; mode=display">V_{out}=-R_F∑\frac{V_{in}}{R_{in}}</script><p>加法放大器（反相输入）的增益为：  </p><script type="math/tex; mode=display">G=\frac{V_{out}}{V_1+V_2}</script><h3 id="积分器"><a href="#积分器" class="headerlink" title="积分器"></a>积分器</h3><p>积分器的电路如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210909123818.png width=60%>  </p><script type="math/tex; mode=display">V_{out}=-\frac{1}{R_{in}C}∫V_{in}dt</script><p>其推导过程如下：  </p><script type="math/tex; mode=display">\begin{aligned}   ∵&V_c=\frac{Q}{C}=-V_{out}\\   ∴&\frac{dV_{out}}{dt}=-\frac{dQ}{Cdt}=-\frac{I_F}{C}\\   ∴&I_F=-C\frac{dV_{out}}{dt}\\   ∵&I_{in}=\frac{V_{in}}{R_{in}}\\   ∴&-C\frac{dV_{out}}{dt}=\frac{V_{in}}{R_{in}}\\   ∴&V_{out}=-\frac{1}{R_{in}C}∫V_{in}dt\end{aligned}</script><h3 id="微分器"><a href="#微分器" class="headerlink" title="微分器"></a>微分器</h3><p>微分器的结构如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210909130230.png width=60%>  </p><script type="math/tex; mode=display">V_{out}=-R_FC\frac{dV_{in}}{dt}</script><p>其推导过程如下：  </p><script type="math/tex; mode=display">\begin{aligned}    ∵&V_c=\frac{Q}{C}=V_{in}\\    ∴&\frac{dQ}{Cdt}=\frac{I_{in}}{C}=\frac{dV_{in}}{t}\\    ∵&I_F=\frac{V_{out}}{R_F},I_F=-I_{in}\\    ∴&V_{out}=-R_FC\frac{dV_{in}}{dt}\end{aligned}</script><h3 id="差分放大器"><a href="#差分放大器" class="headerlink" title="差分放大器"></a>差分放大器</h3><p>与之前的加法器、积分器、微分器不同，差分器使用到了$V_+$和$V_-$两个输入端，结构如图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210915184315.png width=50%>  </p><p>由之前的推理，放大器两个输入端的电压里仍然相等，有$V_+=V_-$。同时，根据分压定理：$V_b=V_2(\frac{R_4}{R_2+R_4})$。<br>由叠加定理，单独看两个电压源：<br>单独看$V_1$，有$V_{out1}=-V_1\frac{R_3}{R_1}$。<br>单独看$V_2$，有$V_{out2}=V_2\frac{R_4}{R_2+R_4}\frac{R_1+R_3}{R_1}$。<br>所以,  </p><script type="math/tex; mode=display">V_{out}=-V_1\frac{R_3}{R_1}+V_2\frac{R_4}{R_2+R_4}\frac{R_1+R_3}{R_1}</script><p>当$\frac{R_2}{R_1}=\frac{R_4}{R_3}$时，有：</p><script type="math/tex; mode=display">V_{out}=\frac{R_2}{R_1}(V_2-V_1)</script><p>这种设计常常在实际中应用。  </p><p>差分放大器的增益可以定义为：  </p><script type="math/tex; mode=display">G=\frac{V_{out}}{V_1-V_2}</script><h4 id="差分放大器的缺陷"><a href="#差分放大器的缺陷" class="headerlink" title="差分放大器的缺陷"></a>差分放大器的缺陷</h4><p>如上图接入的差分放大器有两个缺陷：  </p><ol><li>由于放大器内部输入端阻抗远远高于外部的两个电阻的阻值，因此实际上电流大部分会通过$R_4$流向地面而并非流入运算放大器中。  </li><li>当$\frac{R_2}{R_1}=\frac{R_4}{R_3}$时，差分放大器的增益为:<script type="math/tex; mode=display">Gain=\frac{R_2}{R_1}=\frac{R_4}{R_3}</script>要想改变差分放大器的增益，需要同时改变至少两个电阻以保证条件$\frac{R_2}{R_1}=\frac{R_4}{R_3}$依然成立，事实上通过改变至少两个电阻的阻值来改变放大器增益是非常麻烦的。  </li></ol><h4 id="仪用放大器"><a href="#仪用放大器" class="headerlink" title="仪用放大器"></a>仪用放大器</h4><p>为了减小差分放大器的缺陷，在实际运用中做了如下的改进，改进后的差分放大器称为仪用放大器。<br>对于缺陷1，改进办法是在两个输入端各连接一个缓冲放大器，由于缓冲放大器内部阻抗很高，因此电流不会大量流入接地端。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210916104115.png width=50%>  </p><p>对于缺陷2，改进办法如图所示。下图所示的结构为仪用放大器的结构。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210916104312.png width=50%><br>如图所示的电路中$R_2→R_1→R_2$（下图蓝色标注）上流过的电流是相等的：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210916104500.png width=70%>  </p><p>此处的电流为：$i=\frac{V_2-V_1}{R_1}$。<br>此时差分器输入端的电压差可表示为：$V_{o2}-V_{o1}=i(2R_2+R_1)$。<br>带入之前差分放大器的输出电压：$V_{out}=\frac{R_2}{R_1}(V_2-V_1)$，得到仪用放大器的输出电压表达式：  </p><script type="math/tex; mode=display">V_o=\frac{R_4}{R_3}(V_2-V_1)(1+2\frac{R_2}{R_1})</script><p>仪用放大器的增益：  </p><script type="math/tex; mode=display">Gain=\frac{R_4}{R_3}(1+2\frac{R_2}{R_1})</script><p>结合之前的推导可以发现，此时只需要改变$R_1$的阻值即可改变增益。<br>实际上，仪用放大器可以被集成电路化后做成一个8pin的电路元件，其中$V_k$和$V_Y$两个pin外部连接一个电阻$R_1$来改变放大器增益。  </p><h3 id="共模抑制比"><a href="#共模抑制比" class="headerlink" title="共模抑制比"></a>共模抑制比</h3><p>对于差分放大器，之前只讨论了$\frac{R_2}{R_1}=\frac{R_4}{R_3}$时的增益。<br>当$\frac{R_2}{R_1}≠\frac{R_4}{R_3}$时，对于$V_{out}=-V_1\frac{R_3}{R_1}+V_2\frac{R_4}{R_2+R_4}\frac{R_1+R_3}{R_1}$，很难直接看出差分放大器的增益。所以人为地设置两个新的变量以分离电压，便于求出增益。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210915184315.png width=50%><br>设对差模分量：$V_d=V_2-V_1$<br>共模分量：$V_{cm}=\frac{V_2+V_1}{2}$<br>有$V_1=V_{cm}-\frac{V_d}{2}$、$V_2=V_{cm}+\frac{V_d}{2}$。<br>带入原来的输出电压表达式中，得到：  </p><script type="math/tex; mode=display">V_{out}=\frac{1}{2}\frac{R_4}{R_2+R_4}[\frac{R_3+R_1}{R_1}+\frac{R_3}{R_1}]V_d+[\frac{R_3+R_1}{R_1}-\frac{R_3}{R_1}]V_{cm}</script><p>那么增益可以表示为：  </p><script type="math/tex; mode=display">Gain=\frac{V_{out}}{V_d}=A_d=\frac{1}{2}\frac{R_4}{R_4+R_2}[\frac{R_1+R_3}{R_1}+\frac{R_3}{R_1}]</script><p>这个增益称为<strong>对差模增益</strong>$A_d$。<br>同样地，定义共模增益$A_{cm}$:  </p><script type="math/tex; mode=display">A_{cm}=\frac{V_{out}}{V_{cm}}=\frac{R_4}{R_2+R_4}[\frac{R_3+R_1}{R_1}-\frac{R_3}{R_1}]</script><p><strong>放大器的差模增益是电路所需要的增益，而共模增益将放大直流噪声</strong>。共模抑制比（Common Mode Rejection Ratio，CMRR），定义为差模增益与共模增益的比值:  </p><script type="math/tex; mode=display">CMRR=\frac{A_d}{A_{cm}}</script><script type="math/tex; mode=display">CMRR(dB)=20lg\frac{A_d}{A_{cm}}</script><h2 id="频率响应特性-1"><a href="#频率响应特性-1" class="headerlink" title="频率响应特性"></a>频率响应特性</h2><p>放大器的频率响应特性曲线如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210916105607.png width=60%>  </p><p>其中：  </p><ul><li>$f_b$是$maxgain(dB)-3dB=A_0$时所对应的频率，一般认为在这个频率后放大器增益不再稳定，随着频率的增大而下降。称$f_b$为放大器的<strong>截止频率</strong>。  </li><li>$f_t$是增益为0，即1dB时所对应的频率，称为放大器的<strong>传输频率</strong>。<br>放大器的频率响应特性表示为：  <script type="math/tex; mode=display">A(f)=\frac{A_0}{1+j(\frac{f}{f_b})}</script>当$f&gt;&gt;f_b$时，可以化简为：  <script type="math/tex; mode=display">A(f)=\frac{A_0f_b}{f}</script>当增益为1时，求得传输频率的表达式：  <script type="math/tex; mode=display">f_t=A_0f_b</script></li></ul><h3 id="压摆率"><a href="#压摆率" class="headerlink" title="压摆率"></a>压摆率</h3><p>理想的运算放大器在输入电压接入运算放大器的同时就会立即有稳定的输出电压，然而实际的运算放大器由于内部电容充电过程的存在，需要经过一小段时间才能达到稳定输出电压$V_o$，达到稳定输出电压的最大速率称为<strong>压摆率</strong>或电压转换速率（Slew Rate）。  </p><script type="math/tex; mode=display">S.R.=\frac{dV_o}{dt}|_{max}</script><p>如果输入信号的频率过高，以至于放大器的放大过程跟不上输入信号的变化，放大器的输出信号失真、幅度缩小。<br>当输出信号是一个正弦波$y=Asinωt$时，$S.R.=Aωcosωt,ωt=0$。<br>带入$ω=2πf$，得到电压转换速率与放大器输出电压信号的峰值$A$、频率$f$的关系为:  </p><script type="math/tex; mode=display">S.R.=2πAf</script><p>可以得到运算放大器所支持的某峰值下的最大信号频率为：  </p><script type="math/tex; mode=display">f_{max}=\frac{SR}{2πA}</script><p>$f_{max}$称为全功率带宽，这个表达式也暗示可以通过减小信号的峰值使得运算放大器支持更高频率的信号。  </p><h2 id="泄露和补偿"><a href="#泄露和补偿" class="headerlink" title="泄露和补偿"></a>泄露和补偿</h2><p>在真实的放大器中，输入端$V_+$和$V_-$之间是有电流的，这个电流称为泄露电流，在反相放大器中这个电流会流向$V_+$的接地端。泄露电流的存在会造成假设$V_+=V_-$不成立，因此在运算放大器的内部需要添加一个补偿电容来对$V_+$和$V_-$的电压进行补偿。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210916113332.png width=50%><br>同时在接地端需要额外增加一个补偿电阻以减小泄露电流的影响。在集成化的仪用放大器中，有两个pin：offset用于额外连接一个变阻器，调节补偿电阻的大小。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>电子系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Unit 1~5</title>
    <link href="/2021/09/08/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%201/"/>
    <url>/2021/09/08/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/Unit%201/</url>
    
    <content type="html"><![CDATA[<h1 id="Unit-1-5-あ行・か行"><a href="#Unit-1-5-あ行・か行" class="headerlink" title="Unit 1~5 あ行・か行"></a>Unit 1~5 あ行・か行</h1><h2 id="Unit-1-あ・い・う"><a href="#Unit-1-あ・い・う" class="headerlink" title="Unit 1 あ・い・う"></a>Unit 1 あ・い・う</h2><ul><li>あげく<br>動詞た形・名詞～の＋あげく　  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【最后……，往往带有不好的结果】</span>  </span></li><li>あまり（に）<br>動詞辞書形・名詞～の・な形容詞～な＋あまり（に）    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【过于……而导致】</span>  </span></li><li>以上<br>動詞普通形・名詞～の/である・な形容詞～な/である・い形容詞＋以上　  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【既然……】</span>  </span></li><li>一方・一方で（は）<br>動詞普通形・名詞～の/である・な形容詞～な/である・い形容詞＋一方・一方で（は）   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一边……/一方面……】</span>  </span></li><li>一方だ<br>動詞辞書形＋一方だ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【逐渐地……/越来越……】</span>  </span></li><li>上で（は）  <ul><li>動詞辞書形・名詞～の＋上で（は）  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在（地图、数据等文字内容）的基础之上】</span>  </span></li><li>動詞た形・名詞～の＋上で（は）/名詞～の＋上   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在……之后】</span>  </span></li></ul></li><li>上は<br>動詞辞書形・た形＋上は   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【既然……】</span>  </span></li><li>うちに  <ul><li>動詞普通形・名詞～の・な形容詞～な・い形容詞＋うちに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【趁着……的时候、在……期间】</span>  </span></li><li>▴動詞て形～ている・ない形＋うちに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在发生……的时候同时】</span>  </span></li></ul></li><li>うちは<br>動詞普通形・名詞～の・な形容詞～な・い形容詞＋うちは   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【在（还没）……的时候】</span>  </span></li><li>ようではないか・ようじゃないか<br>動詞意向形＋ようではないか・ようじゃないか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【让我们一起……吧，劝诱的表达】</span>  </span></li></ul><h2 id="Unit-2-え・お・か（が）"><a href="#Unit-2-え・お・か（が）" class="headerlink" title="Unit 2　え・お・か（が）"></a>Unit 2　え・お・か（が）</h2><ul><li>得る/得ない<br>動詞ます形＋得る/得ない    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【可能/不可能……】</span>  </span></li><li><p>おかけで・おかけだ<br>動詞普通形・な形容詞～な・名詞～の・い形容詞    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【多亏了……】</span>  </span></p><blockquote><p>おかけで用在句中，おかけだ用在句末  </p></blockquote></li><li><p>恐れがある<br>動詞辞書形・名詞～の＋恐れがある   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【恐怕会……】</span>  </span>  </p></li><li>甲斐がある/甲斐がない/甲斐もなく  <ul><li>動詞た形・名詞～の＋甲斐がある   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……是有价值的】</span>  </span></li><li>動詞た形・名詞～の＋甲斐がない/甲斐もなく    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……是没价值的/白白地……】</span>  </span></li></ul></li><li>がきっかけに・なって・をきっかけに（して）・きっかけとして　<br>動詞普通形～の・名詞＋がきっかけに・あって・をきっかけに（して）・きっかけとして   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【以……为契机】</span>  </span>  </li><li><p>が契機で・が契機になって・を契機に（して）・を契機として<br>同上，がきっかけ的书面语  </p><blockquote><p>注意：が…あって・を…として/にして  </p></blockquote></li><li><p>かけだ・かけの・かける<br>動詞ます形＋かけだ・かけの・かける   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……做到一半就……/……已经开始发生】</span>  </span>  </p></li><li>がたい<br>動詞ます形＋がたい   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【很难……，常与认知或者是表示说话的词语连用】</span>  </span>  </li><li>限り  <ul><li>動詞辞書形・可能形・名詞～の＋限り   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【最大限度地尽量……】</span>  </span>  </li><li>動詞辞書形・ている・い形容詞＋限り   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只要……就……】</span>  </span> </li></ul></li><li>ない限り　<br>動詞ない形＋ない限り   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只要不……就……/除非……否则就……】</span>  </span> </li><li>限り・限りでは<br>動詞辞書形・た形・ている＋限り・限りでは   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【据……的范围内/据……所】</span>  </span> </li></ul><h2 id="Unit-3-か（が）"><a href="#Unit-3-か（が）" class="headerlink" title="Unit 3　か（が）"></a>Unit 3　か（が）</h2><ul><li>がちだ・がちの・がちな<br>動詞ます形・名詞＋がちだ・がちの・がちな   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【容易……，表示容易发生负面的状态，强调发生次数多】</span>  </span>   </li><li>かというと・かといえば  <ul><li>動詞普通形・い形容詞＋（の）かというと・かといえば </li><li>な形容詞・名詞＋（なの）かというと・かといえば    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【是否是……就……/至于是否是……】*事实上结果相反</span>  </span>   </li><li>疑問詞＋かというと・かといえば   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【要说……，自问自答】</span>  </span></li><li>固定搭配：どちらかというと   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【要说……的话，提起话题】</span>  </span></li></ul></li><li>（か）と思うと・（か）と思ったら  <ul><li>⋆動詞た形＋（か）と思うと・（か）と思ったら    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【刚……就……，几乎同时发生，表示客观叙述，含有惊讶的情绪】</span>  </span> </li><li>動詞辞書形・た形＋（か）と思うと・（か）と思ったら   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【原以为……，却……】</span>  </span>  </li></ul></li><li>かと思えば  <ul><li>動詞辞書形・た形＋かと思えば   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【原以为……，却……】</span>  </span></li><li>⋆動詞辞書形＋かと思えば   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【既……，又……】</span>  </span></li></ul></li><li>~か~ないかのうちに<br>動詞辞書形＋か＋同じ動詞ない形＋ないかのうちに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【还没……，就……，几乎同时发生】</span>  </span></li><li>か何か<br>名詞＋か・や・を・で+何か   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……啊这些的，泛指】</span>  </span></li><li>かねる・かねない  <ul><li>動詞ます形＋かねる   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【想做却很难……，书面语】</span>  </span></li><li>動詞ます形＋かねない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【可能……，负面的结果】</span>  </span></li></ul></li><li><p>かのように・かのような・かのようだ<br>動詞普通形＋かのように・かのような・かのようだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【就像……一样】</span>  </span></p><blockquote><p>だ用于句末，な、に用于句中修饰对应成分  </p></blockquote></li><li><p>からいいようなものの・からよっかたものの<br>普通形＋からいいようなものの・からよっかたものの　  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【幸好……】</span>  </span>  </p></li></ul><h2 id="Unit-4-か（が）・き（ぎ）"><a href="#Unit-4-か（が）・き（ぎ）" class="headerlink" title="Unit 4　か（が）・き（ぎ）"></a>Unit 4　か（が）・き（ぎ）</h2><ul><li>からいうと・からいえば・からいって・からすると・からすれば<br>名詞＋からいうと・からいえば・からいって・からすると・からすれば   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……上来看，名词不能为人】</span>  </span> </li><li>から見ると・から見れば・から見ても<br>名詞＋から見ると・から見れば・から見ても   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……上来看，名词可以为人】</span>  </span> </li><li>からこそ<br>普通形＋からこそ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【正是因为……，正面原因】</span>  </span>  </li><li>からして<br>名詞＋からして   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【单从……来看】</span>  </span>  </li><li>からといって<br>普通形＋からと言って   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【虽然说……】</span>  </span> </li><li><p>からには  </p><ul><li>動詞普通形・い形容詞＋からには   </li><li>な形容詞・名詞＋である＋からには     <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【既然……】</span>  </span></li></ul></li><li><p>かわりに<br>普通形＋かわりに</p><ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【相对地，但是……，表示转折】</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【代替】</span>  </span></li></ol></li><li>気味<br>動詞ます形＋気味   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【有点……，形容说话人自己的感觉，负面】</span>  </span></li><li>きり・きりだ  <ul><li>動詞辞書形・た形・名詞＋きり   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【只有……，表示限定】</span>  </span></li><li>動詞た形＋きり・きりだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【一……就再没有……】</span>  </span>  </li></ul></li></ul><h2 id="Unit-5-き・く（ぐ）・こ"><a href="#Unit-5-き・く（ぐ）・こ" class="headerlink" title="Unit 5 き・く（ぐ）・こ"></a>Unit 5 き・く（ぐ）・こ</h2><ul><li>きる・きれる・きれない  <ul><li>動詞ます形＋きる <ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【做完了……】</span>  </span>  </li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【表示做动作的程度深】</span>  </span>   常用：思い切る  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【下决心】</span>  </span>　いいきる  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【断言】</span>  </span>　わかりきる  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【很明白】</span>  </span>　  </li></ol></li><li>動詞ます形＋きれる   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【能做完……】</span>  </span></li><li>動詞ます形＋きれない<ol><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【做不完……】</span>  </span></li><li>  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【怎么也……做不完】</span>  </span>   常用：死んでも死にきれない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【死也不甘心】</span>  </span>　数え切れないほど  <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【数也数不清】</span>  </span>  　　</li></ol></li></ul></li><li>くせに・くせして<br>普通形＋くせに   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【明明……】</span>  </span></li><li>くらい・ぐらい  <ul><li>動詞辞書形・ない形～ない・な形容詞～な・名詞・い形容詞＋くらい・ぐらい   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【差不多……的程度】</span>  </span></li><li>動詞辞書形・名詞＋くらい・ぐらい～ない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【没有比……更……的了，最高程度】*后项为否定句</span>  </span></li></ul></li><li>ことか<br>普通形＋ことか   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【多么……啊】</span>  </span></li><li>ことから<br>動詞普通形・い形容詞・な形容詞～なである・名詞～である＋ことから   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【从……来看】</span>  </span></li><li>ことだから<br>名詞＋ことだから   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【因为是……，所以……】*名词为人物名词</span>  </span></li><li>ことだ・ないことだ  <ul><li>動詞辞書形＋ことだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【应该做……，劝告】</span>  </span></li><li>動詞ない形＋ないことだ   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【最好不要做……，劝告】</span>  </span></li></ul></li><li>ことなく・こともなく<br>動詞辞書形＋ことなく・こともなく   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【没有……，书面语】</span>  </span></li><li>ことは～が  <ul><li>動詞普通形・い形容詞＋ことは＋動詞普通形・い形容詞＋が</li><li>な形容詞～な＋ことは＋な形容詞＋だが    <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【……是……了，但是……】*表示承认动作，否定结果</span>  </span></li></ul></li><li>ことはない<br>動詞辞書形＋ことはない   <span class="spoiler" onclick="this.classList.toggle('spoiler')">    <span class="spoiler-blur ">【没必要……】</span>  </span></li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>N2备考文法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>自动词·他动词转换一览表</title>
    <link href="/2021/09/07/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/%E8%87%AA%E5%8A%A8%E8%AF%8D%E4%BB%96%E5%8A%A8%E8%AF%8D/"/>
    <url>/2021/09/07/%E6%97%A5%E8%AF%AD/N2%E5%A4%87%E8%80%83/%E8%87%AA%E5%8A%A8%E8%AF%8D%E4%BB%96%E5%8A%A8%E8%AF%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="自动词·他动词转换一览表"><a href="#自动词·他动词转换一览表" class="headerlink" title="自动词·他动词转换一览表"></a>自动词·他动词转换一览表</h1><div class="table-container"><table><thead><tr><th style="text-align:center">他动词</th><th style="text-align:center">自动词</th><th style="text-align:center">举例</th></tr></thead><tbody><tr><td style="text-align:center">〇える</td><td style="text-align:center">〇ある</td><td style="text-align:center">掛ける⇔掛かる</td></tr><tr><td style="text-align:center">〇す</td><td style="text-align:center">〇る</td><td style="text-align:center">消す⇔消える</td></tr><tr><td style="text-align:center">〇る</td><td style="text-align:center">〇れる</td><td style="text-align:center">売る⇔売れる</td></tr><tr><td style="text-align:center">〇く</td><td style="text-align:center">〇ける</td><td style="text-align:center">開く⇔開ける</td></tr></tbody></table></div><h2 id="特殊情况"><a href="#特殊情况" class="headerlink" title="特殊情况"></a>特殊情况</h2><ul><li>有自动词，没有对应的他动词时，需要用他动词的形式，把自动词变成：使役形，就其对应的他动词。<br>例：泣く＜自＞⇔泣かせる “让哭”（使役形）＜他＞  </li><li>有他动词，没有对应的自动词时，需要用自动词的形式，把他动词变成可能形，就是对应的自动词了。<br>例：読む ＜他＞⇔読める “能读”（可能形）＜自＞</li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>N2备考文法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>15.1. 吴恩达：总结和感谢</title>
    <link href="/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/15.%20%E6%80%BB%E7%BB%93%E5%92%8C%E6%84%9F%E8%B0%A2/15.1.%20%E6%80%BB%E7%BB%93%E5%92%8C%E6%84%9F%E8%B0%A2/"/>
    <url>/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/15.%20%E6%80%BB%E7%BB%93%E5%92%8C%E6%84%9F%E8%B0%A2/15.1.%20%E6%80%BB%E7%BB%93%E5%92%8C%E6%84%9F%E8%B0%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="吴恩达：总结和感谢"><a href="#吴恩达：总结和感谢" class="headerlink" title="吴恩达：总结和感谢"></a>吴恩达：总结和感谢</h1><p>欢迎来到《机器学习》课的最后一段视频。我们已经一起学习很长一段时间了。在最后这段视频中，我想快速地回顾一下这门课的主要内容，然后简单说几句想说的话。</p><p>作为这门课的结束时间，那么我们学到了些什么呢？在这门课中，我们花了大量的时间介绍了诸如<strong>线性回归</strong>、<strong>逻辑回归</strong>、<strong>神经网络</strong>、<strong>支持向量机</strong>等等一些监督学习算法，这类算法具有带标签的数据和样本，比如$\{x^{(i)},y^{(i)}\}$。</p><p>然后我们也花了很多时间介绍无监督学习。例如 <strong>K-均值</strong>聚类、用于降维的<strong>主成分分析</strong>，以及当你只有一系列无标签数据 $\{x^{(i)}\}$ 时的<strong>异常检测算法</strong>。</p><p>当然，有时带标签的数据，也可以用于异常检测算法的评估。此外，我们也花时间讨论了一些特别的应用或者特别的话题，比如说<strong>推荐系统</strong>。以及<strong>大规模机器学习系统</strong>，包括并行系统和映射化简方法，还有其他一些特别的应用。比如，用于计算机视觉技术的滑动窗口分类算法。</p><p>最后，我们还提到了很多关于<strong>构建机器学习系统的实用建议</strong>。这包括了怎样理解某个机器学习算法是否正常工作的原因，所以我们谈到了偏差和方差的问题，也谈到了解决方差问题的正则化，同时我们也讨论了怎样决定接下来怎么做的问题，也就是说当你在开发一个机器学习系统时，什么工作才是接下来应该优先考虑的问题。因此我们讨论了学习算法的评价法。介绍了评价矩阵，比如：查准率、召回率以及F1分数，还有评价学习算法比较实用的训练集、交叉验证集和测试集。我们也介绍了学习算法的调试，以及如何确保学习算法的正常运行，于是我们介绍了一些诊断法，比如学习曲线，同时也讨论了误差分析、上限分析等等内容。</p><p>所有这些工具都能有效地指引你决定接下来应该怎样做，让你把宝贵的时间用在刀刃上。现在你已经掌握了很多机器学习的工具，包括监督学习算法和无监督学习算法等等。</p><p>但除了这些以外，我更希望你现在不仅仅只是认识这些工具，更重要的是掌握怎样有效地利用这些工具来建立强大的机器学习系统。所以，以上就是这门课的全部内容。如果你跟着我们的课程一路走来，到现在，你应该已经感觉到自己已经成为机器学习方面的专家了吧？</p><p>我们都知道，机器学习是一门对科技、工业产生深远影响的重要学科，而现在，你已经完全具备了应用这些机器学习工具来创造伟大成就的能力。我希望你们中的很多人都能在相应的领域，应用所学的机器学习工具，构建出完美的机器学习系统，开发出无与伦比的产品和应用。并且我也希望你们通过应用机器学习，不仅仅改变自己的生活，有朝一日，还要让更多的人生活得更加美好！</p><p>我也想告诉大家，教这门课对我来讲是一种享受。所以，谢谢大家！</p><p>最后，在结束之前，我还想再多说一点：那就是，也许不久以前我也是一个学生，即使是现在，我也尽可能挤出时间听一些课，学一些新的东西。所以，我深知要坚持学完这门课是很需要花一些时间的，我知道，也许你是一个很忙的人，生活中有很多很多事情要处理。正因如此，你依然挤出时间来观看这些课程视频。我知道，很多视频的时间都长达数小时，你依然花了好多时间来做这些复习题。你们中好多人，还愿意花时间来研究那些编程练习，那些又长又复杂的编程练习。我对你们表示衷心的感谢！我知道你们很多人在这门课中都非常努力，很多人都在这门课上花了很多时间，很多人都为这门课贡献了自己的很多精力。所以，我衷心地希望你们能从这门课中有所收获！</p><p>最后我想说！再次感谢你们选修这门课程！</p><p><strong>Andew Ng</strong></p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210828131429.png width=90%></p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>15. 总结和感谢</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14.5. 上限分析</title>
    <link href="/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.5.%20%E4%B8%8B%E4%B8%80%E6%AD%A5%E9%9C%80%E8%A6%81%E5%81%9A%E4%BB%80%E4%B9%88/"/>
    <url>/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.5.%20%E4%B8%8B%E4%B8%80%E6%AD%A5%E9%9C%80%E8%A6%81%E5%81%9A%E4%BB%80%E4%B9%88/</url>
    
    <content type="html"><![CDATA[<h1 id="上限分析"><a href="#上限分析" class="headerlink" title="上限分析"></a>上限分析</h1><p>在之前的学习中已经知道，在机器学习系统设计之初就需要设计整个系统的流水线。现在在构建好整个机器学习系统之后，回顾整个流程图，使用<strong>上限分析</strong>的策略来分析现在对整个流水线中的哪些部分进行改进、哪些部分需要花费最大的资源，才能够最大化地提升系统的性能。  </p><p>最好的方法仍然是对整个系统的评估进行量化。<br>回顾之前的照片光学字符识别的流水线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094605.png width=70%><br>现在构建一个评估方式量化这个系统的性能，并应用控制变量法对整个系统的每个模块进行评估。<br>这样的思路建立在人工的做法准确率为100%之上。即将某个模块的准确度拉到100%，观察其他模块或者是整个系统的上限。<br><strong>应用控制变量法，人为地除去流水线上的某一个模块，将这个模块改为由人工来进行，运行这个系统，观察人工进行这个模块后，系统整体的准确率会有多大的改变。最终转为人工后对整个系统准确率提升最大的部分将会是需要耗费更多精力改进的部分。</strong>  </p><p>比如整个系统的准确率一开始是72%，当我们不进行文字检测，而使用人工圈出图像中有文字的部分喂给流水线上的下一个模块，得到的整个系统的准确率是89%。而人工分割字符后整个系统的准确率是90%，只在上一个改进的基础上提升了1%。 这意味着需要花费更多的精力在提升文字检测的准确率上。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210828125921.png width=90%>  </p><h2 id="案例：人脸识别系统"><a href="#案例：人脸识别系统" class="headerlink" title="案例：人脸识别系统"></a>案例：人脸识别系统</h2><p>人脸识别系统的流程要比照片光学字符识别更为复杂。下图描述了人工替换系统中的每一个模块后，整个系统的准确率。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210828130357.png width=90%><br>从整体上来看，可以发现如果对脸部检测进行改进，其带来的对整个系统的提升是最大的。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>14. 机器学习实例：光学字符识别（OCR）</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14.4. 人工数据合成</title>
    <link href="/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.4.%20%E8%8E%B7%E5%BE%97%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE/"/>
    <url>/2021/08/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.4.%20%E8%8E%B7%E5%BE%97%E5%A4%A7%E9%87%8F%E6%95%B0%E6%8D%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="人工数据合成"><a href="#人工数据合成" class="headerlink" title="人工数据合成"></a>人工数据合成</h1><p>通过之前的学习，可以得出机器学习的实质是使用一个低偏差的算法学习一个相对庞大甚至是非常庞大的数据集，如何获得大量的数据集呢。实际上，有时寻找一些特定的数据集是非常困难的，通常有如下的几种思路可以获得大量数据：  </p><ul><li>人工数据合成</li><li>手动标记标签</li><li>雇佣众包来标记数据</li></ul><p>本节主要介绍一种称为<strong>人工数据合成</strong>的方法。人工数据合成可以通过<strong>生成数据集</strong>或者是<strong>对现有的数据集进行扩增</strong>以增加数据量。  </p><p>下面将以光学字符识别为例，介绍人工数据合成所采用的两种策略。  </p><h2 id="生成数据集"><a href="#生成数据集" class="headerlink" title="生成数据集"></a>生成数据集</h2><p>要获得识别光学字符识别所需要的大量数据集，一个办法是通过计算机字体库自动生成一些单独的字符图像，与任意的背景进行组合，从而人为地创造数据集。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210828122037.png width=90%><br>如上图所示的合成数据（图左），可以发现通过这种方式创造的数据集事实上和真实数据集（图右）之间的差别不大。  </p><h2 id="数据集扩增"><a href="#数据集扩增" class="headerlink" title="数据集扩增"></a>数据集扩增</h2><p>数据集扩增是建立在原有的少量数据集之上。对于光学字符识别所需要的字符图像，一种可行的办法是对图像进行各种拉伸以创造新的图像，如下图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210828122408.png width=50%><br>扩增的核心思想是对现有的数据人为地加入一些噪音或者变换，以制造更多的可能数据。<br>需要注意：这些噪声和变换的目的是为了增加数据集中的丰富性，从而使得算法能够应对更多的场景。因此这些噪声和变换需要是在现实中可能出现的、有意义的，以模拟识别目标的多样性和真实性。  </p><h2 id="注意事项"><a href="#注意事项" class="headerlink" title="注意事项"></a>注意事项</h2><ol><li>在进行人工数据合成之前，仍然要保证算法处于低偏差状态。  </li><li>在进行人工合成之前，需要评估这样做的工作量。评估花这么多的工作量是否值得。如果以很小的代价就能够获得10倍乃至更多的数据，那么这样的工作是值得的。  </li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>14. 机器学习实例：光学字符识别（OCR）</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14.3. 文字分离·字符识别</title>
    <link href="/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.3.%20%E6%96%87%E5%AD%97%E5%88%86%E7%A6%BB/"/>
    <url>/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.3.%20%E6%96%87%E5%AD%97%E5%88%86%E7%A6%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="文字分离·字符识别"><a href="#文字分离·字符识别" class="headerlink" title="文字分离·字符识别"></a>文字分离·字符识别</h1><p>照片OCR系统的流水线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094605.png width=70%><br>本节将着重于“Character segmentation”文字分离和“Character recognition”字符识别的部分。<br>这一部分需要再次应用监督学习算法制作分类器。  </p><h2 id="文字分离"><a href="#文字分离" class="headerlink" title="文字分离"></a>文字分离</h2><h3 id="构建数据集"><a href="#构建数据集" class="headerlink" title="构建数据集"></a>构建数据集</h3><p>文字分离的数据集同样由正样本和负样本组成，其中正样本是图像中有两个字符分割线的图像，负样本是没有字符分割线的图像。负样本由单个的字符图像和没有字符的图像组成。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826103727.png width=90%>  </p><h3 id="滑动窗口"><a href="#滑动窗口" class="headerlink" title="滑动窗口"></a>滑动窗口</h3><p>同样地，对每一个上一步文字检测中检测到的区域，应用滑动窗口分类器检测字符分割线的位置。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826104135.png width=50%><br>算法会在识别到分割线的位置对图像进行分割。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826104419.png width=50%></p><h2 id="字符识别"><a href="#字符识别" class="headerlink" title="字符识别"></a>字符识别</h2><p>分割好的图像会传入一个用于识别字符的监督学习多元分类器，从而对字符进行识别。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826104524.png width=90%>  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>14. 机器学习实例：光学字符识别（OCR）</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14.2. 滑动窗口分类器</title>
    <link href="/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.2.%20%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/"/>
    <url>/2021/08/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.2.%20%E6%BB%91%E5%8A%A8%E7%AA%97%E5%8F%A3/</url>
    
    <content type="html"><![CDATA[<h1 id="滑动窗口分类器"><a href="#滑动窗口分类器" class="headerlink" title="滑动窗口分类器"></a>滑动窗口分类器</h1><p>上一节中照片OCR系统的流水线：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094605.png width=70%><br>本节课将着重于“Text detection”文字检测的部分，这一部分的功能由一种称为<strong>滑动窗口分类器</strong>（Sliding window classifier）的算法承担。<br>滑动窗口分类器能够全局扫描整幅图像并检测图像上的有文字的部分。  </p><h2 id="案例：行人检测"><a href="#案例：行人检测" class="headerlink" title="案例：行人检测"></a>案例：行人检测</h2><p>滑动窗口的最经典应用是行人检测，相比于文字检测要简单的地方在于：行人检测所检测的目标拥有相似的长宽比。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826095820.png width=50%>  </p><h3 id="制作分类器"><a href="#制作分类器" class="headerlink" title="制作分类器"></a>制作分类器</h3><p>为了识别行人，需要制作一个监督学习分类器，分类器需要识别图像是否是行人，具体的做法如下：<br>收集一个行人的数据集，这个数据集由正样本和负样本组成。其中正样本是行人的图片，要求行人需要占到这个图像的相当大的部分。负样本则是一些没有行人的街景图像，大小和行人相同，这些图像要求种类尽量多一些（比如房屋、树木等等）。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826100311.png width=60%>  </p><h3 id="全幅扫描"><a href="#全幅扫描" class="headerlink" title="全幅扫描"></a>全幅扫描</h3><p>现在，给出一个有若干行人的全幅图像，算法需要在图像中选取一个矩阵块（即窗口），将这个矩阵块中的图像部分传入上一布设置好的分类器当中，并对这部分图像进行识别，判断这部分图像中是否有行人。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826100631.png width=50%><br>接着，这个窗口会稍微移动一些，并将窗口内的新内容传递给分类器，再次识别。<br>窗口移动的大小称为<strong>步长</strong>（Stride/Step size），如果步长设置的很小，那么总计需要识别的图块数量就会增多，增加计算量。如果步长设置的很大，那么窗口可能不会覆盖到图像的某些区域。<br>常见的设置是将步长设置在4-8像素。<br>滑动窗口直到图像所有的位置都被这个窗口扫过一遍。<br>接着，设置一个面积更大的图块，再次对图像进行扫描。<br>设置更大图块的目的是为了识别更多尺寸的目标。   </p><h2 id="实例：文字检测"><a href="#实例：文字检测" class="headerlink" title="实例：文字检测"></a>实例：文字检测</h2><p>在文字检测中，同样地思路训练一个分类器。  </p><h3 id="放大算子"><a href="#放大算子" class="headerlink" title="放大算子"></a>放大算子</h3><p>同样地运用滑动窗口识别字符，但是在识别完成之后，需要应用放大算子对监测到文字的区域进行拓展。即将识别到的文字区域稍微向四周扩展一些，以便检测这些文字区域的周围是否还有未识别到的，或者是不完整的文字。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826102506.png width=90%><br>如上图所示，左边的灰度图是一种可视化识别结果的方式：白色表示该区域滑动窗口识别到了文字，而灰色区域的灰度表示可能为文字区域的概率，黑色区域表示这些区域内没有文字。<br>右边的灰度图表示将左图应用放大算子后的结果。  </p><h3 id="检测长宽比"><a href="#检测长宽比" class="headerlink" title="检测长宽比"></a>检测长宽比</h3><p>接下来对识别到的文字区域进行排除，舍弃一些长宽比较为反常的、分类器认为是文字的区域。（比如：英语中很少有竖着写的情况，因此宽度过分大于长度的区域应当被舍弃）<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826103154.png width=50%><br>上图的绿色区域是经过检测长宽比后被认为是文字的区域，而红色的区域是检测长宽比后被舍弃的区域。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>14. 机器学习实例：光学字符识别（OCR）</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>14.1. 问题背景与框架设计</title>
    <link href="/2021/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.1.%20%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1/"/>
    <url>/2021/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/14.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%AE%9E%E4%BE%8B%EF%BC%9AOCR/14.1.%20%E6%A1%86%E6%9E%B6%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="问题背景与框架设计"><a href="#问题背景与框架设计" class="headerlink" title="问题背景与框架设计"></a>问题背景与框架设计</h1><p>本章以光学字符识别技术为实例，介绍一个机器学习系统是如何被组装起来的，以及设计机器学习系统的路线。</p><h2 id="问题背景"><a href="#问题背景" class="headerlink" title="问题背景"></a>问题背景</h2><p>照片光学字符识别（Photo OCR），顾名思义，即机器学习能够自动识别照片当中包含的文字。对于给定的照片，算法会全局扫描照片，然后找出照片中的文字信息。在找出这些信息后，算法会对这些文字进行识别。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826093941.png width=50%></p><h2 id="框架设计·流水线"><a href="#框架设计·流水线" class="headerlink" title="框架设计·流水线"></a>框架设计·流水线</h2><p>一个照片光学字符识别系统的框架设计流水线（Pipline）如下：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094605.png width=70%></p><ol><li>文字检测<br>全局扫描照片，找出照片中可能是文字信息的部分。  </li><li>文字分离（Character segmentation）<br>对这些文字信息的部分，将这些文字信息分割成一个个独立字符的区域。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094359.png width=50%>  </li><li>字符分类<br>对每个独立的字符区域进行识别。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210826094458.png width=50%>  </li></ol><p>在机器学习系统设计中，用流水线的形式来表示机器学习系统的每一个组成部分的形式非常常见，这些组成部分可能是一些部分独立的机器学习组件能够被拆分直接调用。<br>使用这样的流水线的另一个优势是在构建机器学习系统时能够快速地分配人员和开发资源，一些相互独立的部分也可以同时进行开发，加快开发速度。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>14. 机器学习实例：光学字符识别（OCR）</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13.5. 并行计算（减少映射）</title>
    <link href="/2021/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.5.%20%E5%87%8F%E5%B0%91%E6%98%A0%E5%B0%84/"/>
    <url>/2021/08/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.5.%20%E5%87%8F%E5%B0%91%E6%98%A0%E5%B0%84/</url>
    
    <content type="html"><![CDATA[<h1 id="并行计算（减少映射）"><a href="#并行计算（减少映射）" class="headerlink" title="并行计算（减少映射）"></a>并行计算（减少映射）</h1><p><strong>减少映射</strong>（Map-reduce）是第二种能够在大规模机器学习中用于减少计算量的算法。本质上，<strong>减少映射的工作就是将机器学习算法进行并行化处理</strong>，使得多个计算机共同、同时承担梯度下降算法中的一部分计算内容以缩短计算时间和单台计算机的计算量。减少映射与随机梯度下降一样重要。<br>机器学习算法能够被减少映射的关键在于算法本身或者是其中的某些步骤能够以<strong>求和</strong>的方式表示。事实上，大规模机器学习的主要问题也来自于求和项的计算量过于庞大，并且大部分的机器学习算法都拥有求和项，因此可被减少映射。  </p><h2 id="梯度下降算法的并行化"><a href="#梯度下降算法的并行化" class="headerlink" title="梯度下降算法的并行化"></a>梯度下降算法的并行化</h2><p>减少映射的思想基础来源于批量梯度下降算法。根据批量梯度下降的更新公式：  </p><script type="math/tex; mode=display">θ_j:=θ_j-α\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}</script><p>此时如果用多台计算机平均负担求和项（或者说是代价函数的偏导项）$∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}$。比如如果有4台计算机，这四台计算机分别计算数据集中$\frac{m}{4}$份数据的求和项，最后再将这些计算结果放入一个中心计算机进行更新公式的计算。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210824142914.png width=50%>  </p><h2 id="逻辑回归的并行化"><a href="#逻辑回归的并行化" class="headerlink" title="逻辑回归的并行化"></a>逻辑回归的并行化</h2><p>逻辑回归的代价函数公式：  </p><script type="math/tex; mode=display">J_{train}(θ)=-\frac{1}{m}[∑_{i=1}^m y^{(i)} log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) log(1−h_θ (x^{(i)}))]</script><p>同样地，逻辑回归的代价函数中求和项也可以分配给多台计算机承担。<br>而且逻辑回归的代价函数的偏导项和线性回归一样：  </p><script type="math/tex; mode=display">\frac{∂}{∂θ_j}J_{train}(θ)=\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}</script><p>其中的求和项也可以被并行化处理，最终以便于使用梯度下降算法。<br>这些求和项在不同的计算机上被计算出来后，传入中央计算机，并执行求和和求和之外的其他计算。  </p><h2 id="多核计算"><a href="#多核计算" class="headerlink" title="多核计算"></a>多核计算</h2><p>由于GPU或者CPU的多核计算功能，并行化计算也可以在单机上运行。类似地，训练集被划分然后送入CPU中不同的处理核心中进行计算，最后整合结果。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210824144419.png width=50%>  </p><p>有些机器学习库或者线性代数库可以自动地将算法矩阵化后做并行化处理，因此不需要人为地设置减少映射。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>13. 大规模机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13.4. 在线学习</title>
    <link href="/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.4.%20%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0/"/>
    <url>/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.4.%20%E5%9C%A8%E7%BA%BF%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="在线学习"><a href="#在线学习" class="headerlink" title="在线学习"></a>在线学习</h1><p>在线学习（Online learning）可以针对于连续的数据流进行学习。 今天，许多大型网站或者许多大型网络公司，使用不同版本的在线学习机制算法，从大批的涌入又离开网站的用户身上进行学习。  </p><h2 id="梯度下降的在线学习"><a href="#梯度下降的在线学习" class="headerlink" title="梯度下降的在线学习"></a>梯度下降的在线学习</h2><p>对于数据流，在线学习采用了类似于随机梯度下降/小批量梯度下降的方式进行学习。在线学习的更新方程为：   </p><script type="math/tex; mode=display">θ_j:=θ_j-α(h_θ(x)-y)x</script><p>和随机梯度下降/小批量梯度下降相同，在线学习的每一次参数迭代只会使用一个或者一小批样本$(x,y)$。<br>与随机梯度下降/小批量梯度下降不同的是，<strong>在线学习舍弃了数据集的概念，样本是一次性的：在线学习机制将数据集转化为数据流——一旦样本被学习，这些样本将被舍弃并且永远都不会使用。新的样本将更新原有的样本$(x,y)$，因此在线学习始终学习的是最新的样本。</strong><br>这样的更新机制在线学习可以变化地适应用户的偏好。算法可以针对用户的当前行为不断地更新模型以适应用户。<br>不过，在线学习要求一个源源不断拥有庞大数据量的数据流，倘若没有这么大的数据流，最好还是应用数据集的概念采用定期学习的模式。  </p><h2 id="案例：点击率预测问题（CTR-problem）"><a href="#案例：点击率预测问题（CTR-problem）" class="headerlink" title="案例：点击率预测问题（CTR problem）"></a>案例：点击率预测问题（CTR problem）</h2><p>假设一个在线商店，用户搜索关键词会自动推荐10件与关键词相关的商品。用户可能点击其中的一个链接查看（视作对这个商品感兴趣），也可能不会查看。<br>设商品的特征向量$x$，它表示这个商品具有的一些关键词在各个维度的匹配程度。<br>设用户的点击为$y$，$y=1$表示用户点击了这件商品的链接，$y=0$表示用户没有点击。<br>当用户访问网站时，会一次性得到10个样本。在线学习可以对用户点击某一个商品的概率$p(y=1|x;θ)$进行实时建模，进行连续的学习，模型会在用户点击时不断地更新以适应用户的取向。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>13. 大规模机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13.3. 小批量梯度下降算法</title>
    <link href="/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.3.%20%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/"/>
    <url>/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.3.%20%E5%B0%8F%E6%89%B9%E9%87%8F%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D/</url>
    
    <content type="html"><![CDATA[<h1 id="小批量梯度下降算法"><a href="#小批量梯度下降算法" class="headerlink" title="小批量梯度下降算法"></a>小批量梯度下降算法</h1><p><strong>小批量梯度下降算法</strong>（Mini-batch gradient descent）是另一种改善由大数据造成的计算量问题的梯度下降算法。小批量梯度下降算法的思路介于批量梯度下降算法和随机梯度下降算法之间，在一些情况下的表现比随机梯度下降算法更为出色。  </p><h2 id="小批量梯度下降算法的思路"><a href="#小批量梯度下降算法的思路" class="headerlink" title="小批量梯度下降算法的思路"></a>小批量梯度下降算法的思路</h2><p>回顾之前的梯度下降算法：  </p><ul><li>批量梯度下降算法在一次迭代中使用了数据集中所有的样本  </li><li>随机梯度下降算法在一次迭代中使用了数据集中的一个样本  </li></ul><p>而小批量梯度下降算法介于这两者之间，在一次迭代中选择使用$b$个样本，称为数据集中的一批(Batch)数据。$b$是每一批数据的批量大小（Batch-size）。通常$b$在2-100之间，常取$b=10$作为一次迭代所使用的数据量。<br>内循环的更新方程：<br>使用一个Batch的数据，求出平均梯度以更新$θ_j$。  </p><script type="math/tex; mode=display">θ_j:=θ_j-α\frac{1}{b}∑_{k=i}^{i+b-1}(h_θ(x^{(k)})-y^{(k)})x_j^{(k)}</script><p>更新指针$i$以切换到下一个batch：  </p><script type="math/tex; mode=display">i:=i+b</script><p>直到所有batch的数据都执行完这一流程，重复遍历直到找到使得$J_{train}(θ)$最小化的$θ_j$。  </p><h2 id="隐式并行性"><a href="#隐式并行性" class="headerlink" title="隐式并行性"></a>隐式并行性</h2><p>如果有合适的向量化工具，小批量梯度下降算法在内循环的部分拥有并行性，意味着能够在一次迭代内能够并行计算多个batch的梯度并更新$θ_j$。虽然随机梯度下降也具有并行性，但是如果将随机梯度下降做并行处理，同时计算每一个样本的梯度，这样消耗的并行计算资源要比小批量梯度下降算法大得多。<br>因此如果将小批量算法利用合适的向量化工具并行化，其计算速度会比批量梯度下降和随机梯度下降要快的多。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>13. 大规模机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13.2. 随机梯度下降算法</title>
    <link href="/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.2.%20%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
    <url>/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.2.%20%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="随机梯度下降算法"><a href="#随机梯度下降算法" class="headerlink" title="随机梯度下降算法"></a>随机梯度下降算法</h1><p>在13.1. 中提到使用传统的梯度下降算法来最小化大数据集的代价函数计算量非常大，因此需要找到一种方式来改进现有的梯度下降算法。一种可行的方式是<strong>随机梯度下降算法</strong>（Stochastic gradient desent）。  </p><h2 id="回顾：线性回归的梯度下降算法"><a href="#回顾：线性回归的梯度下降算法" class="headerlink" title="回顾：线性回归的梯度下降算法"></a>回顾：线性回归的梯度下降算法</h2><p>对于假设函数：$h_θ(x)=∑_{j=0}^mθ_jx_j$<br>其训练集的代价函数为：  </p><script type="math/tex; mode=display">J_{train}(θ)=\frac{1}{2m}(h_θ(x^{(i)})-y^{(i)})^2</script><p>使用梯度下降算法找到最小化$J_{train}(θ)$的参数$θ$，其内循环为：  </p><script type="math/tex; mode=display">θ_j:=θ_j-α\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}</script><p>其中$\frac{∂}{∂θ}J_{train}(θ)=\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}$<br>梯度下降算法通过不断地迭代求梯度找寻局部最小值，最终达到算法收敛。上述的梯度下降算法对整个数据集中的所有项求和，在一次下降迭代中需要同时考虑整个数据集中所有的数据，称为<strong>批量梯度下降算法</strong>（Batch gradient desent）。  </p><h2 id="随机梯度下降的思路"><a href="#随机梯度下降的思路" class="headerlink" title="随机梯度下降的思路"></a>随机梯度下降的思路</h2><p>随机梯度下降算法在每一次迭代时不需要考虑所有的数据。<br>观察批量梯度下降算法，可以发现代价函数的本质实际上是衡量参数$θ$对每一个某个样本$(x^{(i)},y^{(i)})$的拟合程度，再取平均值。因此代价函数$J_{train}(θ)$可以被分解为：  </p><script type="math/tex; mode=display">cost(θ,(x^{(i)},y^{(i)}))=\frac{1}{2}(h_θ(x^{(i)})-y^{(i)})^2</script><p>如之前所说，这一部分衡量的是参数$θ$在某个样本$(x^{(i)},y^{(i)})$上的具体表现情况。<br>原来的代价函数可以改写为：  </p><script type="math/tex; mode=display">J_{train}(θ)=\frac{1}{m}cost(θ,(x^{(i)},y^{(i)}))</script><p>按照上文的理解方式，$J_{train}(θ)$可以看做是衡量参数$θ$对数据集整体的平均表现。<br>与批量梯度下降算法不同的是，随机梯度下降算法的每一次迭代只观察数据集中的一个样本$(x^{(i)},y^{(i)})$，根据这一个样本的评价来缩小$θ_j$直到遍历完整个数据集。然后重复这一遍历数据集，分别以每个样本的评价来缩小$θ_j$的过程，直到$θ_j$达到收敛。  </p><h3 id="随机梯度下降算法的流程"><a href="#随机梯度下降算法的流程" class="headerlink" title="随机梯度下降算法的流程"></a>随机梯度下降算法的流程</h3><ol><li>将整个数据集随机打乱排列</li><li><ul><li>对于每一个样本，以这个样本的梯度来下降迭代$θ_j$：  <script type="math/tex; mode=display">θ_j:=θ_j-α(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}</script>其中$\frac{∂}{∂θ_j}cost(θ,(x^{(i)},y^{(i)})=(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}$  </li><li>移动到下一个样本，重复上述过程，直到遍历完整个数据集。  </li></ul></li><li>重复整个遍历过程，直到找到使得$J_{train}(θ)$取得最小值的$θ_j$。  </li></ol><blockquote><p>注意随机梯度下降算法有两个嵌套的循环。一般来说，遍历1次数据集（最多不超过10次）能够使得算法达到收敛。  </p></blockquote><p>由于每次迭代只考虑一个样本而并非是整个数据集，因此随机梯度下降的计算量更小，收敛速度也更快。但是收敛的路径更为曲折。<br>对比批量梯度下降，由于批量梯度下降每次迭代都需要找到全局（指整个数据集的求和项）极小值，因此批量梯度下降算法迭代的路线基本上始终是向着最小值收敛的（下图红线）。然而局部梯度下降算法收敛的路线更为曲折（下图洋红色线）。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822104112.png" alt="">  </p><h2 id="调试随机梯度下降算法"><a href="#调试随机梯度下降算法" class="headerlink" title="调试随机梯度下降算法"></a>调试随机梯度下降算法</h2><h3 id="绘制图像"><a href="#绘制图像" class="headerlink" title="绘制图像"></a>绘制图像</h3><p>在批量梯度下降中，可以绘制$min_θJ(θ)-batch$的图像<a href="https://l61012345.top/2021/02/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.4.%20%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/#%E5%AD%A6%E4%B9%A0%E7%8E%87-Learning-rate">1.4. 调试方法 θ:minJ(θ)-batch图像</a>，或者是绘制$J(θ)-batch$的图像，根据图表来判断梯度下降是否收敛。但是，在大规模的训练集的情况下，要周期性地暂停学习并且求得此时的$J(θ)$或者是使得$J(θ)$最小化的$θ$的值所带来的计算量非常地大。因此需要其他的调试方法应用于大数据学习时的随机梯度下降算法。<br>对于随机梯度下降算法，在计算当前样本的$cost(θ,(x^{(i)},y^{(i)})$后,在更新$θ$之前，直接输出此时的$cost$函数值。<br>在固定周期的迭代次数（比如每1000次迭代）后，计算这个迭代周期内这些样本的$cost$函数值的平均值，通过观察绘制的图来判断梯度下降算法是否达到了收敛。  </p><h4 id="观察周期的设置"><a href="#观察周期的设置" class="headerlink" title="观察周期的设置"></a>观察周期的设置</h4><p>迭代周期设置的越大，迭代过程中的噪声就越不明显，曲线越平滑。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822123714.png width=50%><br>如上图，蓝色线的所观察的周期要比红色线所观察的周期更短。<br>如果观察的周期设置的太短，则有可能观察不出下降的趋势，如下图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822124049.png width=50%><br>当设定比较大的周期进行观察，如果此时下降程度仍然不明显，表明算法几乎没有学习数据集，需要对算法进行进一步的调整。   </p><h3 id="学习率的影响"><a href="#学习率的影响" class="headerlink" title="学习率的影响"></a>学习率的影响</h3><p>在这两种算法中，学习率越小，算法收敛的越慢，但是最后收敛的结果可能会更小。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822123426.png width=50%>  </p><p>如上图，图中蓝色线的学习率比红色线的学习率更大。<br>如果图像呈上升趋势，那么表明算法发散，则需要设置更小的学习率。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822124352.png width=50%>  </p><p>也可以令学习率随着迭代次数的增加而减小，例如令：</p><script type="math/tex; mode=display">\alpha=\frac{c_1}{IterationNumber + c_2}</script><p>其中$c_1$和$c_2$是两个常数。<br>随着不断地靠近全局最小值，通过减小学习率，迫使算法收敛而非在最小值附近徘徊。 但是通常不需要这样做便能有非常好的效果了——对$α$进行调整所耗费的计算通常不值得。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>13. 大规模机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4.3. 线性回归的正则化</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.3.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.3.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="线性回归的正则化"><a href="#线性回归的正则化" class="headerlink" title="线性回归的正则化"></a>线性回归的正则化</h1><h2 id="正则化的梯度下降算法"><a href="#正则化的梯度下降算法" class="headerlink" title="正则化的梯度下降算法"></a>正则化的梯度下降算法</h2><p>在线性回归中，我们使用修改后的梯度下降算法：<br>Repeat {   </p><script type="math/tex; mode=display">θ_0:=θ_0-\alpha\frac{1}{m}\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})x_0^{(j)} \tag{1}</script><blockquote><p>$θ_0$  不需要正则化  </p></blockquote><script type="math/tex; mode=display">θ_j:=θ_j-\alpha[\frac{1}{m}\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}+\frac{λ}{m}θ_j] \tag{2}</script><script type="math/tex; mode=display">j=1,2,3,...,n</script><p>}<br>事实上： $\frac{1}{m}\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})x_j^{(j)}+\frac{λ}{m}θ_j=\frac{∂J(θ)}{∂θ_j}$<br>$\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})x_0^{(i)}=\frac{∂J(θ)}{∂θ_0}$  </p><p>如果将（2）中的$\theta_j$统一，那么就可以得到（3）：  </p><script type="math/tex; mode=display">θ_j:=θ_j（1-α\frac{λ}{m}）-\frac{α}{m}\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})x_j^{(i)} \tag{3}</script><p>由于$1-α\frac{λ}{m}&lt;1$,且只比1小一点点，也就是说，梯度下降算法每次更新的时候$θ_j$在一开始都会比原来小一点点，再进行原来的梯度下降更新  </p><h2 id="正规方程"><a href="#正规方程" class="headerlink" title="正规方程"></a>正规方程</h2><p>在之前的讲义中，探讨过设计两个矩阵：<br>$X=\begin{bmatrix} (x^{(1)})^T \\ …\\ (x^{(m)})^T \end{bmatrix}$ 代表有m个数据的数据集 和 $y=\begin{bmatrix} y^{(1)} \\ …\\ y^{(m)} \end{bmatrix}$ 代表训练集当中的所有的标签<br>通过：</p><script type="math/tex; mode=display">θ=(X^TX)^{-1}X^Ty</script><p>（相当于对$J(θ)$中的每一个θ求偏导数，并且使其等于0）<br>可以求出最适合的θ<br>现在改变在正规方程中加入一项：</p><script type="math/tex; mode=display">θ=(X^TX+λ\begin{bmatrix}0 & 0 & 0 & ...&0 \\   0 & 1 & 0& ...&0 \\ 0 & 0 & 1& ...&0 \\ ... & ... & ...& ...&... \\ 0 & 0 & 0& ...&1\end{bmatrix})^{-1}X^Ty</script><p>来达到同样的效果  </p><blockquote><p>$\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; …&amp;0 \\   0 &amp; 1 &amp; 0&amp; …&amp;0 \\ 0 &amp; 0 &amp; 1&amp; …&amp;0 \\ … &amp; … &amp; …&amp; …&amp;… \\ 0 &amp; 0 &amp; 0&amp; …&amp;1<br>\end{bmatrix}$是一个(n+1)的方阵  </p></blockquote><p>如果矩阵X不可逆$（m&lt;=n）$,那么$(X^TX)^{-1}$也同样不可逆,但是经过数学证明，无论如何$(X^TX+λ<br>\begin{bmatrix}<br>0 &amp; 0 &amp; 0 &amp; …&amp;0 \\   0 &amp; 1 &amp; 0&amp; …&amp;0 \\ 0 &amp; 0 &amp; 1&amp; …&amp;0 \\ … &amp; … &amp; …&amp; …&amp;…\\ 0 &amp; 0 &amp; 0&amp; …&amp;1<br>\end{bmatrix})^{-1}$ 都是可逆的。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>04. 正则化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4.2. 代价函数的正则化</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.2.%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.2.%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E7%9A%84%E6%AD%A3%E5%88%99%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="代价函数的正则化"><a href="#代价函数的正则化" class="headerlink" title="代价函数的正则化"></a>代价函数的正则化</h1><p>对于代价函数：</p><script type="math/tex; mode=display">min_{θ} \frac{1}{2m} \Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2</script><p>增加两个惩罚项$1000\theta^2_3$和$1000\theta^2_4$，代价函数变为：  </p><script type="math/tex; mode=display">min_{θ} \frac{1}{2m} \Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+1000\theta^2_3+1000\theta^2_4</script><p>如果要最小化这个函数，那么$\theta_3$与$\theta_4$就要尽可能的接近0，那么最后拟合的结果（假设函数）：$\theta_0+\theta_1x+\theta_2x^2+\theta_3x^3+\theta_4x^4$，仍然是一个类似的二次函数.<br>正则化的基本思想是<strong>如果所有的参数足够小，那么假设模型就更简单。</strong>  </p><blockquote><p>事实上，如果参数足够小，得到的函数就会越平滑，越简单，越不容易出现过拟合的问题  </p></blockquote><p>在实际上，对于大量的特征和大量的参数，比如$x_1..x_{100}$和$\theta_0…\theta_{100}$，我们无法确定哪些参数是高阶项的参数，这个时候采用的方法就是对代价函数进行修改，使得所有的参数都尽可能的小。<br>修改后的代价函数方程：  </p><script type="math/tex; mode=display">J_{\theta}=\frac{1}{2m}[\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+λ\Sigma_{j=1}^{m}\theta_j^2]</script><p>其中$λ\Sigma_{j=1}^{m}\theta_j^2$称为<strong>正则化项</strong>，它的目的是为了<strong>缩小每一项的参数</strong>。</p><blockquote><p>$\theta_0$是否正则化对结果影响不大<br>λ的作用是对“+”号的前后（前：更好的拟合训练集，后：假设函数足够简单）两项进行取舍平衡，称为正则化系数  </p></blockquote><p>如果λ被设置的太大，那么所有参数的惩罚力度被加大，这些参数最后的结构都将全部接近于0，那么最后的假设函数将会变成$h_\theta(x)=θ_0$,最终导致欠拟合。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>04. 正则化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4.1. 过拟合问题</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.1.%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/4.%20%E6%AD%A3%E5%88%99%E5%8C%96/4.1.%20%E8%BF%87%E6%8B%9F%E5%90%88%E9%97%AE%E9%A2%98/</url>
    
    <content type="html"><![CDATA[<h1 id="过拟合问题"><a href="#过拟合问题" class="headerlink" title="过拟合问题"></a>过拟合问题</h1><p>对于模型，如果一个模型对于数据的偏差很大，不能能够很好的拟合数据的分布，称为欠拟合，或者说这个算法具有高偏差的特性。 如果一个模型虽然可以穿过所有的数据点，但是其图像波动很大，其同样也不能描述数据的分布，（其数据的分布是无法被泛化处理），称为过拟合，或者说这个算法具有高方差的特性。 在这种情况下，模型的参数过于多（有可能代价函数正好为0），以至于可能没有足够多的数据去约束它来获得一个假设函数。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201224205854.png" alt=""><br>过拟合现象往往会发生在<strong>参数过多，而训练样本过少的情况</strong>。减小过拟合现象的思路有两种： </p><ol><li>尽可能的去掉那些影响因素很小的变量，这种方法虽然解决了过拟合问题，但是损失了精度。  </li><li><strong>正则化</strong>（Regularization）  </li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>04. 正则化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>13.1. 大规模学习的计算问题·预学习</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.1.%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.1.%20%E5%A4%A7%E6%95%B0%E6%8D%AE%E9%9B%86/</url>
    
    <content type="html"><![CDATA[<h1 id="大规模学习的计算问题·预学习"><a href="#大规模学习的计算问题·预学习" class="headerlink" title="大规模学习的计算问题·预学习"></a>大规模学习的计算问题·预学习</h1><p>在机器学习中，起决定因素的往往不是最好的算法，而是谁有大量的数据。机器学习发展的近10年到近5年的时间中，社会生活所产生的数据量不断增大，机器学习更倾向于学习更大规模的数据集。<br>接下来一章将讨论如何处理大数据集。  </p><h2 id="计算问题"><a href="#计算问题" class="headerlink" title="计算问题"></a>计算问题</h2><p>大数据集学习面临的首要问题是计算问题。<br>假设训练集大小为$m=100,000,000$（这个数据是非常现实的，以美国人口为例，美国人口大约3亿，如果查询这些人的某些数据，数据量能够轻松地达到上亿规模），此时直接应用传统算法在计算量上会有很大的难度。以梯度下降算法为例：此时如果想要应用批量梯度下降来最小化代价函数，批量梯度下降的更新公式为：  </p><script type="math/tex; mode=display">θ_j:=θ_j-α\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x_j^{(i)}</script><p>按照$m=100,000,000$来算，梯度下降算法需要对一亿个项求和，这显然是非常不现实的工作。<br>有两种适用于大规模机器学习、处理大规模数据的算法为：  </p><ol><li>随机梯度下降 (Stochastic gradient desent)  </li><li>减少映射（Map reduce）  </li></ol><h2 id="预学习"><a href="#预学习" class="headerlink" title="预学习"></a>预学习</h2><p>不过在正式开始对大数据的学习之前，有必要弄清楚一个问题：究竟有没有必要使用这么多数据来进行训练？<br>一种有效的方法是随机选择这一亿个数据中的一小部分（比如1000个数据）进行预学习，绘制<a href="https://l61012345.top/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.3.%20%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/">6.3. 学习曲线</a>。  观察此时的学习曲线是否表征出现了高方差特性（如下图所示），由于高方差问题是可以通过增大数据量来改善的，在这种情况下才更应当增加数据集的量来学习。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210821153002.png width=50%></p><p>倘若学习曲线未出现高方差特性，或者是出现了高偏差特性（如下图所示），此时增大数据量对机器学习的效果不会有太大改善。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210821152919.png width=50%>  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>13. 大规模机器学习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12.4. 协同过滤算法的优化</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.4.%20%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.4.%20%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="协同过滤算法的优化"><a href="#协同过滤算法的优化" class="headerlink" title="协同过滤算法的优化"></a>协同过滤算法的优化</h1><h2 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h2><p>设计一个大小为$n_m × n_u$的矩阵$Y$，其每一个元素表示用户$j$对电影$i$的评分$y(i,j)$。  由于预测的评分由$θ^Tx$给出，因此预测评分的矩阵能够表示为：  </p><script type="math/tex; mode=display">Y_{pre}=Θ^TX</script><p>其中$X$是所有电影的特征向量组成$x$的电影的特征矩阵，其每一行都是一部电影的特征向量。  $Θ$是所有用户倾向的特征向量$θ$组成的用户的特征矩阵，其每一行都是一个用户的特征向量。<br>协同过滤算法的向量化后的算法又称为低秩矩阵分解。  </p><h3 id="寻找相关内容"><a href="#寻找相关内容" class="headerlink" title="寻找相关内容"></a>寻找相关内容</h3><p>协同过滤算法能对每一个目标（比如电影、商品等等）都生成一个特征向量$x^{(i)}∈R^n$，两个目标$i$和$j$的类型相似在线性代数上的直观反映是两个目标的特征向量的欧氏距离很小： </p><script type="math/tex; mode=display">||x^{(i)}-x^{(j)}||</script><p>因此找到和目标$i$比较近的其他目标就能实现推荐与$i$内容相近的内容。  </p><h2 id="均值归一化"><a href="#均值归一化" class="headerlink" title="均值归一化"></a>均值归一化</h2><p>假设现在有一个用户没有对任何的电影评分，观察代价函数对其的影响：  </p><script type="math/tex; mode=display">J(θ^{(i)},x^{(j)})=\frac{1}{2}∑_{(i,j):r(i,j)=1}((θ^{(i)})^Tx^{(i)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_u}∑_{k=1}^n(θ_k^{(j)})^2+\frac{λ}{2}∑_{j=1}^{n_m}∑_{k=1}^n(x_k^{(i)})^2</script><p>可以发现，由于$x$是一个零向量，代价函数中只有$θ$:的正则化项$\frac{λ}{2}∑_{j=1}^{n_u}∑_{k=1}^n(θ_k^{(j)})^2$对其有影响。<br>最小化这个代价函数，最终会得到这个用户的特征向量也是一个零向量，故预测对所有电影评分的结果全是0。或者如果一个用户给所有的电影评分都为0，推荐算法将不会很好地推荐内容。<br>均值归一化能够解决上述问题，<br>现在除了生成评分矩阵$Y$之外，另外设计一个均值向量$μ$用于储存每一部电影的平均得分。<br>现在将评分矩阵$Y$的每一行（也就是每个用户对同一部电影的评分）都减去平均得分。未评分的项（以$?$记）不做处理。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210820104239.png width=50%><br>对新的评分矩阵$Y_{norm}$使用协同过滤算法：<br>现在用户$j$对电影$i$的评分需要补上之前减去的均值：  </p><script type="math/tex; mode=display">y_{pre}^{(i,j)}=(θ^{(j)})^T(x^{(i)})+μ_i</script><p>那么没有对任何电影评分的用户得到的预测评分将不再为0，而是反映所有人打分均值的$μ_i$。  </p><p>同样的思路，假设有一部新上映的电影没有被任何人评价过，则可以采用列向量均值归一的方法：生成列向量的均值（同一个用户对所有电影的平均得分），用评分矩阵$Y$的每一列减去这个均值进行处理。<br>不过关心没有评分的用户比关心没有评分的电影要更为重要。因此列向量的均值归一化并不是必须的。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>12. 内容推荐</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12.3. 协同过滤算法</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.3.%20%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.3.%20%E5%8D%8F%E5%90%8C%E8%BF%87%E6%BB%A4%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="协同过滤算法"><a href="#协同过滤算法" class="headerlink" title="协同过滤算法"></a>协同过滤算法</h1><p>和基于内容的线性回归模型不同，协同过滤算法能够自动学习所要使用的特征，避免了需要先手动评价“爱情度”和“动作度”这样的不可理喻的事情。  </p><h2 id="整合到一起"><a href="#整合到一起" class="headerlink" title="整合到一起"></a>整合到一起</h2><p>在上一节中利用线性回归模型作出了两个算法分别用于预测用户的取向和电影的内容特征。两个算法的思路分别是；已知电影的特征$x^{(i)}$，求出用户的取向$θ^{(j)}$；已知用户的取向$θ^{(j)}$，求出电影的特征$x^{(i)}$——这看起来是一个先有鸡还是先有蛋的问题，解决办法的构想如下：  </p><ol><li>随机初始化$θ$</li><li>利用随机初始化的$θ$建立线性回归模型，预测出电影的特征向量$x$  </li><li>利用预测出电影的特征向量建立线性回归模型，预测出用户的取向$θ$  </li></ol><p>重复二三两步，$θ$和$x$在不断线性回归迭代中得到优化，最终算法将收敛并得到到合理的电影特征向量。<br>但是这种思路中包含反复建模的过程，这使得算法的计算量倍增。   </p><h2 id="应用线性回归的协同过滤算法"><a href="#应用线性回归的协同过滤算法" class="headerlink" title="应用线性回归的协同过滤算法"></a>应用线性回归的协同过滤算法</h2><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p><strong>协同过滤算法</strong>（Collaborative filtering）在上述思路的基础上能够同时优化$θ$和$x$，进而减小计算量。<br>之前的两个代价函数：  </p><script type="math/tex; mode=display">J(θ)=\frac{1}{2}∑_{j=1}^{n_u}∑_{i:r(i,j)=1}((θ^{(j)})^Tx^{(j)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_u}∑_{k=1}^n(θ_k^{(j)})^2</script><script type="math/tex; mode=display">J(x^{(j)})=\frac{1}{2}∑_{j=1}^{n_m}∑_{i:r(i,j)=1}((θ^{(i)})^Tx^{(i)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_m}∑_{k=1}^n(x_k^{(i)})^2</script><p>这两个代价函数中$\frac{1}{2}∑∑_{i:r(i,j)=1}((θ^{(i)})^Tx^{(i)}-y^{(i,j)})^2$的本质都是对所有用户的所有评分计算后求和，因此可以合并。<br>定义协同过滤算法的代价函数：  </p><script type="math/tex; mode=display">J(θ^{(i)},x^{(j)})=\frac{1}{2}∑_{(i,j):r(i,j)=1}((θ^{(i)})^Tx^{(i)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_u}∑_{k=1}^n(θ_k^{(j)})^2+\frac{λ}{2}∑_{j=1}^{n_m}∑_{k=1}^n(x_k^{(i)})^2</script><p>找到使得$J(θ^{(i)},x^{(j)})$最小化的$(θ^{(i)},x^{(j)})$。  </p><p>由于现在是在学习所有的特征，没有必要将一个特征值硬编码为1，因为如果真的有恒为1的特征，算法也能自己学习到。在此可以将$x$中的截距项$x_0$删除以统一维度为$n$。  </p><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ol><li>随机初始化小的$(θ^{(i)},x^{(j)})$  </li><li>使用梯度下降算法或者是其他的算法来最小化$J(θ^{(i)},x^{(j)})$  </li><li>给定一个特定用户的特征向量$θ$和一个特定的电影，利用：  <script type="math/tex; mode=display">y_{pre}(i,j)=(θ^{(j)})^Tx^{(i)}</script>来预测用户对某部电影的评分</li></ol><h2 id="协同过滤算法的理解"><a href="#协同过滤算法的理解" class="headerlink" title="协同过滤算法的理解"></a>协同过滤算法的理解</h2><p>协同过滤算法的“协同”体现在系统通过观察大量用户的行为同时对内容和用户进行建模，并且每一个用户的行为都在帮助系统建立更好的内容模型。反过来，优秀的内容模型也会帮助建立精准的用户行为模型，实现精准的内容推荐。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>12. 内容推荐</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12.2. 基于内容的推荐算法·内容的特征</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.2.%20%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.2.%20%E5%9F%BA%E4%BA%8E%E5%86%85%E5%AE%B9%E7%9A%84%E6%8E%A8%E8%8D%90%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="基于内容的推荐算法·内容的特征"><a href="#基于内容的推荐算法·内容的特征" class="headerlink" title="基于内容的推荐算法·内容的特征"></a>基于内容的推荐算法·内容的特征</h1><h2 id="系统参数"><a href="#系统参数" class="headerlink" title="系统参数"></a>系统参数</h2><p>沿着电影推荐的例子，在上一节中提到过内容推荐系统的相关参数：  </p><ul><li>$n_u$:用户的数量。  </li><li>$n_m$:电影的数量。  </li><li>$r(i,j)$：标记函数，如果$r(i,j)=1$则表示第$j$个用户已经对第$i$部电影进行了评分。  </li><li>$y^{(i,j)}$:评分，表示用户$i$对电影$j$的评分。当且仅当$r(i,j)=1$时$y^{(i,j)}$有值  </li></ul><p>现在设出电影的特征，假设每一部电影都有两个特征：爱情度$x_1$和动作度$x_2$分别表示某一部电影内容包含爱情片和动作片的程度，以0表示最低，1表示最高。（例如《泰坦尼克号》：$x_1=0.9$，$x_2=0.001$），再加入一个截距特征$x_0=1$。那么每一部电影的特征向量$x^{(i)}$都由上述的三个特征值组成。  </p><h2 id="寻找用户的取向"><a href="#寻找用户的取向" class="headerlink" title="寻找用户的取向"></a>寻找用户的取向</h2><p>对于评分的预测，可以看成是一个线性回归问题。规定用户$j$的参数向量$θ^{(j)}∈ R^{n+1}$，$n$表示特征的数量（不包括$x_0$）。对每一个用户都应用线性回归，用户$j$对于电影$i$的评分的预测值可以表示为：  </p><script type="math/tex; mode=display">y^{(i,j)}_{pre}=(θ^{(j)})^Tx^{(j)}</script><h3 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h3><p>如果用$m^{(j)}$表示第$j$个用户评分电影的数量，学习$θ^{(j)}$的过程就是一个基本的线性回归的代价函数：  </p><script type="math/tex; mode=display">J(θ)=\frac{1}{2m^{(j)}}∑_{i:r(i,j)=1}((θ^{(j)})^Tx^{(j)}-y^{(i,j)})^2+\frac{λ}{2m^{(j)}}∑_{k=1}^n(θ_k^{(j)})^2</script><p>由于$m^{(j)}$对于表达式中求最小$J(θ)$时的$θ^{(j)}$无影响，则可以直接去掉：  </p><script type="math/tex; mode=display">J(θ)=\frac{1}{2}∑_{i:r(i,j)=1}((θ^{(j)})^Tx^{(j)}-y^{(i,j)})^2+\frac{λ}{2}∑_{k=1}^n(θ_k^{(j)})^2</script><p>最小化代价函数即可得到最优的$θ^{(j)}$。<br>如果要找到所有用户的参数向量，则根据多元线性回归公式可以得到代价函数：  </p><script type="math/tex; mode=display">J(θ)=\frac{1}{2}∑_{j=1}^{n_u}∑_{i:r(i,j)=1}((θ^{(j)})^Tx^{(j)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_u}∑_{k=1}^n(θ_k^{(j)})^2</script><p>同样地，最小化的方式可以采用梯度下降算法来找到$J(θ)$的最小值。<br>这种基于内容的特征来预测用户评分的算法称为基于内容的推荐算法。  </p><h2 id="寻找内容的特征"><a href="#寻找内容的特征" class="headerlink" title="寻找内容的特征"></a>寻找内容的特征</h2><p>还是之前的电影推荐的例子，对于很多电影，很难以特征向量的方式来量化“爱情片”或者是“动作片”的程度，也很难获取全部的特征。  换一种思路，假设模型中每个用户的参数向量$θ^{(i)}$是已知的（可以看做是每个用户对于电影类型的倾向是已知的），那么就能够反推出每一部电影的“动作度”和“爱情度”：比如如果一部电影倾向于爱情片的用户给电影的评分普遍高，那么可以反推出这个电影大概率是一个爱情片。<br>用这种思路进行数学建模：即求得$x^{(i)}$使得方程：  </p><script type="math/tex; mode=display">\begin{cases}    (θ^{(1)})^Tx^{(j)}=r(1,i) \\    (θ^{(2)})^Tx^{(j)}=r(2,i) \\    ...\\    (θ^{(n_u)})^Tx^{(j)}=r(n_u,i) \\\end{cases}</script><p>成立。  </p><h3 id="代价函数-1"><a href="#代价函数-1" class="headerlink" title="代价函数"></a>代价函数</h3><p>对于已知的$θ^{(1)}…θ^{(n_u)}$，为了学习电影$i$的特征向量$x^{(i)}$，应用线性回归模型：  </p><script type="math/tex; mode=display">J(x^{()i})=\frac{1}{2}∑_{i:r(i,j)=1}((θ^{(j)})^Tx^{(i)}-y^{(i,j)})^2+\frac{λ}{2}∑_{k=1}^n(x_k^{(i)})^2</script><p>找到使得代价函数$J(θ)$最小化的$x^{(i)}$。<br>应用多元线性回归模型的代价函数公式：  </p><script type="math/tex; mode=display">J(x^{(j)})=\frac{1}{2}∑_{j=1}^{n_m}∑_{i:r(i,j)=1}((θ^{(i)})^Tx^{(i)}-y^{(i,j)})^2+\frac{λ}{2}∑_{j=1}^{n_m}∑_{k=1}^n(x_k^{(i)})^2</script><p>就能够得到所有电影的特征向量。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>12. 内容推荐</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>12.1. 内容推荐问题</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.1.%20%E9%97%AE%E9%A2%98%E8%A7%84%E5%88%92/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/12.%20%E5%86%85%E5%AE%B9%E6%8E%A8%E8%8D%90/12.1.%20%E9%97%AE%E9%A2%98%E8%A7%84%E5%88%92/</url>
    
    <content type="html"><![CDATA[<h1 id="内容推荐问题"><a href="#内容推荐问题" class="headerlink" title="内容推荐问题"></a>内容推荐问题</h1><h2 id="引子"><a href="#引子" class="headerlink" title="引子"></a>引子</h2><p>通过对之前的部分的学习可以知道：特征在机器学习中扮演着重要的角色，特征的选取对于学习算法的性能有很大的影响。相比于手动编写算法，有一些算法能够自动挖掘特征，而内容推荐算法就是其中的一个典型的例子。<br>通过对内容推荐算法的学习，能够进一步体会机器学习中特征的重要性。  </p><h2 id="案例：电影推荐系统"><a href="#案例：电影推荐系统" class="headerlink" title="案例：电影推荐系统"></a>案例：电影推荐系统</h2><p>假设现在有一个电影推荐系统，这个系统允许对电影进行0分到5分的评价，这个系统有如下的量化参数：  </p><ul><li>$n_u$:用户的数量。  </li><li>$n_m$:电影的数量。  </li><li>$r(i,j)$：标记函数，如果$r(i,j)=1$则表示第$j$个用户已经对第$i$部电影进行了评分。  </li><li>$y^{(i,j)}$:评分，表示用户$i$对电影$j$的评分。当且仅当$r(i,j)=1$时$y^{(i,j)}$有值  </li></ul><p>这个推荐系统的目的是根据用户已经评分的电影进行建模，从而预测用户对其未评分的电影的评分，进而得到用户对电影类型的取向。这也是内容推荐问题的主要形式。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>12. 内容推荐</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11.5. 多元异常检测算法</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.5.%20%E5%A4%9A%E5%85%83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.5.%20%E5%A4%9A%E5%85%83%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="多元异常检测算法"><a href="#多元异常检测算法" class="headerlink" title="多元异常检测算法"></a>多元异常检测算法</h1><h2 id="问题动机"><a href="#问题动机" class="headerlink" title="问题动机"></a>问题动机</h2><p>实际问题中的有些异常并不能直接通过一个变量指标观测出来，这时候就需要引入多个变量综合进行分析，比如如下的这个例子。<br>如图所示，在计算机状态监测中，考虑CPU负载和内存使用两个变量，正常数据在这两个变量上的分布记为红色标记，现在引入一个绿色的异常数据：如果观察绿色的异常数据在分别的两个变量指标上的分布（图右部分），发现这个异常数据很难在整个数据集中被发现，而通过综合两个变量指标，观察二维分布，则比较容易发现这个异常的数据。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210812150029.png width=50%>  </p><h2 id="多元高斯分布"><a href="#多元高斯分布" class="headerlink" title="多元高斯分布"></a>多元高斯分布</h2><p>为了进一步改进异常检测算法，需要用到多元高斯分布的相关知识。<br>假设特征变量$x∈R^n$，现在不通过为每一个特征分别建模$p(x_i)$的方法，转而对整体直接建立模型$p(x)$。<br>根据多元高斯分布的公式：  </p><script type="math/tex; mode=display">p(x;μ,Σ)=\frac{1}{(2π)^{\frac{n}{2}}|Σ|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))</script><p>其中$Σ∈R^{n×n}$，是$x$的协方差矩阵。$|Σ|$表示$Σ$的行列式。<br>$μ∈R^n$是一个均值向量。<br>$p(x)$在高维空间中呈现出高斯分布。<br>类比与二维高斯分布，$Σ$内的元素值控制极值点的大小，同时控制从极值点到零点各方向的变化率（同时非对角线上的元素控制着各维度之间的相关性）。$μ$控制极值点的位置。  </p><h3 id="多元高斯分布的参数估计问题"><a href="#多元高斯分布的参数估计问题" class="headerlink" title="多元高斯分布的参数估计问题"></a>多元高斯分布的参数估计问题</h3><p>假设随机变量$x∈R^n$的$m$个样本$\{x^{(1)},x^{(2)},…,x^{(m)}\}$，可以利用如下的公式对$μ$和$Σ$进行参数估计:  </p><script type="math/tex; mode=display">μ=\frac{1}{m}∑_{i=1}^mx^{(i)}</script><script type="math/tex; mode=display">Σ=\frac{1}{m}∑_{i=1}^m(x^{(i)}-μ)(x^{(i)}-μ)^T</script><h2 id="使用多元高斯分布的多元异常检测算法"><a href="#使用多元高斯分布的多元异常检测算法" class="headerlink" title="使用多元高斯分布的多元异常检测算法"></a>使用多元高斯分布的多元异常检测算法</h2><p>假设数据集有$m$个样本$\{x^{(1)},x^{(2)},…,x^{(m)}\}$，首先假设数据集的分布服从多元高斯分布，算法流程如下：  </p><ol><li>使用样本数据建立$p(x)$的模型：  <script type="math/tex; mode=display">μ=\frac{1}{m}∑_{i=1}^mx^{(i)}</script><script type="math/tex; mode=display">Σ=\frac{1}{m}∑_{i=1}^m(x^{(i)}-μ)(x^{(i)}-μ)^T</script></li><li>建立$p(x)$的模型：  <script type="math/tex; mode=display">p(x;μ,Σ)=\frac{1}{(2π)^{\frac{n}{2}}|Σ|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))</script></li><li>对于给定的新样本$x_{new}$，带入$p(x)$的模型中进行计算得到$p(x_{new})$</li><li>设定阈值$ɛ$,如果$p(x_{new})&lt;ɛ$则表明$x_{new}$为异常数据。  </li></ol><h2 id="多元异常检测算法与原始异常检测算法的关系"><a href="#多元异常检测算法与原始异常检测算法的关系" class="headerlink" title="多元异常检测算法与原始异常检测算法的关系"></a>多元异常检测算法与原始异常检测算法的关系</h2><p>原始模型：  </p><script type="math/tex; mode=display">p(x)=Π_{i=1}^np(x_i,μ_i,σ^2_i)</script><p>多元高斯模型：  </p><script type="math/tex; mode=display">p(x;μ,Σ)=\frac{1}{(2π)^{\frac{n}{2}}|Σ|^{\frac{1}{2}}}exp(-\frac{1}{2}(x-μ)^TΣ^{-1}(x-μ))</script><p><strong>其实原始模型是多元高斯模型的一种特殊情况：所有的特征之间都独立不相关，而多元高斯分布模型考虑到了特征之间的相关性。</strong><br>特征不相关时，协方差矩阵$Σ$是一个对角矩阵：  </p><script type="math/tex; mode=display">Σ=\begin{bmatrix}    σ^2_1 & ... &...\\    ... & σ^2_2 & ... \\    ... & ... & ... \\    ... & ... & σ^2_n \\\end{bmatrix}</script><p>带入多元高斯模型中即可推导出原始模型。  </p><h3 id="模型对比"><a href="#模型对比" class="headerlink" title="模型对比"></a>模型对比</h3><div class="table-container"><table><thead><tr><th style="text-align:center"></th><th style="text-align:center">原始模型</th><th style="text-align:center">多元高斯模型</th></tr></thead><tbody><tr><td style="text-align:center">探测关联特征的方式</td><td style="text-align:center">手动创建一个新特征</td><td style="text-align:center">自动捕捉特征之间的关系</td></tr><tr><td style="text-align:center">计算性能</td><td style="text-align:center">计算成本低，能够适应数量巨大的特征</td><td style="text-align:center">由于需要计算协方差矩阵，计算成本高，仅能对特征数少的情况适用</td></tr><tr><td style="text-align:center">数据要求</td><td style="text-align:center">可以适用于数据少，特征多（$m&lt;n$）的情况</td><td style="text-align:center">由于协方差矩阵必须可逆，因此要求$m&gt;n$甚至是$m&gt;&gt;n$</td></tr></tbody></table></div><blockquote><p>手动创建特征的方式见<a href="https://l61012345.top/2021/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.3.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/#%E5%AF%BB%E6%89%BE%E7%89%B9%E5%BE%81">9.9. 异常检测算法的评价·关键变量</a><br>原则上使用多元高斯分布时要求$m≥10n$   </p></blockquote><h3 id="奇异的协方差矩阵"><a href="#奇异的协方差矩阵" class="headerlink" title="奇异的协方差矩阵"></a>奇异的协方差矩阵</h3><p>如果在实际应用过程中协方差矩阵$Σ$不可逆，有如下两种常见的可能：  </p><ol><li>数据的量小于特征的数量</li><li>冗余的特征：存在相同的特征，或者存在某个特征是其他若干个特征的线性组合（高度线性相关）的情况。  </li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>11. 异常检测算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11.4. 比较异常检测与监督学习算法</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.4.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.4.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E4%B8%8E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="异常检测与监督学习的对比"><a href="#异常检测与监督学习的对比" class="headerlink" title="异常检测与监督学习的对比"></a>异常检测与监督学习的对比</h1><p>在上一讲：<a href="https://l61012345.top/2021/08/08/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.3.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/">11.3. 异常检测算法的评价</a>中使用的原数据集是一个有标签的数据集，既然如此，那为何不使用监督学习的方法？<br>使用监督学习方法来训练并识别异常目标是一个好的办法，和异常检测算法相比，两者适用于不同的数据集条件，具体如下：  </p><div class="table-container"><table><thead><tr><th>类别</th><th>异常检测</th><th>监督学习</th></tr></thead><tbody><tr><td>数据集类型</td><td>非常少量的正向类（异常数据 $y=1$）, 大量的负向类（$y=0$）</td><td>同时有大量的正向类和负向类</td></tr><tr><td>异常的类型</td><td>异常的类型非常多。根据非常少量的正向类数据来训练算法。</td><td>异常的类型比较少且固定。有足够多的正向类实例，足够用于训练算法。</td></tr><tr><td>新产生的异常</td><td>未来遇到的异常可能与已掌握的异常、非常的不同。</td><td>未来遇到的正向类实例可能与训练集中的非常近似。</td></tr><tr><td>应用</td><td>欺诈行为检测 生产（例如飞机引擎）检测数据中心的计算机运行状况</td><td>邮件过滤器 天气预报 肿瘤分类</td></tr></tbody></table></div><p>其中最根本依据是：<strong>如果数据集中的异常样本太少以至于无法完成监督学习时，就应当考虑异常检测算法</strong>。<br>另外由于正态分布的统计性质，一般采用异常检测算法时，数据量应该在万级单位左右。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>11. 异常检测算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11.3. 异常检测算法的评价·关键变量</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.3.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.3.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95%E7%9A%84%E8%AF%84%E4%BB%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="异常检测算法的评价·关键变量"><a href="#异常检测算法的评价·关键变量" class="headerlink" title="异常检测算法的评价·关键变量"></a>异常检测算法的评价·关键变量</h1><h2 id="异常检测算法的实数评价"><a href="#异常检测算法的实数评价" class="headerlink" title="异常检测算法的实数评价"></a>异常检测算法的实数评价</h2><h3 id="实数评价"><a href="#实数评价" class="headerlink" title="实数评价"></a>实数评价</h3><p>评估学习算法的重要方法是实数评价，即对评价的指标返回一个实数，通过实数的大小来直观表示学习算法在这一指标上的优劣性。<br>假设有一系列带标签（标记正常或者异常）的数据集用于异常检测算法，从数据集中分离出一个无标签的训练集（其中绝大部分的数据都应该是正常/异常的），使用训练集来建立数据集的概率密度模型$p(x)$。<br>接着建立有标签的交叉验证集和测试集来评估这个算法。  </p><blockquote><p>在实际训练中，数据集中正常样本的数量应该比异常样本数量要多得多。推荐的数据划分比例：训练集：测试集：交叉验证集=60:20:20  </p></blockquote><p>将测试集和验证集的数据放入模型$p(x)$，模型给出预测的结果。<br>由于该数据集是一个偏斜类数据集，因此单纯的使用算法准确率指标对其评估并不是一个好的选择。在偏斜类问题中，常采用的指标有：  </p><ul><li>真阳性/真阴性/假阳性/假阴性率</li><li>查准率和召回率</li><li>F值</li></ul><blockquote><p>偏斜类问题/查准率、召回率/F值的知识见：<a href="https://l61012345.top/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.2.%20%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/">7.2. 查准率和召回率</a></p></blockquote><h2 id="关键变量的选取"><a href="#关键变量的选取" class="headerlink" title="关键变量的选取"></a>关键变量的选取</h2><h3 id="阈值（-e-）的选取"><a href="#阈值（-e-）的选取" class="headerlink" title="阈值（$ɛ$）的选取"></a>阈值（$ɛ$）的选取</h3><p>阈值$ɛ$很大程度上会影响算法的性能：  </p><script type="math/tex; mode=display">y=\begin{cases}    1,p(x_{test})<ɛ \\    0,p(x_{test})≥ɛ  \end{cases}</script><p>通常设定一系列的$ɛ$值，取能够使得F值最大的$ɛ$作为最终阈值。也可以使用交叉验证集来选择$ɛ$。  </p><h2 id="特征的选取"><a href="#特征的选取" class="headerlink" title="特征的选取"></a>特征的选取</h2><h3 id="特征变换"><a href="#特征变换" class="headerlink" title="特征变换"></a>特征变换</h3><p>由于异常检测的关键在于利用高斯分布的概率密度函数进行计算，因此在将数据输入进算法前有必要绘制数据在某些特征上的分布以检验是否符合高斯分布的特性。<br>虽然数据不符合高斯分布，算法也能够正常运行，但是算法性能会有所损失。常见的做法是使用一些变换将这类数据变为类似于高斯分布的形式，比如下图对数据进行的对数变换。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210809110548.png width=50%><br>常用的特征变换：  </p><ul><li>对数变换：$x→log(x+c)$  </li><li>分数幂指数变换：$x→x^{\frac{1}{c}}$  </li></ul><h3 id="寻找特征"><a href="#寻找特征" class="headerlink" title="寻找特征"></a>寻找特征</h3><p>基本思路是用误差分析：观察测试集和验证集中识别错误的数据，再想出另外的特征加入到原来的算法中。<br>如果异常的样本和正常的样本给出的$p(x)$值差异不大，则应当观察数据在其他新特征上的分布规律，这些新特征应该能够明显的区分异常样本和正常样本。<br>通常可以通过将一些线性相关的特征进行非线性组合，来打破线性相关性。从而获得一些新的更好的特征（异常数据的该特征值异常地大或小从而能够更明显地被区分开）。<br>例如，在检测数据中心的计算机状况的例子中，一般情况下网络通信量$x_1$越高，CPU负载$x_2$越高，这样的两个特征有可能不容易区分异常的服务器（网络通信量正常，但CPU负载高）。此时可以用CPU负载与网络通信量的比:</p><script type="math/tex; mode=display">\frac{x_2}{x_1}</script><p>作为一个新的特征，以放大CPU负载在网络通信量正常时的效果。新的特征能够很好的凸显上述问题：如果该值异常地大，有可能意味着该服务器是陷入了一些问题中。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>11. 异常检测算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11.2. 异常检测算法的原始模型</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.2.%20%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%92%8C%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.2.%20%E9%AB%98%E6%96%AF%E5%88%86%E5%B8%83%E5%92%8C%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="异常检测算法的原始模型"><a href="#异常检测算法的原始模型" class="headerlink" title="异常检测算法的原始模型"></a>异常检测算法的原始模型</h1><h2 id="高斯分布"><a href="#高斯分布" class="headerlink" title="高斯分布"></a>高斯分布</h2><p>随机变量$x$的均值为$μ$方差为$σ^2$，如果$x$的概率密度函数服从</p><script type="math/tex; mode=display">P(x;μ,σ^2)=\frac{1}{√{2π}}exp(-\frac{(x-μ)^2}{2σ^2})</script><p>则称$x$服从高斯分布（或者称为正态分布,Gaussian distribution/Normal distribution），将$x$记作$x∿N(μ,σ^2)$。<br>高斯分布的概率密度函数图像如下图所示：<br><img src="https://img.mianfeiwendang.com/pic/0b1df5c172c3e5197756b634/1-786-png_6_0_0_465_676_166_142_892.979_1262.879-924-0-1451-924.jpg" alt=""><br>高斯分布在$x$取到均值时的概率最大。  </p><h3 id="参数估计"><a href="#参数估计" class="headerlink" title="参数估计"></a>参数估计</h3><blockquote><p>参数估计的相关内容：  <a href="https://l61012345.top/2021/04/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/#%E6%A0%B7%E6%9C%AC%E7%9A%84%E7%82%B9%E4%BC%B0%E8%AE%A1%E6%B3%95">概率论与数理统计：样本的点估计法</a>  </p></blockquote><p>假设随机变量$x$的$m$个样本：$\{x^{(1)},..,x^{(m)}\}$，已知$x$服从$x∿N(μ,σ^2)$的高斯分布，通过样本数据估计随机变量$x$总体的$μ$与$σ$，它们服从如下的估计规则（即最大似然估计法）：  </p><script type="math/tex; mode=display">μ=\frac{1}{m}∑x^{(k)}</script><script type="math/tex; mode=display">σ^2=\frac{1}{m}∑(x^{(k)}-μ)^2</script><h2 id="使用高斯分布的异常检测算法"><a href="#使用高斯分布的异常检测算法" class="headerlink" title="使用高斯分布的异常检测算法"></a>使用高斯分布的异常检测算法</h2><p>假设$i$维的数据集$X=\{x^{(1)},..,x^{(m)}\}$，假设数据集$X$的特征$x_i$都服从高斯分布：$x_i∿N(μ_i,σ_i^2)$，那么$X$的概率密度模型$p(x)$可以理解为所有特征的概率密度模型的乘积：  </p><script type="math/tex; mode=display">p(x)=Π_{i=1}^mp(x_i;μ_i,σ_i^2)</script><blockquote><p>这个模型建立的假设基于$\{x^{(1)},..,x^{(m)}\}$相互独立，事实上大多数时候这些变量仍然是独立的，并且在即是有相关性的前提下算法性能仍然比较好。    </p></blockquote><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><ol><li>选取$n$个能够识别出异常的特征  </li><li>通过已知数据集构建数据集$X=\{x^{(1)},..,x^{(m)}\}$  </li><li>利用参数估计计算出每一个特征的均值$μ_i$和方差$σ_i^2$：  <script type="math/tex; mode=display">μ_i=\frac{1}{m}∑_{k=1}^mx^{(k)}_i</script><script type="math/tex; mode=display">σ_i^2=\frac{1}{m}∑_{k=1}^m(x^{(k)}_i-μ_i)^2</script></li><li>计算$X$的概率密度模型：  <script type="math/tex; mode=display">p(x)=Π_{i=1}^np(x_i;μ_i,σ_i^2)=Π_{i=1}^n\frac{1}{√{2π}}exp(-\frac{(x-μ_i)^2}{2σ_i^2})</script></li><li>给定一个新的$x$，带入到$p(x)$中，判断$p(x)$与阈值$ɛ$的大小，给出结论。  <script type="math/tex; mode=display">y=\begin{cases} 1（异常）,p(x_{test})<ɛ \\ 0（正常）,p(x_{test})≥ɛ\end{cases}</script></li></ol>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>11. 异常检测算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11.1. 异常检测问题</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.1.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/11.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B%E7%AE%97%E6%B3%95/11.1.%20%E5%BC%82%E5%B8%B8%E6%A3%80%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="异常检测问题"><a href="#异常检测问题" class="headerlink" title="异常检测问题"></a>异常检测问题</h1><p>异常检测(Anomaly detection)算法是另一种常在非监督学习中使用的算法。这种算法虽然常常用于非监督学习，但与监督学习有许多相似之处。<br>对于一个非监督学习的数据集，假定数据集里的数据都是正常或异常的，此时加入一个新的数据，判断其在空间内的分布是否异常（符合现有数据集的分布规律）的问题称为异常检测问题。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210804145801.png width=50%>  </p><p>解决这类问题，基本思路是对现有数据集的分布概率进行建模：设数据集$X$的分布概率模型为$p(x)$，然后检测新数据$x_{test}$的分布概率为$p(x_{test})$，通过设定一个阈值$ɛ$来检测$x_{test}$是否异常：如果$p(x_{test})&lt;ɛ$，则判定$x_{test}$的数据出现了异常。  </p><blockquote><p>概率分布模型$p(x)$在数据密集的中心区域位置的值很高，越疏离中心，$p(x)$的值越低。  </p></blockquote><h3 id="应用案例"><a href="#应用案例" class="headerlink" title="应用案例"></a>应用案例</h3><ul><li>用户欺诈行为检测  </li><li>产品质量检测  </li><li>生产监控  </li><li>…  </li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>11. 异常检测算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10.3. 主成分分析算法的优化</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.3.%20PCA%E4%BC%98%E5%8C%96/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.3.%20PCA%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="PCA算法优化"><a href="#PCA算法优化" class="headerlink" title="PCA算法优化"></a>PCA算法优化</h1><h2 id="主成分数量的选取"><a href="#主成分数量的选取" class="headerlink" title="主成分数量的选取"></a>主成分数量的选取</h2><p>$K$称作主成分的数量，通常$K$的选取与如下的两个参数有关：<br>平均投影误差的平方：  </p><script type="math/tex; mode=display">\frac{1}{m}∑_{i=1}^m|x^{(i)}-x^{(i)}_{approx}|^2</script><p>$x_{approx}=U_{reduce}z$，是通过$z$复原后得到的向量。<br>反应每一个数据到投影的距离之和。<br>数据的方差：  </p><script type="math/tex; mode=display">\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2</script><p>反应每一个数据到原点的距离之和。<br>$K$的选取通常遵循以下规律：<br>满足最小的$K$,使得：  </p><script type="math/tex; mode=display">\frac{\frac{1}{m}∑_{i=1}^m|x^{(i)}-x^{(i)_{approx}}|^2}{\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2}≤ 0.1(1\%)</script><p>表示99%的数据中的特征被保留，仅有1%的数据特征被压缩。<br>如果希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。  </p><blockquote><p>理解： </p><ol><li>投影误差对应的是被放弃的$n-k$个特征值$λ$之和，而均方值对应的是所有的$n$之和，因此从这一点来看，$\frac{∑_{i=1}^k λ_i}{∑_{i=1}^n λ_i}≥99\%$的说法与此处的解释并无冲突。  </li><li>1%其实是一个容错的区间，从5%到15%的区间内选取都是比较合理的，取决于具体问题。  </li></ol></blockquote><h3 id="实现过程"><a href="#实现过程" class="headerlink" title="实现过程"></a>实现过程</h3><p>从$k=1$开始应用PCA，计算出$U_{reduce}$和$z$，然后计算比例是否小于1%。如果不是的话再令$k=2$，如此类推，直到找到可以使得比例小于1%的最小$k$值（原因是各个特征之间通常情况存在某种相关性）。<br>这样做的问题在于奇异值分解的过程计算量非常的大。<br>实际上，在Octave中应用时，奇异值分解：<code>svd()</code>函数会返回三个矩阵U,S,V，其中U即为前文中提到的一个含有$n$个方向向量（也是特征向量）的矩阵（所有的列向量是方向向量/特征向量）。S是一个对角矩阵，对角线上的元素$s_{ii}$为特征值。<br>$\frac{\frac{1}{m}∑_{i=1}^m|x^{(i)}-z^{(i)}|^2}{\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2}≤ 0.1(1\%)$可以等价为：  </p><script type="math/tex; mode=display">1-\frac{∑_{i=1}^ks_{ii}}{∑_{i=1}^ns_{ii}}≤0.01</script><p>如此则只需要应用一次<code>svd()</code>函数通过返回的特征值矩阵$S$得到所有的特征值，尝试前$k$个特征值，直到找到符合条件的最小$k$即可。  </p><blockquote><p>事实上，$k$的选取还与应用PCA的目的有关，如果应用PCA的目的是为了减小计算量、加速算法的学习，则应当按照上述流程选取$k$。如果应用PCA的目的只是为了可视化数据集，那么$k=2$或$k=3$。  </p></blockquote><h2 id="重建的压缩表示"><a href="#重建的压缩表示" class="headerlink" title="重建的压缩表示"></a>重建的压缩表示</h2><p>PCA是一个数据压缩算法，那么如何将压缩后的数据复原回原来的维度？<br>应用公式：</p><script type="math/tex; mode=display">x_{approx}=U_{reduce}z</script><p>可以看出$U_{reduce}$是$n × k$的矩阵，$z$是$k × 1$的向量，根据矩阵乘法的性质可以推导出$x_{approx}$是$n × 1$的向量。重构的数据$x_{approx}$在原始空间中的分布是共低维平面的。  </p><h2 id="加速监督学习"><a href="#加速监督学习" class="headerlink" title="加速监督学习"></a>加速监督学习</h2><p>如果对于高维的数据，通过应用PCA的降维效果能够显著的降低监督学习的计算量。<br>对于数据集$(x^{(i)},y^{(i)})$，先抽取所有的数据:$x^{(i)}$，然后应用PCA得到这些数据的低维表示$z^{(i)}$，现在新的数据集变为$(z^{(i)},y^{(i)})$进行训练。同样的对预测的数据$x$也需要将$x$映射到$z$再进行预测。  </p><blockquote><p>$U_{reduce}$只能通过训练集来进行定义，再将$U_{reduce}$应用到交叉验证集或者是测试集。  </p></blockquote><h2 id="不恰当的应用案例"><a href="#不恰当的应用案例" class="headerlink" title="不恰当的应用案例"></a>不恰当的应用案例</h2><h3 id="使用PCA来防止过拟合"><a href="#使用PCA来防止过拟合" class="headerlink" title="使用PCA来防止过拟合"></a>使用PCA来防止过拟合</h3><p>合理性： 由于PCA能够降维、减小数据的特征量，因此认为使用PCA来防止过拟合是合理的，但是并不是一个好的应用。<br>由于PCA不关心数据的标签$y$来降维，因此可能会在降维过程中丢失一些非常有用的特征信息。而正则化会考虑数据的标签$y$，因此正则化比PCA更不容易损失有用的信息。  </p><h3 id="滥用PCA"><a href="#滥用PCA" class="headerlink" title="滥用PCA"></a>滥用PCA</h3><p>另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分。应当先尝试使用原始数据作为机器学习算法的输入，当计算量非常大、计算速度非常慢、硬盘空间不足时，才应该应用PCA对数据进行压缩。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>10. 主成分分析</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10.2. 算法思路和流程</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.2.%20PCA/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.2.%20PCA/</url>
    
    <content type="html"><![CDATA[<h1 id="主成分分析算法的思路和流程"><a href="#主成分分析算法的思路和流程" class="headerlink" title="主成分分析算法的思路和流程"></a>主成分分析算法的思路和流程</h1><p>主成分分析,PCA,是最流行的降维方法之一。  </p><h2 id="主成分分析问题"><a href="#主成分分析问题" class="headerlink" title="主成分分析问题"></a>主成分分析问题</h2><p>PCA会找一个低维平面，将所有的数据投影到这个平面内，并使得的所有数据点到这个地维平面的距离（称为投影误差）之和最短。<br>在应用PCA之前，通常会将数据归一化和特征缩放，使得所有的数据在可比的范围之内。<br>具体而言，PCA会在$n$维的数据空间中寻找到$K$个能够代表这个低维平面的方向向量$u^{(1)},…,u^{(K)}$，使得这$K$个向量所定义的低维平面，即线性代数中这些向量的张成空间$Span[u^{(1)},…,u^{(K)}]$。<br>根据线性代数的相关知识，这$K$个向量应当是线性不相关且两两正交的。  </p><h3 id="PCA与线性回归的区别"><a href="#PCA与线性回归的区别" class="headerlink" title="PCA与线性回归的区别"></a>PCA与线性回归的区别</h3><p>需要注意的是，尽管看上去比较相似，但是PCA并不是线性回归。在线性拟合中需要寻找的是数据点到直线的垂直距离，而在PCA需要找到的是数据点到直线的最短距离，如图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210802143928.png width=50%><br>而且线性回归的目的是寻找给定某个$x$的预测值$y$，而PCA只是单纯的在$x_1,..x_n$的$n$维特征空间中寻找一个低维平面。但是PCA和线性拟合运用的思想是相似的。    </p><h2 id="主成分分析流程"><a href="#主成分分析流程" class="headerlink" title="主成分分析流程"></a>主成分分析流程</h2><blockquote><p>新加坡国立大学讲义中关于PCA的部分：<a href="https://l61012345.top/2021/01/28/Machine%20Learning-NAU/5.%20%E7%89%B9%E5%BE%81/#PCA">NUS-Machine Learning:5.特征-PCA</a></p></blockquote><p>对于训练集：$x^{(1)},..,x^{(m)} ∈ \mathbb{R}^n$，首先对其进行归一化处理或者是特征缩放，使得所有的特征都具有可比性。<br>然后计算训练集的协方差矩阵$\Sigma$：  </p><script type="math/tex; mode=display">Σ=\frac{1}{m}∑_{i=1}^{n}(x^{(i)})(x^{(i)})^T</script><p>Σ是一个$n × n$的矩阵。<br>对协方差矩阵应用奇异值分解，得到协方差矩阵的所有特征向量所组成的矩阵$U$。  </p><script type="math/tex; mode=display">U=[u^{(1)}|u^{(2)}…|u^{(k)}…|u^{(n)}]</script><p>$U$是一个$n × n$的矩阵。<br>现在将这些特征向量按照分别所对应的特征值从大到小的顺序排列，选择其中$k$的最大的特征向量构成主成分矩阵$U_{reduce}$。<br>新的降维后的数据集$z^{(1)},..,z^{(m)}∈ \mathbb{R}^k$可以通过投影（即乘上转置矩阵）：  </p><script type="math/tex; mode=display">z^{(i)}=U_{reduce}^Tx^{(i)}</script><p>这样每一个$z$都是一个$k$维的向量。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>10. 主成分分析</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10.1. 降维的目的</title>
    <link href="/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.1.%20%E9%99%8D%E7%BB%B4/"/>
    <url>/2021/08/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/10.%20%E4%B8%BB%E6%88%90%E5%88%86%E5%88%86%E6%9E%90/10.1.%20%E9%99%8D%E7%BB%B4/</url>
    
    <content type="html"><![CDATA[<h1 id="降维的目的"><a href="#降维的目的" class="headerlink" title="降维的目的"></a>降维的目的</h1><p>降维是非监督学习中常用的一种算法，使用降维的目的有如下两个：  </p><h2 id="压缩数据"><a href="#压缩数据" class="headerlink" title="压缩数据"></a>压缩数据</h2><p>使用降维的其中一个目的是压缩数据，压缩数据能够减小算法的计算量的同时提高计算速度。<br>降维的手段是合并一些高度相关的特征。<br>具体而言，如果两个特征在二维空间内呈现出线性相关，那么则可以设定一个新的特征，将所有数据在这个二维空间上的分布投射至一维数轴上，如图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210730163758.png width=20%><br>对于三个特征，如果数据都分布在这个三维空间的一个平面上，那么同理能够将数据的分布投射至一个二维的平面上。  </p><h2 id="可视化数据"><a href="#可视化数据" class="headerlink" title="可视化数据"></a>可视化数据</h2><p>高维的数据很难用可视化的方法来表现它们的数据分布，这时可以将数据降维到可视化的维度（&lt;=3维）以便观察它们的分布特性。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>10. 主成分分析</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>标记说明</title>
    <link href="/2021/08/21/%E6%97%A5%E8%AF%AD/%E6%A0%87%E8%AE%B0%E8%AF%B4%E6%98%8E/"/>
    <url>/2021/08/21/%E6%97%A5%E8%AF%AD/%E6%A0%87%E8%AE%B0%E8%AF%B4%E6%98%8E/</url>
    
    <content type="html"><![CDATA[<h1 id="标记说明"><a href="#标记说明" class="headerlink" title="标记说明"></a>标记说明</h1><h2 id="格式"><a href="#格式" class="headerlink" title="格式"></a>格式</h2><figure class="highlight markdown"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs markdown"><span class="hljs-section">## 语法主干</span><br><span class="hljs-bullet">-</span> 词性接续1<br>  【翻译1】[用法类型1]，解释1。特殊说明1。<br>  固定搭配1  <br>  例：例句1  <br><span class="hljs-bullet">-</span> 词性接续2<br>  【翻译2】[用法类型2]，解释2。特殊说明2。<br>  固定搭配2  <br>  例：例句2<br></code></pre></div></td></tr></table></figure><p>特别说明：  </p><ol><li>[用法类型]表示该用法使用的场合，标记有：  <ul><li>[口]：口语。  </li><li>[书]：书面语。  </li><li>[正式]：只能在正式场合使用。  </li></ul></li><li>如果形如以下的情形：   <figure class="highlight markdown"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs markdown"> ## 语法主干<br><span class="hljs-bullet">-</span> 词性接续1<br><span class="hljs-bullet">-</span> 词性接续2<br> 【翻译】[用法类型]，解释。特殊说明。<br> 固定搭配  <br> 例：例句  <br></code></pre></div></td></tr></table></figure> 若无特殊说明，表明词性接续1和词性接续2所对应的用法和含义是相同的。  </li><li>固定搭配的描述以“常与……连用。”的格式给出，“……”中的变形以语法接续为准。  </li></ol><h2 id="符号"><a href="#符号" class="headerlink" title="符号"></a>符号</h2><ul><li>讲义中以上标来表示之前汉字或单词的假名。例如：漢字<sup>かんじ</sup>  </li><li>以符号~表示接续中的变形或者是词性应当加上随后的假名，再与语法进行接续。例如：名詞～の＋恐れがある  </li><li>以符号·表示并列：可以是语法的并列，也可以是接续词的并列。  </li></ul><h2 id="用词"><a href="#用词" class="headerlink" title="用词"></a>用词</h2><p>讲义使用动词分类而不以体言和用言进行区分。下面给出具体的名词解释：  </p><ul><li>動詞辞書形：又称动词字典形。  </li><li>動詞ない形：又称动词未然形。  </li><li>動詞普通形：包括動詞辞書形・動詞た形・動詞ない形  </li><li>い形容詞：<ul><li>讲义中的い形容詞默认后面带有い。  </li><li>て形：即い形容詞去掉い加上くて。  </li></ul></li><li>な形容詞：<ul><li>な形容詞默认不带な。  </li><li>て形：即な形容詞加で。</li></ul></li><li>前项：指包含接续词的部分。  </li><li>后项：指语法结束后，跟在语法之后的部分。  </li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>十级别语法</title>
    <link href="/2021/07/31/%E6%97%A5%E8%AF%AD/%E6%A8%B1%E8%8A%B1%E6%95%99%E6%9D%90/%E5%8D%81%E7%BA%A7%E5%88%AB/"/>
    <url>/2021/07/31/%E6%97%A5%E8%AF%AD/%E6%A8%B1%E8%8A%B1%E6%95%99%E6%9D%90/%E5%8D%81%E7%BA%A7%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="十级别语法"><a href="#十级别语法" class="headerlink" title="十级别语法"></a>十级别语法</h1><h2 id="意志和判断（Unit-1）"><a href="#意志和判断（Unit-1）" class="headerlink" title="意志和判断（Unit 1）"></a>意志和判断（Unit 1）</h2><h3 id="までだ"><a href="#までだ" class="headerlink" title="までだ"></a>までだ</h3><ul><li>動詞辞書形＋までだ・までのことだ  </li></ul><ol><li>【只好做……】，用于表示觉悟，表示没有其他办法的情况下只能这样做。  </li><li>【只是……】，表示辩解，表示没有别的意图。<br>例：これだけ頑張っても合格できないなら、あきらめるまでです。（觉悟）<br>例：私はこの点を考えるまでだ。（辩解）  </li></ol><h3 id="にはない"><a href="#にはない" class="headerlink" title="にはない"></a>にはない</h3><ul><li>動詞辞書形・名詞＋にはあたらない<br>【以……来说，不值得……】，评价由于某个人的能力等出众，所以用不着（惊讶，称赞等等）。通常表示对对方能力的肯定，也可用于挖苦。<br>常与：感謝、驚く、褒める、称賛等连用。<br>例：山田さんの体力からすれば、三時間走るにはあたらない。　   </li></ul><h3 id="でなくてなんで"><a href="#でなくてなんで" class="headerlink" title="でなくてなんで"></a>でなくてなんで</h3><ul><li>名詞＋でなくてなんで<br>【如果说不是……的话，那又是什么呢】[书]，言下之意表示就是这个。是主观的判断。前面的名词是抽象性名词。<br>例：これは恋でなくてなんでしょう。  </li></ul><h3 id="まい"><a href="#まい" class="headerlink" title="まい"></a>まい</h3><ul><li>動詞辞書形＋まい</li><li>二、三類動詞＋まい・すまい<br>【绝对不是……】，表示第一人称的强烈否定。<br>常与：ある连用<br>例：これはただのミスじゃあるまい。  </li></ul><h3 id="にほかない"><a href="#にほかない" class="headerlink" title="にほかない"></a>にほかない</h3><ul><li>名詞＋にほかない<br>【绝对是……】[书]，表示断言，说话人有百分之百的确信。<br>例：あんな成績を取って、彼女の努力あらわれにほかありません。  </li></ul><h3 id="にきまっている"><a href="#にきまっている" class="headerlink" title="にきまっている"></a>にきまっている</h3><ul><li>名詞～である・な形容詞～である＋にきまっている  </li><li>い形容詞・動詞普通形＋にきまっている<br>【……一定会……】[口]，表示说话人相信的事情/结果一定会发生。<br>例：暗い部屋で勉強するのは、目に悪いにきまっていません。  </li></ul><h3 id="に過ぎない"><a href="#に過ぎない" class="headerlink" title="に過ぎない"></a>に過ぎない</h3><ul><li>名詞～である・な形容詞～である＋にすぎない  </li><li>い形容詞・動詞普通形＋にすぎない<br>【只不过是……罢了】，表示说话人主观的判断。<br>例：幽霊なんで、現代科学は説明できない部分であるにすぎない。  </li></ul><h3 id="しかない"><a href="#しかない" class="headerlink" title="しかない"></a>しかない</h3><ul><li>名詞・動詞辞書形＋しかない<br>【不得不/只好……】，没有更好的解决方法了，强调唯一性。<br>例：逃げるしかない。  </li></ul><h3 id="というものだ"><a href="#というものだ" class="headerlink" title="というものだ"></a>というものだ</h3><ul><li>名詞～である・な形容詞～である＋というものだ  </li><li>動詞辞書形・い形容詞＋というものだ<br>【就是……的】，表示主观地、理所当然地认为。前项为事实，后项为常识性的评价和判断。<br>例：爆弾は爆物処理班に回収されだ後、起爆するというものだ。  </li></ul><h2 id="劝诱和禁止（Unit-2）"><a href="#劝诱和禁止（Unit-2）" class="headerlink" title="劝诱和禁止（Unit 2）"></a>劝诱和禁止（Unit 2）</h2><h3 id="べからず"><a href="#べからず" class="headerlink" title="べからず"></a>べからず</h3><ul><li>動詞辞書形＋べからず<br>【禁止……】[书]，是一种老旧的表达。<br>例：仕事中サボるべからず。  </li></ul><h3 id="ようにではない"><a href="#ようにではない" class="headerlink" title="ようにではない"></a>ようにではない</h3><ul><li>動詞意向形＋ようにではない<br>【让我们一起……吧】，是一种劝诱和提出建议的方式。说话场景是一对多的情况下使用，不能用于一对一的对话中。<br>例：この社会を改造しようにではない。  </li></ul><h3 id="こと"><a href="#こと" class="headerlink" title="こと"></a>こと</h3><ul><li>動詞辞書形・ない形・名詞～の＋こと<br>【请……】，多用于提醒别人注意。<br>例：英語の成績を上げたいと思ったら、まず単語量を増やすことです。  </li></ul><h3 id="ことだ"><a href="#ことだ" class="headerlink" title="ことだ"></a>ことだ</h3><ul><li>動詞辞書形・ない形＋ことだ<br>【最好……】，主观地给对方忠告和建议。只能用于身份高的对身份低的人使用。<br>例：受験前に遊ばないことだ。  </li></ul><h3 id="ことはない"><a href="#ことはない" class="headerlink" title="ことはない"></a>ことはない</h3><ul><li>動詞辞書形・ない形＋ことはない  </li></ul><ol><li>【没必要……】，表示劝告。   </li><li>【不需要考虑……】，由于没有发生的可能性而不需要考虑。<br>例：君は復習したから、慌てることはない。  </li></ol><h3 id="ものではない"><a href="#ものではない" class="headerlink" title="ものではない"></a>ものではない</h3><ul><li>動詞辞書形＋ものではない<br>【不应该……】，在社会常识的角度上出发对对方进行劝诫。<br>例：君は公務員として、賄賂に受けるものではない。  </li></ul><h3 id="べき・はず"><a href="#べき・はず" class="headerlink" title="べき・はず"></a>べき・はず</h3><ul><li>動詞辞書形＋べき<br>【理应……】，是主观的表示说话人认为的义务<br>例：やるべきことはたくさんいる。  </li><li>動詞辞書形＋はず<br>【理应……】，表示客观地判断。<br>例：この時間で、小林さんは仕事しているはずです。  </li></ul><h2 id="话题提起（Unit-3）"><a href="#话题提起（Unit-3）" class="headerlink" title="话题提起（Unit 3）"></a>话题提起（Unit 3）</h2><h3 id="とは"><a href="#とは" class="headerlink" title="とは"></a>とは</h3><ul><li>名詞＋とは  </li></ul><ol><li>【所谓……，就是……】[书]，表示解释前项的名词。<br>例：神経ネットワークとは、人脳の神経を模擬して、作った人工知能です。  </li><li>【意外地……】，表示意外的情绪<br>例：京都とはこんなに住みごこちがよいところだとは思わなかった。（住着意外的舒服）  </li></ol><h3 id="というものは"><a href="#というものは" class="headerlink" title="というものは"></a>というものは</h3><ul><li>名詞＋とうものは<br>【所谓……】，后项用于对该抽象名词进行说明。说明的内容是一般性质或者是本质。往往包含着某种感情。<br>例：人間というものは一人生きていくことはできません。  </li></ul><h3 id="といえば"><a href="#といえば" class="headerlink" title="といえば"></a>といえば</h3><ul><li>名詞＋と言えば<br>【说到……的话】，表示提起一个由前述话题联想得到的新话题。<br>例：センター試験と言えば、もうすぐ模擬テストが来るでしょう。  </li></ul><h3 id="というと"><a href="#というと" class="headerlink" title="というと"></a>というと</h3><ul><li>名詞・動詞辞書形＋というと  </li></ul><ol><li>【一提到……，就会想到……】，表示一提到某个话题就会想起与之相关联的某个事物。<br>例：先生というと，李先生を思い出す。  </li><li>【你的意思是……吧】，表示对前述内容的确认。<br>例：田中さんというと，あの中国語の先生ですか。  </li></ol><ul><li>名詞＋はというと<br>表示与前项对比后，提出新的话题<br>例：難関校を受験するということは並大抵（一般的）のことではありません。  </li></ul><h3 id="といったら"><a href="#といったら" class="headerlink" title="といったら"></a>といったら</h3><ul><li>名詞＋と言ったら<br>【说起……那真是……】，表示提起话题，含有惊讶的语气。<br>例：あの学校の英語の難しさといったら言葉では言い表せません。  </li></ul><h3 id="にかけては"><a href="#にかけては" class="headerlink" title="にかけては"></a>にかけては</h3><ul><li>名詞＋にかけては<br>【说起……，那可就……】，表示提出一个话题，后项的内容是一些褒义的、称赞性的句子。有表示主语对于话题提到的事物很擅长的意思。可以用于自己和他人，用于自己时表自信。<br>例：数学にかけては、彼女はクラスでいつも一番だった。  </li></ul><h3 id="ときたら"><a href="#ときたら" class="headerlink" title="ときたら"></a>ときたら</h3><ul><li>名詞＋ときたら<br>【说起……，就……】，后项是贬义句子，有不满和挖苦之意。<br>例：彼女ときたら,最近おしゃれのことにばっかり気をつけている。 （说到她，最近光是注意打扮。有挖苦之意）  </li></ul><h2 id="强调心情（Unit-4）"><a href="#强调心情（Unit-4）" class="headerlink" title="强调心情（Unit 4）"></a>强调心情（Unit 4）</h2><h3 id="てやまない"><a href="#てやまない" class="headerlink" title="てやまない"></a>てやまない</h3><ul><li>動詞て形＋てやまない<br>【由衷地……】[正式]，表带强烈的愿望和一种心情。通常用于关照和忠告。一直都有认为是这样的情况时使用。<br>常与「祈る」、「期待する」、「願う」、「愛する」、「尊敬する」等动词一起使用。<br>例：二人の幸せを祈ってやみません。  </li></ul><h3 id="かぎりだ"><a href="#かぎりだ" class="headerlink" title="かぎりだ"></a>かぎりだ</h3><ul><li>な形容詞～な・名詞～の・い形容詞＋かぎりだ（です）<br>【从心底上……】，表示说话人自己现在有非常强烈的意愿。只能对说话人自己使用。<br>例：成績が上がって、嬉しいかぎりだ。  </li></ul><h3 id="といったらない・といったらありはしない"><a href="#といったらない・といったらありはしない" class="headerlink" title="といったらない・といったらありはしない"></a>といったらない・といったらありはしない</h3><ul><li>い形容詞・程度に表示する名詞＋といったらない<br>【……极了】，表示程度已经到了用语言无法表达的程度。是一种极端的叙述。对于好的和坏的事物都可以用。  </li><li>い形容詞・程度に表示する名詞＋といったらありはしない<br>例：災害の規模は大きさといったらなかった。  </li></ul><h3 id="仕方ない・しょうがない・てたまらない・てならない"><a href="#仕方ない・しょうがない・てたまらない・てならない" class="headerlink" title="仕方ない・しょうがない・てたまらない・てならない"></a>仕方ない・しょうがない・てたまらない・てならない</h3><ul><li>自動詞て形・い形容詞て形・な形容詞て形＋しかたない  </li><li><p>自動詞て形・い形容詞て形・な形容詞て形＋しょうがない [口]<br>【难以抑制地/情不自禁地……】，表示自发性的、难以抑制的心情或者行为。しょうがない为口语。<br>例：クラスで一番になって嬉しくてしかたない。  </p></li><li><p>動詞て形・い形容詞て形・な形容詞て形＋てたまらない<br>【怎么都不能……】，也表示难以抑制的，但是不能用于自发性的词语。<br>例：徹夜続きで眠くてたまりません。  </p></li><li><p>動詞て形・い形容詞て形・な形容詞て形＋てならない<br>【情不自禁地……/……得不得了】，表示自然而然涌上心头的心情或行为，多用于表达负面情绪。<br>例：大学の時もっと勉強しておけば良かったと悔やんでならない。（后悔的不得了）  </p></li></ul><h2 id="强制（Unit-5）"><a href="#强制（Unit-5）" class="headerlink" title="强制（Unit 5）"></a>强制（Unit 5）</h2><h3 id="ないではすまい・ずにはすまない"><a href="#ないではすまい・ずにはすまない" class="headerlink" title="ないではすまい・ずにはすまない"></a>ないではすまい・ずにはすまない</h3><ul><li>動詞ない形＋ないではすまい・ずにはすまない<br>常识上的强制。表示考虑到社会的常识、规则而必须要做。<br>常与：謝る等连用。<br>例：社会に謝まないではすまい。  </li></ul><h3 id="わけにはいかない"><a href="#わけにはいかない" class="headerlink" title="わけにはいかない"></a>わけにはいかない</h3><ul><li>動詞普通形＋わけにはいかない  </li></ul><ol><li>常识上的强制。表示心里面想做，但是因为社会的常识而必须不能做的事情。<br>例：あの人を殺すわけにはいかない。  </li><li>心理上的强制。表示因为内心抵触而不做的事情。<br>例：横島屋の倒産は三条さんに責任があると言わざるを得ない。  </li></ol><h3 id="ないではおかない"><a href="#ないではおかない" class="headerlink" title="ないではおかない"></a>ないではおかない</h3><ul><li>動詞ない形＋ないではおかない<br>心理上的强制。有一种强烈的愿望一定要做。<br>例：あのパン屋さんのケーキを買わないではおかない。  </li></ul><h3 id="禁じえない"><a href="#禁じえない" class="headerlink" title="禁じえない"></a>禁じえない</h3><ul><li>名詞＋禁じ得ない<br>【禁不住……】，心理上的强制。看到事物的样子，心中自然而然地就会产生无法压抑的情绪。<br>常与：怒り、涙、悲しみ　连用。<br>例：地震に破壊された建物を見ると、悲しみ禁じ得ない。  </li></ul><h3 id="ずにはいられない・ないではいられない"><a href="#ずにはいられない・ないではいられない" class="headerlink" title="ずにはいられない・ないではいられない"></a>ずにはいられない・ないではいられない</h3><ul><li>動詞ない形＋ずにはいられない・ないではいられない<br>心理上的强制。表示看到某种情况，身体上就不能自主地做出某种行为。<br>例：美味しそうなケーキを目の前にして、買わないではいられませんでした。  </li></ul><h3 id="ざるを得ない"><a href="#ざるを得ない" class="headerlink" title="ざるを得ない"></a>ざるを得ない</h3><ul><li>動詞ない形＋ざるをえない<br>外力的强制。心理想做，但由于不可避免地情况出现而不得不做。<br>常与：諦めない 连用。<br>例：悪天候が続ければ登頂は断念せざるを得ない。  </li></ul><h3 id="余儀なくされる"><a href="#余儀なくされる" class="headerlink" title="余儀なくされる"></a>余儀なくされる</h3><ul><li>名詞＋を余儀なくされる<br>外力的强制。表示因为外力的强大和个人的弱小而不得不做。<br>例：一人暮らしを余儀なくされる高齢者の数も増えてくるというわけである。（这导致不得不独居的空巢老人也在增加。）  </li></ul><h2 id="传闻·推测（Unit-6）"><a href="#传闻·推测（Unit-6）" class="headerlink" title="传闻·推测（Unit 6）"></a>传闻·推测（Unit 6）</h2><h3 id="ということで"><a href="#ということで" class="headerlink" title="ということで"></a>ということで</h3><ul><li>動詞普通形＋ということです  </li><li>動詞普通形＋とのことです[书]<br>【据说……/听说……】，表示前项的内容是一个传闻。とのことです是书面语。<br>例：かれは彼女がいるということです。  </li></ul><h3 id="とか"><a href="#とか" class="headerlink" title="とか"></a>とか</h3><ul><li>動詞普通形＋とか<br>【听说……】，与ということで相比，带有更加不确定的语气。常用于委婉的表达当中。<br>例：あの子は先生に怒られるとか。  </li></ul><h3 id="まい·まいか"><a href="#まい·まいか" class="headerlink" title="まい·まいか"></a>まい·まいか</h3><ul><li>動詞辞書形＋まい·まいか  </li><li>二・三グループ動詞ない形＋まい·まいか  </li><li>三グループ動詞の名詞＋すまい·まいか  </li><li>い形容詞～くある・名詞～ではある・な形容詞～ではある＋まい·まいか<br>【不会……吧】，是ない的变体，比动词未然形而言有不确定的语气。<br>まいか是一种委婉的表达。<br>例：横島屋は倒産すまい。  </li></ul><h3 id="恐れがある"><a href="#恐れがある" class="headerlink" title="恐れがある"></a>恐れがある</h3><ul><li>動詞普通形・名詞～の＋おそれがある<br>【恐怕会……】[正式]，用于描述可能会发生的不好的事情。常用于天气预报、报告书等正式的场合。<br>例：今日は大雪のおそれがあります。  </li></ul><h3 id="かねない"><a href="#かねない" class="headerlink" title="かねない"></a>かねない</h3><ul><li>動詞ます形＋かねない<br>【可能会导致……】，用于描述不好的结果。含有担心的情感。<br>例：ちょっとした間違いが命取りになりかねない。  </li></ul><h3 id="に違いない・に相違ない"><a href="#に違いない・に相違ない" class="headerlink" title="に違いない・に相違ない"></a>に違いない・に相違ない</h3><ul><li>動詞普通形・名詞・な形容詞・い形容詞＋に違いない・に相違<sup>そうい</sup>ない<br>【觉得一定是……】[正式]，表示说话人根据事实做出的肯定的判断。<br>例：この本は内容が豊富でおもしろい。きっと売れるに違いない。  </li></ul><h3 id="と見える"><a href="#と見える" class="headerlink" title="と見える"></a>と見える</h3><ul><li>動詞普通形・名詞・な形容詞・い形容詞＋と見える・と見えて<br>【看上去好像……】，前项是看到的事实，后项是基于前项的判断。也可以单独使用前项。<br>例：人類はよほど戦争が好きと見える。  </li></ul><h2 id="否定（Unit-7）"><a href="#否定（Unit-7）" class="headerlink" title="否定（Unit 7）"></a>否定（Unit 7）</h2><h3 id="ことなしに"><a href="#ことなしに" class="headerlink" title="ことなしに"></a>ことなしに</h3><ul><li>動詞辞書形・名詞（～とさせ）＋ことなしに<br>【没有做……，就做……】，表示在没有做前项事情的条件下，就进行了后项的行为。<br>例：委員会は詳しい調査を行うことなしに、早急に結論を出してしまった。</li></ul><h3 id="ことなく"><a href="#ことなく" class="headerlink" title="ことなく"></a>ことなく</h3><ul><li>動詞辞書形＋ことなく<br>【没有做……，而做……】[正式]，前项通常是日常会做的事情，后项是反常的事情。用于表达与日常不同的事情。<br>例：忙しいので、休日にも休むことなく、ずっど働きます。  </li></ul><h3 id="までもない"><a href="#までもない" class="headerlink" title="までもない"></a>までもない</h3><ul><li>動詞辞書形＋までもない<br>【没有必要做……】，表示不必要的行为。<br>例：誰も知っていることだから、今さら調べるまでもない。  </li></ul><h3 id="わけがない・はずがない"><a href="#わけがない・はずがない" class="headerlink" title="わけがない・はずがない"></a>わけがない・はずがない</h3><ul><li>動詞辞書形・い形容詞・な形容詞～な・名詞～の＋わけがない<br>【当然不能……】，表示说话人根据充足的客观事实推断所述事情不成立。<br>例：こんな難しい問題、解けるわけがない。  </li><li>動詞辞書形・い形容詞・な形容詞～な・名詞～の＋はずがない<br>【当然不可能……】，对可能形的否定。表示说话人主观判断事情没有发生的可能。<br>例：あの温厚な人がそんなひどいことをするはずがない。  </li></ul><h3 id="っこない"><a href="#っこない" class="headerlink" title="っこない"></a>っこない</h3><ul><li>動詞ます形＋っこない<br>【根本不可能……】[口]，表示对可能性的强烈否定。体现出说话人的主观判断。<br>例：そんなことは子供にできっこない。  </li></ul><h3 id="ものか"><a href="#ものか" class="headerlink" title="ものか"></a>ものか</h3><ul><li>動詞辞書形・い形容詞・な形容詞～な・名詞～の＋ものか<br>【绝不……】，表示对事实的强烈否定。体现说话人的排斥和拒绝。<br>例：あの店は店員の態度が悪すぎる。二度と行くものか。  </li></ul><h3 id="どころではない"><a href="#どころではない" class="headerlink" title="どころではない"></a>どころではない</h3><ul><li>動詞辞書形・名詞＋どころではない<br>【没有做……的时间/余地】[口]，表示没有做某事的时间或者余地。<br>例：忙しくて映画を見に行くどころではない。  </li></ul><h2 id="部分否定（Unit-8）"><a href="#部分否定（Unit-8）" class="headerlink" title="部分否定（Unit 8）"></a>部分否定（Unit 8）</h2><h3 id="ないものでもない・ないでもない"><a href="#ないものでもない・ないでもない" class="headerlink" title="ないものでもない・ないでもない"></a>ないものでもない・ないでもない</h3><ul><li>動詞ない形＋ないものでもない・ないでもない<br>【……也不是不可能的/也不是不可以】，是消极的表达。常常是针对说话人自己的事发表意见。<br>例：今から頑張って、合格できないものでもありません。  </li></ul><h3 id="ないこともない"><a href="#ないこともない" class="headerlink" title="ないこともない"></a>ないこともない</h3><ul><li>動詞ない形・名詞～で・な形容詞～で・い形容詞て形＋ないこともない<br>【也能……】，表示在某种条件下也能达成所述事物，通常是不能达成的。是消极的表达。<br>例：実際に読まないことには、この小説のおもしろさはわからないだろう。</li></ul><h3 id="というものではない"><a href="#というものではない" class="headerlink" title="というものではない"></a>というものではない</h3><ul><li>動詞普通形＋というものではない<br>表示按常理应当发生的事情，最终没有发生。<br>例：勉強すれば合格できるというものではない。  </li></ul><h3 id="わけではない"><a href="#わけではない" class="headerlink" title="わけではない"></a>わけではない</h3><ul><li>動詞普通形・な形容詞～な・名詞～の・い形容詞＋わけではない<br>【并不是只……】，表示某一个范围内的某个事物并不是完全占据了整个范围，还有其他的事物。<br>例：中澤先生も学生時代、勉強ばかりしていたわけだはない。  </li></ul><h3 id="ことは"><a href="#ことは" class="headerlink" title="ことは"></a>ことは</h3><ul><li>動詞普通形・い形容詞・な形容詞～な・名詞～な＋ことは＋同じ単語＋が・けど<br>【……是……了，但是……】，表示姑且承认所述的行为，但是后项的结果是预期的相反结果。<br>例：単語は覚えることは覚えるが、すっぐ忘れてしまいました。  </li></ul><h2 id="过程（Unit-9）"><a href="#过程（Unit-9）" class="headerlink" title="过程（Unit 9）"></a>过程（Unit 9）</h2><h3 id="っぱなし"><a href="#っぱなし" class="headerlink" title="っぱなし"></a>っぱなし</h3><ul><li>動詞ます形＋っぱなし<br>【一直……】/【放任不管……】，表示对象一直进行的动作或者状态。<br>例：電気は徹夜でつけっぱなし。  </li></ul><h3 id="にいたっては"><a href="#にいたっては" class="headerlink" title="にいたっては"></a>にいたっては</h3><ul><li>動詞辞書形・名詞＋に至っては<br>【甚至到了……的地步，以至于……】，表示过程到了一个极端的状态，并导致了后项的结果。<br>例：テレビ報道が過熱するに至っては、報道管制はできません。  </li></ul><h3 id="たところ"><a href="#たところ" class="headerlink" title="たところ"></a>たところ</h3><ul><li>動詞た形＋たところ<br>【刚……后就……】，表示在前项刚刚结束时就进行了后项的行为。<br>例：先生が行ったところ、教室は静かにしました。  </li></ul><h3 id="あげく・末に"><a href="#あげく・末に" class="headerlink" title="あげく・末に"></a>あげく・末に</h3><ul><li>動詞た形・名詞～の＋あげく<br>【最终……】，表示在经历了一个漫长的过程后得到了消极的结果。<br>例：抵抗したあげく、残った人たちは全部投降した。  </li><li>動詞た形・名詞～の＋末<sup>すえ</sup>に<br>【最终……】，表示在经历了一个漫长的过程后的得到了一个结果。结果既可以是消极的也可以是积极的。强调过程是漫长的。<br>例：勉強した末に、大学に採用された。　  </li></ul><h3 id="きりで"><a href="#きりで" class="headerlink" title="きりで"></a>きりで</h3><ul><li>動詞た形＋きりで<br>【……之后就一直……】，表示前项的状态结束后就一直持续后项的状态，后项是意料之外的状态。<br>例：忘年会であったきりで、彼を連絡取れなかった。  </li></ul><h2 id="结局（Unit-10）"><a href="#结局（Unit-10）" class="headerlink" title="结局（Unit 10）"></a>结局（Unit 10）</h2><h3 id="始末だ"><a href="#始末だ" class="headerlink" title="始末だ"></a>始末だ</h3><ul><li>動詞普通形・名詞～の・な形容詞～な・い形容詞＋始末だ<br>【到了……的地步】，表示经历了某种不好的事件，最后变成了更坏的结局（前项）。<br>常用表达：この始末，表示变成了这样不好的境地。<br>例：何度も注意しているのに遅刻するし、宿題も忘れる始末だ。  </li></ul><h3 id="に至る"><a href="#に至る" class="headerlink" title="に至る"></a>に至る</h3><ul><li>動詞辞書形・名詞＋に至る<br>【以至于……】[正式]，表示在经历了许多事情之后，变成了前项的程度、结果、范围。<br>例：彼女とは10年交際して結婚に至りました。  </li></ul><h3 id="まで"><a href="#まで" class="headerlink" title="まで"></a>まで</h3><ul><li>動詞た形＋までだ・（のことだ）<br>【只是……而已】，强调说话人没有别的意图。<br>例：近くまで来る用事あったから、ちょっと寄ったまでだ。（因为有事要到附近来，顺便去了一下而已。）  </li><li>動詞辞書形＋までだ・（のことだ）<br>【只能做……】，表示在没有其他办法的情况下做出的选择。用于陈述理由。<br>例：彼が言わないから、私が言うまでです。  </li></ul><h3 id="切る・抜く"><a href="#切る・抜く" class="headerlink" title="切る・抜く"></a>切る・抜く</h3><ul><li><p>動詞ます形＋きる<br>【完全/直到最后……】，表示将前项的动作彻底做完。强调“完全”。<br>例：練習はやりきりました。  </p></li><li><p>動詞ます形＋ぬく<br>【完全/直到最后……】，表示将前项动作彻底做完。前项动作是一个很困难的或者需要下功夫的事情。<br>例：考えぬいた結果、地元の大学に進学することにしました。  </p></li></ul><h3 id="次第だ"><a href="#次第だ" class="headerlink" title="次第だ"></a>次第だ</h3><ul><li>動詞普通形・名詞～の・な形容詞～な・い形容詞＋次第だ<br>【所以……】[正式]，表示成为了某种结果，用于表示理由、说明结果。<br>例：以上の理由で、御社の求人に応募する次第です。  </li></ul><h3 id="わけだ・ことになる"><a href="#わけだ・ことになる" class="headerlink" title="わけだ・ことになる"></a>わけだ・ことになる</h3><ul><li>動詞普通形・名詞～の・な形容詞～な＋わけだ  </li><li>動詞辞書形・動詞ない形・い形容詞＋ことになる<br>【理应就会……】，表示理所应当的结果。<br>例：運動すれば、瘦せられるわけです。  </li></ul><h3 id="ことになっている"><a href="#ことになっている" class="headerlink" title="ことになっている"></a>ことになっている</h3><ul><li>動詞辞書形・動詞ない形・い形容詞＋ことになっている<br>【就会……】[书]，用于表示约定、规则、习惯。<br>表示规则时多与许可或者禁止的表达连用。<br>例：国立大学は二回まで受けていいことになっています。   </li></ul><h3 id="ということだ"><a href="#ということだ" class="headerlink" title="ということだ"></a>ということだ</h3><ul><li>動詞普通形＋ということだ<br>【就是……的意思】，表示解释和说明。<br>例：「駐車禁止」ということは、車ををめてはいけないということです。  </li></ul><h3 id="ところだった"><a href="#ところだった" class="headerlink" title="ところだった"></a>ところだった</h3><ul><li>動詞辞書形・動詞ない形＋ところだった<br>【差点就变成了……】，表示差点就变成了某个结果，但是这个结果实际上并未发生。<br>例：朝雨ので、遅刻するところだった。  </li></ul><h3 id="っけ・たっけ"><a href="#っけ・たっけ" class="headerlink" title="っけ・たっけ"></a>っけ・たっけ</h3><ul><li>動詞普通形＋っけ・でしたっけ・ましたっけ<br>【好像是……吧】，用于说话人向对方确认某个内容，或者是自言自语表示自己确认某个内容。<br>例：彼の名前なんだっけ。  </li></ul><h2 id="让步·意外·转折（Unit-11）"><a href="#让步·意外·转折（Unit-11）" class="headerlink" title="让步·意外·转折（Unit 11）"></a>让步·意外·转折（Unit 11）</h2><h3 id="と思いきや"><a href="#と思いきや" class="headerlink" title="と思いきや"></a>と思いきや</h3><ul><li>動詞普通形＋と思いきや<br>【意外地】[口]，表示意外的情绪。前项为推测，后项为和推测不一样的结果。<br>例：不合格するかと思いきや、合格していました。  </li></ul><h3 id="ものを"><a href="#ものを" class="headerlink" title="ものを"></a>ものを</h3><ul><li>動詞普通形・な形容詞～な・名詞～の＋ものを<br>【要是……就……了】，不满现实未按照期待的方向发展。前句为想象的符合期望的行为，ものを之前为这个期望行为的结果。<br>例：覚えれば、この問題をとけたものを。  </li></ul><h3 id="ところ"><a href="#ところ" class="headerlink" title="ところ"></a>ところ</h3><ul><li>動詞普通形・な形容詞～な・名詞～の・い形容詞＋ところ<br>【虽然是……，却还是做了……】[正式]，前项通常是描述对方的情况，后项是和情况反常的行为。是站在对方立场上进行考虑的表达。常用于寒暄、感谢。<br>常与：忙しい、休み、足元の悪い等连用。<br>例：お忙しいところ、ご協力でいただきます。  </li></ul><h3 id="とはいえ"><a href="#とはいえ" class="headerlink" title="とはいえ"></a>とはいえ</h3><ul><li>動詞普通形・名詞＋とは言え<br>【也不完全是……/虽然说是……】，否定前项的一部分属性、印象，并说明实际情况，后项是说话人的主观意见和判断。<br>例：彼は劣等生とは言え、心は優しいです。  </li></ul><h3 id="いえとも"><a href="#いえとも" class="headerlink" title="いえとも"></a>いえとも</h3><ul><li>動詞普通形・名詞＋いえとも<br>【即使是……，也……】，提出一个极端的情况或者是身份，陈述和这个极端情况反常的事说明话题本身的反常。<br>例：この問題は、先生いえとも、解けられない。  </li></ul><h3 id="からといって"><a href="#からといって" class="headerlink" title="からといって"></a>からといって</h3><ul><li>動詞普通形＋からと言って<br>【作为……而言，却……】，表示从某个人的立场出发而做出不符合立场的反常行为。句末经常与というわけではない、とは限らない等部分否定的表达连用。后项多为批判、判断。<br>例：先生からと言って、賄賂を受けた。　 </li></ul><h3 id="といっても"><a href="#といっても" class="headerlink" title="といっても"></a>といっても</h3><ul><li>動詞普通形・名詞＋と言っても<br>【虽然说……，实际上是……】，前项为说话人推测的依据，后项为与推测相反的结果，多用于解释现在的情况。<br>例：先生と言っても、高級車を持ている。  </li></ul><h3 id="にしても・にしろ・にせよ"><a href="#にしても・にしろ・にせよ" class="headerlink" title="にしても・にしろ・にせよ"></a>にしても・にしろ・にせよ</h3><ul><li>動詞普通形・名詞～である・な形容詞～である＋にしても・にしろ  </li><li>動詞普通形・名詞～である・な形容詞～である＋にせよ [正式]<br>【即是……，但是也……】，表示难以接受的心情。后项为主观意见、判断、评价，多为否定。<br>例：若いにしても責任を免れるわけにはいかない。  </li></ul><h3 id="にもかかわらず"><a href="#にもかかわらず" class="headerlink" title="にもかかわらず"></a>にもかかわらず</h3><ul><li>動詞普通形・名詞（～である）・な形容詞（～である）＋にもかかわらず<br>【明明……，结果却是……】，表示根据前项的推测，后项的结果与推测的结果相反。强调吃惊、意外、不满。表示转折。<br>例：彼は、夏休み中にもかかわらず、毎日図書館で勉強している。  </li></ul><h3 id="ものの・ながら"><a href="#ものの・ながら" class="headerlink" title="ものの・ながら"></a>ものの・ながら</h3><ul><li>動詞普通形・名詞（～である）・な形容詞（～である）＋ものの　<br>【明明……，却……】，承认前项是事实，但是实际上与之关联的后项是无法按预想进行的，或者是与从前项的推断相反。<br>例：大学時代はフランス文学専攻だった。とはいうものの、フランス語はほとんどしゃべれない。  </li></ul><h3 id="つつ"><a href="#つつ" class="headerlink" title="つつ"></a>つつ</h3><ul><li>動詞ます形＋つつ<br>【虽然……，却……】，表示说话人后悔、表白、袒露真言的心情。前项常常是一个不好的事情。<br>例：母親は口では子どもを叱りつつも、心の中では子供がかわいくてたまらないのです。  </li></ul><h3 id="くせに・くせして"><a href="#くせに・くせして" class="headerlink" title="くせに・くせして"></a>くせに・くせして</h3><ul><li>動詞普通形・名詞～である/の・な形容詞～である/な＋くせに・くせして<br>【明明……，却……】，多用于人，强调谴责、蔑视对方、意外和不满的心情。<br>例：あいつ男のくせに、よく泣くよなぁ。　　  </li></ul><h3 id="ながら"><a href="#ながら" class="headerlink" title="ながら"></a>ながら</h3><ul><li>動詞ます形・い形容詞・名詞～でありの・な形容詞～であり/な＋ながら<br>【虽然……，却……】，表示转折，后项是与前项相反的事实。<br>例：狭いながらも楽しいわが家。  </li></ul><h2 id="举例（Unit-12）"><a href="#举例（Unit-12）" class="headerlink" title="举例（Unit 12）"></a>举例（Unit 12）</h2><h3 id="であれ・にしろ・にしても・にせよ"><a href="#であれ・にしろ・にしても・にせよ" class="headerlink" title="であれ・にしろ・にしても・にせよ"></a>であれ・にしろ・にしても・にせよ</h3><ul><li><p>名詞＋であれ<br>【不管是……，还是……】，表示例子都适用于后项。是复数的举例。<br>例：論文であれ、試験であれ、私立大学の問題は難しいです。  </p></li><li><p>動詞辞書形・名詞＋にしろ<br>【不管是……，还是……】，表示例子都适用于后项。是复数的举例。但是举例的前后两个例子是相反的例举。<br>例：東京の大学へ通うにしても、地方へ行くにしても、自分の好き環境を優先させて決めたいです。  </p></li><li><p>動詞辞書形・名詞・な形容詞・い形容詞＋にしても・にせよ<br>【不管是……，还是……】，表示例子都适用于后项。是复数的举例。但是举例的前后两个例子是相反的例举。<br>例：好きにせよ嫌いにせよ、彼女が優れた歌手であることはみんなが認めている。  </p></li></ul><h3 id="といわず"><a href="#といわず" class="headerlink" title="といわず"></a>といわず</h3><ul><li>名詞＋といわず<br>【不管是……，还是……】，举例的事物是同一范围内的。或者是同一事物的两个部分。<br>例：子供たちは手といわず足といわず全身砂だらけだ。  </li></ul><h3 id="といい"><a href="#といい" class="headerlink" title="といい"></a>といい</h3><ul><li>名詞＋といい<br>【无论……也好，还是……也好】，对同一个话题的多个部分进行举例。表示无论从那个方面看都是相同的属性。后项是说话人的主观判断。<br>例：あの店の服は、品質といい、デザインといい、申し分ない。  </li></ul><h3 id="なり"><a href="#なり" class="headerlink" title="なり"></a>なり</h3><ul><li>動詞辞書形・名詞＋なり<br>【……或者……】，用于两个并列的举例。常用于建议。不能对上级使用。不能用过去式。<br>例：書面でなり口頭でなり申し込むこと</li></ul><h3 id="やら"><a href="#やら" class="headerlink" title="やら"></a>やら</h3><ul><li>動詞普通形・い形容詞・名詞＋やら<br>【……呀，……呀之类的】，表示从同类事物中选取一个两个具有代表性的事物作为例子举出。或者其他的暂未想到。多用于描述不好的事情。<br>例：最近、勉強やらバイトやらで毎日忙しい。  </li></ul><h3 id="とか・や・など"><a href="#とか・や・など" class="headerlink" title="とか・や・など"></a>とか・や・など</h3><ul><li>動詞普通形・名詞＋とか・や・等<br>【……呀，……呀之类的】，用于同类型的举例，但是暗含有还有其他例子之意。<br>例：梅とか桃とか桜とか、いろいろな花があった。<br>例：その事は国会等で問題になった。（不只是在国会，在其他机关也成为了问题）  </li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>樱花教材</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>九级别语法</title>
    <link href="/2021/07/27/%E6%97%A5%E8%AF%AD/%E6%A8%B1%E8%8A%B1%E6%95%99%E6%9D%90/%E4%B9%9D%E7%BA%A7%E5%88%AB/"/>
    <url>/2021/07/27/%E6%97%A5%E8%AF%AD/%E6%A8%B1%E8%8A%B1%E6%95%99%E6%9D%90/%E4%B9%9D%E7%BA%A7%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="九级别语法"><a href="#九级别语法" class="headerlink" title="九级别语法"></a>九级别语法</h1><h2 id="假定（Unit-1）"><a href="#假定（Unit-1）" class="headerlink" title="假定（Unit 1）"></a>假定（Unit 1）</h2><h3 id="さえ"><a href="#さえ" class="headerlink" title="さえ"></a>さえ</h3><ul><li>名詞・な形容詞～で・い形容詞～く＋さえあれば  </li><li>動詞ます形＋さえすれば<br>【如果……了的话，就会……】，表示条件假设<br>例：私は家庭さえあれば、幸せです。  <h3 id="としたら"><a href="#としたら" class="headerlink" title="としたら"></a>としたら</h3></li><li>普通形＋としたら<br>【如果……了的话，就会……】，和さえ相同。<br>后面既可以跟主观意见，也可以是客观的事情<br>例：お金持ちになれるとしたら、世界旅行に行きます。</li><li>普通形＋とすれば<br>后面跟主观的评价、判断<br>例：アンドロイドが人間に代わりなるとしたら、世界は終わるかもしれません。</li><li>普通形＋とすると<br>后面跟客观的，自然发生的事件<br>例：飛行機が五時間ほど遅くなるとすると、到着するのは明日の朝になるな。  </li></ul><h3 id="ないには"><a href="#ないには" class="headerlink" title="ないには"></a>ないには</h3><ul><li>名詞～で＋ないには  </li><li>動詞ない形＋ないことには<br>【如果不……就不会……】，后面通常跟可能性的否定：られない，不能用意志形。<br>例：資格外活動許可証がないには、アルバイトができない。  </li></ul><h3 id="ものなら"><a href="#ものなら" class="headerlink" title="ものなら"></a>ものなら</h3><ul><li><p>可能動詞、変化動詞辞書形＋ものなら<br>【如果能……，就……】，后项常常表示期待和愿望，但是通常有无法实现之意。<br>例：あんな悲しい思い出、忘れるものなら、早く忘れたい。  </p></li><li><p>名詞・動詞意向形＋ものなら<br>【如果……，就……】，描述如果前项发生的话，就会导致后项灾难性的结果。强调说话人担心和恐惧的心情。<br>例：あの二人が会おうものなら、殺し合いが始まる。  </p></li><li><p>動詞可能形＋ものなら<br>【如果能……，就……】，描述如果能够达成前项，就能够完成后项。强调说话人内心的愿望。<br>例：国に帰れるものなら、帰りたい。  </p></li></ul><h3 id="が最後、たら最後"><a href="#が最後、たら最後" class="headerlink" title="が最後、たら最後"></a>が最後、たら最後</h3><ul><li>動詞ます形＋が最後、たら最後<br>【如果……，就……】，描述如果能够达成前项，就会导致灾难性的后果。强调客观的事实。比ものなら的确信度更高。<br>例：海外で財布を失くしたら最後、絶対戻ってこない。  </li></ul><h3 id="抜きにしては"><a href="#抜きにしては" class="headerlink" title="抜きにしては"></a>抜きにしては　　</h3><ul><li>名詞＋抜きにしては<br>【如果没有……的话，……就难以实现】，以前项为前提，强调如果没有前项的话后项难以实现。<br>例：先生のご指導抜きにしては、試験が合格できない。  </li></ul><h3 id="とあれば"><a href="#とあれば" class="headerlink" title="とあれば"></a>とあれば</h3><ul><li>名詞・動詞辞書形＋とあれば　<br>【如果是……的话，……就能接受】，前项如果发生的话，后项所发生的结果就可以被接受、是合乎情理的。<br>例：病気になるとあれば、欠勤もやむを得ない。  </li></ul><h2 id="评价（Unit-2）"><a href="#评价（Unit-2）" class="headerlink" title="评价（Unit 2）"></a>评价（Unit 2）</h2><h3 id="割りに"><a href="#割りに" class="headerlink" title="割りに"></a>割りに</h3><ul><li>名詞～の・動詞普通形・い形容詞普通形・な形容詞～な＋割りに<br>【……，然而是……】，表示后项的结果不符合前项事物发展的规律，或者和预想完全不一样。用于与想象/常识相反的事实评价。可以对自己使用。<br>例：彼は勉強した割りに、成績が全然悪い。</li></ul><h3 id="にしては"><a href="#にしては" class="headerlink" title="にしては"></a>にしては</h3><ul><li>名詞～の・動詞普通形＋にしては<br>【……，然而是……】，意思同割りに。带有说话人怀疑的语气。不能用于评价自己的事物。<br>例：彼は日本人にしては、漢字が読めない。（有怀疑是否是日本人的语气）<blockquote><p>前面不能为表示程度的名词（比如高さ、長さ），也不能为形容词。  </p></blockquote></li></ul><h3 id="向く"><a href="#向く" class="headerlink" title="向く"></a>向く</h3><ul><li>名詞＋向けの・向きに<br>【面向……的】，向け通常表示事物最初的使用目标对象，向き表示事物适合于的对象。<br>例：この本は子供向けだたか、日本語を勉強している外国人向きでもある。  </li></ul><h3 id="ともなると"><a href="#ともなると" class="headerlink" title="ともなると"></a>ともなると</h3><ul><li>名詞＋ともなると<br>【进入到……后，变得……】，表示进入到前项的阶段后，后项就会理所应当的发生。后项是自然而然的结果。<br>例：結婚ともなると、二人の問題は家族の問題になりました。  </li></ul><h3 id="ともあろ"><a href="#ともあろ" class="headerlink" title="ともあろ"></a>ともあろ</h3><ul><li>名詞＋ともあろ人・団体・会社・組織<br>【原本是……，然而……】，表示后项的行为与前项的身份不符合。带有批评的语气。<br>例：警察官ともあろ人が、ヤクザに繋がる。  </li></ul><h3 id="まじき"><a href="#まじき" class="headerlink" title="まじき"></a>まじき</h3><ul><li>動詞辞書形＋まじき＋名詞<br>【绝对不……】，描述绝对不能允许的行为。通常有固定搭配あるまじき、許すまじき。<br>例：轢<sup>ひ</sup>き逃げ（肇事逃逸）するなんで、許すまじき行為だ。  </li></ul><h3 id="に足る"><a href="#に足る" class="headerlink" title="に足る"></a>に足る</h3><ul><li>動詞辞書形＋に足る<br>【值得/足以……】，表示对前项事情的评价。<br>例：危険をかえりみず乗客の生命を救った彼の行為は、称賛に足るものだ。  </li></ul><h3 id="にたえる"><a href="#にたえる" class="headerlink" title="にたえる"></a>にたえる</h3><ul><li>動詞辞書形・名詞＋にたえる<br>【值得……】，表示前项的某事、某物具有一定的价值。<br>例：最近のCDは品質がよく、厳しい音楽家の耳にも十分にたえるだろう。  </li></ul><h2 id="陈述理由，原因（Unit-3-4）"><a href="#陈述理由，原因（Unit-3-4）" class="headerlink" title="陈述理由，原因（Unit 3,4）"></a>陈述理由，原因（Unit 3,4）</h2><h3 id="こととて"><a href="#こととて" class="headerlink" title="こととて"></a>こととて</h3><ul><li>動詞普通形・名詞＋の＋こととて<br>【由于……】[正式]，通常用于陈述道歉的理由。是正式的表达。<br>例：材料が足りないこととて、販売中止してございます。　　</li></ul><h3 id="とあって"><a href="#とあって" class="headerlink" title="とあって"></a>とあって</h3><ul><li>名詞・動詞辞書形＋とあって　<br>表示前项已经发生了十分特殊的情况，后项因此发生了。<br>例：ボーナス後の週末とあって、デパートはすごい人出だ。  </li></ul><h3 id="故に"><a href="#故に" class="headerlink" title="故に"></a>故に</h3><ul><li>名詞・動詞普通形＋故<sup>ゆえ</sup>に<br>【由于……】[书]，后项通常是常识、真理。多用于新闻报道，论文中。<br>例：日本は島国故に、四季が分明です。  </li></ul><h3 id="ことから"><a href="#ことから" class="headerlink" title="ことから"></a>ことから</h3><ul><li>名詞・動詞普通形＋ことから<br>【由于……】，表示基于事实的理由、判断。前项是事实。<br>例：現場に残った指紋か一致したことから、彼は犯人を特定された。</li></ul><h3 id="からこそ"><a href="#からこそ" class="headerlink" title="からこそ"></a>からこそ</h3><ul><li>名詞・動詞普通形＋からこそ<br>【正是因为……】，强调前项的条件，后项一般是积极的结果。<br>例：あの時期苦労したからこそ、今幸せな生活があるのです。  </li></ul><h3 id="につき"><a href="#につき" class="headerlink" title="につき"></a>につき</h3><ul><li>名詞＋につき<br>【由于……】[书]，用于通知和看板表示原因。<br>例：業務拡大につき、解放碑<sup>ひ</sup>で新しい支店を開けます。  </li></ul><h3 id="おかけで"><a href="#おかけで" class="headerlink" title="おかけで"></a>おかけで</h3><ul><li>名詞＋お掛けで<br>【多亏了……】，常用于表示感激，也可以用于挖苦。<br>例：先生のお掛けで、病気がすぐ治りました。（感激）<br>例：貴様のお掛けで、働き時間が長くにしました。（挖苦）  </li></ul><h3 id="せいで"><a href="#せいで" class="headerlink" title="せいで"></a>せいで</h3><ul><li>名詞～の・動詞普通形＋せいで<br>【都怪……】，用于描述不好的事情。<br>例：寝坊したせいで、遅刻した。  </li></ul><h3 id="ものですから"><a href="#ものですから" class="headerlink" title="ものですから"></a>ものですから</h3><ul><li>名詞～の・動詞普通形＋ものですから・もので・ものでして<br>【因为……】[正式]，用于在道歉时描述不好的事情的原因，有迫不得已，无法避免的含义。<br>例：人身事故か起きたものですから、遅刻したの件がすみませんでした。  </li></ul><h3 id="ばかりに"><a href="#ばかりに" class="headerlink" title="ばかりに"></a>ばかりに</h3><ul><li>動詞普通形＋ばかりに　<br>【明明……】，表示做了前项的事情，但是没有得到理应的结果。<br>例：ちゃんと告白したばかりに、彼女は他の人と付き合いました。  </li></ul><h3 id="だけに"><a href="#だけに" class="headerlink" title="だけに"></a>だけに</h3><ul><li>名詞・い形容詞・な形容詞～な・動詞普通形＋だけに<br>【由于……】，陈述客观原因，含有惊叹的语气。<br>例：故宮<sup>こきゅう</sup>は広いだけに、一日だけは参れません。  </li></ul><h3 id="だけあって"><a href="#だけあって" class="headerlink" title="だけあって"></a>だけあって</h3><ul><li>動詞普通形＋だけあって<br>【由于……】，后接理所应当的结果。<br>例：海外で育たちだけあって、英語がペラペラで喋ってきます。  </li></ul><h3 id="あまりに"><a href="#あまりに" class="headerlink" title="あまりに"></a>あまりに</h3><ul><li>い形容詞・動詞普通形・名詞～の＋あまりに<br>【由于太……了】，表示前项超出了应有的范围而导致后项的结果出现。<br>例：緊張するあまりに、頭中の内容は全部忘れでしまいました。  </li></ul><h3 id="こそ"><a href="#こそ" class="headerlink" title="こそ"></a>こそ</h3><ul><li>名詞＋であればこそ・がいればこそ<br>【只有……，才能……】，强调前项理由的唯一性。多用于好的评价上。<br>例：皆は社会に奉献の気持ちにあれば、未来が光れる。  </li></ul><h2 id="既然（Unit-5）"><a href="#既然（Unit-5）" class="headerlink" title="既然（Unit 5）"></a>既然（Unit 5）</h2><h3 id="以上、上は"><a href="#以上、上は" class="headerlink" title="以上、上は"></a>以上、上は</h3><ul><li>動詞普通形＋以上<br>【既然/鉴于……】，后面跟说话者的判断或者是命令。<br>例：この件は君に担当である以上、責任をとってください。（命令）<br>例：お金がない以上、買わないべきです。（判断）  </li><li>動詞普通形＋上<sup>うえ</sup>は<br>【既然/鉴于……】[书]，后面跟说话者的决定，日常上不常用。<br>例：相手を倒すと決めた上は、全力で戦かいます。  </li></ul><h3 id="からには"><a href="#からには" class="headerlink" title="からには"></a>からには</h3><ul><li>動詞普通形＋からには<br>【既然/鉴于……】，后面跟说话人的推测或者是对对方的义务进行描述。<br>例：やったからには、最後までやろう。  </li></ul><h3 id="ことだから"><a href="#ことだから" class="headerlink" title="ことだから"></a>ことだから</h3><ul><li>名詞（名前・身元・人）＋のことだから<br>【既然是……，那……也……】，主语名詞（名前・身元）是现在对话中双方都熟悉的人。表示后项的事情是符合主语的特征的。<br>例：山田さんはいつもゆらゆらですね。彼のことだから、遅刻するかもしれません。  </li></ul><h3 id="ところを見ると"><a href="#ところを見ると" class="headerlink" title="ところを見ると"></a>ところを見ると</h3><ul><li>動詞て形＋ているところを見ると<br>表示根据看到的事实进行的判断。<br>例：彼の憂鬱<sup>ゆううつ</sup>な顔をしているところをみると、きっとテストをやってきませんね。  </li></ul><h3 id="あるまいし"><a href="#あるまいし" class="headerlink" title="あるまいし"></a>あるまいし</h3><ul><li>名詞（名前・身元・人）＋じゃ・では＋あるまいし<br>【又不是……，……】，表示对方的行为不符合某种身份。通常用于忠告。描述坏的事情。<br>例：子供じゃあるまいし、めとめそ（抽泣）泣<sup>な</sup>くな。  </li></ul><h2 id="倾向（Unit-6）"><a href="#倾向（Unit-6）" class="headerlink" title="倾向（Unit 6）"></a>倾向（Unit 6）</h2><h3 id="嫌いがある"><a href="#嫌いがある" class="headerlink" title="嫌いがある"></a>嫌いがある</h3><ul><li>動詞辞書形・動詞ない形・名詞～の＋嫌いがある<br>【……不太好】，表示前项这件事有着不好的倾向。对不好的事情呈批评的态度。不能用于自然现象和发生次数多的事件上。<br>例：彼女は人の言葉を安く信じる嫌いがある。</li></ul><h3 id="まみれ・だらけ"><a href="#まみれ・だらけ" class="headerlink" title="まみれ・だらけ"></a>まみれ・だらけ</h3><ul><li>名詞＋まみれ<br>【一身都是……】，表示令人不快的物体弄得全身都是。<br>例：油まみれ、泥まみれ  </li><li>名詞＋だらけ<br>【到处都是……】，表示令人不快的物体附着在物体表面。<br>例：ゴミだらけ  </li></ul><h3 id="ずくめ"><a href="#ずくめ" class="headerlink" title="ずくめ"></a>ずくめ</h3><ul><li>名詞＋ずくめ<br>【全……】，表示全部都是某种状态。<br>例：工藤新一は黒ずくめの男たちに小さくされてしまった。  </li></ul><h3 id="めく"><a href="#めく" class="headerlink" title="めく"></a>めく</h3><ul><li>名詞＋めく<br>【没有完全、但是也有……的感觉】<br>例：春めく、謎めく  </li></ul><h3 id="がち"><a href="#がち" class="headerlink" title="がち"></a>がち</h3><ul><li>動詞ます形・名詞＋がち<br>【容易……】，表示有容易进入某种状态的倾向。多用于不好的事情。<br>例：社会人になると、運動不足にありがちだから、とても心配です。  </li></ul><h3 id="ぽい"><a href="#ぽい" class="headerlink" title="ぽい"></a>ぽい</h3><ul><li>名詞・い形容詞～<del>い</del>+っぽい<br>【有……的感觉】，表示感觉具有另一种事物的本质特性。<br>例：男っぽい</li><li>名詞＋っぽい<br>表示大量的含有某种液体。<br>例：水っぽい</li><li>動詞ます形＋っぽい<br>【容易……的】，形容人的性格。<br>例：忘れっぽい</li></ul><h3 id="気味"><a href="#気味" class="headerlink" title="気味"></a>気味</h3><ul><li>動詞ます形・名詞＋気味<br>【多少有一点……的样子】，程度不深，多用于不好的事情。<br>例：風邪気味で最近、調子が悪い。  </li></ul><h2 id="事情完成的可能（Unit-7）"><a href="#事情完成的可能（Unit-7）" class="headerlink" title="事情完成的可能（Unit 7）"></a>事情完成的可能（Unit 7）</h2><h3 id="がたい"><a href="#がたい" class="headerlink" title="がたい"></a>がたい</h3><ul><li>動詞ます形・名詞＋がたい<br>【难以……】，表示由于心理方面的主观因素而难以做某事。<br>例：テロリストに攻撃されたなんで、信じがたい。　 </li></ul><h3 id="兼ねる"><a href="#兼ねる" class="headerlink" title="兼ねる"></a>兼ねる</h3><ul><li>動詞ます形＋かねる<br>【难以……】</li></ul><ol><li>因为情绪上抵触而不能做。  </li><li>[正式]由于公司的规章制度等不能办到。<br>例：会社のルールありかねますので、このお金、私は受けられない。  </li></ol><h3 id="はけにはいけない"><a href="#はけにはいけない" class="headerlink" title="はけにはいけない"></a>はけにはいけない</h3><ul><li>動詞辞書形＋はけにはいけない<br>【难以……】，表示因为常识性的原因而不能做。<br>例：受験する前に遊ぶわけにはいけません。  </li></ul><h3 id="ようがない"><a href="#ようがない" class="headerlink" title="ようがない"></a>ようがない</h3><ul><li>動詞ます形＋ようがない<br>【想去尝试，但不能……】，表示有想要尝试做的意愿，但是由于条件的不允许而不能做。<br>例：世界旅行へ行きようがない。（虽然想去，但由于各种时间、金钱等而不能去旅行。）  </li></ul><h3 id="得る"><a href="#得る" class="headerlink" title="得る"></a>得る</h3><ul><li>動詞ます形＋得る<br>【有可能做到……】  </li><li>動詞ます形＋得ない<br>【没有可能做到……】<br>例：これははたしが合格し得る最高の大学です。  </li></ul><h3 id="ようがない-1"><a href="#ようがない-1" class="headerlink" title="ようがない"></a>ようがない</h3><ul><li>動詞ます形＋ように＋同じ動詞のます形＋ようがない<br>【想做……但不能做……】，表示消极的、不可能做到的愿望。<br>例：京大に合格しように合格しようがありますせん。  </li></ul><h3 id="に難くない"><a href="#に難くない" class="headerlink" title="に難くない"></a>に難くない</h3><ul><li>名詞＋にかたくない<br>【不难做到……】，前面所说的事情是心理因素。表示从现实考虑不难做到。<br>例：想像にかたくない。  </li></ul><h2 id="假定转折（Unit-8）"><a href="#假定转折（Unit-8）" class="headerlink" title="假定转折（Unit 8）"></a>假定转折（Unit 8）</h2><h3 id="たとえ"><a href="#たとえ" class="headerlink" title="たとえ"></a>たとえ</h3><ul><li>たとえ＋動詞て形＋ても<br>【即使/就算……，也……】，假定前项发生了，也不考虑后项。<br>例：たとえお腹が空いても、他の人からの食べ物を受けません。  </li></ul><h3 id="ところで"><a href="#ところで" class="headerlink" title="ところで"></a>ところで</h3><ul><li>動詞た形＋ところで<br>【即便是……，也……】，假定前项发生，也无法满足后项的预期结果。后项是不可能完成的状况。后项不能用过去式。<br>例：頑張したところで、合格できない。  </li></ul><h3 id="としても"><a href="#としても" class="headerlink" title="としても"></a>としても</h3><ul><li>動詞普通形＋としても<br>【就算是……，也……】，现在不能达成某种结果，但是即使是这样也没有关系，也当做结果达成的状态进行后项。后项为程度比较低的事情，与前项有相反性。<br>例：叶わぬ恋だとしても、自分の気持ちを伝えたいです。  </li></ul><h3 id="にしろ"><a href="#にしろ" class="headerlink" title="にしろ"></a>にしろ</h3><ul><li>い形容詞・動詞普通形・な形容詞～である・名詞～である＋にしろ<br>【即使……】[口]，即是是前项那样，也不会影响到后项。后面跟主观的评价、判断、责备。后项常常是坏的。<br>常用：いずれにしろ  </li><li>A にしろ　B にしろ<br>【无论是……，还是……，都……】，是举例无论是A还是B都对后项不会有影响，后项常常是负面的、否定的用法。A和B的接续同单独的にしろ。<br>例：結果は失敗するにしろ、何もしないで諦めるは嫌いです。  </li></ul><h3 id="といえども"><a href="#といえども" class="headerlink" title="といえども"></a>といえども</h3><ul><li>名詞・動詞普通形＋といえども<br>【即使……】[正式]，即便是发生了前项的极端情况、立场、人物身份，后项也会进行。后项的结果与前项相反。<br>例：失恋といえども、自分を成長させてくれるはずです。（情况）<br>例：警察といえども、被害者の身元をはんめいできない。（人物身份）  </li></ul><h3 id="であれ"><a href="#であれ" class="headerlink" title="であれ"></a>であれ</h3><ul><li>名詞＋であれ<br>【不论……，也……】，不管前项如何，都与后项无关。用于举例，举例说明在……的情况下都不能做的事情。后面常常跟主观的判断、表现。<br>例：どんな結果であれ、自分の気持ちを伝えたいです。  </li></ul><h3 id="ようが"><a href="#ようが" class="headerlink" title="ようが"></a>ようが</h3><ul><li><p>意向形＋ようが＋動詞意向形＋ようが<br>【不论是不是……，也……】，后项是与前项相似的，或者相对的事物。  </p><blockquote><p>此处可以是動詞、い形容詞（～かろう）・な形容詞（～だろう）・名詞（～だろう）的意向形。  </p></blockquote><p>例：嫌われようが、笑われようが、はたし気になっていません。  </p></li></ul><h3 id="がまいが"><a href="#がまいが" class="headerlink" title="がまいが"></a>がまいが</h3><ul><li><p>動詞意向形＋が＋動詞辞書形＋まいが<br>【不论……，也……】，不管前项是否成立，后项都成立。与ようが不同的是，前后项必须对立。  </p><blockquote><p>する→しまい・するまい・すまい　来る→くるまい・こまい</p></blockquote><p>例：相手はいこうが来るまいが、はたしはここで待っています。  </p></li></ul><h2 id="关联（Unit-9）"><a href="#关联（Unit-9）" class="headerlink" title="关联（Unit 9）"></a>关联（Unit 9）</h2><h3 id="如何で"><a href="#如何で" class="headerlink" title="如何で"></a>如何で</h3><ul><li><p>名詞～の＋如何で<br>【依照……，来……】[正式]，表示根据前项的变化来做出后项对应的反应。<br>例：首都圏内新カタログの感染規模の如何で、五輪の観衆数を決めてます。  </p></li><li><p>名詞～の＋如何では<br>【依照……，来……】[正式]，比名詞～の＋如何で的用法来说，后项通常是更加具有对立性的事件。<br>例：首都圏内新カタログの感染規模の如何で、五輪は中止するかもしれません。  </p></li></ul><h3 id="によって"><a href="#によって" class="headerlink" title="によって"></a>によって</h3><ul><li>名詞＋によって<br>【依据……的不同，而……】，表示依据前面的标准来划分，依据前项的不同而后项不同。<br>例：センター試験の成績によって、学校が振り分けられます。</li><li>名詞＋によっては<br>【在……情况下，而……】，表示依据前面的主题，后项为前项条件下的多个可能发生的事件。<br>例：大学によっては、社会ではなく、数学でも受験できます。  </li></ul><h3 id="次第で"><a href="#次第で" class="headerlink" title="次第で"></a>次第で</h3><ul><li>名詞＋次第で<br>【依据……，有可能会……】，表示依据前项的变化而导致后项有出现的可能性。  </li><li>名詞＋次第では<br>[口]，前者的口语化表达。<br>例：能力次第で、給料は高すぎることができます。  </li></ul><h3 id="応じて"><a href="#応じて" class="headerlink" title="応じて"></a>応じて</h3><ul><li>名詞＋おうじて<br>【与……相对应地，……】，表示后项的行为与前项相呼应。<br>例：自分の興味応じて、専門を選ぶ。  </li></ul><h3 id="たびに"><a href="#たびに" class="headerlink" title="たびに"></a>たびに</h3><ul><li>動詞辞書形・名詞～の＋たびに<br>表示每次前项的事情发生，后项的事情也会发生。<br>例：雨降るたびに、たくさんの生徒は遅刻する。  </li></ul><h3 id="にっけても"><a href="#にっけても" class="headerlink" title="にっけても"></a>にっけても</h3><ul><li>動詞辞書形＋にっけても<br>处于同一情况下的时候，总会带着某种心情做某事。<br>例：中村は何事にっけても、一生懸命にやる人ですね。  </li></ul><h3 id="きっかけに"><a href="#きっかけに" class="headerlink" title="きっかけに"></a>きっかけに</h3><ul><li>名詞＋をきっかけに<br>【以……为契机】，表示以前项的事情为契机，开始做后项的事情。<br>例：彼は国会議事堂前の講演をきっかけに、革命活動をやります。  </li></ul><h2 id="例外·不论（Unit-10）"><a href="#例外·不论（Unit-10）" class="headerlink" title="例外·不论（Unit 10）"></a>例外·不论（Unit 10）</h2><h3 id="如何に"><a href="#如何に" class="headerlink" title="如何に"></a>如何に</h3><ul><li>名詞（～の）＋いかんによらず・いかんにかかわらず・いかんを聞<sup>と</sup>わず<br>【与……没有关系/不论……】，表示后项在前项不管是怎么样子的前提下都能够进行。常用于说教。是一种老旧的说话方式。<br>常与：目的、理由连用。<br>例：目的のいかんによらず、そのやり方は違反行為です。   </li></ul><h3 id="にかかわらず"><a href="#にかかわらず" class="headerlink" title="にかかわらず"></a>にかかわらず</h3><ul><li>名詞＋にかかわらず・に（は）かかわりなく<br>【不管……】，表示后项在前项不管是什么样子的前提下都保持某种状态。后接种类、程度。<br>例：この店は曜日にかかわらず、いつも空いています。  </li></ul><h3 id="いざしらず"><a href="#いざしらず" class="headerlink" title="いざしらず"></a>いざしらず</h3><ul><li>名詞～は・なら・だったら＋いざしらず  </li><li>動詞普通形～なら・い形容詞～なら・な形容詞～なら＋いざしらず<br>【暂且不论……】，表示先不考虑前项，以后项为话题进行陈述。前项为不知道的问题，后项为已知的问题。<br>例：遅刻したならいざしらず、宿題を全部で間違ってしたのは、どうゆうことですか。  </li></ul><h3 id="よそに"><a href="#よそに" class="headerlink" title="よそに"></a>よそに</h3><ul><li>名詞＋をよそに<br>【不顾……】，贬义。表示对前项的事情漠不关心的态度来进行后项。<br>例：両親の心配をよそに、彼は遊んでばかりいます。  </li></ul><h3 id="ものともせず"><a href="#ものともせず" class="headerlink" title="ものともせず"></a>ものともせず</h3><ul><li>名詞＋をものともせず<br>【不顾……】，褒义。前项通常是已知的问题、困难。用于称赞他人，不能对自己使用。<br>例：自分の命をものともせず、彼は火事に数人を助けた。  </li></ul><h3 id="もかまわず"><a href="#もかまわず" class="headerlink" title="もかまわず"></a>もかまわず</h3><ul><li>名詞・な形容詞～な・動詞普通形・い形容詞＋もかまわず<br>【不在乎……】，表示不在乎前项的事情来做后项，前项通常是平常会在意的事情。<br>例：人目もかまわず、電車の中で化粧している女子高生をよく見かけます。  </li></ul><h3 id="ともかく"><a href="#ともかく" class="headerlink" title="ともかく"></a>ともかく</h3><ul><li>名詞＋はともかく（として）<br>【虽然……是不得不考虑的，但是当下应当优先考虑……】，表示在前项和后项的问题中进行对比后选择做后项。前后两项都是不得不考虑的事情，后项更紧急。<br>例：近くの便利さはともかく、家賃は耐えられません。  </li></ul><h3 id="さておき"><a href="#さておき" class="headerlink" title="さておき"></a>さておき</h3><ul><li>名詞＋はさておき<br>【先不考虑……，更理应考虑……】，表示先不考虑前项，后项的事情更为重要。<br>例：勉強はさておき、体の回復するのが先決です。  </li></ul><h2 id="程度强调（Unit-11）"><a href="#程度强调（Unit-11）" class="headerlink" title="程度强调（Unit 11）"></a>程度强调（Unit 11）</h2><h3 id="からある・からする・からの"><a href="#からある・からする・からの" class="headerlink" title="からある・からする・からの"></a>からある・からする・からの</h3><ul><li>程度を表示する名詞・量詞＋からある  </li><li>人数＋からの  </li><li>価額＋からする<br>【超过……以上】，强调数量之多、长度之长、人数之多、价格之高等等。总之就是强调前项名词的上限。<br>与「以上」・「以上ある」用法相同。<br>例：開店日は八万人からのお客様が来店しました。  </li></ul><h3 id="というもの"><a href="#というもの" class="headerlink" title="というもの"></a>というもの</h3><ul><li>動詞普通形・名詞～の・な形容詞～な＋というもの<br>【真是这么……啊】，强调说话人的感想，后项为说话人的判断或者是批判。<br>例：彼女が愛国の心を持っていないというものはきっと世間に批判されるよう。  </li><li>時間を表示する名詞＋というもの<br>【……这么长】，强调时间非常的长。<br>例：ここ一ヶ月というもの、仕事に追われて全く余裕がない。</li><li>動詞普通形＋というものではない<br>【不完全是……】，同「とは言えない」。<br>例：お金があれば幸せになれるというものではない。  </li></ul><h3 id="にして"><a href="#にして" class="headerlink" title="にして"></a>にして</h3><ul><li>名詞＋にして<br>【到……的程度才能/就连……的程度都不能】，两种意思取决于后项是否为否定。强调到达一定高的程度才能或者是都不能做。<br>例：アインシュタインさんみたいなに物理学者して量子論に関する問題を解けできるね。（正向的程度：只有像爱因斯坦那样的物理学家才能把量子物理学相关的问题解开。）<br>例：この問題は、先生にして解けないはずです。（反向的程度：这道题就连老师也解不出来。）  </li></ul><h3 id="あっての"><a href="#あっての" class="headerlink" title="あっての"></a>あっての</h3><ul><li>名詞１＋あっての＋名詞２  </li><li>名詞＋あっての….<br>【只有……才能有……】，表示只有前项（名词1）存在，后项（名词2）才可能成立。<br>例：両親あっての私です。</li></ul><h3 id="極まる・極まりない・の極み"><a href="#極まる・極まりない・の極み" class="headerlink" title="極まる・極まりない・の極み"></a>極まる・極まりない・の極み</h3><ul><li>な形容詞＋極<sup>きわ</sup>まる・極まりない  </li><li>名詞＋の極み<br>【没有比这更……的了/……之极】，描述某种程度说话人认为到了极点。表示说话人主观的、激动的心情，对于好的和坏的事物都可以描述。<br>例：店員の態度が失礼きわまるな。  </li></ul><h3 id="の至り"><a href="#の至り" class="headerlink" title="の至り"></a>の至り</h3><ul><li>名詞＋の至り<br>【……之至】，描述某种程度说话人认为到了极点。只能描述好的事物。<br>常用表达：光栄の至り、感激の至り<br>例：ご客様は弊店を訪れるのことはさすが弊店の光栄の至りです。</li></ul><h3 id="くらい・ぐらい"><a href="#くらい・ぐらい" class="headerlink" title="くらい・ぐらい"></a>くらい・ぐらい</h3><ul><li>動詞普通形・名詞・な形容詞～な＋くらい・ぐらい  </li></ul><ol><li>【……点程度的小事】，表示说话人认为十分简单。是轻视的说法。<br>常用表达：これぐらい　どれぐらい<br>例：この程度ぐらいで諦めるは笑えるな。  </li><li>【十分……】，强调程度的极端。<br>例：やっと車が一台通れるぐらい狭い道だった。  </li></ol><h3 id="など・なんか・なんて"><a href="#など・なんか・なんて" class="headerlink" title="など・なんか・なんて"></a>など・なんか・なんて</h3><ul><li>名詞＋など・なんか・なんて</li></ul><ol><li>【这样……】，表示厌恶、轻视的情绪。后项用否定的表达。<br>对自己的事情进行表述时，表示自谦。<br>例：スキーなんて簡単ですよ。だれでもすぐできるようになります。  </li><li>【像……样的】，表示举例。<br>例：お見舞いならカーネーションなんてどうしたら。  </li></ol><h3 id="こそ-1"><a href="#こそ-1" class="headerlink" title="こそ"></a>こそ</h3><ul><li>名詞＋こそ<br>【正是……】，强调主体与其他事物关键性的区别。表示正是由于这样的区别才使得主体独特起来。对好的主体使用，用于称赞。<br>例：これこそ本当の日本料理です。  </li></ul><h3 id="までして"><a href="#までして" class="headerlink" title="までして"></a>までして</h3><ul><li>動詞て形・名詞＋までして<br>【连……都做】，表示举出一个说话人认为极端低下的例子，强调连这种程度的事情都要做。有轻蔑和批判的感情。<br>例：借金までしてパチンコをするなんて、どうも理解できない。  </li></ul><h2 id="极端程度（Unit-12）"><a href="#极端程度（Unit-12）" class="headerlink" title="极端程度（Unit 12）"></a>极端程度（Unit 12）</h2><h3 id="たりとも（ない）"><a href="#たりとも（ない）" class="headerlink" title="たりとも（ない）"></a>たりとも（ない）</h3><ul><li>一＋量詞＋たりとも  </li><li>名詞＋たりとも<br>【即是一点……，也（不能）……】，后项是否定的用法。强调在前项的最低程度下也不能完成。是全面否定的表达方式。<br>常用表达：何人たりとも～ない，表示是谁都不例外。<br>例：一分たりとも遅刻は許さない。  </li></ul><h3 id="といえども（ない）"><a href="#といえども（ない）" class="headerlink" title="といえども（ない）"></a>といえども（ない）</h3><ul><li><p>一＋量詞＋といえども<br>【即是……，也（不能）……】[书]，后项是否定的用法。意思和用法同たりとも（ない）。是一种相当古老的表达。  </p></li><li><p>動詞普通形・名詞＋といえども<br>见Unit 9。表示在极端场合、人物、身份的条件下也不能完成。  </p></li></ul><h3 id="として（ない）・も（ない）"><a href="#として（ない）・も（ない）" class="headerlink" title="として（ない）・も（ない）"></a>として（ない）・も（ない）</h3><ul><li>一＋量詞＋として＋動詞ない形＋ない  </li><li>一＋量詞＋も＋動詞ない形＋ない<br>【完全没有……】[书]，全部否定的用法。强调完全没有。<br>例：一日として、ゆっくり休めた日はありません。  </li></ul><h3 id="すら・ですら"><a href="#すら・ですら" class="headerlink" title="すら・ですら"></a>すら・ですら</h3><ul><li>名詞＋（で）すら<br>【甚至连……也……】[口]，举出一个极端的事例说明连这样的事物都……，其他的事物也自然不例外。<br>例：この問題は先生ですら、解けないでしょう。  </li></ul><h3 id="だに"><a href="#だに" class="headerlink" title="だに"></a>だに</h3><ul><li>動詞辞書形・ます形・三類動詞名詞・名詞＋だに<br>【就连……也不能……/完全不能……】[书]，表示形容事件的程度让说话人完全不能做（想象，思考等等）。<br>常与：思う、考えろ、聞く、想像等连用。<br>例：受験の日を想像だに、とても緊張してきます。  </li></ul><h3 id="さえ-1"><a href="#さえ-1" class="headerlink" title="さえ"></a>さえ</h3><ul><li>名詞＋（で）さえ<br>【就连……也……】，后面是否定的用法。表示说话的对象连最低的限度都不能完成。<br>例：日本人なのに、平仮名さえ書けない。  </li></ul>]]></content>
    
    
    <categories>
      
      <category>日语</category>
      
      <category>樱花教材</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9.3. K均值算法的优化</title>
    <link href="/2021/07/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.3.%20Kmeans%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/"/>
    <url>/2021/07/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.3.%20Kmeans%E7%AE%97%E6%B3%95%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="K均值算法的优化"><a href="#K均值算法的优化" class="headerlink" title="K均值算法的优化"></a>K均值算法的优化</h1><h2 id="多次随机初始化"><a href="#多次随机初始化" class="headerlink" title="多次随机初始化"></a>多次随机初始化</h2><p>初始化的状态不同，可能最后得到的结果是不一样的。<br>随机初始化聚类中心的其中一种方法为：<br>随机选择K个样本$μ_1…μ_k$作为$K$个聚类中心。<br>但是按如上的随机初始化方式可能导致最后的分类的结果不同，并且有可能使得代价函数$J$落入局部最优解而不是最小值。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210729123016.png width=50%><br>解决这个问题的方法是多次（比如50-100次）随机初始化聚类中心并运行K-Means算法，每运行一次都会得到代价函数的值 $J$，最后从这些代价函数的值中挑选最小的一个。<br>实验说明，当$K$的取值比较小（2-10）时，多次随机初始化能够有效改善出现局部最优解的情况，而$K$的取值很大时，这种方法不会起到比较好的改善。  </p><h2 id="正确选取-K-的数量"><a href="#正确选取-K-的数量" class="headerlink" title="正确选取$K$的数量"></a>正确选取$K$的数量</h2><h3 id="肘部法则"><a href="#肘部法则" class="headerlink" title="肘部法则"></a>肘部法则</h3><p>通常在数据集中有多少个类是不清楚的，因此用一个自动化的算法内选择聚类的数量是困难的。但是仍然有一些法则能够帮助设置聚类数量，其中一个法则称为肘部法则（Elbow method），具体方法如下：<br>通过不断改变K的值运行K-Means算法，计算出不同的代价函数值$J$，如图所示：<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210729125538.png width=50%><br>图示的拐点常常被用于设置聚类数据。<br>但是在实际中，往往曲线的拐点并不明确，比如如下所示，因此通过肘部法则来选取聚类数量的方法具有局限性。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210729125729.png width=50%>  </p><h3 id="根据后续目的选择-K"><a href="#根据后续目的选择-K" class="headerlink" title="根据后续目的选择$K$"></a>根据后续目的选择$K$</h3><p>很多时候运行K-Means算法是为了一些后续的目的，比如市场划分等等。如果后续的目的能够给出一个评估标准，那么决定聚类数量的最好方法是看那个聚类数量更适合这个评估标准。<br>比如要分出衣服的尺寸，可以根据衣服的尺寸：S，M，L，将K设置为3；或者根据XS,S,M,L,XL将K设置为5，如下图所示。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210729130236.png width=50%>  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>09. K均值算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9.2. K均值算法的过程与实现</title>
    <link href="/2021/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.2.%20Kmeans%E7%AE%97%E6%B3%95/"/>
    <url>/2021/07/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.2.%20Kmeans%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="K均值算法的过程与实现"><a href="#K均值算法的过程与实现" class="headerlink" title="K均值算法的过程与实现"></a>K均值算法的过程与实现</h1><p><strong>K均值算法</strong>（K-Means）是一种流行的聚类算法。  </p><h2 id="执行过程"><a href="#执行过程" class="headerlink" title="执行过程"></a>执行过程</h2><p>以如下数据集的例子来说明K均值算法的执行过程：  </p><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210629111841.png" alt=""></p><p>对于如图所示的数据集，使用K均值算法将其分成两类数据。<br>K均值算法的第一步是在数据集中随机生成两点，称为<strong>聚类中心</strong>（Cluster Centroid）。（要分为多少类，就要生成多少个聚类中心）<br>K均值算法是一个迭代算法，每一次迭代过程分为两部分：  </p><ol><li>簇分配<br>K均值算法会遍历每一个数据，计算该点与每一个聚类中心的距离，该点会被归属到最近的聚类中心。  </li><li>移动聚类中心<br>移动聚类中心到当前集群的平均位置。<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210629113257.png" alt="">  </li></ol><p>之后K均值算法会重复上述两步，直到聚类中心不再移动，此时可以认为聚类已经实现。    </p><h2 id="实现"><a href="#实现" class="headerlink" title="实现"></a>实现</h2><h3 id="算法输入"><a href="#算法输入" class="headerlink" title="算法输入"></a>算法输入</h3><ul><li>簇的数量： $K$</li><li>训练集: $\{x^{(1)},x^{(2)},…,x^{(m)} \}$<br>对每一个数据而言，$x^{(i)}$都是一个n维的向量。  </li></ul><h3 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h3><p>K均值算法首先会随机初始化聚类中心$μ_i$：<br>Repeat{   </p><div class="hljs code-wrapper"><pre><code># 计算每个聚类中心到该点的距离，并返回最近距离的聚类中心标签  for $i=1$ to $m$  $c^&#123;(i)&#125;$:=index(from 1 to $K$)  of cluster centroid closest to $x^&#123;(i)&#125;$ 或者  $c^&#123;(i)&#125;$:=$min||x^&#123;(i)&#125;-μ_k||^2$  # 移动聚类中心  for $k=1$ to $K$    $μ_k$:=arverage of points assigned to cluster $k$  </code></pre></div><p>}  </p><blockquote><p>如果此时出现所有点都不属于某一个聚类中心的情况，则可以直接移除这个聚类中心，或者重新随机初始化这个聚类中心  </p></blockquote><h2 id="代价函数"><a href="#代价函数" class="headerlink" title="代价函数"></a>代价函数</h2><p>K-Means算法的代价函数会重点跟踪如下的两个参数的变化规律：<br>$c^{(i)}$：当前每一个样本$x^{(i)}$所属的聚类中心$μ_c^{(i)}$对应的标签<br>$μ_k$: 聚类中心的位置<br>代价函数以如下形式表示：  </p><script type="math/tex; mode=display">J(c^{(1)}...c^{(m)},μ_1...μ_K)=\frac{1}{m}∑_{i=1}^{m}||x^{(i)}-μ_c^{(i)}||^2</script><p>代价函数的目标是找到使得$J(c^{(1)}…c^{(m)},μ_1…μ_K)$最小化的$c^{(1)}…c^{(m)},μ_1…μ_K$。  </p><p>重回K-Means算法的执行过程：<br>计算每个聚类中心到该点的距离，并返回最近距离的聚类中心标签的实质是保持$μ_1…μ_K$固定，而找到使得$J$最小化的$c^{(i)}$。<br>移动聚类中心的实质是保持$c^{(1)}…c^{(m)}$不变，找到使得$J$最小化的$μ_k$。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>09. K均值算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9.1. 非监督学习的概念</title>
    <link href="/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.1.%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5/"/>
    <url>/2021/07/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/9.%20K-Means%E7%AE%97%E6%B3%95/9.1.%20%E9%9D%9E%E7%9B%91%E7%9D%A3%E5%AD%A6%E4%B9%A0%E7%9A%84%E6%A6%82%E5%BF%B5/</url>
    
    <content type="html"><![CDATA[<h1 id="非监督学习的概念"><a href="#非监督学习的概念" class="headerlink" title="非监督学习的概念"></a>非监督学习的概念</h1><h2 id="非监督学习"><a href="#非监督学习" class="headerlink" title="非监督学习"></a>非监督学习</h2><ul><li><p>回顾： 监督学习<br>数据集有一系列的标签，监督学习的目的是找到空间中不同类数据标签之间的决策边界。<br>数据集的表示：$\{(x^{(i)},y^{(i)}),…\}$  </p></li><li><p>非监督学习<br>在非监督学习中，数据集没有事先预设好的标签。非监督学习的目的是先要自动根据数据的特征对数据进行分类，再找到不同类数据之间的决策边界。<br>数据集的表示：$\{(x^{(i)})..\}$  </p></li></ul><h2 id="聚类算法"><a href="#聚类算法" class="headerlink" title="聚类算法"></a>聚类算法</h2><p>根据数据分布的聚集情况自动将数据分为多类/簇，或者是多个子集的算法称为<strong>聚类算法</strong>（Clustering Algorithm）。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>09. K均值算法</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>遗传算法导论</title>
    <link href="/2021/07/18/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/"/>
    <url>/2021/07/18/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E9%81%97%E4%BC%A0%E7%AE%97%E6%B3%95%E5%AF%BC%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="遗传算法导论"><a href="#遗传算法导论" class="headerlink" title="遗传算法导论"></a>遗传算法导论</h1><blockquote><p>A genetic algorithm tutorial, Darrell Whitley, 1994</p></blockquote><h2 id="遗传算法的概念"><a href="#遗传算法的概念" class="headerlink" title="遗传算法的概念"></a>遗传算法的概念</h2><p>遗传算法是一类将特定问题潜在的解决方案编码并组织到形如染色体（chromosome）结构的数据结构（下文直接称之为染色体）上，然后应用推荐算子(recommend operators)对数据结构中的特定信息进行保留的算法。<br>遗传算法的操作对象是一组这样的染色体，称之为<strong>种群</strong>（population）。遗传算法会针对这样的种群进行评价，然后筛选：对于目标问题有更优解的染色体会被赋予更高的机会进行复制和重组，称为”繁殖”（Reproduce）。</p><h2 id="优化问题"><a href="#优化问题" class="headerlink" title="优化问题"></a>优化问题</h2><p>遗传算法遇到的问题大多可以归结为两类：编码问题和评估函数的问题。  </p><h3 id="编码（Encoding）问题"><a href="#编码（Encoding）问题" class="headerlink" title="编码（Encoding）问题"></a>编码（Encoding）问题</h3><p>对于参数的选取，通常认为参数之间应该具备线形不相关的特性，但事实上很难保证参数的这一性质，在遗传算法中，参数之间的关联称为基因关联（Epistasis）。<br>遗传算法对与参数的编码建立在一个基本的假设上：<strong>代表系统参数的变量可以用字节串（位串，Bit string）来进行表达</strong>，这也意味着这些变量能够以某种方式被离散化。离散化的范围以$2^n$表示，例如如果每个参数都用10bit来表示，那么经过离散化后，我们能至多得到1024个离散值（1024种01的组合）。对参数作离散化处理是为了在保证精度的前提下，给系统输出提供尽可能大的分辨率（Resolution）以便调整系统输出。<br>字节化编码的问题在于离散值的冗余，如果变量离散化后有1200个（介于1024和2048之间）离散值，那么需要用11个字节才能表示完全，但是如此会有2048-1200=848个无用的离散值，这些无用的离散值可能会导致没有评估，或者是出现不好的评估结果。   </p><h3 id="评估函数（Evaluation-function）问题"><a href="#评估函数（Evaluation-function）问题" class="headerlink" title="评估函数（Evaluation function）问题"></a>评估函数（Evaluation function）问题</h3><p>评估函数能够对系统的输出进行评估。构建评估函数的过程是一个模拟（仿真）系统的过程，这样的仿真相比与真实系统必然只能给出近似解或者是部分解。因此评估函数对系统输出的结果只是近似的，或是部分的评价。   </p><p>对于遗传算法来说评估函数的计算速度是一个问题：首先，对于现有种群的评估计算量就比较大。不仅如此，种群的后代也需要进行评估。   </p><h4 id="搜索空间（Search-space）"><a href="#搜索空间（Search-space）" class="headerlink" title="搜索空间（Search space）"></a>搜索空间（Search space）</h4><p>假设参数之间的关系是非线形的，如果用于表示参数的比特数为L，那么参数空间的大小是$2^L$,<strong>遗传算法在这样的一个$L$维的超空间（Hypercube）中采样</strong>。这个超空间的大小随着L指数型增长，将带来巨大的采样难度和计算量。  </p><h2 id="经典遗传算法"><a href="#经典遗传算法" class="headerlink" title="经典遗传算法"></a>经典遗传算法</h2><h3 id="算法流程"><a href="#算法流程" class="headerlink" title="算法流程"></a>算法流程</h3><p>经典遗传算法通过对当前种群的<strong>评估（Evaluation）</strong>，<strong>选择（Selection）</strong>，<strong>重组（Recombination）</strong>和<strong>突变（Mutation）</strong>  后，能够在现有种群的基础上产生下一代种群。 </p><h4 id="原始种群（Initial-population）"><a href="#原始种群（Initial-population）" class="headerlink" title="原始种群（Initial population）"></a>原始种群（Initial population）</h4><p>在遗传算法中，定义<strong>种群中编码后的一条固定长度为L的字节串称为一个个体，这样的个体称为基因型（Genotype）或者是染色体（Chromosome）</strong>。  在大多数情况下，原始种群被随机的产生出来。    </p><blockquote><p>此处的随机指在空间内随机的取出一些编码的组合（当然也受制于编码机制等）。  </p></blockquote><h4 id="评估和适应度"><a href="#评估和适应度" class="headerlink" title="评估和适应度"></a>评估和适应度</h4><p>原始种群被生成后，每一个个体会通过评估函数和适应度函数（Fitness funtion）生成其对种群的适应度（Fitness）。  </p><blockquote><p>评估函数和适应度函数两个概念一般来说是可以替换的。事实上，评估函数是通过一组参数来实现对个体表现的衡量，而适应度函数是通过增殖（Reproductive）概率来衡量个体表现的。  评估函数的衡量不依赖于种群中的其他个体，适应度函数的衡量与种群中其他个体有关。     </p></blockquote><p>种群中个体$i$的适应度定义为：  </p><script type="math/tex; mode=display">\frac{f_i}{\overline{f}}</script><p>其中，$f_i$表示评估函数对第$i$个个体的评估结果，$\overline{f}$表示种群的平均评估。  </p><h4 id="选择-轮盘赌选择"><a href="#选择-轮盘赌选择" class="headerlink" title="选择(轮盘赌选择)"></a>选择(轮盘赌选择)</h4><p>定义在<strong>现种群经过选择后保留的种群称为中间种（Imermediate population），中间种经过突变和重组后会成为下一代种群。</strong><br>在遗传算法中，<strong>选择的本质是概率性地将现种群中的个体进行复制，最终得到中间种的过程。</strong><br>具体而言，对于适应度大于1的个体，适应度的整数部分表示该个体会被复制多少次。对所有的个体，适应度的小数部分表示额外被复制的概率。  比如，适应度2.3的个体能够获得2次复制，并且有0.3的概率能获得第三次复制的机会。<br>更加形象化的表述为轮盘赌：如果整个轮盘表示整个种群，每个个体所占面积与适应度成正比，每一次转动就能随机地抽取一个个体复制，更高效的办法是轮盘外围上均匀地分布着N个均等间距的指针，每一次转动就能随机抽取N个个体进行复制。  经过若干次转动后，结果的集合构成中间种。  </p><h4 id="重组（单点交叉）"><a href="#重组（单点交叉）" class="headerlink" title="重组（单点交叉）"></a>重组（单点交叉）</h4><p><strong>遗传算法中重组的本质是杂交（Crossover）</strong>，其过程主要有两步： </p><ol><li>随机地使得个体间两两配对。  </li><li>随机地选取一对个体，两者在某个随机且相同的比特位处断开，前后的两段基因型进行交叉互换。  </li></ol><p><img src="https://img-blog.csdnimg.cn/20191202151959116.gif#pic_center" alt=""></p><p>新生成的两个个体称为后代（Offspring），后代能够插入到下一代的概率计作$p_c$。  </p><h4 id="突变"><a href="#突变" class="headerlink" title="突变"></a>突变</h4><p>重组之后利用突变算子对后代作突变处理，对于种群中的所有比特位，其突变的概率计作$p_m$，这是一个非常小的值，通常小于1%。  <strong>突变有可能随机地产生一些比特（并且有50%的可能性改变原本的比特值），也有可能反转原有的比特（一定能改变原本的比特值）。</strong><br>中间种经过重组和突变，最终能称为新的种群。</p><p><div align="center">  <img src=https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210718132905.png width=40% />  </div></p><center>▲ 经典遗传算法的选择和重组过程</center><h3 id="可行性分析"><a href="#可行性分析" class="headerlink" title="可行性分析"></a>可行性分析</h3><p>经典遗传算法的鲁棒性和复杂性建立在样本空间中有偏向性的超平面采样之上。   </p><h4 id="搜索空间和超平面"><a href="#搜索空间和超平面" class="headerlink" title="搜索空间和超平面"></a>搜索空间和超平面</h4><p>在几何学上，称n维空间的某一个小于n维的子空间为超平面（hyperplane）， 比如二维空间的超平面是一条线，三位空间的超平面是一个面。<br><strong>在位串长度固定位$L$的前提下，种群中所有可能的编码方式所构成的空间称为搜索空间（Search space）。</strong> 如果每一种特定的编码方式在L维搜索空间中对应了一个角（Corner），那么共超平面的几个角对应的编码中必定在相同的某几个比特位上的值是相同的，此时引入通配符（Don‘t care，以*记）的概念，那么搜索空间的一个超平面就可以表示为含有Don’t care（*）的位串（比如：0****，11*****），这样的位串称为模式（Schema），每一个模式对应了一个超平面。   </p><h4 id="复制：偏向性地采样"><a href="#复制：偏向性地采样" class="headerlink" title="复制：偏向性地采样"></a>复制：偏向性地采样</h4><p>对于一个$K$维的搜索空间：***…***，该空间能够被分割为1**…***和0**…***两个超平面，对这两个超平面分别计算平均适应度，采样过程总是有高概率地采集适应度更高的超平面内的样本。在下一次采样中，这个超平面再度被等距划分为多个子部分，采样会更倾向于平均适应度更高的子部分，重复若干次采样后，<strong>采样总是更倾向于采集整个搜索空间中适应度最高的部分</strong>。因此通过这样的采样能够在搜索空间中找到适应度最高的部分。换句话说，遵循这样规律的复制总是能够有高概率地选择到种群中适应度更高的个体。  </p><blockquote><p>采样过程的本质是一个在搜索空间中不断寻找局部最大值的过程。  </p></blockquote><p>其次，定义选择后某一特定超平面$H$内留存的样本的期望数目为该超平面现有的样本数目$M（H,t）$与该超平面适应度均值$f(H,t)$的乘积：</p><script type="math/tex; mode=display">E=M(H,t) \times f(H,t)</script><p>这样的采样方法会使得采样后在特定超平面的样本数与其期望大致相符合,事实上经过选择后$H$留存的样本数目$M(H,t+1)$可以被公式化为：  </p><script type="math/tex; mode=display">M(H,t+1)=M(H,t)\frac{f(H,t)}{\overline{f}}</script><p>其中$\overline{f}$表示整个种群的平均适应度，近似为1。   </p><h4 id="重组：产生新的样本的同时带来破坏"><a href="#重组：产生新的样本的同时带来破坏" class="headerlink" title="重组：产生新的样本的同时带来破坏"></a>重组：产生新的样本的同时带来破坏</h4><p>由于复制不会产生新的样本，而选择可能会减少种群中的样本数目，<strong>为了避免最终种群的个体数目过小，同时产生新的可能性</strong>，因此在每一次采样后需要用染色体重组（交叉）来产生新的样本。 不仅如此，染色体重组（交叉）还可以起到部分地保留当前的采样超平面倾向的作用，下面来讨论染色体重组对原来染色体中信息的破坏（Disruption）程度：<br>对于一组一阶染色体，其染色体中的信息必不可能受到染色体重组的影响。<br>对于二阶和二阶以上的染色体组，其破坏程度和交叉点的数目有关：<br>如果只有一点发生染色体重组，染色体组在一点交叉后发生比特变换（破坏）的概率受Schema中确定字符（该位置上的值不是通配符）的位置决定。<br>如果有两点发生染色体重组，则在互补位置发生交叉时对染色体组的破坏最大。<br>总而言之，<strong>染色体中的原本信息在重组中受到破坏的程度与模式中确定字符的位置有着密切的关系。</strong><br>不管是一点交叉还是两点交叉，可以发现Schema中相邻的既定比特位受到重组带来的破坏最小。    </p><h5 id="定义距"><a href="#定义距" class="headerlink" title="定义距"></a>定义距</h5><p>称在交叉过程中被整体保留下来的确定字符称为适应性等位基因（Coadapted alleles）。在某一个模式当中，两个确定字符之间的距离称为两个字符的联系（Linkage），第一个确定字符的位置和最后一个确定字符的位置之间（这个部分称为有义部分（Significant Portion of Schema））的距离称为模式的定义距（Defining length），以$\Delta(H)$记。</p><blockquote><p>两点及两点以上的交叉中需要将Schema组织为首尾相连的环状形式，才能得出其定义距。  </p></blockquote><p>通过之前对重组破坏的推演可以得出结论：破坏程度与定义距的长度有关：定义距的长度越长，在交叉过程中原本染色体信息被破坏的可能性就越大。不仅如此，定义距直接反映了交叉发生在有义部分的概率，对于一点交叉而言，一点交叉发生在有义部分的概率为： $\frac{\Delta(H)}{L-1}$。   </p><h5 id="倒换"><a href="#倒换" class="headerlink" title="倒换"></a>倒换</h5><p>除了交叉和变异之外，遗传算法中还会用到的对染色体的基本操作是倒换（Inversion）。 倒换是随机的将染色体中的某一段序列进行镜像翻转。倒换可以改变染色体上确定字符之间的连接，这样具有更大非线性的确定字符在染色体上的间隔距离可能会被缩小。<br> 倒换的前提是比特以一种位置无关的方式进行编码（否则倒换就等同于大规模变异）。一种可行的编码方式是染色体上的每一个基因以（位置，值）的形式表示。比如对于010010110而言，染色体为((9,0)(6,0)(2,1)(7,1)(5,1)(8,1)(3,0)(1,0)(4,0))。 对于倒换和如此表示所带来的问题，在此不做过多叙述。<br><img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210718133527.png width=40% /> </p><h2 id="模式定理"><a href="#模式定理" class="headerlink" title="模式定理"></a>模式定理</h2><h3 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h3><p>模式定理（Schema theorem）提供了进化时采样率的下界，推导过程如下：<br>由之前提出的经过选择后超平面$H$留存的样本（个体）数目$M(H,t+1)$：  </p><script type="math/tex; mode=display">M(H,t+1)=M(H,t)\frac{f(H,t)}{\overline{f}}</script><p>考虑重组对选择后超平面$H$中种群样本数目的影响：</p><ol><li>重组是有概率发生的，概率为$p_c$。  </li><li>对于发生重组的种群，交叉既有可能产生出现有空间内某个模式的副本（比如100和010交叉就可能产生000，使得000的副本增加一个），同时也有可能使得原有的样本消失。    </li></ol><p>那么现在后代中落在超平面$H$的样本数目：  </p><script type="math/tex; mode=display">M(H,t+1)=(1-p_c)M(H,t) \frac{f(H,t)}{\overline{f}} +p_c [M(H,t)\frac{f(H,t)}{\overline{f}}(1-losses)+gains]</script><p>为了简化计算，忽略gain，并且假设发生在Schema上有义部分的交叉必然导致染色体破坏，记破坏概率为$disruption$，那么有：  </p><script type="math/tex; mode=display">M(H,t+1) \geq (1-p_c)M(H,t) \frac{f(H,t)}{\overline{f}} +p_c [M(H,t)\frac{f(H,t)}{\overline{f}}(1-disruption)]</script><p>定义超平面$H$的采样率表示超平面$H$的样本数目与种群中样本数目的比，以$P(H,t)$记。<br>由之前对定义距的理解，对原信息的破坏只可能发生在定义距的区间段内。此外，如果发生重组的位串都在平面$H$内，那么重组也不可能对原本信息造成破坏，因此要想让重组破坏原有的信息，亲本中的另一条位串必定来自于其他平面。<br>由这上述两点可以将破坏概率定义为：  </p><script type="math/tex; mode=display">\frac{\Delta(H)}{L-1}(1-P(H,t))</script><p>由破坏的定义可以得出如下结论：<br><strong>定义距$Δ(H)$越小，模式受到破坏的概率就越小。</strong>从直观上来说，定义距越小，交叉发生在定义距内（即一定能破坏信息）的概率也越小。<br>那么下一代超平面$H$的采样率可以表示为：</p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t))]</script><p>如果考虑亲代是基于适应度选择出来的：  </p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})]</script><p>最后，考虑突变的影响：记突变发生的概率为$p_m$，超平面$H$的阶数为$o(H)$，那么表示超平面$H$的Schema不会受到突变影响的概率为：  </p><script type="math/tex; mode=display">(1-p_m)^{o(H)}</script><p>可以得出结论：<br><strong>模式的阶数$o(H)$越小,模式不会受到突变影响的概率越大。</strong>从直观上来看，模式的阶数代表着有效字符的个数，有效字符越少，在交叉过程中越容易被保留下来。<br>最终，超平面$H$在下一代中被采样到的概率可以表示为：  </p><script type="math/tex; mode=display">P(H,t+1) \geq P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})] (1-p_m)^{o(H)}</script><p>可以通过数学推算出，在适应度$\frac{f(H,t)}{\overline{f}}&gt;1$时：</p><script type="math/tex; mode=display">P(H,t) \frac{f(H,t)}{\overline{f}} [1-p_c \frac{\Delta(H)}{L-1}(1-P(H,t)\frac{f(H,t)}{\overline{f}})]=P(H,t) \frac{f(H,t)}{\overline{f}}(1-p_c \frac{\Delta(H)}{L-1})+[P(H,t) \frac{f(H,t)}{\overline{f}} ]^2</script><p>用$t=0$代来推算$t$代时候的采样率：  </p><script type="math/tex; mode=display">P(H,t) ≥ \{P(H,0) \frac{f(H,0)}{\overline{f}}(1-p_c \frac{\Delta(H)}{L-1})+[P(H,0) \frac{f(H,0)}{\overline{f}} ]\}^t(1-p_m)^{o(H)}</script><p>可以发现：<strong>在适应度$\frac{f(H,t)}{\overline{f}}&gt;1$时，采样率呈现指数型上升。</strong><br>可以总结为：<br><strong>在选择，重组，突变算子的作用下，当某个超平面的适应度大于1时，模式的阶数$o(H)$越小，定义距$Δ(H)$越小的个体越能够被保留下来，且数目成指数型上升。</strong><br>模式定理在数学上证明了重组和突变的有效性，并给出了采样率的下界，是遗传算法中重要的理论基础之一。  </p><h3 id="突变和收敛问题"><a href="#突变和收敛问题" class="headerlink" title="突变和收敛问题"></a>突变和收敛问题</h3><p>显然，模式定理最强调交叉和超平面采样在遗传搜索中的作用。为了在选择后最大限度地保存超平面样本，应尽量减少交叉和突变的破坏。这表明突变可能根本不应该使用，或者至少应该在非常低的水平上使用。<br>突变的积极作用是突变可以防止任何特定位点或等位基因的永久丢失（尤其是对种群中个体数目非常小的时候而言）， 同时突变也增加了种群的基因多样性。<br>随着代数的增加，选择有可能使得在某些位置上的比特全部变成相同的值，表明算法收敛。但是与此同时，个体之间适应度的差别会越来越小，选择的影响也会越来越小，最终可能导致提前收敛。可以通过对适应度的缩放来改善这一问题。     </p><blockquote><p>关于算法的收敛：遗传算法的收敛性一直是一个问题，简单而言，当选择的代数达到一定程度后，选择压力减弱，导致种群中适应度优秀的个体数始终处于一个水平上而不发生变化，此时称遗传算法达到收敛。和深度学习不同的是，如果在收敛后继续学习，那么优秀个体的数目在理论上并不会下降。  </p></blockquote><h3 id="重组的采样方式·均匀交叉"><a href="#重组的采样方式·均匀交叉" class="headerlink" title="重组的采样方式·均匀交叉"></a>重组的采样方式·均匀交叉</h3><h4 id="交叉点数目问题"><a href="#交叉点数目问题" class="headerlink" title="交叉点数目问题"></a>交叉点数目问题</h4><p>在某个范围内，交叉点的数目多一些，破坏的影响随之减弱。但是过多的交叉点数目会导致出现非常大的破坏。    </p><h4 id="均匀交叉（Uniform-crossover）"><a href="#均匀交叉（Uniform-crossover）" class="headerlink" title="均匀交叉（Uniform crossover）"></a>均匀交叉（Uniform crossover）</h4><p>均匀交叉的流程是首先随机对种群中的染色体进行两两配对，和单点交叉不同的是，均匀交叉随机地选择亲代染色体中的某些位置，然后对换亲代染色体上这一位置上的比特值。 与单点交叉相比，均匀交叉的破坏概率不受定义距的影响，均匀交叉的破坏概率为：  </p><script type="math/tex; mode=display">1-（\frac{1}{2}）^{o(H)-1}</script><p>虽然相比于单点交叉均匀交叉的破坏概率更大，但是对于个体数目小的种群，更大的破坏概率能解除信息量小的限制。<br>同时，在采样方式上，相比与单点交叉，理论上均匀交叉能够采集到更多的样本，具体的可由Fig 4 说明。 如果把两个位串中同一位置上的比特值不相同的位置数称为海明距离（Hamming distance），记作$\mathcal{H}$，那么理论上均匀交叉可以产生$2^\mathcal{H}-2$种不同的位串，而单点交叉只能产生$2(\mathcal {H}-1)$种不同的位串。<br><img src="https://img-blog.csdnimg.cn/2019120215430277.gif#pic_center" alt="">  </p><h3 id="简化取代表示"><a href="#简化取代表示" class="headerlink" title="简化取代表示"></a>简化取代表示</h3><p>对于两个位串，将同一位置上比特值相同的地方用“-”表示，不同部分保留的表示方法称为简化取代表示（Reduced surrogates）法。 例如，对于0001111011010011和0001001010010，就可以表示为——11—-1——-1和——00—-0——-0，如图所示。<br><img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210718134138.png width=40% /><br>这样的表示法好处是可以方便的理解这两个位串的重组其实是发生在一个4维空间中的，由于均匀交叉的距离无关性，可以发现对亲代的破坏就发生在这些点上，因此可以将均匀交叉简化为在这种表示方法下的一点交叉。  其次，如果至少一个交叉点存在于这种表示方法的第一个确定字符和最后一个确定字符之间，那么能够保证交叉结果绝对不同于亲代，这意味着能够在这个空间内采到新的样本。   </p><h3 id="种群大小"><a href="#种群大小" class="headerlink" title="种群大小"></a>种群大小</h3><p>低阶的超平面拥有比较高的采样率。一个采样空间可被划分为$2^iC_L^i$个$i$阶的超平面。超平面的数量与研究种群大小$N$和遗传算法能够采样到的超平面数有关。通常认为超平面的数量与一开始的随机种群中的个体数量是一个指数关系：在$N$大小的种群里，$i$阶的超平面大约会被采集到$(\frac{1}{2})^i N$个样本。  </p><h4 id="N-3-理论"><a href="#N-3-理论" class="headerlink" title="$N^3$理论"></a>$N^3$理论</h4><p>$N^3$理论认为，当种群大小为$N$时，遗传算法处理的有效超平面个数为$N^3$。  记$\theta$为至少复制$\phi$次后种群中超平面的最高阶数，$\theta=log_2(\frac{N}{\phi})$，那么有采样空间中$\theta$阶的超平面总数一定大于等于遗传算法处理的超平面个数：  </p><script type="math/tex; mode=display">2^\theta C_L^\theta \geq N^3</script><p>长度为$L$的模式总数为$3^L$。根据上述理论，如果选用$N=3^L$，那么至多有$N$个超平面可以被遗传算法处理。  因此种群大小要根据$L$进行选择。  </p><h3 id="模式理论的局限性"><a href="#模式理论的局限性" class="headerlink" title="模式理论的局限性"></a>模式理论的局限性</h3><ol><li>忽略了gains和低估了losses的影响。  </li><li>当搜索逐渐聚拢在一些特定的超平面的子空间内时，观察到的超平面$H$的适应度会有巨大变化。因此取平均适应度为分母的方法仅在前几代可行。  </li><li>字符串采样的偏差使得用模式理论计算并预测结果并不可行。  </li></ol><p>总而言之，模式定理没有为遗传算法的行动轨迹提供确切的描述，也无法预测特定超平面是如何随着时间的推移而处理的。</p><h2 id="具体的标准遗传算法模型"><a href="#具体的标准遗传算法模型" class="headerlink" title="具体的标准遗传算法模型"></a>具体的标准遗传算法模型</h2><p>下述内容中提出了一种利用标准遗传算法思路的算法模型，这种算法模型解决模式理论的局限性，并对模式理论进行一些定量计算。<br>还原模式定理推导的第一步：  </p><script type="math/tex; mode=display">M(H,t+1)=(1-p_c)M(H,t) \frac{f(H,t)}{\overline{f}} +p_c [M(H,t)\frac{f(H,t)}{\overline{f}}(1-losses)+gains]</script><p>现在从个体的视角来看，设某一个位串$Z$在下一代中被留下的概率为$P(Z,t+1)$，上述式子可以改写成：  </p><script type="math/tex; mode=display">P(Z,t+1)=P(Z,t)\frac{f(Z,t)}{\overline{f}}(1-\{p_c losses\})+\{p_c gains\}</script><p>如果将这个式子应用于搜索空间中的每一个个体，那么就能够将遗传算法进行定性的计算。  </p><h3 id="损失和增益"><a href="#损失和增益" class="headerlink" title="损失和增益"></a>损失和增益</h3><p>在交叉的过程中，损失来源于两个亲本在交叉后子代为现有种群中没有的新位串，（此时认为由于交叉后亲本没有被保留，因此原有的亲本信息受到了损失），而增益来源于两个亲本在交叉后产生的子代与现有种群中的另一亲本相同（相当于现有种群中的某一个位串被复制了一次）。<br>对于某一个个体而言，损失和增益都是可以被计算的，下述一例：<br>令$Z=000$，其损失可以按照如下方式计算：  </p><script type="math/tex; mode=display">losses=P_{I0}\frac{f(111,t)}{\overline{f}}P(111,t)+P_{I0}\frac{f(101,t)}{\overline{f}}P(101,t)+P_{I1}\frac{f(110,t)}{\overline{f}}P(110,t)+P_{I2}\frac{f(011,t)}{\overline{f}}P(011,t)</script><p>$P_{I0}$:表示在与000进行交叉时，任何一位中出现交叉的概率，$P_{I0}=1$<br>$P_{Ii}$:第$i$位与第$i+1$位之间发生交叉的概率。  </p><p>增益也可以用同样的方式进行计算。  </p><p>这种计算方式可以由采样空间$S$中的每一个位串$S_i$与目标位串$Z$做异或运算求得。  </p><blockquote><p>$S_i$表示$S$中的位串按照特定顺序进行排列后的第$i$个位串，未作特殊说明时，这个排列顺序为从0依次+1。即：$S_0=0_{2(二进制)}$，$S_i=i_2$。</p></blockquote><h3 id="标准形式下单点交叉的损失"><a href="#标准形式下单点交叉的损失" class="headerlink" title="标准形式下单点交叉的损失"></a>标准形式下单点交叉的损失</h3><p>形如：0000000000与0010000100，如果两个位串$B$,$B’$满足如下条件：  </p><script type="math/tex; mode=display">B:相同-b-相同-b-相同</script><script type="math/tex; mode=display">B':相同-b'-相同-b'-相同</script><p>相同：$B$和$B’$在这些位置上的比特是相同的。  </p><p>如果$Z$与$S_i$满足这样的关系，那么在第二个相同部分发生的交叉必然会导致亲本信息的损失。因此$Z$与某个特定的$S_i$进行单点交叉发生损失概率可以写作：</p><script type="math/tex; mode=display">\frac{δ(S_i)}{L-1}</script><p>$δ(S_i)$:表示$Z$与$S_i$的最大连续相同部分的比特数。  </p><p>$Z$在搜索空间$S$中由单点交叉产生的损失（总概率）可以描述为：  </p><script type="math/tex; mode=display">losses=∑\frac{δ(S_i)}{L-1}\frac{f(S_i,t)}{\overline{f}}P(S_i,t)</script><h3 id="单点交叉的增益"><a href="#单点交叉的增益" class="headerlink" title="单点交叉的增益"></a>单点交叉的增益</h3><p>要想让两个位串通过交叉产生位串$Z$，那么以位串中的某一个位置为断点，其中一个位串在这个断点之前的部分与$Z$完全相同，另一个位串在这个断点之后的部分与$Z$完全相同。   </p><p>具体而言：如果两个位串$S_{α+x}$和$S_{ω+y}$，其中$S_{α+x}$在第$α-1$位置之前与$Z$连续相同，$S_{ω+y}$在第$L-ω$位置之后与$Z$连续相同，记$ρ(S_{α+x},S_{ω+y})$表示$S_{α+x}$和$S_{ω+y}$重叠部分的长度，那么两个位串在重叠部分发生交叉则必然会生成$Z$，因此这两个位串交叉产生$Z$的概率为：  </p><script type="math/tex; mode=display">\frac{ρ(S_{α+x},S_{ω+y})}{L-1}</script><p>所以$Z$在$S$中由单点交叉产生的增益（总概率）可以描述为：  </p><script type="math/tex; mode=display">gain=∑\frac{ρ(S_{α+x},S_{ω+y})}{L-1}\frac{f(S_{α+x},t)}{\overline{f}}P(S_{α+x},t)\frac{f(S_{ω+y},t)}{\overline{f}}P(S_{ω+y},t)</script><h3 id="概率矩阵"><a href="#概率矩阵" class="headerlink" title="概率矩阵"></a>概率矩阵</h3><p>Vose和Liepins将$S$中两个位串$S_i$与$S_j$生成$S_0$的概率进行了矩阵化，下面是其矩阵化的步骤：<br>设$s^t$为一个向量，这个向量表示第$t$代$S$空间中每一个位串被选择的概率，$s_i^t$表示第$t$代中位串$S_i$被选择的概率，通常认为这个概率与适应度和前一次选择的概率之积成正比：  </p><script type="math/tex; mode=display">s_i^t = kP(S_i,t)f(S_i),k>0</script><p>那么$S_k$被选择出来的概率的期望值可以用如下公式来表示：  </p><script type="math/tex; mode=display">E(p_k^{t+1})=∑s^t_is_j^tr_{i,j}(k)</script><p>$r_{i,j}(k)$:$S_i$与$S_j$交叉产生$S_k$的概率。<br>$r_{i,j}(0)$可以用概率矩阵$M$表示，其中行表示$S_i$，列表示$S_j$，$m_{i,j}=r_{i,j}(0)$，即$S_i$与$S_j$产生$S_0$的概率。  </p><h4 id="M-的特性"><a href="#M-的特性" class="headerlink" title="$M$的特性"></a>$M$的特性</h4><ol><li>$M$的第0行和第0列表示的概率都是损失发生的概率</li><li>$M$除了$m_{0,0}=1$在对角线上的其它值都为0  </li><li>$M$是一个对称矩阵</li></ol><h4 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h4><p>$s^{t+1}$可以用$M$进行表示： </p><script type="math/tex; mode=display">E(s^{t+1})=s^TMs</script><p>将$M$的上三角部分全部归零，得到矩阵$M’$，通过之前的分析，$M’$的第一列表示$s_0$的损失，而$s_i=P(S_i,t)\frac{f(S_i,t)}{\overline{f}}$，有：  </p><script type="math/tex; mode=display">S^TM'(:,1)s_0=P(S_0,t)\frac{f(S_0,t)}{\overline{f}}(1-losses)</script><p>记向量$\sigma$有：  </p><script type="math/tex; mode=display">σ_j<s_0,...s_{2^L-1}^T>=<s_{j⊕0},...s_{j⊕2^L-1}^T></script><p>记$\mathcal{M}(s)$：  </p><script type="math/tex; mode=display">\mathcal{M}(s)=<(σ_0s)^TMσ_0s,...,(σ_{V-1}s)^TMσ_{V-1}s>^T</script><p>矩阵$F$为对角线是$f(i)$的对角矩阵，有：  </p><script type="math/tex; mode=display">s^{t+1}=kFM(s^t),k>0</script><h2 id="其他进化模型"><a href="#其他进化模型" class="headerlink" title="其他进化模型"></a>其他进化模型</h2><p>除了标准进化模型之外，还有一些其他的进化模型。大致可分为进化策略(Evolutionary Strategies,ES)和进化编程(Evolutionary Programming,EP)两种。<br>进化编程中每一个个体是一个有限状态机（Finit-state machine），在此不做过多叙述。<br>进化策略中细分为两种类型：$(μ+λ)-ES$和$(μ,λ)-ES$。<br>在$(μ+λ)-ES$机制中，亲代$μ$产生后代$λ$后，种群还会对亲代和后代共同进行选择，选择其中表现出色的个体生成下一代。在这种选择机制下，亲代会被保留直到被比亲代表现更出色的个体替代。<br>在$(μ,λ)-ES$机制中，后代被产生后就直接替代亲代，选择在后代中执行。这种进化机制在选择阶段与经典遗传算法近似。但是在重组阶段所采用的算子与经典遗传算法不同。<br>$(μ+λ)-ES$机制相比于$(μ,λ)-ES$机制，其被优化的后代数目一定是单调增加的。  </p><h3 id="Genitor-算法"><a href="#Genitor-算法" class="headerlink" title="Genitor 算法"></a>Genitor 算法</h3><p>Genitor算法是一种使用$(μ+λ)-ES$机制的算法，其与经典遗传算法中的进化模型不同点有三处。  </p><ol><li>选择在亲代中执行，选择后的亲代产生的后代被立即投放到下一代种群中。  </li><li>后代不会替代亲代，但是每一代中适应度最差的个体被直接移除以加强选择压力。  </li><li>适应度函数通过排名算法（Ranking）而非比值来表现。排名也同样能够保持选择压力的有效性。  <blockquote><p>排名算法：<br>设三个个体的适应度评估为：$h_1,h_2,h_3$.<br>首先对所有个体按照适应度从小到大排序，比如：$h_2,h_1,h_3$;<br>按照上面的顺序重新赋予fitness，即$f(h_2)=1,f(h_1)=2,f(h_3)=3$<br>计算选择概率:$p(h_2)=\frac{1}{1+2+3}=\frac{1}{6},p(h_1)=\frac{2}{6},p(h_3)=\frac{3}{6}$  </p></blockquote></li></ol><h3 id="CHC-算法"><a href="#CHC-算法" class="headerlink" title="CHC 算法"></a>CHC 算法</h3><p>CHC算法是另一种能够单调选择位串的算法，CHC指Cross-generational elitist selection, Heterogenous recombination, Cataclysmic mutation。<br>Genitor算法是一种使用$(μ+λ)-ES$机制的算法，具体的执行过程为：<br>在重组之后，亲代和子代中最好的$N$个个体生成中间种群，由于这样的选择已经能够制造足够的压力，因此CHC直接采用随机选择的方式从这个中间种群中进行挑选。同时，选择后的中间种中，海明距离远的两个个体才被允许进行繁殖。<br>在突变阶段，除了选择出来的优秀个体外，其余所有的个体都要经历相当大的突变，再进行交叉。   </p><h3 id="Hybrid-算法"><a href="#Hybrid-算法" class="headerlink" title="Hybrid 算法"></a>Hybrid 算法</h3><p>Hybrid算法在个体编码时直接用实数进行编码，而非二进制数。其次，每个个体都在进行局部爬山算法（Local hill-climbing）来改善自身，产生后代之后，后代做爬山算法。<br>Hybrid算法通过这种多点局部搜索的方式使得搜索变得高效，局部爬山算法能够帮助改善染色体，但是不会对后代有太大的变化。基于上述特性，Hybrid算法在优化问题中的表现比较出色。  </p><blockquote><p>局部爬山算法：从当前的节点开始，和周围的邻居节点的值进行比较。 如果当前节点是最大的，那么返回当前节点，作为最大值 ( 既山峰最高点 ) ；反之就用最高的邻居节点来，替换当前节点，从而实现向山峰的高处攀爬的目的。如此循环直到达到最高点。</p></blockquote><h2 id="并行遗传算法"><a href="#并行遗传算法" class="headerlink" title="并行遗传算法"></a>并行遗传算法</h2><p>使用锦标赛算法（Tournaments）对现有种群进行选择就可以实现经典遗传算法的并行化。</p><blockquote><p>锦标赛算法：  </p><ol><li>确定每次选择的个体数量N。（二元锦标赛选择即选择2个个体）</li><li>从种群中随机选择N个个体(每个个体被选择的概率相同) ，根据每个个体的适应度值，选择其中适应度值最好的个体进入下一代种群。</li><li>重复步骤(2)多次（重复次数为种群的大小），直到新的种群规模达到原来的种群规模。<br>锦标赛算法相当于是有噪声的排序算法。  </li></ol></blockquote><p>具体的实现方法有两种模型：岛模型（island，图左）和细胞模型（cellular，图右）。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210718134422.png width=50%>  </p><h3 id="岛模型"><a href="#岛模型" class="headerlink" title="岛模型"></a>岛模型</h3><p>岛模型将一个大种群均分为多个小种群，称为亚种（Sub-population），每个小种群中进行选择，并且每隔几代就将小种群中的一部分个体与另外的小种群中的个体进行交换，这个过程称为迁徙（migration）。<br>迁徙的目的是为了让小种群之间能够部分地交换基因信息。通过迁徙，岛模型更能挖掘每一个亚种内部的信息差异。  </p><h3 id="细胞模型"><a href="#细胞模型" class="headerlink" title="细胞模型"></a>细胞模型</h3><p>细胞模型将若干个简单处理元（processor）放在网格中，每一个处理单元处理一个位串，并且选择其相邻的单元中最优的位串，或者以一定概率选择相邻的某个位串与其进行配对，并且产生新的位串。  两个距离远的位串是无法进行配对的，这样的设定模拟了生物学上的地理隔离。  在几代之后，网格中会出现许多适应度接近的团块，随着进化的推进和选择的压力，这些团块的规模会随着适应度变大或者变小。</p>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>卷积神经网络简介</title>
    <link href="/2021/07/15/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/"/>
    <url>/2021/07/15/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="卷积神经网络简介"><a href="#卷积神经网络简介" class="headerlink" title="卷积神经网络简介"></a>卷积神经网络简介</h1><blockquote><p>针对用于图像识别的卷积神经网络而言  </p></blockquote><h2 id="卷积神经网络的识别"><a href="#卷积神经网络的识别" class="headerlink" title="卷积神经网络的识别"></a>卷积神经网络的识别</h2><p>卷积神经网络的结构分为输入层，隐含层和输出层。其中隐含层包括了卷积层（矩阵通过卷积层后还需要经过激活函数处理），池化层和全连接层。图像依次通过这三个层，然后通过softmax函数输出最终的概率。  </p><h3 id="输入层"><a href="#输入层" class="headerlink" title="输入层"></a>输入层</h3><p>彩色图像在输入层被分离为RGB三通道的三个大矩阵。  </p><h3 id="隐含层"><a href="#隐含层" class="headerlink" title="隐含层"></a>隐含层</h3><h4 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h4><p>卷积的实质是图滤波，通过卷积核参数的设定为图像的像素赋予权重，达到增强并削弱图像中特定像素点的效果。卷积层的作用是通过预设好的卷积核对三通道矩阵进行照射，起到提取图像特征的作用。  </p><h5 id="卷积层的参数"><a href="#卷积层的参数" class="headerlink" title="卷积层的参数"></a>卷积层的参数</h5><p>卷积层的参数为：卷积核大小，步长，填充，三者称为卷积层的超参数，共同决定卷积层输出图像的尺寸。  </p><ul><li><p>卷积核大小<br>卷积核的大小通常是奇数，主要原因是根据卷积公式，最终得到的图像长宽均与卷积核的基数倍有关，如果设置卷积核大小为偶数维度则最终得到的图像长宽可能不是一个整数。此外还有便于强调中心，奇数卷积核对边沿、对线条更加敏感，可以更有效的提取边沿信息等优点。  </p></li><li><p>步长（Step）<br>指一次照射结束后，卷积核移动的像素单位数，通常以$\alpha$表示。  步长过大可能导致图像的某些位置未被处理，步长过小则被重叠滤波的像素面积增多。  </p></li><li><p>填充(Padding)<br>由于卷积过程是一个降维过程（直观来看图像会被缩小），有时为了保证卷积输出的图像不被降维，需要在图像外围添加像素值为0的像素点，填充反映了像素点添加的多少。 填充的方式有非常多种。  </p></li></ul><h4 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h4><p>激活函数为卷积神经网络建立了非线形的建模能力，使得神经网络能够表达非线性映射关系，能够非线形分类。 图像通过卷积层后，需要通过激活函数对这一层的结果进行非线性化，使得模型具有复杂的建模能力。   </p><h5 id="常见的激活函数"><a href="#常见的激活函数" class="headerlink" title="常见的激活函数"></a>常见的激活函数</h5><ul><li><p>Sigmoid 函数</p><script type="math/tex; mode=display">f(x)=\frac{1}{1+e^{-x}}</script><p>Sigmoid函数是最简单的非线形二分类函数，能够把连续实数进行放缩，使得函数输出值在0-1的范围内。  缺点是当输入非常大或者非常小的时候梯度容易消失。  </p></li><li><p>ReLU 函数</p><script type="math/tex; mode=display">f(x)=max(0,x)</script><p>输入信号<0时，输出都是0，输入>0 的情况下，输出等于输入。 好处是过滤了负值像素的同时提供了一种极其简便的计算方式，使得计算量小，收敛速度比较快。 缺点是一个非常大的梯度通过一个 ReLU 神经元，更新过参数之后，这个神经元再也不会对任何数据有激活现象了，这个神经元的梯度永远都是0。 尤其是学习率设置的比较大的时候，可能大部分神经元都会出现这类问题。  </p></li></ul><h4 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h4><p>池化层的作用是通过对卷积图的降维过程进一步加强提取到的特征，具体的实现方式是通过预设的卷积核照射卷积图，得到能够表征整个照射区域的数值（比如最大值，均值，中值），这些数值组成新的矩阵。  常见的池化方法是最大值池化（用照射区域的最大值表征整个照射区域）和均值池化（用照射区域的均值表征整个照射区域）。   </p><h3 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h3><p>全连接层的作用是把隐含层的输出结果向量化以减小分类函数的计算量，具体而言全连接层的作用就是首先按顺序把最后一个隐含层的所有神经元输出的特征图按顺序展开并拼接为一个特征向量。 这个特征向量会被投入到激活函数当中，最终输出为一个位置表示tag，值表示评分的标签向量。  最终这个标签向量被投入到softmax函数中，求出目标属于每一类的概率，并返回最大的概率值和类别。  </p><h4 id="softmax-函数"><a href="#softmax-函数" class="headerlink" title="softmax 函数"></a>softmax 函数</h4><script type="math/tex; mode=display">p(y|x)=\frac{e^{X_i}}{\sum_{i=1} e^{X_i}}</script><p>通过softmax函数的归一化作用，将输出映射成为(0,1)的值，而这些值的累和为1，满足概率的性质。最后选取输出时，选取概率最大的结果，输出为预测目标。softmax函数使用指数作为表达的原因是一是归一化操作满足概率性质，二是可以将负值输出正值化。    </p><h2 id="神经网络的训练"><a href="#神经网络的训练" class="headerlink" title="神经网络的训练"></a>神经网络的训练</h2><h3 id="前向传播"><a href="#前向传播" class="headerlink" title="前向传播"></a>前向传播</h3><p>对于一组数据和其标签$(x,y)$，去掉标签后投入到神经网络中，得到每一个神经单元的输出和最终的预测结果$(x,a)$的过程叫做前向传播。   </p><h3 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h3><p>执行反向传播的目的是为了求出每一个神经单元的误差$\delta=y-a$进而求出$\frac{\partial J}{\partial \Theta}$ 的值，以此来带入到梯度下降算法当中求得梯度并更新参数。  </p><h4 id="从池化层的误差推导卷积层的误差"><a href="#从池化层的误差推导卷积层的误差" class="headerlink" title="从池化层的误差推导卷积层的误差"></a>从池化层的误差推导卷积层的误差</h4><p>以最大值池化为例，对于池化前特征图中每一个被池化卷积核照射到的区域，由于只有最大值所处的位置才会有误差，其余区域由于最大池化过滤而不会对误差有任何影响，因此原特征图被照射区域中只有最大值对应的位置（需要在前向传播时记录下来）有误差$\delta$，其余位置的误差为0.<br>对均值池化，原特征图被照射区域的所有位置上对误差均等的贡献造成了整体误差$\delta$，因此每个位置上的误差都是$\frac{\delta}{N}$.<br>通用的解决办法为：<br>当第$l$层为卷积层，第$l+1$层为池化层时，第$l$层某一个像素（神经元）的误差为第$l+1$层与其相关的所有像素（神经元）的误差与权重的乘积之和。由于激活函数的影响，当前层激活之前的特征图矩阵$X$每一个位置通过激活函数的导数处理，再将处理后的矩阵与第$l+1$层的神经元误差矩阵对应位置相乘。此处神经元误差矩阵需要做上采样处理以统一维度进行运算，该过程表示为：  </p><script type="math/tex; mode=display">\delta_j^l=w_j^{l+1}(f’(x_j^l) \odot up(\delta_j^{l+1}))</script><p>$w_j^{l+1}$:$l+1$层第$j$神经元的权重，$up$：上采样，$\odot$：对应位置相乘。<br>记激活函数$f(x)=z$,矩阵化后有第$l$层的误差向量$\delta^l$：  </p><script type="math/tex; mode=display">\delta^l=w_j^{l+1}（ z’^{l} \odot up(\delta^{l+1}))</script><h4 id="卷积层的反向传播"><a href="#卷积层的反向传播" class="headerlink" title="卷积层的反向传播"></a>卷积层的反向传播</h4><p>从卷积层推导池化层，$l$层的误差$δ^{l-1}$，等于卷积后结果的$δ^{l}$误差经过零填充后，与卷积核旋转180度后的卷积。如图所示：<br><img src="https://grzegorzgwardys.files.wordpress.com/2016/01/screenshot-from-2016-04-17-212043.png" alt=""></p><script type="math/tex; mode=display">\delta^{l-1} =  (\frac{\partial z^{l}}{\partial z^{l-1}})^T\delta^{l} = \delta^{l}*rot180(W^{l}) \odot  \sigma^{'}(z^{l-1})</script><p>已知$δ^{l-1}$，求损失函数$C$对该层参数的导数$\frac{∂C}{∂w^l}$:  </p><script type="math/tex; mode=display">\frac{∂C}{∂w^l}=δ^l*σ(z^{l-1})</script><h3 id="卷积神经网络的训练过程"><a href="#卷积神经网络的训练过程" class="headerlink" title="卷积神经网络的训练过程"></a>卷积神经网络的训练过程</h3><ol><li>对神经网络进行初始化，定义好网络结构，设定好激活函数，对卷积层的卷积核$W$、偏置$b$进行随机初试化，对全连接层的权重矩阵$W$和偏置$b$进行随机初始化。<br>设置好训练的最大迭代次数，每个训练batch的大小，学习率$η$。  </li><li>从训练数据中取出一个batch的数据</li><li>从该batch数据中取出一个数据，包括输入$x$以及对应的正确标签$y$</li><li>将$x$放入CNN的输入端利用前向传播得到$z^l$，$a^l$</li><li>结合$z^l$，$a^l$和$y$，算出神经网络的损失函数</li><li>计算损失函数对输出层的误差$δ^L$</li><li>利用反向传播，计算前一层的误差$δ^l-1$：<ul><li>全连接层：$δ^l=(W^{l+1})^Tδ^{l+1}⊙ \sigma^{‘}(z^{l})$</li><li>卷积层：$\delta^{l-1} =  (\frac{\partial z^{l}}{\partial z^{l-1}})^T\delta^{l} = \delta^{l}*rot180(W^{l}) \odot  \sigma^{‘}(z^{l-1})$  </li><li>池化层：$\delta^l=w_j^{l+1}（ z’^{l} \odot up(\delta^{l+1}))$  </li></ul></li><li>利用误差求出损失函数对该层参数的导数：  <ul><li>全连接层：$\frac{∂C}{∂W^l}=δ^l(a^{l-1})^T$  </li><li>卷积层：$\frac{∂C}{∂w^l}=δ^l*σ(z^{l-1})$</li></ul></li><li>将求得的导数加到该batch数据求得的导数之和上(初始化为0)，跳转到步骤3，直到该batch数据都训练完毕</li><li>利用一个batch数据求得的导数之和，根据梯度下降法对参数进行更新</li><li>跳转到步骤2，直到达到指定的迭代次数</li></ol>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>天线知识点总结</title>
    <link href="/2021/07/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/%E5%A4%A9%E7%BA%BF%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/"/>
    <url>/2021/07/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/%E5%A4%A9%E7%BA%BF%E7%9F%A5%E8%AF%86%E7%82%B9%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="知识点总结"><a href="#知识点总结" class="headerlink" title="知识点总结"></a>知识点总结</h1><blockquote><p>author: Kigha Oreki/ Hikari Kobayashi </p></blockquote><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210621190843.png&quot;" alt=""></p><h2 id="基本理论"><a href="#基本理论" class="headerlink" title="基本理论*"></a>基本理论*</h2><h3 id="传输线模型"><a href="#传输线模型" class="headerlink" title="传输线模型"></a>传输线模型</h3><p>传输线模型中的幅值电压反射系数$Γ$：</p><script type="math/tex; mode=display">Γ=\frac{Z_L-Z_0}{Z_L+Z_0}</script><p>其中$Z_L$为天线负载的阻抗，$Z_0$为传输线上的阻抗。<br>驻波比：  </p><script type="math/tex; mode=display">SWR=\frac{V_{max}}{V_{min}}</script><h3 id="麦克斯韦方程组·平面波理论"><a href="#麦克斯韦方程组·平面波理论" class="headerlink" title="麦克斯韦方程组·平面波理论"></a>麦克斯韦方程组·平面波理论</h3><p>真空中的特征阻抗：$η_0=√\frac{μ_0}{ϵ_0}=120π$<br>波数：$k=\frac{2π}{λ}=ω√{μ_0ϵ_0}$<br>E和H的关系:$H=\frac{1}{2η}|E|$  </p><h2 id="天线基础知识"><a href="#天线基础知识" class="headerlink" title="天线基础知识"></a>天线基础知识</h2><h3 id="天线的方向图"><a href="#天线的方向图" class="headerlink" title="天线的方向图"></a>天线的方向图</h3><p>HPBW(Half-Power Beamwidth)： $U(2θ_{HPBW})=0.5U$<br>FNBW(First-Null Beamwidth): $U(2θ_{FNBW})=0$</p><h3 id="天线的远场区"><a href="#天线的远场区" class="headerlink" title="天线的远场区"></a>天线的远场区</h3><script type="math/tex; mode=display">\frac{2D^2}{λ}</script><h3 id="天线的能量"><a href="#天线的能量" class="headerlink" title="天线的能量"></a>天线的能量</h3><ul><li>平均能量密度<script type="math/tex; mode=display">W_(av)=\frac{1}{2}Re[E×H^*]=\frac{1}{2η}|E|^2</script></li><li>平均辐射强度<script type="math/tex; mode=display">U=r^2W_{av}</script></li><li>平均能量<script type="math/tex; mode=display">P_{rad}=∯W_{rad}ds=∯UdΩ=∫_0^{2π}∫_0^{π}W_{rad}r^2sinθdθdφ</script></li></ul><blockquote><p>注意积分的上下限，题目没有给出的情况下： $θ:0-π,φ:0-2π$</p></blockquote><ul><li><p>方向性</p><script type="math/tex; mode=display">D=\frac{U}{U_0}=\frac{4πU}{P_{rad}}</script></li><li><p>有效面积</p><script type="math/tex; mode=display">A_{em}=\frac{λ^2}{4π}D_{max}</script></li></ul><ul><li><p>辐射阻抗</p><script type="math/tex; mode=display">P_{rad}=\frac{1}{2}I^2R_r</script></li><li><p>输入阻抗</p><script type="math/tex; mode=display">\frac{1}{2}I_{in}^2R_{in}=\frac{1}{2}I^2R_r+P_{waste}</script><p>当$P_{waste}=0$时，对偶极子天线有$I_{in}=I_0sin(\frac{kl}{2})$。<br>$R_{in}=\frac{R}{sin^2(\frac{kl}{2})}$。  当偶极子天线长度$l=\frac{λ}{2}$时，输入转发射的效率最高。  &lt;/li&gt;<br>&lt;/ul&gt;</p></li></ul><h3 id="天线的效率"><a href="#天线的效率" class="headerlink" title="天线的效率"></a>天线的效率</h3><script type="math/tex; mode=display">e=e_re_{cd}</script><p>$e_r$：由传输线模型反射（reflection）所造成的损失产生的效率：$e_r=1-|Γ|^2=\frac{P_{avg}}{P_{input}}$<br>天线的增益：</p><script type="math/tex; mode=display">G=e_{cd}D</script><p>考虑传输线模型中的反射：  </p><script type="math/tex; mode=display">G_{realize}=e_re_{cd}D=(1-|Γ|^2)G</script><h3 id="天线的极化"><a href="#天线的极化" class="headerlink" title="天线的极化"></a>天线的极化</h3><p>单个天线的极化方式：a) 线极化 b) 圆极化 c) 椭圆极化<br>极化适配：如果波的极化方向$\hat{ρ_w}$和天线的极化方向$\hat{ρ_a}$不相同，波的接收会有损失，定义<strong>极化损失因子</strong>（PLF）或<strong>极化效率</strong>：</p><script type="math/tex; mode=display">PLF=|cosφ_p|^2</script><p>$φ_p$为$\hat{ρ_w}$与$\hat{ρ_a}$的夹角，如图所示：<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210621194643.png"  style="zoom: 33%;" /><br>当两天线正交时，理论上接收不到任何电磁波。当两天线重合时，极化效率最高。  </p><blockquote><p>天线的互易性*：同一个天线在作为发射或接收天线时所有性质不变。  </p></blockquote><h2 id="偶极子天线"><a href="#偶极子天线" class="headerlink" title="偶极子天线"></a>偶极子天线</h2><h3 id="辅助位函数"><a href="#辅助位函数" class="headerlink" title="辅助位函数"></a>辅助位函数</h3><script type="math/tex; mode=display">A=\frac{μ_0Il}{4πr}e^{-jkr}\hat{e_z}</script><p>由$A=\hat{e_r}A_r+\hat{e_θ}A_θ+\hat{e_φ}A_φ$，有：<br>$\begin{cases}<br>    A_r=A_zcosθ \\<br>    A_θ=-A_zsinθ \\<br>    A_ϕ=0 \\<br>\end{cases}$</p><h3 id="远场区辐射"><a href="#远场区辐射" class="headerlink" title="远场区辐射"></a>远场区辐射</h3><p>由$H=\frac{1}{μ_0}▿×A$：  </p><script type="math/tex; mode=display">H_ϕ=j\frac{Il}{2λr}sinθe^{-jkr}</script><p>由$E=\frac{1}{jωɛ}▿×H$：    </p><script type="math/tex; mode=display">E_θ=j\frac{60πIl}{λr}sinθe^{-jkr}</script><h3 id="能量和方向性"><a href="#能量和方向性" class="headerlink" title="能量和方向性"></a>能量和方向性</h3><script type="math/tex; mode=display">W=\frac{1}{2}Re[E×H^*]=\frac{1}{2η}|E|^2=\frac{15πI_A^2l^2}{λ^2r^2}sin^2θ\hat{e_r}</script><script type="math/tex; mode=display">P=∯WdS=40π^2I^2(\frac{l}{λ})^2</script><script type="math/tex; mode=display">D_0=4π\frac{U_{max}}{P_r}=\frac{3}{2}</script><h2 id="天线阵列"><a href="#天线阵列" class="headerlink" title="天线阵列"></a>天线阵列</h2><h3 id="各向同性天线阵列的参数"><a href="#各向同性天线阵列的参数" class="headerlink" title="各向同性天线阵列的参数"></a>各向同性天线阵列的参数</h3><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210621201409.png"  style="zoom: 40%;" />   </p><ul><li>阵列因子<br>如图，由$E=∑E_i$:  <script type="math/tex; mode=display">E=\frac{E_0}{r^2}[C_01+C_1e^{-jkr_1}+...]</script><script type="math/tex; mode=display">AF_{norm}=∑_{n}^NC_ne^{j(n-1)(kdcosθ+β)}</script><script type="math/tex; mode=display">AF_{norm}=\frac{sin(\frac{N}{2}φ)}{sin(\frac{1}{2}φ)}</script><blockquote><p>n=0的天线（参考天线）位于原点，如果负半轴有天线，n应当从负数开始加起  </p></blockquote></li></ul><p>$d$:两个天线的间距，$β$:两个天线的相位差(对偶极子天线来说为0)，$C_n$为激活常数（默认为1）  </p><ul><li><p>平均辐射强度（归一化）</p><script type="math/tex; mode=display">U_{norm}=AF_{norm}^2</script></li><li><p>最大方向性</p><script type="math/tex; mode=display">D_0=2N(\frac{d}{λ})</script></li></ul><h3 id="天线阵列的方向图"><a href="#天线阵列的方向图" class="headerlink" title="天线阵列的方向图"></a>天线阵列的方向图</h3><p>方向图的最大点：  $AF(θ)=AF(θ)_{max}$时的$θ$<br>方向图的零点：  $AF(θ)=0$时的$θ$<br>方向图的半波宽度： $AF_{norm}|θ_{3db}=0.707,Θ_{hpbw}=2|θ_{max}-θ_{3dB}|$</p><p><h2 id="线天线"><a href="#线天线" class="headerlink" title="线天线"></a>线天线</h2><h3 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h3></p><h4 id="环形天线"><a href="#环形天线" class="headerlink" title="环形天线"></a>环形天线</h4><p>环形天线根据电尺寸分为两类： 电大天线和电小天线。<br>电大天线的周长近似于波长，电小天线的波长小于0.1个波长。    </p><p>&lt;/h4&gt;<h4 id="螺旋天线"><a href="#螺旋天线" class="headerlink" title="螺旋天线"></a><strong>螺旋天线</strong></h4><ul></p><ul><li><p>正常模式（Normal）  </p><p>当每一节螺旋的长度$L_0&lt;&lt;λ$时，螺旋天线可以视作是偶极子天线和环形天线的组合。<br>螺旋天线的轴比：   </p><script type="math/tex; mode=display">AR=\frac{|E_θ|}{|E_ϕ|}=\frac{2λs}{(πD)^2}</script></li></ul><p>  $s$:相邻螺旋的高度差，$D$:螺旋天线一个螺旋（圆部分）的直径。<br>当螺旋天线的轴比为0时，螺旋天线是线极化的。  &lt;/p&gt;</p><p>  <strong>正常模式下，整个螺旋线长度上的电流是恒定大小和相位的。由于其尺寸决定了天线的辐射特性，其辐射阻值$R_r$非常大，容易造成阻抗不匹配，且带宽很窄，辐射效率低下，方向性也比较差。</strong></p><ul><li>端射模式（End-fire）<br>螺旋天线一个螺旋（圆部分）的周长为$C$，当$C≈λ,S≈\frac{λ}{4}$时，螺旋天线视为端射模式。<br><strong>端射模式的带宽比较宽，因此端射模式的辐射效率比较高。在端射模式下，天线的方向性非常的好。</strong>  &lt;/p&gt;</li></ul><p><h4 id="八木天线"><a href="#八木天线" class="headerlink" title="八木天线"></a><strong>八木天线</strong></h4><p>八木天线的结构和方向图如下图所示：<br><br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210622213017.png" style="zoom: 70%;" /><br><br>八木天线的结构：<br></p><p>反射子：反射电磁波。<br>驱动子： 发射电磁波，其长度通常略小于$0.5λ$(0.45-0.49)，通常是一个环形天线用于阻抗匹配。<br>方向子： 通过感性电流扩大辐射，其长度通常略小于$0.5λ$（0.4-0.45）。<br>通常方向子的间距在$0.3λ-0.4λ$之间&lt;/p&gt;</p><p><h2 id="非频变天线"><a href="#非频变天线" class="headerlink" title="非频变天线"></a>非频变天线</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p></p><p>非频变天线指电磁波频率对其辐射性质（方向图，前后比，输入阻抗等）变化不大的一类天线。<br>天线的一系列物理边缘$r$可以与一系列频率的电磁波产生谐振。对于非频变天线，如果其第一个边缘$r$的表达式为$r=F(θ,ϕ)$，当后续边缘的表达式满足：  &lt;/p&gt;</p><script type="math/tex; mode=display">KF(θ,ϕ)=F(θ,ϕ+C)</script><p>其中K表示为第一个K倍大的电尺寸，C为第二个边缘旋转C角，如此旋转角度C取决于K而不取决于$θ$或者是$ϕ$，进而实现频率无关。<br>对其两边求微分后解得$r=e^{aϕ}f(θ)$，所有边缘满足该表达式的天线是非频变天线。  &lt;/p&gt;</p><h3 id="类型-1"><a href="#类型-1" class="headerlink" title="类型"></a>类型</h3><ul><li>平面等角螺旋天线(Planar Spiral Antenna)  </li><li>锥形等角螺旋天线(Conical Spiral Antenna)  </li><li>阿基米德螺旋天线  </li><li>对数周期天线  </li></ul><h4 id="等角螺旋天线"><a href="#等角螺旋天线" class="headerlink" title="等角螺旋天线*"></a><strong>等角螺旋天线*</strong></h4><p>因为等角螺旋的表面几何形状可以用$f(\theta)$来表示，所以它可以被设计为一个频率无关天线。<br>对于等角螺旋天线，取特殊值时，它的</p>$$r = \rho = Ae^{a\phi}=\rho_0 e^{a(\phi-\phi_0)}$$<p>以波长记时，</p>$$\rho_\lambda = Ae^{a[\phi + \ln(\lambda)/a]}$$所以，改变$\lambda$即改变$\phi_0$，结果方向图只是单纯的旋转而其它不变，所以我们得到的时频率无关天线。<br>螺旋总长的计算式*</p>$$L=(\rho_1 - \rho_0)\sqrt{1+\frac{1}{a^2}}$$等角螺旋辐射的波的极化由臂长来控制，全臂长和波长相比很小时，辐射场是线极化的，全臂长与波长相比不断增高时会从椭圆极化最终变成圆极化。实际应用中大多数会选轴比等于或小于$2:1$的点，它发生在全臂长约一个波长的时候。</p><h4 id="对数周期天线"><a href="#对数周期天线" class="headerlink" title="对数周期天线*"></a><strong>对数周期天线*</strong></h4><p>另一个频率无关的天线时对数周期天线，但是，它的形状不能由角度来描述，所以其实它不是真正的频率无关。<br>对数周期的结构形状可以写成</p>$$\theta = \theta_0 \sin [b\ln(\frac{r}{r_0})]$$只要角频率的对数相差$2\pi/b$，那么$\theta$就会重复，所以叫做对数周期天线。<br>虽然它不是严格频率无关，但是实际应用中把振幅变化设计的很小，所以看成是频率无关的。<br>最后，对数周期天线是线极化的。<h2 id="微带天线"><a href="#微带天线" class="headerlink" title="微带天线"></a>微带天线</h2><h3 id="辐射原理"><a href="#辐射原理" class="headerlink" title="辐射原理"></a>辐射原理</h3><p>当微带天线的贴片宽度$W$与基底高度$h$之比$\frac{W}{h}&gt;&gt;1$，并且$ɛ_r&gt;&gt;1$时，磁场从基底溢出（微带天线通过这样的磁场泄漏来发射电磁波），因此微带天线的电尺寸要大于实际尺寸，称之为边界效应。<br>在计算时，将电池溢出的部分和天线的基底一同视作新的基底，其等效介电常数为$ɛ_{reff}$。  </p><script type="math/tex; mode=display">1<ɛ_{reff}<ɛ_r</script><p>&lt;/script&gt;<h3 id="馈电方式"><a href="#馈电方式" class="headerlink" title="馈电方式"></a>馈电方式</h3><p>微带天线有四种馈电方式:  </p></p><ul><li>微带传输线馈电（Microstrip line feed）  </li><li>探针馈电（Probe feed）  </li><li>耦合孔馈电（Aperture-coupled feed）  </li><li>耦合馈电（Proximity-coupled feed）  </li></ul><p>如下图所示：</p><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210623105505.png" style="zoom: 33%;" /><br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210623105527.png" style="zoom: 33%;" />   </p><p>四种馈电方式的等效电路为：</p><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210623105712.png" style="zoom: 33%;" /> </p><h3 id="微带天线的结构"><a href="#微带天线的结构" class="headerlink" title="微带天线的结构"></a>微带天线的结构</h3><p>微带天线的结构如下图所示：<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210623105224.png" style="zoom: 50%;" />  </p><h2 id="孔径天线"><a href="#孔径天线" class="headerlink" title="孔径天线"></a>孔径天线</h2><p>由于直接求解孔径天线是非常复杂的，所以需要用等效方法和惠更斯原理来进行求解。</p><h3 id="等效"><a href="#等效" class="headerlink" title="等效"></a>等效</h3><p>等效是指用一个封闭的平面将原来的辐射场包围起来，然后在封闭面上放置满足边界条件的适当的电流和磁流密度（电流元和磁流元）。这时边界上的电流和磁流可以唯一确定边界内的场，得到一个等效。<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/5.jpg" style="zoom: 50%;" />  </p>具体而言，如上图所示，假设孔径天线的波导处电场方向$E_a$向$z$轴方向，根据惠更斯原理假设电流元向$-x$轴方向，那么$J_s=0$。考虑镜像原理，$M_s=-2\hat{n}×E_a$。<br>因此口径天线的电流密度和磁流密度可以等效为：   $$\begin{cases}  J_s=0 \\  M_s=-2\hat{n}×E_a \\\end{cases}$$$\hat{n}$: 如图的$y$方向上的单位向量<h3 id="惠更斯原理"><a href="#惠更斯原理" class="headerlink" title="惠更斯原理"></a>惠更斯原理</h3><p>波前上每一点都可以看成是一个次级波的新波源。所以在等效过后，就可以通过惠更斯原理求出原辐射源在封闭面外的辐射。  </p>## 喇叭天线### 相移<img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/449AD0ED032201E01C288EBF58E7F3BC.png" style="zoom: 50%;" />  如图为喇叭天线的侧视图，到达$x'$的平面波之间的相位差是由距离的不同$δ$产生的，$δ$与高度$y'$有关，记为$δ(y')$，称为波程差（Spherical phase term）。  根据如图的几何关系，有：  $$[ρ_1+δ(y')]^2=ρ_1^2+y'^2$$化简得到$δ(y')=\frac{1}{2}(\frac{y'}{ρ_1})^2$。  则波的相位差为：  $ΔΦ=kδ(y')$其中$k$为相位常数，在数值上等于波数。  当$y'=\frac{1}{2}b_1$时$δ(y')$取最大值。  <h2 id="反射天线"><a href="#反射天线" class="headerlink" title="反射天线*"></a>反射天线*</h2><h3 id="抛物面天线"><a href="#抛物面天线" class="headerlink" title="抛物面天线"></a>抛物面天线</h3><p>由于抛物面有从焦点到抛物面上任意一点的长度与该点到准线的长度之和始终为定值的特性，因此以焦点为馈电点，到准线的所有电磁波都是平面波。<br>前馈的抛物面天线有两种：抛物柱面（Parabolic cylinder）天线和抛物面天线（Paraboloid）。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">振幅函数</th><th style="text-align:center">馈电源</th><th style="text-align:center">极化方式</th></tr></thead><tbody><tr><td style="text-align:center">抛物柱面天线</td><td style="text-align:center">与$\frac{1}{ρ}$呈正比</td><td style="text-align:center">线形（通常是偶极子天线）</td><td style="text-align:center">只有线极化</td></tr><tr><td style="text-align:center">抛物面天线</td><td style="text-align:center">与$\frac{1}{r^2}$呈正比</td><td style="text-align:center">点</td><td style="text-align:center">任何极化</td></tr></tbody></table></div><p>与抛物面天线相比，抛物柱面天线的机械结构简单，能提供较大的口径阻挡，没有抛物面天线的吸引特性。<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210624153124.png" style="zoom: 50%;" />  </p><h3 id="透镜天线"><a href="#透镜天线" class="headerlink" title="透镜天线"></a>透镜天线</h3><p>透镜天线的使用频率在1000MHz以上，在3000MHz以上工作效果会更好。  </p><ul><li><p>优点  </p><ol><li>馈电点和支撑不妨碍传播 </li><li>更大的设计公差（Design tolerance）   </li><li>可以处理比抛物面天线更多的波  </li></ol></li><li><p>缺点   </p><ol><li>笨重  </li><li>设计复杂  </li><li>比同尺寸的抛物面天线贵  </li></ol></li><li><p>应用</p><ol><li>宽带天线   </li><li>微波传输 </li></ol></li></ul><h2 id="传输基本原理"><a href="#传输基本原理" class="headerlink" title="传输基本原理"></a>传输基本原理</h2><h3 id="传输过程的基本参数"><a href="#传输过程的基本参数" class="headerlink" title="传输过程的基本参数"></a>传输过程的基本参数</h3><p>真空中的特征阻抗：$η_0=√\frac{μ_0}{ϵ_0}=120π$<br>波数：$k=\frac{2π}{λ}=ω√{μ_0ϵ_0}$<br>通信链路公式：  </p><script type="math/tex; mode=display">P_L=(\frac{λ}{4πr})^2P_{in}G_rG_t</script><h3 id="自由空间传播损耗"><a href="#自由空间传播损耗" class="headerlink" title="自由空间传播损耗"></a>自由空间传播损耗</h3><script type="math/tex; mode=display">L_{fb}=10lg\frac{P_t}{P_r}=-20lg\frac{4πd}{λ}</script><script type="math/tex; mode=display">L_{fb}=32.4+20lgf[MHz]+20lgd[km]</script><p>$d$：传输距离，$f$：电磁波频率  </p><p><h3 id="菲涅尔区"><a href="#菲涅尔区" class="headerlink" title="菲涅尔区"></a>菲涅尔区</h3><p><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210623115057.png"style="zoom: 50%;" /><br>如图，第n菲涅尔区满足条件：</p></p><script type="math/tex; mode=display">l-d=n\frac{λ}{2}</script><p>当$d_1,d_2&gt;&gt;λ$时，原式可以化简为： </p><script type="math/tex; mode=display">F_n=√{\frac{nd_1d_2λ}{d_1+d_2}}</script><p><strong>菲涅尔区允许最大的侵占体积为整个菲涅尔区的40%，侵占体积最好不要超过整个菲涅尔区的20%。</strong> </p><p><h2 id="移动通信"><a href="#移动通信" class="headerlink" title="移动通信"></a>移动通信</h2><p>移动通信面临的问题是动态且多变的，具体表现为：  </p></p><ol><li>环境和信号都随着时间不断变化  </li><li>这样的变化是毫无规律的  </li></ol><h3 id="衰落"><a href="#衰落" class="headerlink" title="衰落"></a>衰落</h3><p>移动通信中的衰落主要有两种：  </p><ol><li>长期衰落：在传播中的微小变化通过时间积累后被放大。  </li><li>短期衰落：传播过程中多次反射/多径效应造成的衰落。<br>短期衰落主要来源于: 障碍物的直接遮挡（阴影效应，Shadow）、接收者的移动、地形（Terrain）、链路的不平衡传输（下行数据速率大于上行）等等。<br>因此即使是在同一个点，不同时间接收到的信号的能量和场强等也会变化，其变化规律符合正态分布。接收信号的场强可以用$E_q(dBμV/m)$表示： $$E_q=E_m+Q_iσ_L$$  $E_m$:该点场强的中值，$Q_i$:指定信号需要覆盖$q\%$的衰落储备(Fade Margin)所对应的指数分布系数，可通过查表找到$q_i$对应$Q_i$，$σ_L(dB)$:标准差。  其中定义：  $$FM=Q_iσ_L$$称为衰落储备(Fade Margin)。  接收端移动天线所接收的能量$P_{rM}$和敏感度$P_{rS}$，衰落储备之间的关系：  $$P_{rM}=P_{rS}+FM$$### 多径效应和多普勒效应<p>由于障碍物的存在，实际上接收的电磁波来源有两类：  </p><ol><li>直接接收到的电磁波  </li><li>通过障碍物和地面的反射接收到的电磁波<br>由同一传输信号沿两个或多个路径传播，以微小的时间差到达接收机的信号相互干涉所引起的衰落称之为多径衰落。多径效应对信号的幅值、频率、相位都有很大的影响。<br>多径效应的模型分为三类：静态（接收和发射都静止），半动态（接收运动），动态（接收和发射都运动）。<br>在动态模型中，需要考虑多普勒效应对观察频率$f_d$的影响：  $$f_d=f_mcosθ$$$f_m=\frac{V}{λ}$：最大多普勒频率，$θ$:波和运动方向的夹角。  <br>多普勒效应会对信号产生频移，不同的多径信号上存在时变的多普勒频移，如果信号由于多普勒效应产生的频移大于信道的时分复用周期，用户将接收不到信号。  </li></ol><h3 id="通信链路"><a href="#通信链路" class="headerlink" title="通信链路"></a>通信链路</h3><p><strong>简单来说，接收的能量等于发射的能量加上传输增益、减去传输损失。</strong><br>通信链路分为上行链路和下行链路，由于上行和下行设备的不同因此需要分开计算。<br>传输损失小的一方覆盖更大，最终链路的覆盖由损失更大的一方决定。  </p><h4 id="上行链路"><a href="#上行链路" class="headerlink" title="上行链路"></a><strong>上行链路</strong></h4><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/%5Cimg20210624132416.png"alt=""><br>如图所示：  </p>$$P_{rB}=P_{tM}-L_d-L_p-L_{fM}-L_{fB}+G_t+G_r$$  $$P_{rB}+FM=P_{tM}-L_d-L_p-L_{fM}-L_{fB}+G_t+G_r$$  <h4 id="下行链路"><a href="#下行链路" class="headerlink" title="下行链路"></a><strong>下行链路</strong></h4><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/%5Cimg20210624132502.png"alt=""><br>下行链路需要用多路耦合器（Multi coupler）将多个用户的信息进行整合，此处会有传输损失$L_c$。  如图所示：  </p>$$P_{rM}=P_{tB}-L_c-L_d-L_{fB}-L_{fM}+G_t+G_r$$  $$P_{rS}+FM=P_{tB}-L_c-L_d-L_{fB}-L_{fM}+G_t+G_r$$  <h3 id="区域覆盖预测模型"><a href="#区域覆盖预测模型" class="headerlink" title="区域覆盖预测模型"></a>区域覆盖预测模型</h3><p>区域覆盖预测模型有三种：经验模型（Empirical model）、精确模型（Deterministic model）、和混合模型（Physical-statistical model）。  </p><div class="table-container"><table><thead><tr><th style="text-align:left">名称</th><th style="text-align:left">特点</th></tr></thead><tbody><tr><td style="text-align:left">经验模型</td><td style="text-align:left">1.基于实验测量  <br> 2.结果通常是基于有限的频率和一些特定的介质 <br> 3.缺乏对无线电波传播机制的物理观点(Physical view)</td></tr><tr><td style="text-align:left">精确模型</td><td style="text-align:left">1.应用十分有限，主要应用于特殊几何结构的情况 <br> 2.对不同情况需要不同的传输路径特性(如ɛ和σ) <br> 3.由于考虑了直射、折射和衍射，因此模型十分复杂 <br> 4.考虑了不同地形的电参数</td></tr><tr><td style="text-align:left">混合模型</td><td style="text-align:left">两者的折中方案</td></tr></tbody></table></div><h2 id="电磁波在介质中的实际传输"><a href="#电磁波在介质中的实际传输" class="headerlink" title="电磁波在介质中的实际传输"></a>电磁波在介质中的实际传输</h2><p>在实际情况下，根据电磁波的传输介质，电磁波可以分为：空间波、天波、地表面波三类，其频率、传播环境和应用如下表所示。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">类型</th><th style="text-align:center">频率</th><th style="text-align:center">传播环境</th><th style="text-align:center">应用</th></tr></thead><tbody><tr><td style="text-align:center">空间波</td><td style="text-align:center">&gt;30MHz</td><td style="text-align:center">视距无线传输(Line of sight)</td><td style="text-align:center">微波通信、广播、导航</td></tr><tr><td style="text-align:center">天波</td><td style="text-align:center">3-30MHz</td><td style="text-align:center">电离层(Ionosphere)</td><td style="text-align:center">长距离通信、广播</td></tr><tr><td style="text-align:center">地表面波</td><td style="text-align:center">&lt;2MHz</td><td style="text-align:center">地表面</td><td style="text-align:center">短距离通信、报时信号</td></tr></tbody></table></div><h3 id="地表面波"><a href="#地表面波" class="headerlink" title="地表面波"></a>地表面波</h3><ul><li><p>特征  </p><ol><li>水平极化的地表面波衰减很大，并没有实用价值。因此基于地表面波的大部分应用都是基于地表面波的垂直极化。  </li><li>向前传输<br>地表面波可以分解为$E_z$和$E_ρ$两个方向上的波，由于$E_z>E_ρ$，因此两者的矢量和始终是向前的。  </li><li>地面以上部分的地表面波是椭圆极化：地表面波由径向分量和垂直分量组成。径向分量相对较小，相位差近似为零，形成椭圆偏振。  </li></ol><li><p>地表面电参数</p><ol><li>土质  </li><li>湿度  </li><li>温度  </li><li>能量吸收的能力  </li></ol></li><li><p>地表面类型对传播的影响</p><ol><li>地表面的导电性越好，传输过程中的衰落就越小。  </li><li>波的频率越高，传输过程中的衰落越大。  </li></ol></li></ul><h3 id="天波"><a href="#天波" class="headerlink" title="天波"></a>天波</h3><h4 id="大气层结构"><a href="#大气层结构" class="headerlink" title="大气层结构"></a><strong>大气层结构</strong></h4><ul><li>对流层（Troposphere）<br>这一层主要对电波有 吸收、衰减、折射、反射、极化改变、散射等等影响。  </li><li>电离层（Ionosphere）  </li></ul><ol><li>这一层内部有许多的等离子体（plasma）/电离气体（Ionized gas）以防护宇宙射线。  </li><li>电离层能够极大的改变电磁波的电性质。  </li><li>电离层自身处于动态且周期性的变化中。<br>天波主要在这一层进行传播。天波的内部分为多个小层：  </li></ol><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">距离</th><th style="text-align:center">注解</th></tr></thead><tbody><tr><td style="text-align:center">D</td><td style="text-align:center">50-70km</td><td style="text-align:center"></td></tr><tr><td style="text-align:center">E</td><td style="text-align:center">70-100km</td><td style="text-align:center">等离子体密度达到最大相对值<br>对电波传输的影响白天比晚上强，夏天比冬天强</td></tr><tr><td style="text-align:center">F</td><td style="text-align:center">1000km</td><td style="text-align:center">等离子体密度再次达到相对最大值</td></tr></tbody></table></div><p>在白天F层会分成$F_1$和$F_2$两个子层，在晚上这两层又会重新合并。<br>在白天，D层的下部对中频电波的损失非常的大，因此在中频和高频通信中往往选用频率比较高的电磁波（Lower frequency in MF band）。由于F层在白天分层的特性，中频通信中使用的较低频率的电磁波只能在晚上传输，白天通常传输中频/高频通信中的较高频率的电磁波（Higher frequency in MF band）。  </p><h4 id="电离层中的传播"><a href="#电离层中的传播" class="headerlink" title="电离层中的传播"></a>电离层中的传播</h4><p>定义电离层中的等离子体谐振角频率、频率$ω_p$、$f_p$，那么电离层的介电常数可以由如下公式界定：  </p>$$ɛ_r=1-\frac{f_p}{f}$$电离层中的传输常数$k_c$:$k_c=k_0√{1-(\frac{f_p}{f})^2}$  <ul><li>垂直发射电离层中的平面波电场可以简化为：$E=E_0e^{-jk_cz}$垂直发射电磁波，当电磁波频率小于$f_c=9√N,N$：等离子体密度时，电磁波将无法穿过电离层并且反射回地球。  </li><li>斜向发射<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210624114607.png"alt=""><br>斜向发射电磁波时，这一最大频率取决于电磁波的入射角$Φ$(上图中的$ϕ_i$)和$f_c$，定义斜向发射时的最大可用频率MUF:  $$MUF=f_c×secΦ$$ 在发射矢量与地球相切（发射仰角$Δ=0$）时，认为$Φ=74°$$$MUF=f_c×secΦ=3.6f_c$$ 由于各种因素的影响，定义最佳电磁波频率OUF：$$OUF=MUF×(50\%-80\%)$$>如果题目中没有告诉百分比，默认取80%</li></ul><p>实际上，电磁波的斜向传输是通过在地面和电离层之间来回多次反射进行的，每一次反射能跨越的距离主要受三个因素影响：  </p><ol><li>发射频率  </li><li>电磁波的仰角（Elevation angle）  </li><li>电离层中多个小层的变化  </li>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>常考知识点总结</title>
    <link href="/2021/06/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%80%83%E7%9F%A5%E8%AF%86%E7%82%B9/"/>
    <url>/2021/06/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F%E5%B8%B8%E8%80%83%E7%9F%A5%E8%AF%86%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="常考知识点总结"><a href="#常考知识点总结" class="headerlink" title="常考知识点总结"></a>常考知识点总结</h1><blockquote><p>针对Brunel University 2021: EE2622 Fundamentals of Signals and Systems 的期末复习笔记<br>Lecturer: Dr. Ruiheng Wu (武瑞恒)  </p></blockquote><h2 id="信号的基本分类"><a href="#信号的基本分类" class="headerlink" title="信号的基本分类*"></a>信号的基本分类*</h2><p>连续信号：x轴，y轴都连续<br>离散信号：x轴连续的信号<br>数字信号：x轴，y轴都连续的信号</p><ul><li>三角离散信号的采样周期和周期<br>对于离散信号$sin(ω_0n)$，如果其连续信号角频率为$Ω$，其取样为$sin(ω_0n)=sin(ΩTn)$，其周期：<script type="math/tex; mode=display">\frac{2π}{ω_0}=\frac{N_{dis}}{T_{con}}</script>其中$N_{dis}$为离散信号的周期，$T_{con}$为连续信号的周期。  <blockquote><p>如果两者的比值不是一个有理数，那么其离散信号不是一个周期函数。  </p></blockquote></li></ul><h2 id="冲激函数的特性"><a href="#冲激函数的特性" class="headerlink" title="冲激函数的特性"></a>冲激函数的特性</h2><h3 id="冲激函数的特性-1"><a href="#冲激函数的特性-1" class="headerlink" title="冲激函数的特性"></a>冲激函数的特性</h3><div class="table-container"><table><thead><tr><th style="text-align:center">特性</th><th style="text-align:center">公式</th></tr></thead><tbody><tr><td style="text-align:center">赋值性</td><td style="text-align:center">$∫δ(t)f(t)dt=f(0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">$f(t)δ(t)=f(0)δ(t)$</td></tr><tr><td style="text-align:center">偶函数</td><td style="text-align:center">$δ(t)=δ(-t)$</td></tr><tr><td style="text-align:center">缩放</td><td style="text-align:center">$δ(at)=\frac{1}{ ⃒  a ⃒ }δ(t)$</td></tr></tbody></table></div><h3 id="冲激函数的应用"><a href="#冲激函数的应用" class="headerlink" title="冲激函数的应用"></a>冲激函数的应用</h3><p>单位冲激函数可以描述带有间断点函数的倒数。   </p><p>单位冲激函数可以描述门函数的导数。  </p><h3 id="冲激偶函数的特性"><a href="#冲激偶函数的特性" class="headerlink" title="冲激偶函数的特性"></a>冲激偶函数的特性</h3><div class="table-container"><table><thead><tr><th style="text-align:center">特性</th><th style="text-align:center">公式</th></tr></thead><tbody><tr><td style="text-align:center">赋值性</td><td style="text-align:center">$∫δ’(t)f(t)dt=-f’(0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">$f(t)δ’(t)=f(0)δ’(t)-f’(0)δ(t)$</td></tr><tr><td style="text-align:center">奇函数</td><td style="text-align:center">$δ’(t)=-δ’(t)$</td></tr></tbody></table></div><h2 id="信号的表示"><a href="#信号的表示" class="headerlink" title="信号的表示"></a>信号的表示</h2><ol><li>有限重复非周期的信号： 利用时移进行表示  </li><li>“/-”信号（斜坡和阶跃信号的组合）是门信号的积分结果。  </li></ol><h3 id="信号的微分关系"><a href="#信号的微分关系" class="headerlink" title="信号的微分关系"></a>信号的微分关系</h3><script type="math/tex; mode=display">tu(t)→u(t)→δ(t)→δ'(t)</script><blockquote><p>$δ(t)$有关的性质都用积分相等进行证明。  </p></blockquote><script type="math/tex; mode=display">/-信号→G(t)→δ(t)的组合</script><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/%5Cimg20210622105802.png" alt=""></p><h2 id="信号的基本操作"><a href="#信号的基本操作" class="headerlink" title="信号的基本操作"></a>信号的基本操作</h2><h3 id="时移和尺度变换"><a href="#时移和尺度变换" class="headerlink" title="时移和尺度变换"></a>时移和尺度变换</h3><p><strong>对$f(at+b)$，其化为$f(a(t+\frac{b}{a}))$后对$f(t)$的图像先缩放$\frac{1}{a}$，再向左平移$\frac{b}{a}$个单位。</strong>  </p><h3 id="信号的分解"><a href="#信号的分解" class="headerlink" title="信号的分解*"></a>信号的分解*</h3><p>奇偶分解：$f(t)=\frac{1}{2}[f(t)+f(-t)]_{even}+\frac{1}{2}[f(t)-f(-t)]_{odd}$<br>复数分解：$f(t)=\frac{1}{2}[f(t)+f^*(t)]_{real}+\frac{1}{2}[f(t)-f^*(t)]_{img}$<br>直流分解： $f(t)=[\frac{1}{T}∫_{t_0}^{T+t_0}f(t)dt]_{dc}+f_A(t)$  </p><h3 id="信号的能量（帕塞瓦尔定理）"><a href="#信号的能量（帕塞瓦尔定理）" class="headerlink" title="信号的能量（帕塞瓦尔定理）"></a>信号的能量（帕塞瓦尔定理）</h3><p>信号$f(t)$的总能量可以用如下公式表示：  </p><script type="math/tex; mode=display">P=∫|f(t)|^2dt=\frac{1}{2π}|F(jω)|^2dω</script><blockquote><p>注意：|F(jω)|指模长  </p></blockquote><h3 id="信号的频谱"><a href="#信号的频谱" class="headerlink" title="信号的频谱"></a>信号的频谱</h3><p><strong>周期信号的频谱是离散频谱，非周期信号的频谱是连续频谱。</strong><br>通过傅里叶级数写出信号频谱的办法：  </p><ol><li>将傅里叶级数转化为cos的形式： $f(t)=∑A_ncos(nω+ϕ_n)$  </li><li>对于单边频谱，根据nω直接写出$A_n$或者$ϕ_n$的频谱  </li></ol><blockquote><p>双边频谱的幅值谱是$\frac{A_n}{2}$</p></blockquote><h3 id="门信号的傅里叶系数-频谱"><a href="#门信号的傅里叶系数-频谱" class="headerlink" title="门信号的傅里叶系数/频谱"></a>门信号的傅里叶系数/频谱</h3><p>门信号的傅里叶系数$F(nω)=\frac{1}{2}a_n$<br>其频谱最重要的三个参数:<br>幅值:$F(nω)max$<br>谐波宽度:$ω_0=\frac{2π}{T}$，只与$T$有关。<br>主瓣宽度，$F(nω)=0$，$\frac{2π}{τ}$，只与$τ$有关。  </p><h2 id="系统的性质"><a href="#系统的性质" class="headerlink" title="系统的性质"></a>系统的性质</h2><h3 id="因果性"><a href="#因果性" class="headerlink" title="因果性"></a>因果性</h3><p>$t_0$时刻，系统输出只与$f(t_0)$和$f(t&lt;t_0)$有关。  </p><blockquote><p>也就是说输出的$f(t)$和输入的$t_0$相比，$t_0&gt;t$。（例如$x(-t)$ 输入$t=-4$时，输出为$x(4)$，$4&gt;-4$因此不是因果系统）  </p></blockquote><h3 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h3><p>满足：</p><script type="math/tex; mode=display">H[C_1f_1(t)+C_2f_2(t)]=C_1H[f_1(t)]+C_2H[f_2(t)]</script><h3 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h3><p>满足：</p><script type="math/tex; mode=display">\lim_{t→∞}f(t)<∞</script><blockquote><p>通常判断系统稳定性从系统方程入手，判断s域下极点是否在左半轴或者z域中极点是否在单位圆内。  </p></blockquote><h3 id="时不变性"><a href="#时不变性" class="headerlink" title="时不变性*"></a>时不变性*</h3><p>先变换，后时移与先时移，后变换的结果相同。  </p><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><h3 id="周期信号的傅里叶级数"><a href="#周期信号的傅里叶级数" class="headerlink" title="周期信号的傅里叶级数"></a>周期信号的傅里叶级数</h3><script type="math/tex; mode=display">f(t)=a_0+∑_{n=1}^∞[a_n cos(nω_1t)+b_nsin(nω_1t)]</script><p>组成成分：<br>直流分量：$a_0=\frac{1}{T}∫_0^Tf(t)dt$，表示<strong>一周期内信号的平均值</strong>。<br>基波分量：$a_n=\frac{2}{T}∫_0^Tf(t)cos(nω_1t)dt$<br>谐波分量：$b_n=\frac{2}{T}∫_0^Tf(t)sin(nω_1t)dt$  </p><blockquote><p>注意当$f(t)$是一个奇函数时，$a=0$;$f(t)$是一个偶函数时，$b=0$。  </p></blockquote><p>指数形式的傅里叶级数：  </p><script type="math/tex; mode=display">f(t)=∑F(nω_1)e^{jnω_1t}</script><p>$F(nω_1)=\frac{1}{2}(a_n-jb_n)$<br>幅度：$|F(nω_1)|=\frac{1}{2}√{a_n^2+b_n^2}$<br>相位：$φ_n=arctan(-\frac{b_n}{a_n})$  </p><h3 id="非周期函数的傅里叶变换"><a href="#非周期函数的傅里叶变换" class="headerlink" title="非周期函数的傅里叶变换"></a>非周期函数的傅里叶变换</h3><script type="math/tex; mode=display">F(ω)=∫f(t)e^{-jωt}dt=F[f(t)]</script><p>复数形式：$F(ω)=|F(ω)|e^{jφ(ω)}$<br>傅里叶反变换：  </p><script type="math/tex; mode=display">f(t)=\frac{1}{2π}∫F(ω)e^{jωt}dω</script><h3 id="周期信号的傅里叶变换"><a href="#周期信号的傅里叶变换" class="headerlink" title="周期信号的傅里叶变换"></a>周期信号的傅里叶变换</h3><p>如果周期函数$f_T(t)$一个周期内的子函数为$f(t)$，那么$f_T(t)$的傅里叶变换可以写作：  </p><script type="math/tex; mode=display">F_T(ω)=2π∑F(nω_1)δ(ω-nω_1)</script><p>其中$F(nω_1)=\frac{1}{T}F(ω)|_{ω=nω_1}$<br>因此上式可以化简为：  </p><script type="math/tex; mode=display">F_T(ω)=ω_1∑F(ω)|_{ω=nω_1}δ(ω-nω_1)</script><h3 id="傅里叶变换的运算性质"><a href="#傅里叶变换的运算性质" class="headerlink" title="傅里叶变换的运算性质"></a>傅里叶变换的运算性质</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">对偶性</td><td style="text-align:center">$2πf(-ω)$</td><td style="text-align:center">$F(t)$</td></tr><tr><td style="text-align:center">尺度变换</td><td style="text-align:center">$f(at)$</td><td style="text-align:center">$\frac{1}{\lvert a\rvert}F(\frac{ω}{a})$</td></tr><tr><td style="text-align:center">时移</td><td style="text-align:center">$f(t-t_0)$</td><td style="text-align:center">$F(ω)e^{-jωt_0}$</td></tr><tr><td style="text-align:center">频移</td><td style="text-align:center">$f(t)e^{-jω_0t}$</td><td style="text-align:center">$F(ω+ω_0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域微分</td><td style="text-align:center">$f’(t)$</td><td style="text-align:center">$jωF(ω)$</td></tr><tr><td style="text-align:center">频域微分</td><td style="text-align:center">$-jtf(t)$</td><td style="text-align:center">$F’(ω)$</td></tr><tr><td style="text-align:center">时域积分</td><td style="text-align:center">$∫f(t)dt$</td><td style="text-align:center">$πF(0)δ(ω)+\frac{F(ω)}{jω}$</td></tr></tbody></table></div><h3 id="常见信号的傅里叶变换"><a href="#常见信号的傅里叶变换" class="headerlink" title="常见信号的傅里叶变换"></a>常见信号的傅里叶变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域函数$f(t)$</th><th style="text-align:center">频域函数$F(ω)$</th></tr></thead><tbody><tr><td style="text-align:center">门函数</td><td style="text-align:center">$E[u(t+\frac{τ}{2})-u(t-\frac{τ}{2})]$ <br>$E,-\frac{τ}{2}&lt;t&lt;\frac{τ}{2}$</td><td style="text-align:center">$\frac{2Esin(ω\frac{τ}{2})}{ω}=EτSa(\frac{ωτ}{2})$</td></tr><tr><td style="text-align:center">直流信号/常函数</td><td style="text-align:center">$E$</td><td style="text-align:center">$2πEδ(ω)$</td></tr><tr><td style="text-align:center">冲激函数</td><td style="text-align:center">$δ(t)$</td><td style="text-align:center">$1$</td></tr><tr><td style="text-align:center">冲激偶函数</td><td style="text-align:center">$δ’(t)$</td><td style="text-align:center">$jω$</td></tr><tr><td style="text-align:center">阶跃函数</td><td style="text-align:center">$u(t)$</td><td style="text-align:center">$\frac{1}{jw}+πδ(ω)$</td></tr><tr><td style="text-align:center">单侧指数函数</td><td style="text-align:center">$Ee^{-at}u(t)$</td><td style="text-align:center">$\frac{E}{jω+a}$</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">周期冲激序列</td><td style="text-align:center">$δ_T(t)$</td><td style="text-align:center">$ω_1δ(ω-nω_1)$</td></tr><tr><td style="text-align:center">周期方波/门函数序列</td><td style="text-align:center">-</td><td style="text-align:center">$EτSa(\frac{ωτ}{2})ω_1δ(ω-nω_1)$</td></tr><tr><td style="text-align:center">正弦函数</td><td style="text-align:center">$sin(ω_0t)$</td><td style="text-align:center">$-jπδ(ω-ω_0)+jπδ(ω+ω_0)$</td></tr><tr><td style="text-align:center">余弦函数</td><td style="text-align:center">$cos(ω_0t)$</td><td style="text-align:center">$πδ(ω-ω_0)+πδ(ω+ω_0)$</td></tr></tbody></table></div><h2 id="采样定理"><a href="#采样定理" class="headerlink" title="采样定理"></a>采样定理</h2><p>奈奎斯特采样率：$f_n=2f_m$， 采样频率$f_n$是输入信号的频率的两倍。  </p><h2 id="时域分析方法"><a href="#时域分析方法" class="headerlink" title="时域分析方法"></a>时域分析方法</h2><h3 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h3><p>定义：</p><script type="math/tex; mode=display">∫f(t)h(τ-t)dt=f(t)*h(t)</script><p>称为信号的卷积运算。  </p><p>运算性质： </p><ol><li>$f(t)*δ(t)=f(t)$  </li><li>$f(t)*δ(t-t_0)=f(t-t_0)$</li><li>$f(t)*δ’(t)=f’(t)$</li></ol><ul><li>图解法解卷积运算<br>对于简单的信号，可以采取翻转其中一个信号，将这个信号图像平移，平移过程中观察与另一个信号图像的重叠面积的变化。  </li></ul><h3 id="冲激响应和阶跃响应"><a href="#冲激响应和阶跃响应" class="headerlink" title="冲激响应和阶跃响应"></a>冲激响应和阶跃响应</h3><p>当输入信号为$δ(t)$时，系统的输出为$h(t)$，称为单位冲激响应。<br>当输入信号为$u(t)$时，系统的输出为$g(t)$，称为单位阶跃响应。<br>冲激响应和阶跃响应满足如下关系：  </p><script type="math/tex; mode=display">g(t)=∫_{-∞}^th(t)dt</script><p>由于卷积运算中$f(t)h(τ-t)≠0$，因此阶跃响应可以用于决定积分的上下限。  </p><h3 id="零状态和零响应"><a href="#零状态和零响应" class="headerlink" title="零状态和零响应"></a>零状态和零响应</h3><p>零输入响应：没有任何输入时系统的响应，对应系统的特征微分方程输入为0的情况。  </p><blockquote><p>初始状态的值会直接影响到零状态响应：如果初始状态$x(0)=c$对应的零输入响应为$r_{zs}^i$，那么初始状态为$x(0)=2c$对应的零输入响应为$r_{zs}^{ii}=2r_{zs}^i$</p></blockquote><p>零状态响应：不考虑系统的初始状态，系统输入对系统造成的响应。<br><strong>系统的零状态响应</strong>可以表示为输入信号为$δ(t)$时的系统响应与系统输入信号的卷积：  </p><script type="math/tex; mode=display">r_{zs}=h(t)*e(t) ↔ R_{zs}(s)=H(s)E(s)</script><p>系统的全响应： 系统的零状态响应和系统的零输入响应之和。  </p><script type="math/tex; mode=display">R(s)=H(s)E(s)+R_{zi}(s)</script><h3 id="时域分析法解系统微分方程"><a href="#时域分析法解系统微分方程" class="headerlink" title="时域分析法解系统微分方程"></a>时域分析法解系统微分方程</h3><h4 id="求齐次解（零输入响应）"><a href="#求齐次解（零输入响应）" class="headerlink" title="求齐次解（零输入响应）"></a>求齐次解（零输入响应）</h4><p>系统的齐次解方程：  </p><script type="math/tex; mode=display">f[y(t)]=0</script><ol><li>将特征方程转化为多项式并求解。<br>对于微分方程的特征方程，其$n$阶微分项可以被换元为$α^n$项，最终将特征方程转化为关于$α$的$n$阶多项式。<br>对于差分方程的特征方程，其0阶差分项$y(n)$可以被换元为关于$α$的最高幂项，如此类推，最终将特征方程转化为关于$α$的$n$阶多项式。  </li><li><p>根据多项式的解的个数和是否有重根，可以在下表中找到齐次解的形式，并带入多项式的解。  </p><p>不同特征根所对应的齐次解（微分方程）  </p></li></ol><div class="table-container"><table><thead><tr><th style="text-align:center">特征根</th><th style="text-align:center">齐次解$y_p(t)$</th></tr></thead><tbody><tr><td style="text-align:center">单实根</td><td style="text-align:center">$e^{αk}$</td></tr><tr><td style="text-align:center">r重实根</td><td style="text-align:center">$∑C_{r-1}t^{r-1} e^{αk}$</td></tr></tbody></table></div><p>   不同特征根所对应的齐次解（差分方程）  </p><div class="table-container"><table><thead><tr><th style="text-align:center">特征根</th><th style="text-align:center">齐次解$y_p(k)$</th></tr></thead><tbody><tr><td style="text-align:center">单实根</td><td style="text-align:center">$Cα^k$</td></tr><tr><td style="text-align:center">r重实根</td><td style="text-align:center">$∑C_{r-1}k^{r-1} α^k$</td></tr></tbody></table></div><h4 id="求系统特解（单位冲激响应）"><a href="#求系统特解（单位冲激响应）" class="headerlink" title="求系统特解（单位冲激响应）"></a>求系统特解（单位冲激响应）</h4><ol><li>带入具体的激励$e(t)=δ(t)$到系统的微分/差分方程。</li><li>通过0阶项$r(t)$与激励中最高次数项之间系数的关系，用待定系数法猜想系统响应$r(t)$的结构。</li><li>将$r(t)$的结构代回微分/差分方程，利用对应阶数项系数相等建立方程，解出$r(t)$结构中的常系数。  </li></ol><p>如果已知了一些特解，求另一些特解，可以使用<strong>迭代法</strong>。<br>即从$h(0)$开始列出微分方程，直到列到所求的特解对应的微分方程，将已知的特解带入，从而求出未知的特解。  </p><h2 id="拉普拉斯变换"><a href="#拉普拉斯变换" class="headerlink" title="拉普拉斯变换"></a>拉普拉斯变换</h2><h3 id="傅里叶变换的局限性"><a href="#傅里叶变换的局限性" class="headerlink" title="傅里叶变换的局限性"></a>傅里叶变换的局限性</h3><ol><li>对不满足狄利克雷条件的函数无法变换</li><li>难以求解无穷积分</li></ol><h3 id="拉普拉斯变换对"><a href="#拉普拉斯变换对" class="headerlink" title="拉普拉斯变换对"></a>拉普拉斯变换对</h3><p>拉普拉斯变换：$F(s)=L[f(t)]=∫f(t)e^{-st}dt$<br>拉普拉斯反变换：$f(t)=\frac{1}{2πj}∫F(s)e^{st}ds$<br>拉普拉斯变换通过向傅里叶变换中添加衰减系数$e^{-σ}$来改善$f(t)$的收敛性，使其更可能满足狄利克雷条件。  </p><p>实际上对于反变换，更多的是利用多项式除法，观察多项式的结构来进行反变换：<br>$F(s)=∑\frac{k}{s-p}↔f(t)=∑ke^{pt}$ （一阶实极点）  </p><blockquote><p>如果分子是含有s的表达式，尝试用$A-\frac{C}{f(s)}$的形式进行表达，常数部分转化为冲激函数。  </p></blockquote><h3 id="拉普拉斯变换的运算性质"><a href="#拉普拉斯变换的运算性质" class="headerlink" title="拉普拉斯变换的运算性质"></a>拉普拉斯变换的运算性质</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">时移</td><td style="text-align:center">$f(t-t_0)$</td><td style="text-align:center">$F(ω)e^{-t_0s}$</td></tr><tr><td style="text-align:center">频移</td><td style="text-align:center">$f(t)e^{-at}$</td><td style="text-align:center">$F(s+a)$</td></tr><tr><td style="text-align:center">尺度变换</td><td style="text-align:center">$f(at)$</td><td style="text-align:center">$\frac{1}{\lvert a\rvert}F(\frac{s}{a})$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域微分（一阶）</td><td style="text-align:center">$f’(t)$</td><td style="text-align:center">$sF(s)-f(0)$</td></tr><tr><td style="text-align:center">时域微分（二阶）</td><td style="text-align:center">$\frac{df^2(t)}{dt}$</td><td style="text-align:center">$s[sF(s)-f(0)]-f’(0)$</td></tr><tr><td style="text-align:center">频域微分</td><td style="text-align:center">$t^nf(t)$</td><td style="text-align:center">$(-1)^n\frac{d^nF(s)}{ds^n}$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域积分</td><td style="text-align:center">$∫f(t)dt$</td><td style="text-align:center">$\frac{F(s)}{s}+\frac{f’(0)}{s}$</td></tr><tr><td style="text-align:center">频域积分</td><td style="text-align:center">$\frac{f(t)}{t}$</td><td style="text-align:center">$∫F(s)ds$</td></tr></tbody></table></div><p>初值定理: $f(0_+)\lim_{s→∞}sF(s)$<br>终值定理：$\lim_{t→∞}f(t)=\lim_{s→0}sF(s)$<br>卷积理论：$L[f(t)h(t)]=\frac{1}{2πj}F(s)*H(s)$  </p><h3 id="常见信号的拉普拉斯变换"><a href="#常见信号的拉普拉斯变换" class="headerlink" title="常见信号的拉普拉斯变换"></a>常见信号的拉普拉斯变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域函数$f(t)$</th><th style="text-align:center">频域函数$L(s)$</th></tr></thead><tbody><tr><td style="text-align:center">阶跃函数</td><td style="text-align:center">$u(t)$</td><td style="text-align:center">$\frac{1}{s}$</td></tr><tr><td style="text-align:center">冲激函数</td><td style="text-align:center">$δ(t)$</td><td style="text-align:center">$1$</td></tr><tr><td style="text-align:center">单侧指数函数</td><td style="text-align:center">$Ee^{-at}u(t)$</td><td style="text-align:center">$\frac{E}{s+a}$</td></tr><tr><td style="text-align:center">斜坡函数</td><td style="text-align:center">$tu(t)$</td><td style="text-align:center">$\frac{1}{s^2}$</td></tr><tr><td style="text-align:center">正弦函数</td><td style="text-align:center">$sin(ω_0t)$</td><td style="text-align:center">$\frac{ω_0}{s^2+ω_0^2 }$</td></tr><tr><td style="text-align:center">余弦函数</td><td style="text-align:center">$cos(ω_0t)$</td><td style="text-align:center">$\frac{s}{s^2+ω_0^2}$</td></tr></tbody></table></div><h3 id="利用拉普拉斯变换求微分方程"><a href="#利用拉普拉斯变换求微分方程" class="headerlink" title="利用拉普拉斯变换求微分方程"></a>利用拉普拉斯变换求微分方程</h3><ol><li><p>以时域函数$f(t)$的拉普拉斯变换$F(s)$的微分特性：  </p><blockquote><p>一阶微分：$\frac{df(t)}{dt}→sF(s)-f(0_ )$<br>二阶微分：$\frac{df^2(t)}{dt}→s[sF(s)-f(0_ )]-f’(0_ )$  </p></blockquote><p>可以将微分方程以拉普拉斯变换从时域变换至频域。<br>对于描述系统的微分方程将其做拉普拉斯变换：</p><script type="math/tex; mode=display">F_{out}(R(s),s)=F_{in}(E(s),s)</script></li><li><p>带入初始条件和给定的题目条件中的一些$r(t)$在特定时刻下的值，得到方程  </p></li><li>解出频域内的$R(s)$  </li><li>用待定系数法展开多项式分式并用拉普拉斯反变换得到$r(t)$</li></ol><blockquote><p>注意初始条件  </p></blockquote><p>对于全响应方程$R(s)$，$R(s)$可以分解为两部分，一部分只与初始状态$r(0)$相关（零输入响应），另一部分方程只与输入$E(s)$有关(零状态响应)。对这两部分分别进行拉普拉斯反变换得到零输入响应和零状态响应。  </p><h2 id="Z变换"><a href="#Z变换" class="headerlink" title="Z变换"></a>Z变换</h2><h3 id="Z变换对"><a href="#Z变换对" class="headerlink" title="Z变换对"></a>Z变换对</h3><p>Z变换：$X(z)=∑x(n)z^{-n}$<br>收敛域：$∑|x(n)z^{-n}&lt;∞|$<br>Z反变换：$X(z)=z(\frac{A}{z-p_i})⟷x(n)=∑A(p_i)^n$(一阶单极点)  </p><h3 id="收敛域"><a href="#收敛域" class="headerlink" title="收敛域*"></a>收敛域*</h3><script type="math/tex; mode=display">∑∣x(n)z^{-n}∣<∞</script><h3 id="Z变换的运算性质"><a href="#Z变换的运算性质" class="headerlink" title="Z变换的运算性质"></a>Z变换的运算性质</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">双侧时移</td><td style="text-align:center">$x(n+m)$</td><td style="text-align:center">$z^mX(z)$</td></tr><tr><td style="text-align:center">右侧时移</td><td style="text-align:center">$x(n-m)$</td><td style="text-align:center">$z^{-m}[X(z)+∑_{k=-m}^{-1}x(k)z^{-k}]$</td></tr><tr><td style="text-align:center">尺度变换（时域）</td><td style="text-align:center">$nx(n)$</td><td style="text-align:center">$-z\frac{dX(z)}{dz}$</td></tr><tr><td style="text-align:center">尺度变换(z域)</td><td style="text-align:center">$a^nx(n)$</td><td style="text-align:center">$X(\frac{z}{a})$</td></tr></tbody></table></div><p>初值定理: $x(0_+)\lim_{x→∞}X(z)$<br>终值定理：$\lim_{n→∞}x(n)=\lim_{z→1}(z-1)X(z)$<br>卷积理论：$Z[x(n)*h(n)]=X(z)H(z)$  </p><h3 id="常见信号的Z变换"><a href="#常见信号的Z变换" class="headerlink" title="常见信号的Z变换"></a>常见信号的Z变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域序列$x(n)$</th><th style="text-align:center">频域序列$X(z)$</th><th style="text-align:center">收敛域</th></tr></thead><tbody><tr><td style="text-align:center">单位冲激序列</td><td style="text-align:center">$δ(n)$</td><td style="text-align:center">$1$</td><td style="text-align:center">整个z域</td></tr><tr><td style="text-align:center">单位阶跃序列</td><td style="text-align:center">$u(n)$</td><td style="text-align:center">$\frac{z}{z-1}$</td><td style="text-align:center">$⃒ z ⃒ &lt;1$</td></tr><tr><td style="text-align:center">斜坡序列</td><td style="text-align:center">$nu(n)$</td><td style="text-align:center">$\frac{z}{(z-1)^2}$</td><td style="text-align:center">$⃒ z ⃒ &lt;1$</td></tr><tr><td style="text-align:center">单侧指数序列</td><td style="text-align:center">$a^nu(n)$</td><td style="text-align:center">$\frac{z}{z-a}$</td><td style="text-align:center">$⃒ z ⃒ &gt;⃒ a ⃒$</td></tr><tr><td style="text-align:center">单侧正弦序列</td><td style="text-align:center">$sin(ω_0n)u(n)$</td><td style="text-align:center">$\frac{zsinω_0}{z^2-2zcosω_0+1}$</td><td style="text-align:center">$⃒ z ⃒ &gt;1$</td></tr><tr><td style="text-align:center">单侧余弦序列</td><td style="text-align:center">$cos(ω_0n)u(n)$</td><td style="text-align:center">$\frac{z(z-cosω_0)}{z^2-2zcosω_0+1}$</td><td style="text-align:center">$⃒ z ⃒ &gt;1$</td></tr></tbody></table></div><h3 id="利用Z变换求差分方程"><a href="#利用Z变换求差分方程" class="headerlink" title="利用Z变换求差分方程"></a>利用Z变换求差分方程</h3><blockquote><p>利用Z变换的单边右时移特性：<br>$x(n-1)=z^{-1}X(z)+x(-1)$<br>$x(n-2)=z^{-2}X(z)+z^{-1}x(-1)+x(-2)$<br>注意初始条件</p></blockquote><ol><li>将差分方程改写成Z变换的形式  </li><li>确定初始状态，解出差分方程  </li><li>反变换得到$y(n)$  </li></ol><h2 id="系统方程"><a href="#系统方程" class="headerlink" title="系统方程"></a>系统方程</h2><p>描述系统的方程$H(s)=\frac{R(s)}{E(s)}$<br><strong>$H(s)$的分母为系统微分方程输入侧的特征方程，分子为系统输出侧的特征方程。</strong>   </p><p>系统输入和输出在s域内都以多项式表示，系统方程自然是两个多项式的比值：</p><script type="math/tex; mode=display">H(s)=\frac{R(s)}{E(s)}=K\frac{Π(s-z_i)}{Π(s-p_k)}</script><p>其中$p_i$称为系统方程的极点，$z_k$称为系统方程的零点。   </p><h3 id="系统稳定性"><a href="#系统稳定性" class="headerlink" title="系统稳定性"></a>系统稳定性</h3><p>在s域图像中，如果极点分布在s域的左半轴，表明系统是稳定的。<br>在z域图像中，如果极点分布在z域的单位圆内，表明系统是稳定的。  </p><h3 id="反馈系统的方程"><a href="#反馈系统的方程" class="headerlink" title="反馈系统的方程"></a>反馈系统的方程</h3><p>如图：<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210614142459.png" alt=""><br>系统的闭环传输函数：  </p><script type="math/tex; mode=display">\frac{C(s)}{R(s)}=\frac{G(s)}{1+G(s)H(s)}</script><p>其中：系统的开环传输函数为$G(s)H(s)$。  </p><h3 id="根轨迹图"><a href="#根轨迹图" class="headerlink" title="根轨迹图"></a>根轨迹图</h3><p>系统的开环传输函数加入了一个根轨迹增益$K$以衡量闭环极点对开环传输函数的影响。<br>得到根轨迹图的步骤：  </p><ol><li><p>通过闭环传递函数的特征方程$1+G(s)H(s)=0$解出s与参数$K$之间的关系。  </p><blockquote><p>注意开环传输函数的特征方程是$1+G(s)H(s)=0$<br>二阶多项式方程的根：$\frac{-b⨦√Δ}{2a}$  </p></blockquote></li><li><p>在s域中标出零点。  </p></li><li>在s域中标出极点，即$K=0$的位置。  </li><li>增加K的值，在S域中标出一系列的s的位置，并以（$K=x$）在每个点上方进行标注。  </li><li>判断$k→∞$时，s的移动方向，并用箭头标注。  </li></ol><h2 id="切比雪夫滤波器"><a href="#切比雪夫滤波器" class="headerlink" title="切比雪夫滤波器"></a>切比雪夫滤波器</h2><h3 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h3><ol><li>过渡带很小</li><li>有波纹</li></ol><h3 id="参数"><a href="#参数" class="headerlink" title="参数"></a>参数</h3><p>实际的滤波器波形如图表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210531161932.png" alt=""><br>滤波器波形的四个参数：</p><ol><li>通带边缘（Passband edge,$ω_p$）</li><li>最大允许变化（Maximum allowed variation,$A_{max}$）  </li><li>阻带边缘（Stopband edge,$ω_s$）</li><li>最小阻带衰减要求（Minimum required stopband attenuation,$A_{min}$）  </li></ol><h3 id="传输函数（低通）"><a href="#传输函数（低通）" class="headerlink" title="传输函数（低通）"></a>传输函数（低通）</h3><script type="math/tex; mode=display">|T(jω)|=\frac{1}{√1+ɛ^2C^2_n(ω/ω_p)}</script><p>其中：$n≥\frac{cosh^{-1}M}{cosh^{-1}Ω}$为电路阶数，$ɛ=√{10^{\frac{A_{max}}{10}}-1}$<br>$Ω=\frac{ω_s}{ω_p}$（称为选择因子（Select Factor）），$M=√{\frac{\frac{1}{K_A}-1}{\frac{1}{K_r-1}}}$  </p><h3 id="切比雪夫高通滤波器"><a href="#切比雪夫高通滤波器" class="headerlink" title="切比雪夫高通滤波器"></a>切比雪夫高通滤波器</h3><p>将电感和电容对换就可以得到高通滤波器。<br>和原来的低通滤波器相比，新的高通滤波器$ω_p$相同，$ω_s’=\frac{ω_p^2}{ω_s}$。  </p><h3 id="设计方法"><a href="#设计方法" class="headerlink" title="设计方法"></a>设计方法</h3><ol><li>确定使用的滤波器类型  </li><li>找到能够拟合要求的转换方程（巴特沃斯/切比雪夫）  </li><li>根据波形图求出电路的最小阶数$n$  </li><li>查表找到CL的数值，并作反归一化  </li><li>连接电路  </li></ol>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>知识点与题型总结(计算机结构)</title>
    <link href="/2021/06/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/4.%20%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8E%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/"/>
    <url>/2021/06/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/4.%20%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%8E%E9%A2%98%E7%9B%AE%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="知识点与题型总结"><a href="#知识点与题型总结" class="headerlink" title="知识点与题型总结"></a>知识点与题型总结</h1><blockquote><p>针对Brunel University： 2021 EE2623    Computer Architecture and Interfacing 的期末复习笔记<br>Lecturer: Dr. Itagaki Takebumi（板垣　剛文）/Dr.Hongying Meng（孟鸿鹰）<br>总结 本课程常考到的题型、相关知识点和回答模板</p></blockquote><h2 id="二进制数的表达和运算"><a href="#二进制数的表达和运算" class="headerlink" title="二进制数的表达和运算"></a>二进制数的表达和运算</h2><h3 id="整数的表达方式"><a href="#整数的表达方式" class="headerlink" title="整数的表达方式"></a>整数的表达方式</h3><p>分为Signed和Unsigned两种，两者之间的转换是将源码进行翻转后+1得到其二补码。  </p><h3 id="加法运算"><a href="#加法运算" class="headerlink" title="加法运算"></a>加法运算</h3><p>加法运算时注意进位和溢出的问题，当进位值的前两位数值不同（为10或01）时代表运算符发生了溢出。  </p><h3 id="浮点数的表达方式"><a href="#浮点数的表达方式" class="headerlink" title="浮点数的表达方式"></a>浮点数的表达方式</h3><p>浮点数有两种表达规定：IEEE754和IBM。<br><strong>同一精度下，IBM能够表达的范围更大，最小值也更小，精度更高。</strong>  </p><h4 id="IEEE754的例外"><a href="#IEEE754的例外" class="headerlink" title="IEEE754的例外"></a><strong>IEEE754的例外</strong></h4><ul><li>NaN：Not a Number，是运算错误的表示，通常有如下几种情况运算结果是NaN：  <ol><li>$⨦0 ÷ ⨦0$  </li><li>$∞-∞$  </li><li>$⨦∞÷⨦∞$  </li><li>$⨦∞ × 0$  </li></ol></li><li>无穷:当指数部分全为1，小数部分不为0时，运算接过是无穷。规定如下的情况结果会是无穷：<ol><li>$∞ × ∞$  </li><li>$∞ + ∞$  </li><li>$nonezero ÷ 0$</li></ol></li><li>0：IEEE754中有正零和负零之分：两者的符号位不同，其余比特位全都是0，规定$n ÷ ∞=0$。  <h4 id="最大值和最小值-表示范围-精度"><a href="#最大值和最小值-表示范围-精度" class="headerlink" title="最大值和最小值/表示范围/精度"></a><strong>最大值和最小值/表示范围/精度</strong></h4>其最大值和最小值的求法是相同的。<br>最小数：  <script type="math/tex; mode=display">base^{-bias} × base^{-fraction}</script>最大数：  <script type="math/tex; mode=display">(base-base^{-fraction})×base^{(2^{exponent}-bias)}</script>fraction： 小数部分的总位数，bias：偏置，base：基数  exponent：指数部分的总位数<br>注：IEEE754中由于非正规数的要求，应当写作：$(base-base^{-fraction})×base^{(2^{exponent}-bias-1)}$</li></ul><h4 id="通信"><a href="#通信" class="headerlink" title="通信"></a><strong>通信</strong></h4><p>两者之间的通信数据需要经过转换，转换步骤为：  </p><ol><li>改变指数部分和小数部分的基底  </li><li>指数部分转化为不同的偏置下的新指数部分  </li></ol><p>由于IBM规定的精度大于IEEE754，因此从IBM转到IEEE754时数据的精度会有所损失。  </p><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h3 id="分级存储"><a href="#分级存储" class="headerlink" title="分级存储"></a>分级存储</h3><p>由于访问性和成本的限制，需要对内存进行分级：<br>Level 1： 需要和CPU同步工作，每一个时钟内要确保被CPU完全读取一次，因此储存容量非常的小。<br>Level 2： 需要和数据总线同步工作，用于缓冲与Level 1 内存的数据读取速度差异，但读取速度不需要与level 1相同。<br>外部存储： 外部的存储设备数据读取的速度比数据总线慢，因此需要缓冲来补偿速度差异，但是其成本相比于level 1和level 2更低，因此容量通常更大。  </p><h3 id="大小端"><a href="#大小端" class="headerlink" title="大小端"></a>大小端</h3><p>大端： 对于一个多字节的数据，其MSB首先被存储的硬件称之为大端。 大端模式下，MSB被存储在最小的地址上，后续比特依次存储在更大的地址上，LSB被存储在最大的地址上。<br>小端： 对于一个多字节的数据，其LSB首先被存储的硬件称之为大端。 大端模式下，LSB被存储在最小的地址上，后续比特依次存储在更大的地址上，MSB被存储在最大的地址上。  </p><h2 id="冯诺依曼架构-哈佛架构"><a href="#冯诺依曼架构-哈佛架构" class="headerlink" title="冯诺依曼架构/ 哈佛架构"></a>冯诺依曼架构/ 哈佛架构</h2><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><h4 id="冯诺依曼架构"><a href="#冯诺依曼架构" class="headerlink" title="冯诺依曼架构"></a><strong>冯诺依曼架构</strong></h4><ol><li>基本组成部分：CPU.ALU.I/O.Memory  </li><li>所有的组成部分都与线缆连接，这些线缆在逻辑上和物理上被整合到一起，称为总线。   </li><li>程序和数据都被存放在同一个内存当中，没有任何外部存储。  </li><li>控制器从内存中读取指令并运行。  </li></ol><h4 id="哈佛架构"><a href="#哈佛架构" class="headerlink" title="哈佛架构"></a><strong>哈佛架构</strong></h4><ol><li>物理上具有分别独立的信道和存储用于储存指令和数据。  </li><li>这两部分存储的实现方式、字长、时钟、地址、存储介质都可以不同。  </li></ol><h3 id="判断结构类型"><a href="#判断结构类型" class="headerlink" title="判断结构类型"></a>判断结构类型</h3><ol><li>给出结论  </li><li>说明有哪些结构特点是符合/不符合冯诺依曼架构的（所有的组成部分有无由总线连接）  </li><li>说明有哪些结构特点是符合/不符合哈佛架构的（指令和数据是否具有分别独立的存储）  </li></ol><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ol><li>哈佛架构允许在同一时间内读取指令和数据，且不会产生数据和指令的竞争。  </li><li>哈佛架构允许使用不同的存储介质和方法存储指令和数据。  </li><li>冯诺依曼架构中允许像访问数据一样访问指令，反之亦然。  </li><li>冯诺依曼架构中指令被视作数据，因此冯诺依曼架构允许从外部存储中加载程序。  </li></ol><h2 id="栈和缓存"><a href="#栈和缓存" class="headerlink" title="栈和缓存"></a>栈和缓存</h2><h3 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h3><ol><li>栈是一种数据结构，其遵循后进先出（LIFO）的原则。  </li><li>在现代计算机中，栈被应用于每一级内存。  </li><li>基本的两个对栈的操作：出栈和入栈。  </li></ol><h4 id="栈实例：逆波兰表示法计算器"><a href="#栈实例：逆波兰表示法计算器" class="headerlink" title="栈实例：逆波兰表示法计算器"></a><strong>栈实例：逆波兰表示法计算器</strong></h4><ol><li>表达式遵循从左到右，先运算数后运算符的顺序依次放入栈中。  </li><li>运算符入栈后，栈顶的两个运算数同运算符一起出栈，运算结果入栈。  </li><li>运算结果出栈。  </li></ol><h3 id="缓冲"><a href="#缓冲" class="headerlink" title="缓冲"></a>缓冲</h3><p>缓冲遵循先进先出（FIFO）的原则，分为两种缓冲：线形缓冲和环形缓冲，环形缓冲用于流媒体加载。<br>缓冲区的大小如果过大，初始化时间会比较长，需要将缓冲区填满的时间也比较长。<br>缓冲区如果过小，容易发生溢出，如果缓冲区不能够容纳所有的扰乱（Disruption），整个缓冲就会出错。  </p><h2 id="CPU的类型"><a href="#CPU的类型" class="headerlink" title="CPU的类型"></a>CPU的类型</h2><h3 id="CISC-Complex-Instruction-Set-Computer"><a href="#CISC-Complex-Instruction-Set-Computer" class="headerlink" title="CISC,Complex Instruction Set Computer"></a>CISC,Complex Instruction Set Computer</h3><p>每一条指令可以执行数条低级的操作（比如一条指令就可以实现内存加载和数学运算等）  </p><h3 id="RISC-Reduced-Instruction-Set-Computer"><a href="#RISC-Reduced-Instruction-Set-Computer" class="headerlink" title="RISC,Reduced Instruction Set Computer"></a>RISC,Reduced Instruction Set Computer</h3><p>大多数指令被限制成统一的长度和相似的结构，数学运算被限制在了CPU寄存器当中，只有对内存的读取和储存是分别的指令。<br>大多数的寄存机也是通用的，只有浮点寄存器仍然被专门化。<br>RISC指令集的计算机对pipline stages的平衡更佳，且允许更高的时钟频率，也更为高效。  </p><h3 id="MISC-Minimal-Instruction-Set-Computer"><a href="#MISC-Minimal-Instruction-Set-Computer" class="headerlink" title="MISC,Minimal Instruction Set Computer"></a>MISC,Minimal Instruction Set Computer</h3><p>数量非常少的操作和对应的操作码，指令集基本上是基于栈结构构造的。  </p><blockquote><p>ZISC和OISC在此略</p></blockquote><h2 id="串行连接和并行连接"><a href="#串行连接和并行连接" class="headerlink" title="串行连接和并行连接"></a>串行连接和并行连接</h2><h3 id="对比-1"><a href="#对比-1" class="headerlink" title="对比"></a>对比</h3><ol><li>通常串行传输比并行传输速度更快。  </li><li>串行传输不易出现Clock Skew（时钟信号在不同组件中到达的时间有差异）。   </li><li>串行传输占用空间更少。  </li><li>串行线路不容易受到周围线路的影响。  </li><li>串行线路避免内Crosstalk（数据在传输时对另外的线路产生影响）。  </li><li>串行线路由于Pin数更少，因此更便宜。  </li></ol><h2 id="并行算法"><a href="#并行算法" class="headerlink" title="并行算法"></a>并行算法</h2><h3 id="基本定律"><a href="#基本定律" class="headerlink" title="基本定律"></a>基本定律</h3><p>阿姆达尔定律：理想中对整个系统最大的改进是对系统中的部分进行改进。因此来自部分升级的影响总是有限的。  </p><h2 id="校验码"><a href="#校验码" class="headerlink" title="校验码"></a>校验码</h2><h3 id="汉明码"><a href="#汉明码" class="headerlink" title="汉明码"></a>汉明码</h3><p>在一串$d$位数据的$2^{n-1}$位上加入校验位，校验位的数量$c$满足：$2^c-1&gt;=d$。<br>第$n$个校验码的校验条件满足： 从第$2^n$位开始，使用偶校验检测$2^n$位，再跳过$2^n$位，再检测$2^n$位，重复直到检测最后一位。<br><strong>数据和校验码的位置序号是相反的</strong>,数据的比特位编号是从右到左依次减小，校验码的比特位是从右到左依次增大<br>缺点： 当只有一个校验码出错时，有50%的概率是数据出错，有50%的概率是校验码自己出错，无法确定。  有两个比特出错时可以检验，但无法校正。  </p><p>题目类型：  </p><ol><li>编码</li><li>解码</li><li>求未知数的值（注意可能性有很多种）</li></ol><p>汉明码的局限性：  </p><ol><li>当同时出现两个以上的比特位错误时，可能无法被检测到。  </li><li>出现一位比特错误时，在某些情况下无法判断是校验码还是数据发生了错误。  </li></ol><h3 id="其他的校验方式"><a href="#其他的校验方式" class="headerlink" title="其他的校验方式"></a>其他的校验方式</h3><p><strong>循环冗余校验（CRC,Cyclic Redundancy Checks）</strong><br>通过生成独特的哈希函数来检测比特位的改变，但不能检测出恶意引入的错误。  </p><p><strong>前项校验（Forward Error Correction）</strong><br>在卷积码和块码（通常是里德-所罗门码）之间做校验。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计算机结构与接口</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>PIC16F系列单片机接口程序设计经典案例</title>
    <link href="/2021/06/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/3.%20%E7%BB%8F%E5%85%B8PIC16F%E5%8D%95%E7%89%87%E6%9C%BA%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A1%88%E4%BE%8B/"/>
    <url>/2021/06/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/3.%20%E7%BB%8F%E5%85%B8PIC16F%E5%8D%95%E7%89%87%E6%9C%BA%E7%A8%8B%E5%BA%8F%E8%AE%BE%E8%AE%A1%E6%A1%88%E4%BE%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="PIC16F系列单片机接口程序设计经典案例"><a href="#PIC16F系列单片机接口程序设计经典案例" class="headerlink" title="PIC16F系列单片机接口程序设计经典案例"></a>PIC16F系列单片机接口程序设计经典案例</h1><blockquote><p>针对Brunel University：2021 EE2623    Computer Architecture and Interfacing 的期末复习笔记<br>Lecturer: Dr. Itagaki Takebumi（板垣　剛文）/Dr.Hongying Meng（孟鸿鹰）<br>程序仅包含主函数部分。  </p></blockquote><h2 id="输入接口"><a href="#输入接口" class="headerlink" title="输入接口"></a>输入接口</h2><h3 id="简单开关"><a href="#简单开关" class="headerlink" title="简单开关"></a>简单开关</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>&#123;<br>    <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">1</span>)==<span class="hljs-number">0</span>)<br>    &#123;<br>        delay(<span class="hljs-number">5</span>); <span class="hljs-comment">//避免switch bounce</span><br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">1</span>)==<span class="hljs-number">0</span>)<br>        &#123;<br>            ... <span class="hljs-comment">// 触发开关后的操作</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    adcon1 = <span class="hljs-number">0x06</span>; <span class="hljs-comment">//初始化</span><br>    trisa = <span class="hljs-number">11110000b</span>; <span class="hljs-comment">//设置porta一半输入一半输出</span><br>    porta = <span class="hljs-number">0xff</span>; <span class="hljs-comment">//porta=1111 1111</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>    &#123;<br>        clear_bit(porta,<span class="hljs-number">0</span>); <span class="hljs-comment">//porta=1111 1110 切换到第一行扫描</span><br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x10</span>)==<span class="hljs-number">0</span>) <span class="hljs-comment">// porta=1110 1110</span><br>        &#123;<br>            value = <span class="hljs-string">&#x27;1&#x27;</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x20</span>)==<span class="hljs-number">0</span>) <span class="hljs-comment">// 键盘：为0按下，为1弹起</span><br>        &#123;<br>            value = <span class="hljs-string">&#x27;2&#x27;</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x40</span>)==<span class="hljs-number">0</span>)<br>        &#123;<br>            value = <span class="hljs-string">&#x27;3&#x27;</span>;<br>        &#125;<br>        clear_bit(porta,<span class="hljs-number">1</span>); <span class="hljs-comment">//porta=1111 1101 切换到第二行扫描</span><br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x10</span>)==<span class="hljs-number">0</span>) <span class="hljs-comment">//porta=1110 1101</span><br>        &#123;<br>            value = <span class="hljs-string">&#x27;4&#x27;</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x20</span>)==<span class="hljs-number">0</span>)<br>        &#123;<br>            value = <span class="hljs-string">&#x27;5&#x27;</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>((porta&amp;<span class="hljs-number">0x40</span>)==<span class="hljs-number">0</span>)<br>        &#123;<br>            value = <span class="hljs-string">&#x27;6&#x27;</span>;<br>        &#125;<br>        ...<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="显示接口"><a href="#显示接口" class="headerlink" title="显示接口"></a>显示接口</h2><h3 id="LED"><a href="#LED" class="headerlink" title="LED"></a>LED</h3><h4 id="闪烁LED"><a href="#闪烁LED" class="headerlink" title="闪烁LED"></a>闪烁LED</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    trisb = <span class="hljs-number">0</span>;  <span class="hljs-comment">//设置portb为输出</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>    &#123;<br>        portb = <span class="hljs-number">0xff</span>; <span class="hljs-comment">// LED 灯： 为0熄灭，为1亮起</span><br>        delay(<span class="hljs-number">10</span>); <br>        portb = <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h4 id="流水灯"><a href="#流水灯" class="headerlink" title="流水灯"></a>流水灯</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    trisb = <span class="hljs-number">0</span>;  <span class="hljs-comment">//设置portb为输出</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>    &#123;<br>        portb = portb &lt;&lt; <span class="hljs-number">1</span>; <span class="hljs-comment">// 左移一位</span><br>        delay(<span class="hljs-number">10</span>); <br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="八位数码管"><a href="#八位数码管" class="headerlink" title="八位数码管"></a>八位数码管</h3><h4 id="一位数字显示"><a href="#一位数字显示" class="headerlink" title="一位数字显示"></a>一位数字显示</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">char</span> <span class="hljs-title">seg8</span><span class="hljs-params">(<span class="hljs-keyword">char</span> value)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">if</span>(value == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span>(<span class="hljs-number">0xc0</span>); <span class="hljs-comment">//八位数码管的比特位控制见讲义中图片</span><br>    <span class="hljs-keyword">if</span>(value == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span>(<span class="hljs-number">0xf9</span>); <span class="hljs-comment">// 八位数码管：为0亮，为1不亮</span><br>    ...<br>    <span class="hljs-keyword">if</span>(value &gt; <span class="hljs-number">9</span>) <span class="hljs-keyword">return</span>(<span class="hljs-number">0xff</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><h4 id="四位数显示"><a href="#四位数显示" class="headerlink" title="四位数显示"></a>四位数显示</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">display</span><span class="hljs-params">(<span class="hljs-keyword">int</span> value)</span></span><br><span class="hljs-function"></span>&#123;<br>    portb = seg8(value / <span class="hljs-number">1000</span>); <span class="hljs-comment">// 得到千位数字</span><br>    set_bit(porta,<span class="hljs-number">3</span>); <span class="hljs-comment">// porta负责控制哪一个八位数码管亮起（1为亮）</span><br>    delay(<span class="hljs-number">4</span>);<br>    value = value % <span class="hljs-number">1000</span>; <span class="hljs-comment">// 求余数</span><br>    clear_bit(porta,<span class="hljs-number">3</span>);<br>    portb = seg8(value / <span class="hljs-number">100</span>);<br>    set_bit(porta,<span class="hljs-number">2</span>)；<br>    delay(<span class="hljs-number">4</span>);<br>    value = value % <span class="hljs-number">100</span>;<br>    clear_bit(porta,<span class="hljs-number">1</span>);<br>    portb = seg8(value / <span class="hljs-number">10</span>);<br>    set_bit(porta,<span class="hljs-number">1</span>)；<br>    delay(<span class="hljs-number">4</span>);<br>    value = value % <span class="hljs-number">100</span>;<br>    clear_bit(porta,<span class="hljs-number">2</span>);<br>    portb = seg(value % <span class="hljs-number">10</span>);<br>    set_bit(porta,<span class="hljs-number">0</span>);<br>    delay(<span class="hljs-number">4</span>);<br>    clear_bit(porta,<span class="hljs-number">0</span>);<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="LCD"><a href="#LCD" class="headerlink" title="LCD"></a>LCD</h3><h4 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">lcd_init</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-comment">// 本质上来说是向portb重复发送一些东西，0x23和0x03可以自由设定。</span><br>    delay(<span class="hljs-number">10</span>);<br>    portb = <span class="hljs-number">0x23</span>;<br>    portb = <span class="hljs-number">0x03</span>;<br>    delay(<span class="hljs-number">10</span>);<br>    portb = <span class="hljs-number">0x23</span>;<br>    portb = <span class="hljs-number">0x03</span>;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><h4 id="发送指令"><a href="#发送指令" class="headerlink" title="发送指令"></a>发送指令</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">lcd_cmd</span><span class="hljs-params">(<span class="hljs-keyword">char</span> cmd)</span></span><br><span class="hljs-function"></span>&#123;<br>    portb = <span class="hljs-number">0x20</span>+((cmd&gt;&gt;<span class="hljs-number">4</span>)&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//开启（0x20）+指令头四位</span><br>    portb = (cmd&gt;&gt;<span class="hljs-number">4</span>)&amp;<span class="hljs-number">0x0f</span>; <span class="hljs-comment">//移动指令头四位到后四位，并清除原来头四位</span><br>    portb = <span class="hljs-number">0x20</span>+(cmd&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//开启（0x20）+指令后四位</span><br>    portb = cmd &amp; <span class="hljs-number">0x0f</span>; <span class="hljs-comment">//清除指令头四位</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h4 id="发送单个字符"><a href="#发送单个字符" class="headerlink" title="发送单个字符"></a>发送单个字符</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">lcd_char</span><span class="hljs-params">(<span class="hljs-keyword">char</span> c)</span></span><br><span class="hljs-function"></span>&#123;<br>    portb = <span class="hljs-number">0x30</span> + ((c&gt;&gt;<span class="hljs-number">4</span>)&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//开启（0x30）+指令头四位</span><br>    portb = <span class="hljs-number">0x10</span> + ((c&gt;&gt;<span class="hljs-number">4</span>)&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//移动指令头四位到后四位，并清除原来头四位</span><br>    portb = <span class="hljs-number">0x30</span> + (c&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//开启（0x30）+指令后四位</span><br>    portb = <span class="hljs-number">0x10</span> + (c&amp;<span class="hljs-number">0x0f</span>); <span class="hljs-comment">//清除指令头四位</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h4 id="显示字符串"><a href="#显示字符串" class="headerlink" title="显示字符串"></a>显示字符串</h4><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">display_message</span><span class="hljs-params">(<span class="hljs-keyword">const</span> <span class="hljs-keyword">char</span>* message)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> i = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span>(message[i] != <span class="hljs-number">0</span>)<br>    &#123;<br>        lcd_char(message[i]);<br>        i++;<br>    &#125;<br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    adcon1 = <span class="hljs-number">0x06</span>; <span class="hljs-comment">//设置adcon1接收来自portA的所有pins的数字信号</span><br>    trisa = <span class="hljs-number">0xf8</span>; <span class="hljs-comment">//设置portA的PA0,PA1,PA2为输出</span><br>    trisb = <span class="hljs-number">0x00</span>; <span class="hljs-comment">//设置PortB为输出</span><br>    lcd_cmd(<span class="hljs-number">1</span>); <span class="hljs-comment">//清除显示</span><br>    lcd_init(); <span class="hljs-comment">//初始化LCD</span><br>    lcd_cmd(<span class="hljs-number">0x38</span>); <span class="hljs-comment">//设置两行，8比特，5x7点阵</span><br>    lcd_cmd(<span class="hljs-number">0x0c</span>); <span class="hljs-comment">//设置打开显示，不显示光标</span><br>    lcd_cmd(<span class="hljs-number">0x06</span>); <span class="hljs-comment">//设置光标右移</span><br>    lcd_cmd(<span class="hljs-number">1</span>); <span class="hljs-comment">//清除显示</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>    &#123;<br>        lcd_cmd(<span class="hljs-number">0x80</span>); <span class="hljs-comment">// 第一行第一个光标位置的地址：0x00（地址）+0x80（指令）</span><br>        display_massage(<span class="hljs-string">&quot;Hello&quot;</span>);<br>        lcd_cmd(<span class="hljs-number">0xc0</span>); <span class="hljs-comment">// 第二行第一个光标位置的地址：0x40+0x80</span><br>        display_message(<span class="hljs-string">&quot;world&quot;</span>);<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><blockquote><p>LCD在显示数字时，一定要将数字转换为ASCII码，具体操作为：<code>display_char(&#39;0&#39;+number);</code>  </p></blockquote><h2 id="数模转换器-ADC"><a href="#数模转换器-ADC" class="headerlink" title="数模转换器 ADC"></a>数模转换器 ADC</h2><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">convert</span><span class="hljs-params">(<span class="hljs-keyword">char</span> channel)</span></span><br><span class="hljs-function"></span>&#123;<br>    adcon0 = <span class="hljs-number">11000001b</span> + (channel&lt;&lt;<span class="hljs-number">3</span>); <span class="hljs-comment">//设置channel</span><br>    set_bit(adcon0, GODONE); <span class="hljs-comment">// 清除GODONE，开始转换</span><br>    <span class="hljs-keyword">while</span>((adcon0 &amp; <span class="hljs-number">00000100b</span>) !=<span class="hljs-number">0</span>); <span class="hljs-comment">//等待到转换结束</span><br>    <span class="hljs-keyword">return</span>((adresh&lt;&lt;<span class="hljs-number">8</span>)+adresl);  <span class="hljs-comment">//返回得到的10比特值</span><br>&#125;<br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">main</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> value;<br>    adcon1 = <span class="hljs-number">0x80</span>; <span class="hljs-comment">//设置8个通道都是模拟信号</span><br>    adcon0 = <span class="hljs-number">11000001b</span>; <span class="hljs-comment">//设置转换速度</span><br>    <span class="hljs-keyword">while</span>(<span class="hljs-number">1</span>)<br>    &#123;<br>        value = covnert(<span class="hljs-number">4</span>);<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h2 id="计时器"><a href="#计时器" class="headerlink" title="计时器"></a>计时器</h2><h3 id="延迟函数（通用）"><a href="#延迟函数（通用）" class="headerlink" title="延迟函数（通用）"></a>延迟函数（通用）</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">delay</span><span class="hljs-params">(<span class="hljs-keyword">int</span> j)</span></span><br><span class="hljs-function"></span>&#123;<br>    <span class="hljs-keyword">int</span> i;<br>    <span class="hljs-keyword">for</span>(; j!=<span class="hljs-number">0</span>; j--)<br>    &#123;<br>        <span class="hljs-keyword">for</span>(i=<span class="hljs-number">8333</span>; i!=<span class="hljs-number">0</span>; i--); <span class="hljs-comment">//执行一次循环需要12us 8333*12≈0.1s</span><br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="利用溢出设置延迟"><a href="#利用溢出设置延迟" class="headerlink" title="利用溢出设置延迟"></a>利用溢出设置延迟</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">delay</span><span class="hljs-params">(<span class="hljs-keyword">int</span> x)</span></span><br><span class="hljs-function"></span>&#123;<br>    tmr0 = <span class="hljs-number">0</span>; <span class="hljs-comment">//重置timer0</span><br>    clear_bit(intcon,TOIF); <span class="hljs-comment">//重置溢出flag</span><br>    <span class="hljs-keyword">while</span>(x!=<span class="hljs-number">0</span>)<br>    &#123;<br>        <span class="hljs-keyword">while</span>((intcon &amp; <span class="hljs-number">00000100b</span>) == <span class="hljs-number">0</span>); <span class="hljs-comment">//等到溢出</span><br>        clear_bit(intcon, T0IF); <span class="hljs-comment">//重置溢出flag</span><br>        x--;<br>    &#125;<br><br>&#125;<br></code></pre></div></td></tr></table></figure><blockquote><p>如果Fosc/4=0.2s， Pre-scalar=1:32，x=61时，能造成 0.2x32x256usx61=0.0999424s的延迟  </p></blockquote><h2 id="中断程序"><a href="#中断程序" class="headerlink" title="中断程序"></a>中断程序</h2><h3 id="中断程序的时间控制"><a href="#中断程序的时间控制" class="headerlink" title="中断程序的时间控制"></a>中断程序的时间控制</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c"><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">interrupt</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    clear_bit(intcon,T0IF); <span class="hljs-comment">//重置溢出flag</span><br>    tmr0 = <span class="hljs-number">100</span>; <span class="hljs-comment">//给timer0设置初始值，此时一个中断运行的时间是256-100=156us</span><br>    ··· <span class="hljs-comment">// 中断内的其他操作</span><br>&#125;<br></code></pre></div></td></tr></table></figure><h3 id="PWM-控制马达"><a href="#PWM-控制马达" class="headerlink" title="PWM 控制马达"></a>PWM 控制马达</h3><figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs C">TMR0 = <span class="hljs-number">246</span>; <span class="hljs-comment">// 中断发生的时间为256-246=10us</span><br><span class="hljs-keyword">int</span> cycle; <span class="hljs-comment">// 一个周期的时间，时间设定在中断程序中设置</span><br><span class="hljs-keyword">int</span> pwm = <span class="hljs-number">400</span>; <span class="hljs-comment">// 一个周期内马达开启的时间，此处时间为400 x 10us=4ms</span><br><span class="hljs-function"><span class="hljs-keyword">void</span> <span class="hljs-title">interrupt</span><span class="hljs-params">()</span></span><br><span class="hljs-function"></span>&#123;<br>    cycle--;<br>    <span class="hljs-keyword">if</span>(cycle == <span class="hljs-number">0</span>)<br>    &#123;<br>        cycle = <span class="hljs-number">1000</span>; <span class="hljs-comment">// 此处一个周期的时间为1000 x 10us=10ms</span><br>    &#125;<br>        <span class="hljs-keyword">if</span>(pwm == <span class="hljs-number">0</span>) <span class="hljs-comment">// 如果pwm没有设置</span><br>        &#123;<br>            pulse = <span class="hljs-number">0</span>;<br>            clear_bit(portb,<span class="hljs-number">7</span>); <span class="hljs-comment">// 关闭转子，转子不会工作</span><br>        &#125;<br>        <span class="hljs-keyword">else</span><br>        &#123;<br>        pulse = pwm; <span class="hljs-comment">// 转子开启的时间</span><br>        set_bit(portb,<span class="hljs-number">7</span>); <span class="hljs-comment">// 开启转子</span><br>        &#125;  <br>    <span class="hljs-keyword">else</span><br>    &#123;<br>        <span class="hljs-keyword">if</span>(pulse != <span class="hljs-number">0</span>)<br>        &#123;<br>            pulse--; <span class="hljs-comment">// pulse 自减</span><br>        &#125;<br>        <span class="hljs-keyword">if</span>(pulse == <span class="hljs-number">0</span>)<br>        &#123;<br>            clear_bit(portb,<span class="hljs-number">7</span>); <span class="hljs-comment">//进入转子的关闭期</span><br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计算机结构与接口</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>附录2：冲激信号·卷积·傅里叶/拉普拉斯/Z变换的运算性质</title>
    <link href="/2021/06/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E9%99%84%E5%BD%952%EF%BC%9A%E5%8D%B7%E7%A7%AF%E3%80%81%E4%B8%89%E5%A4%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E8%BF%90%E7%AE%97%E6%80%A7%E8%B4%A8/"/>
    <url>/2021/06/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E9%99%84%E5%BD%952%EF%BC%9A%E5%8D%B7%E7%A7%AF%E3%80%81%E4%B8%89%E5%A4%A7%E5%8F%98%E6%8D%A2%E7%9A%84%E8%BF%90%E7%AE%97%E6%80%A7%E8%B4%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="附录2：冲激信号·卷积·傅里叶-拉普拉斯-Z变换的运算性质"><a href="#附录2：冲激信号·卷积·傅里叶-拉普拉斯-Z变换的运算性质" class="headerlink" title="附录2：冲激信号·卷积·傅里叶/拉普拉斯/Z变换的运算性质"></a>附录2：冲激信号·卷积·傅里叶/拉普拉斯/Z变换的运算性质</h1><h2 id="冲激信号的性质"><a href="#冲激信号的性质" class="headerlink" title="冲激信号的性质"></a>冲激信号的性质</h2><p>采样性质：<br>$δ(t)f(t)=f(0)δ(t)$<br>$∫δ(t)f(t)dt=f(0)$  </p><p>对称:<br>$δ(t)=δ(-t)$  </p><p>尺度变换：<br>$δ(at)=\frac{1}{\lvert a\rvert}δ(t)$</p><p>卷积性质：<br>$f(t)*δ(t)=δ(t)$  </p><p>$f(t)*δ(t-t_0)=f(t-t_0)$  </p><h4 id="冲激偶的性质"><a href="#冲激偶的性质" class="headerlink" title="冲激偶的性质"></a><strong>冲激偶的性质</strong></h4><p>尺度变换：<br>$δ’(at)=\frac{1}{|a|}\frac{1}{a}δ’(t)$<br>积分性质：<br>$∫δ’(t)dt=0$<br>$∫δ’(t)f(t)dt=-f’(0)$  </p><p>卷积性质：<br>$f(t)*δ’(t)=f’(t)$  </p><h2 id="卷积的性质"><a href="#卷积的性质" class="headerlink" title="卷积的性质"></a>卷积的性质</h2><p>交换律、结合律、分配律<br>微分性质：<br>$g’(t)=f(t)h’(t)=f’(t)*h(t)$  </p><p>$g^{(n-m)}(t)=f^{(n)}(t)*h^{(-m)}(t)=f^{(-m)}(t)*h^{(n)}(t)$  </p><p>任何函数都可以表示为自己和冲激函数的卷积：  </p><script type="math/tex; mode=display">f(t)=f(t)*δ(t)</script><h2 id="傅里叶-拉普拉斯-z变换的性质"><a href="#傅里叶-拉普拉斯-z变换的性质" class="headerlink" title="傅里叶/拉普拉斯/z变换的性质"></a>傅里叶/拉普拉斯/z变换的性质</h2><h3 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">对偶性</td><td style="text-align:center">$2πf(-ω)$</td><td style="text-align:center">$F(t)$</td></tr><tr><td style="text-align:center">尺度变换</td><td style="text-align:center">$f(at)$</td><td style="text-align:center">$\frac{1}{\lvert a\rvert}F(\frac{ω}{a})$</td></tr><tr><td style="text-align:center">时移</td><td style="text-align:center">$f(t-t_0)$</td><td style="text-align:center">$F(ω)e^{-jωt_0}$</td></tr><tr><td style="text-align:center">频移</td><td style="text-align:center">$f(t)e^{-jω_0t}$</td><td style="text-align:center">$F(ω+ω_0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域微分</td><td style="text-align:center">$f’(t)$</td><td style="text-align:center">$jωF(ω)$</td></tr><tr><td style="text-align:center">频域微分</td><td style="text-align:center">$-jtf(t)$</td><td style="text-align:center">$F’(ω)$</td></tr><tr><td style="text-align:center">时域积分</td><td style="text-align:center">$∫f(t)dt$</td><td style="text-align:center">$πF(0)δ(ω)+\frac{F(ω)}{jω}$</td></tr></tbody></table></div><h3 id="拉普拉斯变换"><a href="#拉普拉斯变换" class="headerlink" title="拉普拉斯变换"></a>拉普拉斯变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">时移</td><td style="text-align:center">$f(t-t_0)$</td><td style="text-align:center">$F(ω)e^{-t_0s}$</td></tr><tr><td style="text-align:center">频移</td><td style="text-align:center">$f(t)e^{-at}$</td><td style="text-align:center">$F(s+a)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域微分（一阶）</td><td style="text-align:center">$f’(t)$</td><td style="text-align:center">$sF(s)-f(0)$</td></tr><tr><td style="text-align:center">时域微分（二阶）</td><td style="text-align:center">$\frac{df^2(t)}{dt}$</td><td style="text-align:center">$s[sF(s)-f(0)]-f’(0)$</td></tr><tr><td style="text-align:center">频域微分</td><td style="text-align:center">$t^nf(t)$</td><td style="text-align:center">$(-1)^n\frac{d^nF(s)}{ds^n}$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center"></td><td style="text-align:center"></td></tr><tr><td style="text-align:center">时域积分</td><td style="text-align:center">$∫f(t)dt$</td><td style="text-align:center">$\frac{F(s)}{s}+\frac{f’(0)}{s}$</td></tr><tr><td style="text-align:center">频域积分</td><td style="text-align:center">$\frac{f(t)}{t}$</td><td style="text-align:center">$∫F(s)ds$</td></tr></tbody></table></div><p>初值定理: $f(0_+)\lim_{s→∞}sF(s)$<br>终值定理：$\lim_{t→∞}f(t)=\lim_{s→0}sF(s)$<br>卷积理论：$L[f(t)h(t)]=\frac{1}{2πj}F(s)*H(s)$  </p><h3 id="z变换"><a href="#z变换" class="headerlink" title="z变换"></a>z变换</h3><div class="table-container"><table><thead><tr><th style="text-align:center">注解</th><th style="text-align:center">时域</th><th style="text-align:center">频域</th></tr></thead><tbody><tr><td style="text-align:center">双侧时移</td><td style="text-align:center">$x(n+m)$</td><td style="text-align:center">$z^mX(z)$</td></tr><tr><td style="text-align:center">尺度变换（时域）</td><td style="text-align:center">$nx(n)$</td><td style="text-align:center">$-z\frac{dX(z)}{dz}$</td></tr><tr><td style="text-align:center">尺度变换(z域)</td><td style="text-align:center">$a^nx(n)$</td><td style="text-align:center">$X(\frac{z}{a})$</td></tr></tbody></table></div><p>初值定理: $x(0_+)\lim_{x→∞}sX(z)$<br>终值定理：$\lim_{n→∞}x(n)=\lim_{z→1}(z-1)X(z)$<br>卷积理论：$Z[x(n)*h(n)]=X(z)H(z)$  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>附录1：冲激函数的特性·常见信号的傅里叶/拉普拉斯/Z变换</title>
    <link href="/2021/06/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E9%99%84%E5%BD%951%EF%BC%9A%E5%B8%B8%E8%A7%81%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/06/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/%E9%99%84%E5%BD%951%EF%BC%9A%E5%B8%B8%E8%A7%81%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="常见信号的傅里叶-拉普拉斯-Z变换"><a href="#常见信号的傅里叶-拉普拉斯-Z变换" class="headerlink" title="常见信号的傅里叶/拉普拉斯/Z变换"></a>常见信号的傅里叶/拉普拉斯/Z变换</h1><h2 id="冲激函数的特性"><a href="#冲激函数的特性" class="headerlink" title="冲激函数的特性"></a>冲激函数的特性</h2><h3 id="冲激函数的特性-1"><a href="#冲激函数的特性-1" class="headerlink" title="冲激函数的特性"></a>冲激函数的特性</h3><div class="table-container"><table><thead><tr><th style="text-align:center">特性</th><th style="text-align:center">公式</th></tr></thead><tbody><tr><td style="text-align:center">赋值性</td><td style="text-align:center">$∫δ(t)f(t)dt=f(0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">$f(t)δ(t)=f(0)δ(t)$</td></tr><tr><td style="text-align:center">偶函数</td><td style="text-align:center">$δ(t)=δ(-t)$</td></tr><tr><td style="text-align:center">缩放</td><td style="text-align:center">$δ(at)=\frac{1}{ ⃒  a ⃒ }δ(t)$</td></tr></tbody></table></div><h3 id="冲激偶函数的特性"><a href="#冲激偶函数的特性" class="headerlink" title="冲激偶函数的特性"></a>冲激偶函数的特性</h3><div class="table-container"><table><thead><tr><th style="text-align:center">特性</th><th style="text-align:center">公式</th></tr></thead><tbody><tr><td style="text-align:center">赋值性</td><td style="text-align:center">$∫δ’(t)f(t)dt=-f’(0)$</td></tr><tr><td style="text-align:center"></td><td style="text-align:center">$f(t)δ’(t)=f(0)δ’(t)-f’(0)δ(t)$</td></tr><tr><td style="text-align:center">奇函数</td><td style="text-align:center">$δ’(t)=-δ’(t)$</td></tr></tbody></table></div><h2 id="常见函数的傅里叶变换"><a href="#常见函数的傅里叶变换" class="headerlink" title="常见函数的傅里叶变换"></a>常见函数的傅里叶变换</h2><blockquote><p>傅里叶变换：$F(ω)=∫f(t)e^{-jωt}dt$<br>傅里叶反变换：$f(t)=∫F(ω)e^{jωt}dω$  </p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域函数$f(t)$</th><th style="text-align:center">频域函数$F(ω)$</th></tr></thead><tbody><tr><td style="text-align:center">门函数</td><td style="text-align:center">$E[u(t+\frac{τ}{2})-u(t-\frac{τ}{2})]$ <br>$E,-\frac{τ}{2}&lt;t&lt;\frac{τ}{2}$</td><td style="text-align:center">$\frac{2Esin(ω\frac{τ}{2})}{ω}=EτSa(\frac{ωτ}{2})$</td></tr><tr><td style="text-align:center">直流信号/常函数</td><td style="text-align:center">$E$</td><td style="text-align:center">$2πEδ(ω)$</td></tr><tr><td style="text-align:center">冲激函数</td><td style="text-align:center">$δ(t)$</td><td style="text-align:center">$1$</td></tr><tr><td style="text-align:center">冲激偶函数</td><td style="text-align:center">$δ’(t)$</td><td style="text-align:center">$jω$</td></tr><tr><td style="text-align:center">单侧指数函数</td><td style="text-align:center">$Ee^{-at}u(t)$</td><td style="text-align:center">$\frac{E}{jω+a}$</td></tr><tr><td style="text-align:center">-</td><td style="text-align:center">-</td><td style="text-align:center">-</td></tr><tr><td style="text-align:center">周期冲激序列</td><td style="text-align:center">$δ_T(t)$</td><td style="text-align:center">$ω_1δ(ω-nω_1)$</td></tr><tr><td style="text-align:center">周期方波/门函数序列</td><td style="text-align:center">-</td><td style="text-align:center">$EτSa(\frac{ωτ}{2})ω_1δ(ω-nω_1)$</td></tr><tr><td style="text-align:center">正弦函数</td><td style="text-align:center">$sin(ω_0t)$</td><td style="text-align:center">$-jπδ(ω-ω_0)+jπδ(ω+ω_0)$</td></tr><tr><td style="text-align:center">余弦函数</td><td style="text-align:center">$cos(ω_0t)$</td><td style="text-align:center">$πδ(ω-ω_0)+πδ(ω+ω_0)$</td></tr></tbody></table></div><h2 id="常见函数的拉普拉斯变换"><a href="#常见函数的拉普拉斯变换" class="headerlink" title="常见函数的拉普拉斯变换"></a>常见函数的拉普拉斯变换</h2><blockquote><p>拉普拉斯变换：$L(s)=∫f(t)e^{-st}dt$<br>拉普拉斯反变换：$F(s)=∑\frac{k}{s-p}↔f(t)=∑ke^{pt}$ （一阶实极点）  </p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域函数$f(t)$</th><th style="text-align:center">频域函数$L(s)$</th></tr></thead><tbody><tr><td style="text-align:center">阶跃函数</td><td style="text-align:center">$u(t)$</td><td style="text-align:center">$\frac{1}{s}$</td></tr><tr><td style="text-align:center">冲激函数</td><td style="text-align:center">$δ(t)$</td><td style="text-align:center">$1$</td></tr><tr><td style="text-align:center">单侧指数函数</td><td style="text-align:center">$Ee^{-at}u(t)$</td><td style="text-align:center">$\frac{E}{s+a}$</td></tr><tr><td style="text-align:center">斜坡函数</td><td style="text-align:center">$tu(t)$</td><td style="text-align:center">$\frac{1}{s^2}$</td></tr><tr><td style="text-align:center">正弦函数</td><td style="text-align:center">$sin(ω_0t)$</td><td style="text-align:center">$\frac{1}{s^2+ω_0^2 }$</td></tr><tr><td style="text-align:center">余弦函数</td><td style="text-align:center">$cos(ω_0t)$</td><td style="text-align:center">$\frac{s}{s^2+ω_0^2}$</td></tr></tbody></table></div><h2 id="常见序列的Z变换"><a href="#常见序列的Z变换" class="headerlink" title="常见序列的Z变换"></a>常见序列的Z变换</h2><blockquote><p>Z变换：$X(z)=∑x(n)z^{-n}$<br>Z反变换：$X(z)=z(\frac{A}{z-p_i})⟷x(n)=∑A(p_i)^n$(一阶单极点)  </p></blockquote><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">时域序列$x(n)$</th><th style="text-align:center">频域序列$X(z)$</th><th style="text-align:center">收敛域</th></tr></thead><tbody><tr><td style="text-align:center">单位冲激序列</td><td style="text-align:center">$δ(n)$</td><td style="text-align:center">$1$</td><td style="text-align:center">整个z域</td></tr><tr><td style="text-align:center">单位阶跃序列</td><td style="text-align:center">$u(n)$</td><td style="text-align:center">$\frac{z}{z-1}$</td><td style="text-align:center">$⃒ z ⃒ &lt;1$</td></tr><tr><td style="text-align:center">斜坡序列</td><td style="text-align:center">$nu(n)$</td><td style="text-align:center">$\frac{z}{(z-1)^2}$</td><td style="text-align:center">$⃒ z ⃒ &lt;1$</td></tr><tr><td style="text-align:center">单侧指数序列</td><td style="text-align:center">$a^nu(n)$</td><td style="text-align:center">$\lim_{n→∞}\frac{1-(\frac{a}{z})^{n+1}}{1-\frac{a}{z}}$</td><td style="text-align:center">$⃒ z ⃒ &gt;⃒ a ⃒$</td></tr><tr><td style="text-align:center">单侧正弦序列</td><td style="text-align:center">$sin(ω_0n)u(n)$</td><td style="text-align:center">$\frac{zsinω_0}{z^2-2zcosω_0+1}$</td><td style="text-align:center">$⃒ z ⃒ &gt;1$</td></tr><tr><td style="text-align:center">单侧余弦序列</td><td style="text-align:center">$cos(ω_0n)u(n)$</td><td style="text-align:center">$\frac{z(z-cosω_0)}{z^2-2zcosω_0+1}$</td><td style="text-align:center">$⃒ z ⃒ &gt;1$</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>11. 滤波器设计</title>
    <link href="/2021/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/11.%20%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%AE%BE%E8%AE%A1/"/>
    <url>/2021/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/11.%20%E6%BB%A4%E6%B3%A2%E5%99%A8%E8%AE%BE%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="滤波器设计"><a href="#滤波器设计" class="headerlink" title="滤波器设计"></a>滤波器设计</h1><h2 id="失真"><a href="#失真" class="headerlink" title="失真"></a>失真</h2><p>系统方程$H(s)$可以写作：</p><script type="math/tex; mode=display">H(jω)=|H(jω)|e^{jϕ(jω)}</script><p>即幅值和相位两部分。系统输出的实质是对系统方程的频率和赋值用$E(jω)$进行加权。<br>如果不同频率信号的幅值加权或相位校正不同，则输出波形将与输入波形形状不同，从而导致失真。<br>失真分为两种类型：<br>线性失真：信号的幅值和相位发生变化，但是没有引入新的频率信号。<br>非线性失真：引入了新的频率信号。  </p><h2 id="滤波器波形"><a href="#滤波器波形" class="headerlink" title="滤波器波形"></a>滤波器波形</h2><p>实际的滤波器波形如图表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210531161932.png" alt=""><br>滤波器波形的四个参数：</p><ol><li>通带边缘（Passband edge,$ω_p$）</li><li>最大允许变化（Maximum allowed variation,$A_max$）</li><li>阻带边缘（Stopband edge,$ω_s$）</li><li>最小阻带衰减要求（Minimum required stopband attenuation,$A_min$）</li></ol><h2 id="滤波器设计-1"><a href="#滤波器设计-1" class="headerlink" title="滤波器设计"></a>滤波器设计</h2><h3 id="低通-滤波器类型"><a href="#低通-滤波器类型" class="headerlink" title="(低通)滤波器类型"></a>(低通)滤波器类型</h3><h4 id="巴特沃斯滤波器"><a href="#巴特沃斯滤波器" class="headerlink" title="巴特沃斯滤波器"></a><strong>巴特沃斯滤波器</strong></h4><p>传输函数：</p><script type="math/tex; mode=display">|T(jω)|=\frac{1}{√(1+ɛ^2(\frac{ω}{ω_p})^(2n))}</script><p>其中：$n≥\frac{logM}{logΩ}$为电路阶数，$ɛ=√{10^{\frac{A_{max}}{10}}-1}$<br>$Ω=\frac{ω_s}{ω_p}$，$M=√{\frac{\frac{1}{K_A}-1}{\frac{1}{K_r-1}}}$</p><p>滤波器特点：  </p><ol><li>没有波纹</li><li>$|ω_s-ω_p|$较大，无法立刻停止</li></ol><h4 id="切比雪夫滤波器"><a href="#切比雪夫滤波器" class="headerlink" title="切比雪夫滤波器"></a><strong>切比雪夫滤波器</strong></h4><p>传输函数：</p><script type="math/tex; mode=display">|T(jω)|=\frac{1}{√1+ɛ^2C^2_n(ω/ω_p)}</script><p>其中：$n≥\frac{cosh^{-1}M}{cosh^{-1}Ω}$为电路阶数，$ɛ=√{10^{\frac{A_{max}}{10}}-1}$<br>$Ω=\frac{ω_s}{ω_p}$，$M=√{\frac{\frac{1}{K_A}-1}{\frac{1}{K_r-1}}}$  </p><blockquote><p>将电感和电容对换就可以得到高通滤波器。  </p></blockquote><h3 id="设计方法"><a href="#设计方法" class="headerlink" title="设计方法"></a>设计方法</h3><ol><li>确定使用的滤波器类型  </li><li>找到能够拟合要求的转换方程（巴特沃斯/切比雪夫）  </li><li>根据波形图求出电路的最小阶数$n$  </li><li>查表找到CL的数值，并作反归一化  </li><li>连接电路  </li></ol>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>10. 反馈系统</title>
    <link href="/2021/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/10.%20%E5%8F%8D%E9%A6%88%E7%B3%BB%E7%BB%9F/"/>
    <url>/2021/05/31/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/10.%20%E5%8F%8D%E9%A6%88%E7%B3%BB%E7%BB%9F/</url>
    
    <content type="html"><![CDATA[<h1 id="反馈系统"><a href="#反馈系统" class="headerlink" title="反馈系统"></a>反馈系统</h1><h2 id="反馈系统结构"><a href="#反馈系统结构" class="headerlink" title="反馈系统结构"></a>反馈系统结构</h2><p>(负)反馈系统框图可以用下图表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210531144620.png" alt=""><br>$G(s)$是前向系统，$H(s)$是反向系统，$G(s)H(s)$称为开环传递函数，整个系统的闭环传递函数可以写作：  </p><script type="math/tex; mode=display">CLTF=\frac{G(s)}{1+G(s)H(s)}</script><p>$1+G(s)H(s)=0$称为闭环传递函数的特征方程。  </p><blockquote><p>放大器的闭环增益就是一个闭环传递函数。  </p></blockquote><p><strong>反馈系统通过$1+G(s)H(s)$减少了系统对噪声的敏感度，但是相应地，系统增益也同样被减小。</strong>  </p><h2 id="根轨迹"><a href="#根轨迹" class="headerlink" title="根轨迹"></a>根轨迹</h2><p>为了更好的研究开环传输函数$G(s)H(s)$对反馈系统的影响，用根轨迹图（Root locus diagram）来表现当开环传输函数中的某些人为设定的参数发生改变时，闭环传输函数的极点在s域中的变化情况。<br>得到根轨迹图的步骤：  </p><ol><li>通过闭环传递函数的特征方程解出s与参数$K$之间的关系。</li><li>在s域中标出零点。  </li><li>在s域中标出极点，即$K=0$的位置。  </li><li>增加K的值，在S域中标出一系列的s的位置，并以（$K=x$）在每个点上方进行标注。  </li><li>判断$k→∞$时，s的移动方向，并用箭头标注。  </li></ol>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>9. 系统方程</title>
    <link href="/2021/05/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/9.%20%E7%B3%BB%E7%BB%9F%E6%96%B9%E7%A8%8B/"/>
    <url>/2021/05/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/9.%20%E7%B3%BB%E7%BB%9F%E6%96%B9%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="系统方程"><a href="#系统方程" class="headerlink" title="系统方程"></a>系统方程</h1><h2 id="系统方程概述"><a href="#系统方程概述" class="headerlink" title="系统方程概述"></a>系统方程概述</h2><p>对于一个有输入和输出的系统，可以通过观察系统输入和输出的关系来建立描述系统的方程，在拉普拉斯变换的s域下，系统方程可以表述为<strong>系统输出与输入之比</strong>：  </p><script type="math/tex; mode=display">H(s)=\frac{R(s)}{E(s)}</script><p>也可以按照时域分析方法中的理解，当$e(t)=δ(t)$时，其拉普拉斯变换为1，因此系统方程也是<strong>输入为冲激函数时的系统输出</strong>。</p><h3 id="类型"><a href="#类型" class="headerlink" title="类型"></a>类型</h3><h4 id="策动点方程"><a href="#策动点方程" class="headerlink" title="策动点方程"></a><strong>策动点方程</strong></h4><p>当系统是一个单口网络（One-port network，输入和输出在同一个端口的系统）时，系统方程称为策动点方程(Driving point funtion)。对于电路分析，单口网络的系统方程可以是$H(s)=\frac{I(s)}{V(s)}$，也可以是$H(s)=\frac{V(s)}{I(s)}$。</p><h4 id="转换方程"><a href="#转换方程" class="headerlink" title="转换方程"></a><strong>转换方程</strong></h4><p>当系统是一个两口网络时，此时的系统方程称为转换方程（Transfer function）。分析时需要找到电路的输入和输出，作比即可得到转换方程。   </p><h3 id="连接"><a href="#连接" class="headerlink" title="连接"></a>连接</h3><h4 id="并联"><a href="#并联" class="headerlink" title="并联"></a><strong>并联</strong></h4><p>如果两个系统并联，新的系统方程为：$h(t)=h_1(t)+h_2(t)$，在s域内：  </p><script type="math/tex; mode=display">H(s)=H_1(s)+H_2(s)</script><h4 id="串联-级联"><a href="#串联-级联" class="headerlink" title="串联/级联"></a><strong>串联/级联</strong></h4><p>如果两个系统串联，新的系统方程为：$h(t)=h_1(t)*h_2(t)$，在s域内：  </p><script type="math/tex; mode=display">H(s)=H_1(s)H_2(s)</script><blockquote><p>举例：放大器的并联和串联</p></blockquote><h2 id="系统方程的结构"><a href="#系统方程的结构" class="headerlink" title="系统方程的结构"></a>系统方程的结构</h2><p>如之前提到的拉普拉斯反变换和z反变换，由于系统输入和输出在s域内都以多项式表示，系统方程自然是两个多项式的比值：</p><script type="math/tex; mode=display">H(s)=\frac{R(s)}{E(s)}=K\frac{Π(s-z_i)}{Π(s-p_k)}</script><p>其中$p_i$称为系统方程的极点，$z_k$称为系统方程的零点。<br>在电路分析中，极点描述的的对象是电路中电容和电感的个数，即系统方程的阶数。<br>同理，离散系统的方程也可以写作两个多项式的比：</p><script type="math/tex; mode=display">H(z)=\frac{∑b_rz^{-r}}{∑a_kz^{-k}}=A_0+∑\frac{A_kz}{z-p_k}</script><h3 id="强迫响应和自由响应"><a href="#强迫响应和自由响应" class="headerlink" title="强迫响应和自由响应"></a>强迫响应和自由响应</h3><p>如果将系统的输入$E(s)$以多项式表示：$E(s)=\frac{Π(s-z_l)}{Πs-p_k}$，系统方程$H(s)=\frac{Π(s-z_j)}{Πs-p_i}$，由系统的零输入响应$R(s)=E(s)H(s)$:  </p><script type="math/tex; mode=display">R(s)=∑\frac{A_k}{s-p_k}+∑\frac{A_i}{s-p_i}</script><p>经过拉普拉斯反变换：  </p><script type="math/tex; mode=display">r(t)=∑A_ke^{p_kt}u(t)+∑A_ie^{p_it}u(t)</script><p>可以发现$r(t)$受到两部分的影响：系统方程和输入信号：<strong>称$r(t)$受输入影响的部分为强迫响应，受系统方程影响的部分为自由响应。</strong>  </p><h3 id="瞬态响应和稳态响应"><a href="#瞬态响应和稳态响应" class="headerlink" title="瞬态响应和稳态响应"></a>瞬态响应和稳态响应</h3><p>分析时域中的$r(t)$构成，表达式的常数项不会受到$t$变化的影响，<strong>$r(t)$的常数项称为稳态响应</strong>。<strong>$r(t)$中受到$t$影响的部分称为瞬态响应。</strong></p><h2 id="系统稳定性"><a href="#系统稳定性" class="headerlink" title="系统稳定性"></a>系统稳定性</h2><h3 id="s域图像"><a href="#s域图像" class="headerlink" title="s域图像"></a>s域图像</h3><p>由$s=σ+jω$,因此可以将任何一个值在以实部$σ$为横轴，虚部$jω$为纵轴的s域中的一个点来表示。<br>在s域图像中，系统方程的极点以×表示，系统方程的零点以◯表示。  </p><h3 id="连续系统的稳定性"><a href="#连续系统的稳定性" class="headerlink" title="连续系统的稳定性"></a>连续系统的稳定性</h3><p>在时域中有：</p><script type="math/tex; mode=display">∫|h(t)|dt<∞</script><p>满足上述条件的系统是稳定系统。<br>在s域中，如果所有的极点都在s域图像的左侧，即$σ&lt;0$，满足系统稳定的条件。当所有极点都在虚轴上且为一阶时，这个系统是严格的稳定系统。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210531130659.png" alt=""> </p><h3 id="离散系统的稳定性"><a href="#离散系统的稳定性" class="headerlink" title="离散系统的稳定性"></a>离散系统的稳定性</h3><p>由$z=e^{sT}$，当$s=0$时，$z=1$，因此如果极点在z域的单位圆内，离散系统是稳定系统，在单位圆外，系统是非稳定系统。  </p><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210531133708.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>计算机接口程序（C语言）</title>
    <link href="/2021/05/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/2.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%A8%8B%E5%BA%8F/"/>
    <url>/2021/05/28/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/2.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E6%8E%A5%E5%8F%A3%E7%A8%8B%E5%BA%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="计算机接口程序（C语言）"><a href="#计算机接口程序（C语言）" class="headerlink" title="计算机接口程序（C语言）"></a>计算机接口程序（C语言）</h1><blockquote><p>讲义复习<br>BUL EE2623 Computer Architecture and Interface<br>Dr. Hongying Meng   </p></blockquote><h2 id="单片机程序概要"><a href="#单片机程序概要" class="headerlink" title="单片机程序概要"></a>单片机程序概要</h2><h3 id="程序的主要结构"><a href="#程序的主要结构" class="headerlink" title="程序的主要结构"></a>程序的主要结构</h3><p>单片机程序的主要结构：<br>对于任何的单片机程序，其算法结构由三部分组成：  </p><ol><li>重置（Reset）：清空单片机现有的内容并重置单片机设置。  </li><li>初始化（Initialise）：声明变量，初始化变量值，指定寄存器的地址或初始化特殊寄存器的值等，用于初始化单片机和接口。  </li><li>主程序（Main Program）:单片机执行的主要内容。<br><strong>单片机的主程序必须写在一个死循环内（<code>while(1) &#123;&#125;</code>）</strong></li></ol><h3 id="数据类型"><a href="#数据类型" class="headerlink" title="数据类型"></a>数据类型</h3><p>编译器只支持三种数据类型： Unsigned integers, char, int</p><blockquote><p>单片机不支持float 和 double 两种数据类型, PIC系列也不支持Signed integers.<br>int 和 char的区别在于：编译器只支持两个int变量做数学/逻辑运算，而支持多个char变量做数学/逻辑运算。</p></blockquote><h3 id="单片机语法"><a href="#单片机语法" class="headerlink" title="单片机语法"></a>单片机语法</h3><p>除了C语言常见的语法之外，单片机还支持如下的特殊表达：  </p><div class="table-container"><table><thead><tr><th style="text-align:center">表达</th><th style="text-align:left">说明</th><th style="text-align:center">举例</th></tr></thead><tbody><tr><td style="text-align:center"><code>&gt;&gt;</code></td><td style="text-align:left">比特位右移</td><td style="text-align:center"><code>var&gt;&gt;2</code></td></tr><tr><td style="text-align:center"><code>&lt;&lt;</code></td><td style="text-align:left">比特位左移</td><td style="text-align:center"><code>var&lt;&lt;1</code></td></tr><tr><td style="text-align:center"><code>set_bit(file,bit)</code></td><td style="text-align:left">将制定寄存器（File）的制定比特位（bit）设置为1</td><td style="text-align:center"><code>set_bit(porta,0)</code></td></tr><tr><td style="text-align:center"><code>clear_bit(file,bit)</code></td><td style="text-align:left">将制定寄存器（File）的制定比特位（bit）设置为0</td><td style="text-align:center"><code>clear_bit(porta,4)</code></td></tr><tr><td style="text-align:center"><code>for(init;cond;mod)&#123;&#125;</code></td><td style="text-align:left">循环，内部依次是循环变量的初始值、执行循环的条件、对循环变量的操作</td><td style="text-align:center"><code>for(int i=0; i&lt;10 ; i++)&#123;&#125;</code></td></tr><tr><td style="text-align:center"><code>asm&#123;&#125;</code></td><td style="text-align:left">汇编语言指令（Boost C）</td><td style="text-align:center"><code>asm &#123; movlw 0 &#125;</code></td></tr><tr><td style="text-align:center"><code>void interrupt()&#123;&#125;</code></td><td style="text-align:left">中断程序</td><td style="text-align:center"><code>void interrupt()&#123;if(portb==0)&#123;set_bit&#123;porta,3&#125;&#125;&#125;</code></td></tr></tbody></table></div><h3 id="时间控制"><a href="#时间控制" class="headerlink" title="时间控制"></a>时间控制</h3><p>对Boost C编译器，执行一次循环（不含循环内的操作）大约需要12条汇编指令，<strong>执行一次循环大约需要12us</strong>.</p><h2 id="开关"><a href="#开关" class="headerlink" title="开关"></a>开关</h2><p>开关的种类和连接方式有非常多种：<br>对于简单电路连接的开关，需要对其进行电路分析以判断输入进单片机（pin）的电压是5v（1）还是0v（0）。<br>对于旋钮式开关，每一个档位对应了一种比特的情况。比如假设有0-F共16个档位，开关需要连接一个port的4个pin（即需要用4个比特位来反馈），每一个档位都对应了0000到1111的一种情况。  </p><h3 id="Switch-Bounce"><a href="#Switch-Bounce" class="headerlink" title="Switch Bounce"></a>Switch Bounce</h3><p>开关被按下后弹起的瞬间，其开关的值处于不确定状态，这种情况称为Switch Bounce，通常是$10^{-3}s$ 到 $2 × 10^{-3}s$左右。<br>避免Switch Bounce的方法：  </p><ol><li>在pin前加入一个由RC组成的低通滤波器。  </li><li>在pin前使用两个交叉连接的NAND门。  </li><li>在程序中用一个delay跨过Switch Bounce的时间。  </li></ol><h2 id="键盘"><a href="#键盘" class="headerlink" title="键盘"></a>键盘</h2><h3 id="物理原理"><a href="#物理原理" class="headerlink" title="物理原理"></a>物理原理</h3><p>当某个键被按下的时候，该按键所在的行列由键盘的按下被导通。  </p><h3 id="程序思路"><a href="#程序思路" class="headerlink" title="程序思路"></a>程序思路</h3><ol><li>将行作为port的输入/输出，列作为port的输出/输入（用tris进行控制）</li><li><strong>初始化port内所有比特位的值为1，当按键被按下，该按键所对应的两个比特位的值被清零。</strong></li><li>先检查每一行/列是否有按键被按下（if &amp;），如果该行/列有按键被按下，转而检测该行/列的每一列/行。</li></ol><h2 id="LED灯-发光二极管"><a href="#LED灯-发光二极管" class="headerlink" title="LED灯/发光二极管"></a>LED灯/发光二极管</h2><h3 id="物理原理-1"><a href="#物理原理-1" class="headerlink" title="物理原理"></a>物理原理</h3><p>发光二极管处于正向偏置时，其两端电压处于不同值，发光二极管会发出不同颜色的光（比如红色是1.6V，白色是3.5V）。<br>发光二极管通常支持的最大电压在3.5V左右，而单片机的输出电压最大可到5V，为了防止二极管被击穿，应该在二极管前加一个电阻以分压。<br>此外，PIC开发板上的单个pin的供电可到25mA，但是所有pin上的最大电流不能超过200mA，因此需要用BJT晶体管等方法在二极管的输出端限流。<br>在PIC开发板上，8个LED灯连接到PortA上，对应了PortA从PA0到PA7的8个比特位。<br><strong>当比特位为1时，对应的LED灯亮起。</strong>  </p><h3 id="程序思路-1"><a href="#程序思路-1" class="headerlink" title="程序思路"></a>程序思路</h3><p>只需要使用<code>trisa</code>将指定LED灯对应的比特位设置为输出后，设定该比特位的值为1即可控制该LED灯亮起。  </p><h2 id="7-8-位数码管"><a href="#7-8-位数码管" class="headerlink" title="7(8)位数码管"></a>7(8)位数码管</h2><h3 id="物理原理-2"><a href="#物理原理-2" class="headerlink" title="物理原理"></a>物理原理</h3><p>八位数码管的每一个显示笔划（Segment）（7位数码管不包括小数点显示）对应了一个比特位，<strong>当该比特位的值为0时，该笔画亮起</strong>。 </p><h3 id="程序思路-2"><a href="#程序思路-2" class="headerlink" title="程序思路"></a>程序思路</h3><p>创建一个数组其对应位置上的值为该数字应当亮起的显示笔画的比特值，检测输入的值$x$，然后将数组第$x$位上的值传出到port即可。<br>对于多个数码管组成的阵列：</p><ol><li>用另一个port来控制使用哪些数码管，当比特位为1时，对应的八位数码管亮起。  </li><li>每一个数码管会在很短的时间亮起熄灭，然后下一个数码管重复，当循环闪亮的频率快到人眼无法识别的时候，表现为所有的数码管都同时亮起。  </li><li>在一次循环之后，微控制器被释放然后计算新的显示值。  </li></ol><h2 id="LCD-液晶显示面板"><a href="#LCD-液晶显示面板" class="headerlink" title="LCD/液晶显示面板"></a>LCD/液晶显示面板</h2><h3 id="结构与原理"><a href="#结构与原理" class="headerlink" title="结构与原理"></a>结构与原理</h3><h4 id="针脚（Pin）"><a href="#针脚（Pin）" class="headerlink" title="针脚（Pin）"></a><strong>针脚（Pin）</strong></h4><p>液晶显示面板共有11个pin，其中8个用于传输8 bit数据，3个用于控制，这三个pin为:   </p><ul><li>RS: Register select，选择寄存器为指令寄存器还是d数据寄存器。  </li><li>R/W：Read/Write， 控制数据流的方向是从单片机到LED（通常）还是从LED到单片机。  </li><li>E：Enable，控制数据发送的速度：E对应的值每发生一次变化（10），就会发生1bit的数据传输。  </li></ul><h4 id="显示面板"><a href="#显示面板" class="headerlink" title="显示面板"></a><strong>显示面板</strong></h4><p>显示面板被划分为8x2个区域，每个区域可以显示一个字符。 每个区域所对应了一个地址，<strong>第一排显示区域的地址是00到07，第二排显示区域的地址是从40到47</strong>。<br>在显示时需要指定显示的起始位置。<br>由于DDRAM，因此bit7始终为1，<strong>操作码为0xC0+起始区域的地址。</strong>  </p><h4 id="显示与控制"><a href="#显示与控制" class="headerlink" title="显示与控制"></a><strong>显示与控制</strong></h4><p>每一个常用字符（字母，数字，常用符号，片假名）和指令都对应了一个8bit值，这8bit被拆分为两段：MSB和LSB分两次发送，但是先发送哪一段取决于LED的型号。（课程中为先发送MSB，再发送LSB）<br><strong>注意在发送字符/指令时，需要将操作码的头四位清零，发送MSB时，需要将MSB移动到操作码的后四位，再清零其头四位。</strong>  </p><p><strong>发送指令也是8bit，其结构： 0010 | MSB/LSB</strong><br>发送指令的第一段为固定值0x20，后一段为指令的MSB或LSB。  </p><p>发送字符时，发送字符的指令结构：<br><strong>发送MSB： 0011 |MSB</strong><br><strong>发送LSB： 0010 |LSB</strong>  </p><h3 id="程序思路-3"><a href="#程序思路-3" class="headerlink" title="程序思路"></a>程序思路</h3><p>LCD在使用前需要对其进行唤醒（初始化显示），唤醒方法为不断的向portb发送两个不同的任意非零比特值。<br>整个LCD的初始化流程为：   </p><ol><li>设置adcon1接收来自portA的所有pins的数字信号。  </li><li>设置portA的PA0,PA1,PA2为输出。  </li><li>设置portB为输出。  </li><li>清除显示。  </li><li>唤醒LED。</li><li>设置显示模式：显示n行，8bit数据接口，5x7或0.5x7点阵</li><li>开启显示，并设置显示/不显示指针</li><li>设置字符的显示模式:从左到右/从右到左</li><li>设置指针的起始位置。</li><li>清除显示。<br>固定代码为:<figure class="highlight c"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs c">adcon1 = <span class="hljs-number">0x06</span>; <span class="hljs-comment">//设置adcon1接收来自portA的所有pins的数字信号</span><br>trisa = <span class="hljs-number">0xf8</span>; <span class="hljs-comment">//设置portA的PA0,PA1,PA2为输出</span><br>trisb = <span class="hljs-number">0x00</span>; <span class="hljs-comment">//设置PortB为输出</span><br>lcd_cmd(<span class="hljs-number">1</span>); <span class="hljs-comment">//清除显示</span><br>lcd_init(); <span class="hljs-comment">//初始化LCD</span><br>lcd_cmd(<span class="hljs-number">0x38</span>); <span class="hljs-comment">//设置两行，8比特，5x7点阵</span><br>lcd_cmd(<span class="hljs-number">0x0c</span>); <span class="hljs-comment">//设置打开显示，不显示光标</span><br>lcd_cmd(<span class="hljs-number">0x06</span>); <span class="hljs-comment">//设置光标右移</span><br>lcd_cmd(<span class="hljs-number">1</span>); <span class="hljs-comment">//清除显示</span><br></code></pre></div></td></tr></table></figure>将发送的字符串视为一个数组，每一个字符都要进行：“清零，MSB移位，清除头四位，发送MSB，清除头四位，发送LSB”的操作。  </li></ol><h2 id="ADC-模数转换器"><a href="#ADC-模数转换器" class="headerlink" title="ADC/模数转换器"></a>ADC/模数转换器</h2><h3 id="测量原理"><a href="#测量原理" class="headerlink" title="测量原理"></a>测量原理</h3><p>ADC的基本原理为其测量范围内的每一个可测的电压值都对应了一个二进制数。 例如8bit ADC量程为0-5V时，0-5V对应了0000 0000到1111 1111的8bit二进制数。<br>ADC的精度表示为：$\frac{测量范围}{2^n}$。   </p><blockquote><p>注意电压转换为二进制数时，不能整除的情况下，应当只保留整数部分。  </p></blockquote><h4 id="类型"><a href="#类型" class="headerlink" title="类型"></a><strong>类型</strong></h4><p>ADC根据实现原理分类为三种类型：</p><ol><li>Flash ADC：每一个可以测量的电压值对应了一个比较器连接，是一种非常低下的ADC。</li><li>逐次逼近式ADC：<br>下图中8bit Register的值的从MSB开始0-&gt;1，每一个比特位0-&gt;1的变化都会由DAC转换为电压与输入电压进行对比，比较器将两个电压进行对比，判断DAC的电压是否高于输入电压：如果输入电压高于DAC的电压，那么Register中这一比特位的值为1，如果低于DAC的电压，那么Register中这一位比特位的值恢复为0。<br>调整8bit Register的每一个比特位，直到LSB调整完毕，ADC的转换结束。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210529140131.png" alt="">  </li><li>Dual slope ADC：由于不同电压下在固定充电时间内充入的电子数不同，通过测量电容放电的时间即可测量不同的电压。这种ADC测量速度慢，但是相比于上面两者价格相对便宜。  </li></ol><h3 id="寄存器结构"><a href="#寄存器结构" class="headerlink" title="寄存器结构"></a>寄存器结构</h3><h4 id="ADRESH-ADRESL"><a href="#ADRESH-ADRESL" class="headerlink" title="ADRESH/ADRESL"></a><strong>ADRESH/ADRESL</strong></h4><p>两个8bit寄存器用于存放10bit的转换结果，又两种存放方式：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210529143926.png" alt=""><br>这两种方式由ADCON1中的bit7：ADFM进行控制。  </p><h4 id="ADCON1"><a href="#ADCON1" class="headerlink" title="ADCON1"></a><strong>ADCON1</strong></h4><div class="table-container"><table><thead><tr><th style="text-align:center">bit</th><th style="text-align:center">7</th><th style="text-align:center">6</th><th style="text-align:center">5</th><th style="text-align:center">4</th><th style="text-align:center">3</th><th style="text-align:center">2</th><th style="text-align:center">1</th><th style="text-align:center">0</th></tr></thead><tbody><tr><td style="text-align:center">Function</td><td style="text-align:center">ADFM</td><td style="text-align:center">x</td><td style="text-align:center">x</td><td style="text-align:center">x</td><td style="text-align:center">PCFG3</td><td style="text-align:center">PCFG2</td><td style="text-align:center">PCFG1</td><td style="text-align:center">PCFG0</td></tr></tbody></table></div><p>bit7：ADFM，选择寄存模式：  </p><ul><li>为1时10bit转换结果的bit10和bit9放入ADRESH，剩下比特放入ADRESL。  </li><li>为0时10bit转换结果的bit0和bit1放入ADRESL，剩下比特放入ADRSH。<br>bit6-bit4：Don’t Care<br>bit3-bit0: PCFG3-PCFG0，选择ADC的4个pins哪些接收模拟信号（0），哪些接收数字信号（1）。  <h4 id="ADCON0"><a href="#ADCON0" class="headerlink" title="ADCON0"></a><strong>ADCON0</strong></h4></li></ul><div class="table-container"><table><thead><tr><th style="text-align:center">bit</th><th style="text-align:center">7</th><th style="text-align:center">6</th><th style="text-align:center">5</th><th style="text-align:center">4</th><th style="text-align:center">3</th><th style="text-align:center">2</th><th style="text-align:center">1</th><th style="text-align:center">0</th></tr></thead><tbody><tr><td style="text-align:center">Function</td><td style="text-align:center">ADCS1</td><td style="text-align:center">ADCS0</td><td style="text-align:center">CHS2</td><td style="text-align:center">CHS1</td><td style="text-align:center">CHS0</td><td style="text-align:center">GO/DONE</td><td style="text-align:center">x</td><td style="text-align:center">ADON</td></tr></tbody></table></div><p>bit7-bit6： ADCS1-ADCS0，选择转换速度<br>bit5-bit3: CHS2-CHS0，选择当前接受portA的哪一个pin的信号进行转换<br>bit2： GO/DONE，转换开始和结束的flag，设定其为1使ADC转换开始，转换结束后会自动复位为0.<br>bit1: Don’t care<br>bit0: ADON，ADC的总开关，1表示开，0表示关。  </p><h2 id="代码实现"><a href="#代码实现" class="headerlink" title="代码实现"></a>代码实现</h2><p>ADC需要通过给定adcon1和adcon0的值来进行初始化。<br>转换过程的思想思路为，设置GODONE的值为1，开始转换，等到GODONE的值恢复到0时，获取adresh和adresl中的10比特信息（注意移位的问题）。  </p><h2 id="计时器"><a href="#计时器" class="headerlink" title="计时器"></a>计时器</h2><h3 id="结构"><a href="#结构" class="headerlink" title="结构"></a>结构</h3><p>计时器的结构如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210529144418.png" alt=""><br>RA4/T0CK1: PortA的pin4，用于接收输入信号<br>T0SE：选择下降沿还是上升沿触发计数器计数<br>Fosc: 单片机内部的时钟信号频率 （Fosc/4表示$\frac{1}{4}$时钟信号频率）<br>T0CS： 复用器，选择用RA4还是时钟信号作为输入<br>PS2-PS0: Pre-scaler（相当于另一个计数器），用于倍数放大。<br>PSA： 复用器，选择是否使用Pre-scaler。<br>TMR0: 计数器。  </p><h3 id="寄存器结构-1"><a href="#寄存器结构-1" class="headerlink" title="寄存器结构"></a>寄存器结构</h3><h4 id="TMR0"><a href="#TMR0" class="headerlink" title="TMR0"></a><strong>TMR0</strong></h4><p>8bit 计数器，每一个计数信号（1us）会计数一次，8bit计数器每256次计数（也就是每个256us）会发生一次溢出。    </p><h4 id="INTCON"><a href="#INTCON" class="headerlink" title="INTCON"></a><strong>INTCON</strong></h4><p>计数器的状态寄存器。  </p><div class="table-container"><table><thead><tr><th style="text-align:center">bit</th><th style="text-align:center">7</th><th style="text-align:center">6</th><th style="text-align:center">5</th><th style="text-align:center">4</th><th style="text-align:center">3</th><th style="text-align:center">2</th><th style="text-align:center">1</th><th style="text-align:center">0</th></tr></thead><tbody><tr><td style="text-align:center">Function</td><td style="text-align:center">O</td><td style="text-align:center">O</td><td style="text-align:center">O</td><td style="text-align:center">O</td><td style="text-align:center">O</td><td style="text-align:center">T0IF</td><td style="text-align:center">O</td><td style="text-align:center">O</td></tr></tbody></table></div><p>bit2： TMR0溢出标志，T0IF=1表明TMR0发生了溢出。  </p><h4 id="OPTION"><a href="#OPTION" class="headerlink" title="OPTION"></a><strong>OPTION</strong></h4><p>用于控制计时器：  </p><div class="table-container"><table><thead><tr><th style="text-align:center">bit</th><th style="text-align:center">7</th><th style="text-align:center">6</th><th style="text-align:center">5</th><th style="text-align:center">4</th><th style="text-align:center">3</th><th style="text-align:center">2</th><th style="text-align:center">1</th><th style="text-align:center">0</th></tr></thead><tbody><tr><td style="text-align:center">Function</td><td style="text-align:center">O</td><td style="text-align:center">O</td><td style="text-align:center">T0CS</td><td style="text-align:center">T0SE</td><td style="text-align:center">PSA</td><td style="text-align:center">PS2</td><td style="text-align:center">PS1</td><td style="text-align:center">PS0</td></tr></tbody></table></div><p>bit7-bit6: 其他功能<br>bit5: T0CS，选择用RA4还是时钟信号作为输入<br>bit4: T0SE，选择下降沿还是上升沿触发计数器计数<br>bit3: PSA， 选择是否开启pre-scaler<br>bit2-bit0： 选择pre-scaler的倍率  </p><h3 id="理论"><a href="#理论" class="headerlink" title="理论"></a>理论</h3><p>TMR0发生一次overflow的时间：</p><script type="math/tex; mode=display">时钟周期 × 放大倍率 × (256 × 单次计数所需要的时间 - \text{TMR0}初始值)</script><h3 id="代码思路"><a href="#代码思路" class="headerlink" title="代码思路"></a>代码思路</h3><p>可通过给定tmr0的初始值和重置T0IF为0来实现一个精准的delay。  </p><h2 id="中断"><a href="#中断" class="headerlink" title="中断"></a>中断</h2><h3 id="原理"><a href="#原理" class="headerlink" title="原理"></a>原理</h3><p>通常，Programm Counter（PC）负责指向下一条运行指令的地址，IR执行这个地址对应的指令，PC移动到下一条指令。<br>如果中断程序存在，当前的PC，W register 和 STATUS register中的内容会被保存到内存中，然后PC跳转到中断程序所处的位置（固定为<code>PC=4</code>），执行完中断程序后内存中PC，W register 和 STATUS register的内容被复原。  </p><p><strong>每运行一行主循环中的代码，<code>void interrupt&#123;&#125;</code>中的程序就会被执行一次。</strong>  </p><p>程序框图如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210529152258.png" alt=""></p><h3 id="应用：-PWM-控制马达"><a href="#应用：-PWM-控制马达" class="headerlink" title="应用： PWM 控制马达"></a>应用： PWM 控制马达</h3><h4 id="原理-1"><a href="#原理-1" class="headerlink" title="原理"></a><strong>原理</strong></h4><p>马达转速的调节是由输入马达的电压来进行控制的，电压越高，马达转速越快。然而单片机只能输出5v或者0v两种电压，PWM提供了一种解决思路，即在如图所示的一个周期$T$内，有一部分时间输入马达的电压为0，另一部分时间输出马达的电压为1，当$T$非常小时，输入到马达的电压近似为一个周期内电压的平均值：   </p><script type="math/tex; mode=display">V_{out}=\frac{1}{T}∫_0^TV_{in}dt=\frac{t}{T}V</script><p>$t$为一个周期内电压为$V$时的时间。<br><img src="https://gitee.com/l61012345/Pic/raw/master/%5Cimage/20210610144853.png" alt="">  </p><h4 id="代码实现-1"><a href="#代码实现-1" class="headerlink" title="代码实现"></a><strong>代码实现</strong></h4><p>在中断程序中需要有两个计数器cycle（周期计时器） 和 pulse（马达开启状态的计时器）用于控制时间，他们每运行一次中断都会自动-1，当计数器为0时表明对应的阶段已经结束。<br>在程序实现上 cycle自减1后，首先需要判断cycle的值是否为0： 如果为0，表明当前的周期已经结束，应当为cycle赋值以初始化下一个周期。  同时为pulse赋值，并使马达处于工作状态以进入下一个周期的开始（马达工作）。<br>当cycle不为0时，需要判断pulse是否为0：如果pulse的值为0，表明应当进入该周期内马达关闭的阶段，因此关闭马达。如果pulse的值不为0，那么pulse自减1。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计算机结构与接口</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8.4. 使用支持向量机</title>
    <link href="/2021/05/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.4.%20%E4%BD%BF%E7%94%A8SVM/"/>
    <url>/2021/05/11/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.4.%20%E4%BD%BF%E7%94%A8SVM/</url>
    
    <content type="html"><![CDATA[<h1 id="使用支持向量机"><a href="#使用支持向量机" class="headerlink" title="使用支持向量机"></a>使用支持向量机</h1><p>本节将考虑在实际中应用SVM算法的一些问题。  </p><h2 id="调用函数库实现"><a href="#调用函数库实现" class="headerlink" title="调用函数库实现"></a>调用函数库实现</h2><p>求解$θ$的过程很繁琐，因此在实际中通常采用调用现有函数库（比如liblinear,libsvm）的方式实现SVM，但仍然需要给这些函数补充参数：  </p><ol><li>选择参数C。</li><li>选择内核参数。<br>如果不同特征之间的取值差异非常大，需要对特征变量做归一化。  </li></ol><h2 id="其他的核函数"><a href="#其他的核函数" class="headerlink" title="其他的核函数"></a>其他的核函数</h2><p>目前学到的两种核函数：<br>线性内核：即不使用内核参数，比如： $y=1,if θ^Tx≥0$。通常在有大量的特征，但是只有少量的训练样本的情况下，为了避免过拟合而采用线性拟合的方式。<br>高斯核： 通常对大样本且决策边界不规则的情况适用。  </p><p>有些函数库需要用户自己写一个核函数。因此事实上除了这两种核函数之外，用户可以创建自己的核函数。但是只有满足默塞尔定理的函数才能被作为核函数。<br>其他的核函数：</p><ol><li>多项式核函数：$k(x,l)=(x^Tl+b)^n$,b和n都是实数参数。    </li><li>字符串核函数</li><li>直方相交核函数</li><li>卡方核函数</li></ol><h2 id="多类别分类"><a href="#多类别分类" class="headerlink" title="多类别分类"></a>多类别分类</h2><p>在$k$分类下，需要构建$k$个SVM函数，每一个函数需要将一个类别从其他的类别中区分开来。<br>在大部分函数库中，多分类函数已经被预置，因此只需要调用即可。  </p><h2 id="逻辑回归与SVM"><a href="#逻辑回归与SVM" class="headerlink" title="逻辑回归与SVM"></a>逻辑回归与SVM</h2><p>已经知道SVM其实是对于逻辑回归的修改，那么在何种情况下使用它们？<br>设$n$为特征数，$m$为训练样本数：<br><strong>如果$n$远大于$m$（比如文本分类），使用逻辑回归或者是线性核的SVM。</strong><br><strong>如果$n$的值相对于$m$较小且$m$的值比较适中，使用高斯核的SVM。</strong><br><strong>如果$n$远小于$m$,应当首先手动增加一些特征，再使用逻辑回归或者是线性核的SVM。</strong>  </p><blockquote><p>线性核的SVM的本质就是线性的逻辑回归，因此两者的预测结果会非常相似，但是在具体的环境中两者的性能会有差异。  </p></blockquote><p>上述的情况都可以使用神经网络进行训练，但是训练的速度可能会非常地慢。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>08. 支持向量机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 8 非频变天线</title>
    <link href="/2021/05/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/8.%20%E9%9D%9E%E9%A2%91%E5%8F%98%E5%A4%A9%E7%BA%BF/"/>
    <url>/2021/05/10/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/8.%20%E9%9D%9E%E9%A2%91%E5%8F%98%E5%A4%A9%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-8-非频变天线"><a href="#Lecture-8-非频变天线" class="headerlink" title="Lecture 8 非频变天线"></a>Lecture 8 非频变天线</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/1DA60A65D3A7E8030DE4F80370ACB4EF.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8. Z变换</title>
    <link href="/2021/05/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/8.%20z%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/05/07/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/8.%20z%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="Z变换"><a href="#Z变换" class="headerlink" title="Z变换"></a>Z变换</h1><h2 id="Z变换的基本原理"><a href="#Z变换的基本原理" class="headerlink" title="Z变换的基本原理"></a>Z变换的基本原理</h2><p>Z变换的本质是通过采样使得离散信号可以被拉普拉斯变换，因此z变换的对象是<strong>离散信号/序列</strong>。<br>其具体过程如下：<br>由<a href="https://l61012345.top/2021/04/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/6.%20%E5%91%A8%E6%9C%9F%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/">第六讲</a>中提到的采样定理，对于连续序列$x(t)$，对其做自然采样：  </p><script type="math/tex; mode=display">\begin{aligned}    x_s(t)&=x(t)δ_T(t) \\    &=x(t)∑δ(t-nT) \\    &=∑x(nT)δ(t-nT) \\\end{aligned}</script><p>对其做拉普拉斯变换：  </p><script type="math/tex; mode=display">X_s=L[x_s(t)]</script><script type="math/tex; mode=display">\begin{aligned}    L[x_s(t)]&=L[∑x(nT)δ(t-nT)]  \\    &=∑x(nT)L[δ(t-nT)]\\    &=∑x(nT)e^{-snT}\end{aligned}</script><p>令$z=e^{sT}$,得到Z变换的定义式： </p><script type="math/tex; mode=display">X(z)=∑x(n)z^{-n}</script><p>在LTI系统中$n&gt;0$，Z变换的定义式可以写作：</p><script type="math/tex; mode=display">X(z)=∑_{n=0}^∞x(n)z^{-n}</script><h3 id="存在条件-收敛域"><a href="#存在条件-收敛域" class="headerlink" title="存在条件/收敛域"></a>存在条件/收敛域</h3><p>使得序列$x(n)$能够被z变换的条件是<strong>序列$x(n)$收敛</strong>，即：  </p><script type="math/tex; mode=display">∑|x(n)z^{-n}|<∞</script><p>上述条件为z变换的收敛域。  </p><h3 id="Z反变换"><a href="#Z反变换" class="headerlink" title="Z反变换"></a>Z反变换</h3><h4 id="Z变换式的一般形式"><a href="#Z变换式的一般形式" class="headerlink" title="Z变换式的一般形式"></a>Z变换式的一般形式</h4><p>序列$x(n)$的z变换式$X(z)$的一般形式可以写作由两个多项式组成的分式：  </p><script type="math/tex; mode=display">X(z)=\frac{N(z)}{D(z)}=\frac{∑b_mz^m}{∑a_nz^n}</script><p>当极点为一阶时,对等式两边同时除以$z$以提取常系数$A$：  </p><script type="math/tex; mode=display">\frac{X(z)}{z}=∑_{i=1}^N\frac{A_i}{z-z_i}</script><p>其中$A_i=(z-z_i)\frac{X(z)}{z}|_{z=z_i}$。<br>再乘上$z$：  </p><script type="math/tex; mode=display">X(z)=∑_{i=1}^N\frac{A_iz}{z-z_i}</script><p>其中$A_i$为$x(n)$的常系数，$z_i$为底数。<br>对应的$x(n)$：</p><script type="math/tex; mode=display">x(n)=∑_{i=0}^∞A_i(z_i)^n,n≥0</script><blockquote><p>另外两种关于$X(z)$极点结构的情况：</p><ol><li>共轭复数  </li><li>多根<br>本节不会讨论  </li></ol></blockquote><h2 id="Z变换的性质"><a href="#Z变换的性质" class="headerlink" title="Z变换的性质"></a>Z变换的性质</h2><ol><li><p>线性（同傅里叶变换）</p><blockquote><p>线性需要要求两个序列收敛域有公共部分，如果两者没有公共收敛域，那么无法Z变换不具有线性。  </p></blockquote></li><li><p>变换操作  </p><ul><li>双侧时移<br>时移前后信号形状保持不变。<br>右移：$Z[x(n-m)]=z^{-m}X(z)$<br>左移：$Z[x(n+m)]=z^{m}X(z)$  </li><li><p>单侧时移<br>时移后图像$n&lt;0$的部分被消去。<br>右移:$Z[x(n-m)u(n)]=z^{-m}[X(z)-∑_{k=-m}^{-1}x(k)z^{-k}]$<br>左移:$Z[x(n+m)u(n)]=z^m[X(z)-∑_{k=0}^{m-1}x(k)z^{-k}]$  </p></li><li><p>线性权重<br>$Z[nx(n)]=-z\frac{dX(z)}{dz}=-z^{-1}\frac{dX(z)}{dz^{-1}}$  </p></li><li><p>尺度变换（z频域）<br>$Z[a^nx(n)]=X(\frac{z}{a})$  </p></li></ul><h3 id="初值定理"><a href="#初值定理" class="headerlink" title="初值定理"></a>初值定理</h3><p>如果$x(n)$具有因果性且可以被Z变换，有：</p><script type="math/tex; mode=display">x(0)=\lim_{x→∞}X(z)</script><h3 id="终值定理"><a href="#终值定理" class="headerlink" title="终值定理"></a>终值定理</h3><p>如果$x(n)$具有因果性且可以被Z变换，有：</p><script type="math/tex; mode=display">\lim_{x→∞}x(n)=\lim_{z→1}[(z-1)X(z)]</script><h3 id="卷积理论"><a href="#卷积理论" class="headerlink" title="卷积理论"></a>卷积理论</h3><script type="math/tex; mode=display">Z[x(n)*h(n)]=X(z)H(z)</script><script type="math/tex; mode=display">Z[x(n)h(n)]=X(z)*H(z)</script><p>收敛域为两者的公共收敛域：$max(R_{xmin},R_{hmin})&lt;|z|&lt;min(R_{xmax},R_{hmax})$  </p></li></ol><h2 id="常见信号的Z变换"><a href="#常见信号的Z变换" class="headerlink" title="常见信号的Z变换"></a>常见信号的Z变换</h2><h3 id="单位冲激序列"><a href="#单位冲激序列" class="headerlink" title="单位冲激序列"></a>单位冲激序列</h3><script type="math/tex; mode=display">Z[δ(n)]=∑δ(n)z^{-n}=1</script><p>收敛域：整个z域  </p><h3 id="单位阶跃序列"><a href="#单位阶跃序列" class="headerlink" title="单位阶跃序列"></a>单位阶跃序列</h3><script type="math/tex; mode=display">\begin{aligned}    Z[u(n)]&=∑u(n)z^{-n}\\    &=1+z^{-1}+z^{-2}+...+z^{-n}\\    &=\frac{z}{z+1}\end{aligned}</script><p>收敛域：$|z|&gt;1$  </p><h3 id="斜坡序列"><a href="#斜坡序列" class="headerlink" title="斜坡序列"></a>斜坡序列</h3><p>由单位阶跃序列的变换对：$Z[u(n)]=∑_{n=0}^∞z^{-n}=\frac{z}{z+1}$求导  </p><script type="math/tex; mode=display">\begin{aligned}    (∑_{n=0}^∞z^{-n})'&=(\frac{z}{z+1})'\\    -nz^{-n+1}&=-\frac{1}{(1-z^{-1})^2}\\    nz^{-n+1}&=\frac{1}{(1-z^{-1})^2}\\    两边同时乘以z^{-1}:\\    Z[nu(n)]&=\frac{z}{(z-1)^2}\end{aligned}</script><p>收敛域：$|z|&gt;1$<br>推广：</p><script type="math/tex; mode=display">Z[n^mx(n)]=[z^{-1}\frac{d}{dz^{-1}}]^mX(z)</script><h3 id="指数序列"><a href="#指数序列" class="headerlink" title="指数序列"></a>指数序列</h3><script type="math/tex; mode=display">\begin{aligned}    Z[a^nu(n)]&=∑a^nz^{-n}\\    &=∑(\frac{a}{z})^n\\    &=\lim_{n→∞}\frac{1-(\frac{a}{z})^{n+1}}{1-\frac{a}{z}}\end{aligned}</script><p>当$|\frac{a}{z}|&lt;1$时序列收敛，此时可以简化为：</p><script type="math/tex; mode=display">Z[a^nu(n)]=\frac{z}{z-a}</script><p>收敛域：$|z|&gt;|a|$  </p><h3 id="三角函数序列"><a href="#三角函数序列" class="headerlink" title="三角函数序列"></a>三角函数序列</h3><p>由指数序列的变换对带入$sin(n)$和$cos(n)$的欧拉公式中：  </p><script type="math/tex; mode=display">Z[cos(ω_0n)u(n)]=\frac{z(z-cosω_0)}{z^2-2zcosω_0+1}</script><script type="math/tex; mode=display">Z[sin(ω_0n)u(n)]=\frac{zsinω_0}{z^2-2zcosω_0+1}</script><p>收敛域：$|z|&gt;1$  </p><h2 id="Z变换法求解系统差分方程"><a href="#Z变换法求解系统差分方程" class="headerlink" title="Z变换法求解系统差分方程"></a>Z变换法求解系统差分方程</h2><p>对于描述系统的差分方程，可以对两边做Z变换：</p><script type="math/tex; mode=display">F_{out}(Y(s),s)=F_{in}(X(s),s)</script><p>整理出关于$Y(z)$的方程，即系统的全响应：</p><script type="math/tex; mode=display">Y(z)=F_{多项式分式}(y(n_0),s)+F_{多项式分式}(E(s),s)</script><p><strong>其中含有某些初始状态$y(n_0)$的多项式分式是零输入响应，含有$E(s)$的多项式分式是零状态响应。</strong>  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 7 环形天线</title>
    <link href="/2021/05/06/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/7.%20%E7%8E%AF%E5%BD%A2%E5%A4%A9%E7%BA%BF/"/>
    <url>/2021/05/06/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/7.%20%E7%8E%AF%E5%BD%A2%E5%A4%A9%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-7-环形天线"><a href="#Lecture-7-环形天线" class="headerlink" title="Lecture 7 环形天线"></a>Lecture 7 环形天线</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/65414C29988C4753A0FC683F75D69142.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/E8CB233AB24D05F7CC0379CFFD446AC4.png" alt="">  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7. 拉普拉斯变换</title>
    <link href="/2021/04/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/7.%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/04/30/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/7.%20%E6%8B%89%E6%99%AE%E6%8B%89%E6%96%AF%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<h1 id="拉普拉斯变换"><a href="#拉普拉斯变换" class="headerlink" title="拉普拉斯变换"></a>拉普拉斯变换</h1><h2 id="傅里叶变换的局限性"><a href="#傅里叶变换的局限性" class="headerlink" title="傅里叶变换的局限性"></a>傅里叶变换的局限性</h2><ol><li>使用傅里叶变换的条件是$f(t)$必须要满足狄利赫里条件，即必须要满足有界、绝对可积和有有限个间断点三个条件。 有些信号并不满足绝对可积的条件，因此这些信号不能被应用傅里叶变换。  </li><li>傅里叶变换中的无穷积分比较困难。  </li></ol><p>对于不满足狄利赫里条件的信号，可以用拉普拉斯变换进行处理。  </p><h2 id="拉普拉斯变换的基本原理"><a href="#拉普拉斯变换的基本原理" class="headerlink" title="拉普拉斯变换的基本原理"></a>拉普拉斯变换的基本原理</h2><p>拉普拉斯变换的基本思想是将$f(t)$乘上一个<strong>衰减系数</strong>：$AF$(Attenuation factor)以改善$f(t)$的收敛性，使得$f(t)AF$满足狄利赫里条件。<br>通用的衰减系数是$e^{-σt}$。<br>因此$f(t)AF$的傅里叶变换写作：  </p><script type="math/tex; mode=display">F(ω)=F[(f(t)e^{-σt})]=∫f(t)e^{-σt}e^{-jωt}dt=∫f(t)e^{-(σ+jω)t}dt</script><p>令$s=(σ+jω)$，得到拉普拉斯变换的定义式：  </p><script type="math/tex; mode=display">L[f(t)]=F(s)=F(σ+jω)=∫f(t)e^{-st}dt</script><p>对于LIT系统，$f(t)=0,t&lt;0$，因此：</p><script type="math/tex; mode=display">L[f(t)]=F(s)=∫_0^∞f(t)e^{-st}dt</script><h3 id="存在条件-收敛域"><a href="#存在条件-收敛域" class="headerlink" title="存在条件/收敛域"></a>存在条件/收敛域</h3><p>保证拉普拉斯变换存在的条件是$f(t)AF$满足满足狄利赫里条件。<br>使得拉普拉斯变换成立的定义域称为<strong>收敛域</strong>(RoC)。其应当是使得$F(s)$存在的$s$的范围。即$f(t)$应当满足：</p><script type="math/tex; mode=display">lim_{t→∞}f(t)e^{-σt}=0</script><h3 id="拉普拉斯反变换"><a href="#拉普拉斯反变换" class="headerlink" title="拉普拉斯反变换"></a>拉普拉斯反变换</h3><p>傅里叶反变换的定义式：  </p><script type="math/tex; mode=display">f(t)=\frac{1}{2π}∫F(ω)e^{jωt}dω</script><p>带入$f(t)e^{-σt}$:</p><script type="math/tex; mode=display">f(t)e^{-σt}=\frac{1}{2π}∫F(σ+jω)e^{jωt}dω</script><p>将两边同时乘上$e^{σt}$:  </p><script type="math/tex; mode=display">f(t)=\frac{1}{2π}∫F(σ+jω)e^{(σ+jω)t}dω</script><p>带入$s=σ+jω$并替换积分域，得到拉普拉斯反变换的定义式：</p><script type="math/tex; mode=display">f(t)=\frac{1}{2πj}∫_{σ-j∞}^{σ+j∞}F(s)e^{st}ds</script><p>拉普拉斯变换对包含拉普拉斯变换和反变换的定义式。  </p><p><strong>拉普拉斯变换的一般形式和反变换求解</strong><br>$f(t)$经拉普拉斯变换后的$F(s)$可以用多项式分数的形式进行表达：  </p><script type="math/tex; mode=display">F(s)=\frac{A(s)}{B(s)}=\frac{∑a_ms^m}{∑b_ns^n}</script><p>倘若$m&lt;n$，则$F(s)$是一个真分数，可以上下做多项式除法，得到：  </p><script type="math/tex; mode=display">F(s)=\frac{a_m(s-z_1)(s-z_2)L(s-z_m)}{b_n(s-p_1)(s-p_2)L(s-p_n)}</script><p>其中$z$表示$F(s)$的时域变换$f(t)$中的零点，$p$表示$F(s)$的时域变换$f(t)$中的指数系数，称为极点(Pole)。  </p><blockquote><p>真分数意味着$F(s)$在无穷处收敛的概率很大，因此拉普拉斯变换后的式子具有高稳定性的特点。  </p></blockquote><p>在单阶实数极点（Single-order real poles）的条件下：  </p><script type="math/tex; mode=display">F(s)=\frac{A(s)}{(s-p_1)(s-p_2)L(s-p_n)}</script><p>那么$F(s)$经过多项式除法/因式分解之后可以写作：  </p><script type="math/tex; mode=display">F(s)=∑_{i=1}^\frac{k_i}{s-p_i}+L</script><p>可以得到：  </p><script type="math/tex; mode=display">f(t)=∑_{i=1}^{n}k_ie^{p_it}</script><blockquote><p>另外两种关于$F(s)$极点的情况：</p><ol><li>共轭复数  </li><li>多根<br>本节不会讨论  </li></ol></blockquote><h2 id="拉普拉斯变换的性质"><a href="#拉普拉斯变换的性质" class="headerlink" title="拉普拉斯变换的性质"></a>拉普拉斯变换的性质</h2><ol><li>线性（同傅里叶变换）</li><li>变换操作  <ul><li>时移特性（同傅里叶变换）  </li><li>频移特性:$f(t)e^{-αt}→F(s+α)$  </li><li>尺度变换（同傅里叶变换）   </li></ul></li><li>积分和微分（时域）<ul><li>微分<br>一阶微分：$\frac{df(t)}{dt}→sF(s)-f(0_)$<br>二阶微分：$\frac{df^2(t)}{dt}→s[sF(s)-f(0_)]-f’(0_)$  </li><li>积分<br>$∫_{-∞}^tf(τ)dτ→\frac{F(s)}{s}+\frac{f^{(-1)}(0_)}{s}$  <blockquote><p>证明过程是将积分域分解为$[-∞,0]$（表示初始状态）和$[0,t]$两段。</p></blockquote></li></ul></li><li>积分和微分（频域）<ul><li>n阶微分<br>$L[t^nf(t)]=(-1)^n\frac{d^nF(s)}{ds^n}$  </li><li>积分  <script type="math/tex; mode=display">L[\frac{f(t)}{t}]=∫_s^∞F(s)ds</script></li></ul></li></ol><h3 id="初值定理"><a href="#初值定理" class="headerlink" title="初值定理"></a>初值定理</h3><p>如果$f(t)$可积可被拉普拉斯变换，$f(t)$在$0_+$时刻的值（即初值）可以通过如下公式求得：  </p><script type="math/tex; mode=display">f(0_+)=lim_{s→∞}sF(s)</script><h3 id="终值定理"><a href="#终值定理" class="headerlink" title="终值定理"></a>终值定理</h3><p>如果$f(t)$可积可被拉普拉斯变换，$f(t)$在$∞$时刻的值（即初值）可以通过如下公式求得：  </p><script type="math/tex; mode=display">lim_{t→∞}f(t)=lim_{s→0}sF(s)</script><h3 id="卷积理论"><a href="#卷积理论" class="headerlink" title="卷积理论"></a>卷积理论</h3><p>拉普拉斯变换的卷积理论与傅里叶变换的卷积理论大抵相同，但是要注意对于时域中乘法的变换在频域中卷积项的参数是$\frac{1}{2πj}$。 </p><script type="math/tex; mode=display">L[f_1(t)*f_2(t)]=F_1(s)F_2(s)</script><script type="math/tex; mode=display">L[f_1(t)f_2(t)]=\frac{1}{2πj}F_1(s)*F_2(s)</script><h2 id="常见信号的拉普拉斯变换"><a href="#常见信号的拉普拉斯变换" class="headerlink" title="常见信号的拉普拉斯变换"></a>常见信号的拉普拉斯变换</h2><h3 id="阶跃信号"><a href="#阶跃信号" class="headerlink" title="阶跃信号"></a>阶跃信号</h3><script type="math/tex; mode=display">\begin{aligned}    L[u(t)] & =∫_0^∞u(t)e^{-st}dt \\    &=∫_0^∞e^{-st}dt \\    &=\frac{1}{s}\end{aligned}</script><blockquote><p>对于直流信号（常数）信号$f(t)=t_0$，可以在其后乘上一个$u(t)$做拉普拉斯变换，得到$L[t_0]=\frac{t_0}{s}$。</p></blockquote><h3 id="指数信号"><a href="#指数信号" class="headerlink" title="指数信号"></a>指数信号</h3><script type="math/tex; mode=display">\begin{aligned}    L[e^{-(α+jβ)t}]&=∫_0^∞e^{-(α+jβ)t}e^{-st}dt \\    &=\frac{1}{s+α+jβ}\end{aligned}</script><h3 id="单位冲激信号及时移"><a href="#单位冲激信号及时移" class="headerlink" title="单位冲激信号及时移"></a>单位冲激信号及时移</h3><script type="math/tex; mode=display">L[δ(t)]=1</script><script type="math/tex; mode=display">L[δ(t-t_0)]=e^{-st_0}</script><h3 id="斜坡信号"><a href="#斜坡信号" class="headerlink" title="斜坡信号"></a>斜坡信号</h3><script type="math/tex; mode=display">\begin{aligned}    L[tu(t)]&=∫_0^∞te^{-st}dt\\    &=\frac{1}{s^2}\end{aligned}</script><h2 id="拉普拉斯变换法求解系统微分方程"><a href="#拉普拉斯变换法求解系统微分方程" class="headerlink" title="拉普拉斯变换法求解系统微分方程"></a>拉普拉斯变换法求解系统微分方程</h2><h3 id="系统方程与全响应"><a href="#系统方程与全响应" class="headerlink" title="系统方程与全响应"></a>系统方程与全响应</h3><ol><li><p>以时域函数$f(t)$的拉普拉斯变换$F(s)$的微分特性：  </p><blockquote><p>一阶微分：$\frac{df(t)}{dt}→sF(s)-f(0_)$<br>二阶微分：$\frac{df^2(t)}{dt}→s[sF(s)-f(0_)]-f’(0_)$  </p></blockquote><p>可以将微分方程以拉普拉斯变换从时域变换至频域。<br>对于描述系统的微分方程将其做拉普拉斯变换：</p><script type="math/tex; mode=display">F_{out}(R(s),s)=F_{in}(E(s),s)</script></li><li><p>带入初始条件和给定的题目条件中的一些$r(t)$在特定时刻下的值，得到方程  </p></li><li>解出频域内的$R(s)$  </li><li>用待定系数法展开多项式分式并用拉普拉斯反变换得到$r(t)$</li></ol><h3 id="零输入响应"><a href="#零输入响应" class="headerlink" title="零输入响应"></a>零输入响应</h3><h4 id="法1"><a href="#法1" class="headerlink" title="法1"></a><strong>法1</strong></h4><p>对于描述系统的微分方程，整理出关于$R(s)$的等式：  </p><script type="math/tex; mode=display">R(s)=F_{多项式分式}(r(t_0),s)+F_{多项式分式}(E(s),s)</script><p><strong>其中含有某些初始状态$r(t_0)$的多项式分式是零输入响应，含有$E(s)$的多项式分式是零状态响应。</strong><br>选取含有$r(t_0)$的多项式分式，带入初始状态即可得到零输入响应$R_{zi}(s)$。<br>利用拉普拉斯反变换得到$r_{zi}(t)$。  </p><h4 id="法2"><a href="#法2" class="headerlink" title="法2"></a><strong>法2</strong></h4><ol><li>令$E(s)=0$，重新写出此时的系统微分方程： <script type="math/tex; mode=display">F_{out}(R(s),s)=0</script></li><li>带入初始条件和给定的题目条件中的一些$r(t)$在特定时刻下的值，得到方程  </li><li>解出频域内的$R_{iz}(s)$  </li><li>用待定系数法展开多项式分式并用拉普拉斯反变换得到$r_{iz}(t)$</li></ol><h3 id="零状态响应"><a href="#零状态响应" class="headerlink" title="零状态响应"></a>零状态响应</h3><h4 id="法1-1"><a href="#法1-1" class="headerlink" title="法1"></a><strong>法1</strong></h4><p>对于描述系统的微分方程，整理出关于$R(s)$的等式：  </p><script type="math/tex; mode=display">R(s)=F_{多项式分式}(r(t_0),s)+F_{多项式分式}(E(s),s)</script><p><strong>其中含有某些初始状态$r(t_0)$的多项式分式是零输入响应，含有$E(s)$的多项式分式是零状态响应。</strong><br>选取带有系统输入$E(s)$的多项式分式，由$L(δ(t))→1$带入$E(s)=1$，得到系统的零状态响应$R_{zs}(s)$。<br>利用拉普拉斯反变换得到$r_{zs}(t)$</p><h4 id="法2-1"><a href="#法2-1" class="headerlink" title="法2"></a><strong>法2</strong></h4><p>求解到$r(t)$与$r_{iz}(t)$后，利用</p><script type="math/tex; mode=display">r_{zs}(t)=r(t)-r_{iz}(t)</script><p>间接求解到$r_{zs}(t)$。  </p><h2 id="用拉普拉斯变换分析电路"><a href="#用拉普拉斯变换分析电路" class="headerlink" title="用拉普拉斯变换分析电路"></a>用拉普拉斯变换分析电路</h2><p>将电路中主要元件的电压电流关系进行拉普拉斯变换：<br>电阻：  </p><script type="math/tex; mode=display">R=\frac{V(s)}{I}</script><p>电容：<br>由时域：$v(t)=\frac{1}{C}∫i(t)dt$  </p><script type="math/tex; mode=display">V(s)=I(s)\frac{1}{sC}+\frac{1}{s}v_c(0_-)</script><p>电容的阻抗（容抗）：  </p><script type="math/tex; mode=display">Z_c=\frac{1}{sC}</script><p>电感：由时域：$v(t)=L\frac{di(t)}{dt}$  </p><script type="math/tex; mode=display">V(s)=I(s)Ls-Li(0_-)</script><p>电感的阻抗（感抗）：</p><script type="math/tex; mode=display">Z_L=sL</script><p>电路的分析方法仍然遵循KCL和KVL。   </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 6 天线阵列</title>
    <link href="/2021/04/29/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/6.%20%E5%A4%A9%E7%BA%BF%E9%98%B5%E5%88%97/"/>
    <url>/2021/04/29/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/6.%20%E5%A4%A9%E7%BA%BF%E9%98%B5%E5%88%97/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-6-天线阵列"><a href="#Lecture-6-天线阵列" class="headerlink" title="Lecture 6 天线阵列"></a>Lecture 6 天线阵列</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/03105432535A8ACBACA84893DEFA60AA.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/9C59D44507AC8C313C28C27B5A1F4589.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8.3. 核函数</title>
    <link href="/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.3.%20%E6%A0%B8%E5%87%BD%E6%95%B0/"/>
    <url>/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.3.%20%E6%A0%B8%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="核函数"><a href="#核函数" class="headerlink" title="核函数"></a>核函数</h1><h2 id="非线性分类的SVM"><a href="#非线性分类的SVM" class="headerlink" title="非线性分类的SVM"></a>非线性分类的SVM</h2><p>本节将使用核函数对支持向量机进行改造，使其成为复杂的非线性分类器。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210427144124.png" alt=""><br>比如对于如上图所示的分类，决策边界是非线性的。 此时一种对其拟合的方法是用多项式对其进行拟合。<br>比如： 当$θ_0+θ_1x_1+θ_2x_2+θ_3x_1x_2+θ_4x_1^2+θ_5x_2^2+..≥0$时,预测$y=1$。<br>就能够得到一个假设函数：  </p><script type="math/tex; mode=display">h_θ(x)=\begin{cases} 1  \text{if} θ_0+θ_1x_1+..≥0 \\0  \text{otherwise} \\\end{cases}</script><p>这种方法的问题是假设中的某些高阶项可能是冗余的，并且对于计算机视觉而言，用高阶多项式处理矩阵的计算量非常的大。<br>改进方法是用一些新的特征$F=\{f_i\}$来替换原特征$X=\{x_i\}$。<br>具体而言，比如现在只选取三个特征$x_0$（截距项，如下推导中将被忽略）,$x_1$,$x_2$,在这三个维度上手动选取三个点（称为标记（Landmarks））：$l^{(1)}$,$l^{(2)}$,$l^{(3)}$。<br>将新特征i $f_i$表示为训练样本$x$与$l^{(i)}$的相似度，相似度度量可以用如下公式表示：  </p><script type="math/tex; mode=display">Similarity(x,l^{(i)})=e^{-\frac{||x-l^{(i)}||^2}{2σ^2}}</script><blockquote><p>欧氏距离：空间中两点的连线距离，表示为$d=√{∑x_i^2}$。<br>$||x-l^{(i)}||$表示空间中$x$与$l^{(i)}$的（欧式）距离。  </p></blockquote><p>这个相似度函数称为<strong>高斯核函数</strong>（Gaussian Kernel Function）。  </p><script type="math/tex; mode=display">k(x,l^{(i)})=e^{-\frac{||x-l^{(i)}||^2}{2σ^2}}</script><p>此外还有其他用于度量相似度的函数，这些函数统称为<strong>核函数</strong>（Kernel Function）。  </p><h2 id="核函数的意义"><a href="#核函数的意义" class="headerlink" title="核函数的意义"></a>核函数的意义</h2><p>将高斯核函数利用欧氏距离公式展开：  </p><script type="math/tex; mode=display">\begin{aligned}    k(x,l^{(i)})&=e^{-\frac{||x-l^{(i)}||^2}{2σ^2}}\\      &=e^{-\frac{∑_{j=1}^n(x_j-l^{(i)}_j)^2}{2σ^2}}\end{aligned}</script><p>对于某个特定的$i$:<br>如果$x≈l^{(i)}$（两者的欧氏距离非常近）,$f_i≈e^{-\frac{0}{2σ}}≈1$。<br>如果$x$和$l^{(i)}$的欧氏距离非常远,$f_i≈e^{-\frac{∞}{2σ}}≈0$。<br>对于任何一个样本$x$,都可以计算$f_1$,$f_2$,$f_3$三个特征。<br>在图像上反映相似度与两者距离之间的关系即为高维空间中的高斯分布，且σ越大，图像梯度越小。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210427165149.png" alt=""><br>△当$l^{(1)}=[3,5]^T$时x的坐标$[x_1,x_2]^T$与相似度的关系。  </p><h2 id="决策边界"><a href="#决策边界" class="headerlink" title="决策边界"></a>决策边界</h2><p>再回到之前样本在特征上的分布：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210427165915.png" alt=""><br>如果样本距离某个$l^{(i)}$非常近（洋红色），那么边界函数输出的结果大于0，预测$y=1$。<br>如果样本距离三个$l^{(i)}$非常远（蓝色），那么边界函数输出的结果小于0，预测$y=0$。<br>当样本足够多的时候，所有$y=1$的点的边界即为决策边界，此时的决策边界是非线性的。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210427190114.png" alt="">  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>08. 支持向量机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8.2. 数学原理</title>
    <link href="/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.2.%20%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/"/>
    <url>/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.2.%20%E6%95%B0%E5%AD%A6%E5%8E%9F%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 50%;<br>    padding-left: 20%;<br>}</style></p><h1 id="数学原理"><a href="#数学原理" class="headerlink" title="数学原理"></a>数学原理</h1><h2 id="回顾：向量的点乘"><a href="#回顾：向量的点乘" class="headerlink" title="回顾：向量的点乘"></a>回顾：向量的点乘</h2><p>对于向量$u=[\begin{smallmatrix}<br>    u_1 \\<br>    u_2<br>\end{smallmatrix}]$,$v=[\begin{smallmatrix}<br>    v_1 \\<br>    v_2<br>\end{smallmatrix}]$,定义向量的点乘为：$u^Tv=||v||cosθ||u||$。<br>其中$||u||$称为$u$的模长：$||u||=√{u_1^2+u_2^2}$；定义$||v||cosθ=p$，它是v在u上的投影。  </p><h2 id="优化函数的几何意义"><a href="#优化函数的几何意义" class="headerlink" title="优化函数的几何意义"></a>优化函数的几何意义</h2><p>对于svm的目标优化函数： 即存在$min_θ\frac{1}{2}∑θ^2$,使得满足如果$y^{(i)}=1,θ^Tx^{(i)}≥1$，$y^{(i)}=0,θ^Tx^{(i)}≤-1$。<br>现在为了简化运算，假定$θ_0=0$，有且仅有两个参数，此时$\frac{1}{2}∑θ^2=\frac{1}{2}(√{θ_1^2+θ_2^2})^2$。<br>$√{θ_1^2+θ_2^2}$可以看做是向量$Θ$的模长，因此目标优化函数可以看做是0.5倍参数向量$Θ$长度的平方：  </p><script type="math/tex; mode=display">\frac{1}{2}∑θ^2=\frac{1}{2}||Θ||^2</script><p>现在来分析$,θ^Tx^{(i)}$的几何意义，按照向量的点乘法则，可以看做是向量$x^{(i)}$在$Θ$上的投影$p^{(i)}$与$||Θ||$相乘。<br>现在优化函数就可以表示成:<br>存在$min_θ\frac{1}{2}||Θ||^2$，使得：<br>如果$y^{(i)}=1,p^{(i)}||Θ||≥1$，<br>如果$y^{(i)}=0,p^{(i)}||Θ||≤-1$  </p><p>现在来考虑svm对线性可分样本的分类：<br>如果决策边界与样本边界的间距很小，由于参数向量与决策边界是始终正交的，那么每一个样本到参数向量的投影$p^{(i)}$都很小，想要使得$p^{(i)}||Θ||≥1$或者$p^{(i)}||Θ||≤-1$就需要$||Θ||$非常的大。（下图左）<br>反之如果决策边界与样本边界的间距很大，那么$||Θ||$就可以小一些。(下图右)<br>因此决策向量机总是使得决策边界具有大间距的特性。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210330151800.png" alt="">  </p><blockquote><p>由于决策边界的上方有${x^{(i)}}^T||Θ||&gt;0$，下方有${x^{(i)}}^TΘ&lt;0$,因此直线上必定有${x^{(i)}}^T||Θ||=0$。<br>因此<strong>参数向量与决策边界是始终正交的</strong>。 </p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>08. 支持向量机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>8.1. 激活函数、代价函数和决策边界</title>
    <link href="/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.1.%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%92%8C%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C/"/>
    <url>/2021/04/27/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.1.%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%92%8C%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 50%;<br>    padding-left: 20%;<br>}</style></p><h1 id="激活函数、代价函数和决策边界"><a href="#激活函数、代价函数和决策边界" class="headerlink" title="激活函数、代价函数和决策边界"></a>激活函数、代价函数和决策边界</h1><h2 id="逻辑回归的代价函数的线性拟合"><a href="#逻辑回归的代价函数的线性拟合" class="headerlink" title="逻辑回归的代价函数的线性拟合"></a>逻辑回归的代价函数的线性拟合</h2><p>逻辑回归的激活函数：$h(x)=\frac{1}{1+e^{-θ^Tx}}$。<br>对于单个样本$(x,y)$，逻辑回归的代价函数是：$-ylog(h_θ (x))−((1−y)log⁡(1−h_θ (x)))$，将$y=1$与$y=0$时的代价函数作出，并用线性进行拟合得到$Cost_1(z)$与$Cost_0(z)$（$z=θ^Tx$）两个线性的代价函数，两者的函数图像大致如此。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210328160423.png" alt=""><br>支持向量机是线性化的逻辑回归。  </p><h2 id="支持向量机的代价函数"><a href="#支持向量机的代价函数" class="headerlink" title="支持向量机的代价函数"></a>支持向量机的代价函数</h2><p>逻辑回归的代价函数：  </p><script type="math/tex; mode=display">J(θ)=min\frac{1}{m}[∑_{i=1}^m y^{(i)} -log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) -log(1−h_θ (x^{(i)}))]+\frac{λ}{2m}∑θ^2</script><p>将$-log$项替换为如上图所示的两个线性函数：$Cost_1(z)$和$Cost_0(z)$，并去除$\frac{1}{m}$项（并不会改变最终结果）<br>得到支持向量机的代价函数：  </p><script type="math/tex; mode=display">J(θ)=min[∑_{i=1}^m y^{(i)} Cost_1(z))+(1−y^{(i)})Cost_0(z))]</script><p>在支持向量机中，通常通过给前项附加权重$C$而非给正则化项附加权重$λ$的方法来防止过拟合，得到正则化的支持向量机的代价函数：  </p><script type="math/tex; mode=display">J(θ)=minC[∑_{i=1}^m y^{(i)} Cost_1(z))+(1−y^{(i)})Cost_0(z))]+\frac{1}{2}∑θ^2</script><h2 id="支持向量机的激活函数"><a href="#支持向量机的激活函数" class="headerlink" title="支持向量机的激活函数"></a>支持向量机的激活函数</h2><p>与逻辑回归不同的是，逻辑回归的$h(x)$输出的是概率，而支持向量机的激活函数直接给出了预测的结果：  </p><script type="math/tex; mode=display">h_θ(x)=\begin{cases}    1, z>=0 \\      0, otherwise\end{cases}</script><h2 id="支持向量机的决策边界"><a href="#支持向量机的决策边界" class="headerlink" title="支持向量机的决策边界"></a>支持向量机的决策边界</h2><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210328162717.png" alt="">  </p><blockquote><p>原本只需要0作为阈值，但是为了保证SVM的精确度，因此将阈值选定为-1和1，这两个阈值间的距离称为安全间距。  </p></blockquote><p>如上图所示，如果$y=1$，需要$z&gt;=1$,反之如果$y=1$，需要$z≦-1$。<br>当SVM的代价函数前的权重值$C$非常大时：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210328163459.png" alt=""><br>这为SVM创造了一个相当特殊的决策边界：<br>即在样本线性可分的条件下，SVM的决策边界是一条拥有与训练样本的最小距离的直线（图中黑线）。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210328164253.png" alt=""><br>图中的蓝线表示了SVM决策边界与训练样本的间距。<br>因此支持向量机又被称为大间距分类器。<br>但是当正则化系数$C$被设置的非常大时，支持向量机的决策边界对异常数据非常的敏感，如下图的例子中所示。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210328164523.png" alt="">   </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>08. 支持向量机</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>概率论与数理统计-常考知识点</title>
    <link href="/2021/04/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/"/>
    <url>/2021/04/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%A6%82%E7%8E%87%E8%AE%BA%E4%B8%8E%E6%95%B0%E7%90%86%E7%BB%9F%E8%AE%A1/</url>
    
    <content type="html"><![CDATA[<h1 id="概率论与数理统计"><a href="#概率论与数理统计" class="headerlink" title="概率论与数理统计"></a>概率论与数理统计</h1><blockquote><p>整理重邮常考的知识点  </p></blockquote><h2 id="独立、相关、互斥、概率的计算"><a href="#独立、相关、互斥、概率的计算" class="headerlink" title="独立、相关、互斥、概率的计算"></a>独立、相关、互斥、概率的计算</h2><ul><li>独立<br>如果事件A,B相互独立，有$P(AB)=P(A)P(B)$, $E(AB)=E(A)E(B)$</li><li>互斥<br>如果事件A,B互斥，有$P(A+B)=P(A)+P(B)$,即$P(AB)=0$  <blockquote><p>独立与互斥没有任何关系</p></blockquote></li><li>不相关<br>如果事件A，B不相关，有$Cov(A,B)=0$   <blockquote><p>独立可以推出不相关，不相关不能推出独立  </p></blockquote></li><li>概率中常用的计算公式<ul><li>和事件的概率  <script type="math/tex; mode=display">P(A+B)=P(A)+P(B)-P(AB)</script></li><li>德摩根律  <script type="math/tex; mode=display">P(\overline)=1-P(A+B)</script></li><li>概率拆分   <script type="math/tex; mode=display">P(AB)=P(A(1-P(\overline{B})))=P(A)-P(A\overline{B})</script></li></ul></li></ul><h2 id="条件概率"><a href="#条件概率" class="headerlink" title="条件概率"></a>条件概率</h2><ul><li><p>乘法公式<br>在A的条件下，B发生的概率：</p><script type="math/tex; mode=display">P(B|A)=\frac{P(AB)}{P(A)}</script><p>满足性质：  </p><script type="math/tex; mode=display">P(B|A)=1-P(\overline{B}|A)</script></li><li><p>全概率公式<br>将A事件（条件）划分为多个事件$A_i$,那么事件B发生的概率：  </p><script type="math/tex; mode=display">P(B)=ΣP(A_i)P(B|A_i)</script></li><li><p>贝叶斯公式<br>全概率公式的逆公式，表示已知B事件发生的概率下，在A中某一个划分下发生的概率：</p><script type="math/tex; mode=display">P(A_i|B)=\frac{P(A_i)P(B|A_i)}{P(B)}=\frac{P(A_i)P(B|A_i)}{ΣP(A_i)P(B|A_i)}</script></li></ul><h2 id="连续性随机变量的分布"><a href="#连续性随机变量的分布" class="headerlink" title="连续性随机变量的分布"></a>连续性随机变量的分布</h2><ul><li>概率密度函数<br>表示连续性随机变量在数轴上分布的稠密程度,有  <script type="math/tex; mode=display">\int_{-∞}^∞f(x)dx=1</script>性质：  <script type="math/tex; mode=display">P(a≤x≤b)=\int_{a}^bf(x)dx</script></li><li><p>概率分布函数<br>表示连续性随机变量在数轴左端分布的概率情况，即$P(X≤x)$的概率</p><script type="math/tex; mode=display">F(x)=\int_{-∞}^xf(x)dx</script><blockquote><p>分段的概率分布函数不要忘记了还要加上前一段的概率    </p></blockquote><p>性质：  </p><script type="math/tex; mode=display">P(a≤x≤b)=F(b)-F(a)</script><script type="math/tex; mode=display">P(x>a)=1-F(a)</script></li><li><p>正态分布<br>分布函数特性:  </p><ol><li>$Φ(a)=P(x ≤ a)$，$P(x &gt; a)=1-Φ(a)$  </li><li>$Φ(0)=0.5$  </li><li>$Φ(-a)=1-Φ(a)$  </li></ol><p>数值特征：  </p><ol><li>$X∼N(μ,σ^2),E(\overline{X})=μ,D(\overline{X})=Cov(X,\overline{X})=\frac{σ^2}{n}$</li><li>见中心极限定理</li></ol></li><li><p>随机变量之间的函数关系<br>倘若随机变量X，Y 之间存在某种函数关系$Y=g(X)$,给定X的分布函数$F_x(x)$,求Y的概率密度函数   </p><script type="math/tex; mode=display">F_y(y)=P(Y≤y)=P(g(x)≤y)=P(x≤h(y))=F_X(h(y))</script><script type="math/tex; mode=display">f_Y(y)=F'_y(y)=F'_x(h(y))h'(y)=f_x(h(y))h'(y)</script></li></ul><h2 id="二元随机变量"><a href="#二元随机变量" class="headerlink" title="二元随机变量"></a>二元随机变量</h2><ul><li><p>二元连续性随机变量的分布函数</p><script type="math/tex; mode=display">F(x,y)=\iint f(x,y)dA=P(A)</script><p>其中A是由x,y围成的区域，对应x和y的一组规划</p></li><li><p>边缘分布概率密度和分布函数<br>对于$F(x,y)$,  </p><script type="math/tex; mode=display">f_x(x)=∫_{-∞}^{∞}f(x,y)dy</script><script type="math/tex; mode=display">f_y(y)=∫_{-∞}^{∞}f(x,y)dx</script><script type="math/tex; mode=display">F_x(x)=F(x,∞)=\int_{\infty}^x f_x(x)dx</script><script type="math/tex; mode=display">F_y(y)=F(∞,y)=\int_{\infty}^y f_y(y)dy</script></li><li><p>条件分布函数<br>X在Y=y条件下的概率密度：  </p><script type="math/tex; mode=display">f_{X|Y}(x,y)=\frac{f(x,y)}{f_Y(y)}</script></li><li><p>二元随机变量的分布函数  </p><ul><li>Z=X+Y<script type="math/tex; mode=display">f_z(z)=∫ f_x(z-y)f_y(y)dy=∫ f_x(x)f_y(z-x)dx</script><blockquote><p>注意需要考虑$Z-Y$的取值范围，必要的时候要对$X$，$Z-Y$两者的取值范围大小进行分类讨论，始终取最小的区间</p></blockquote></li><li>Z=max{X,Y}  <script type="math/tex; mode=display">F_z(z)=F_x(z)F_y(z)</script></li><li>Z=min{X,Y}<script type="math/tex; mode=display">F_z(z)=1-[(1-F_x(x))(1-F_y(y))]</script></li></ul></li></ul><h2 id="统计特征"><a href="#统计特征" class="headerlink" title="统计特征"></a>统计特征</h2><ul><li><p>数学期望<br>离散型： 略<br>连续型：  </p><script type="math/tex; mode=display">E(x)=\int x f(x)dx</script><script type="math/tex; mode=display">E(g(x))=\iint g(x) f(x,y)dA</script><p>性质：  </p><ul><li>$E(X+Y)=E(X)+E(Y)$  </li><li>X,Y相互独立时：$E(XY)=E(X)E(Y)$  </li></ul></li><li><p>方差</p><script type="math/tex; mode=display">D(x)=E(x^2)-[E(x)]^2</script><script type="math/tex; mode=display">D(x)=Σ[E{(x-E^2(x))}]</script><p>性质:  </p><ul><li>$D(X⨦Y)=D(X)+D(Y)⨦2Cov(X,Y)$<blockquote><p>当X,Y独立的时候才有$D(X⨦Y)=D(X)+D(Y)$，在使用公式之前一定要注意X,Y是否是独立的  </p></blockquote></li><li>$D(Cx)=c^2D(x)$  </li></ul></li><li><p>协方差和相关系数</p><ul><li><p>协方差  </p><script type="math/tex; mode=display">Cov(X,Y)=E[(X-E(X))(Y-E(Y))]=E(XY)-E(X)E(Y)</script><p>协方差反映了两个随机变量的相关性，如果$Cov(X,Y)=0$，则X,Y不相关。<br>相关系数是标准化的协方差：</p><script type="math/tex; mode=display">ρ_{(X,Y)}=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}</script></li><li><p>性质<br>$Cov(X,X)=D(X)$<br>$Cov(aX+bY,cX+dY)=acD(X)+(ad+bc)Cov(X,Y)+bdD(Y)$  </p></li></ul></li><li>方差矩阵  <ul><li>原点矩<br>指  $E(X^k)$  </li><li>中心距<br>指  $E[(X-E(X))^k]$  </li></ul></li></ul><h2 id="中心极限定理"><a href="#中心极限定理" class="headerlink" title="中心极限定理"></a>中心极限定理</h2><p>中心极限定理的使用条件都是n比较大的时候。  </p><ul><li><p>李雅普诺夫定理<br>对于n个独立的随机变量$X_1,X_2,…X_n$,当n以概率趋近于无穷时，他们的和服从正态分布。</p><script type="math/tex; mode=display">\frac{ΣX_i-Σ\mu_i}{√{Σσ^2}}∼N(0,1)</script><p>当n个随机变量都是正态分布的时候，他们的和也服从正态分布，即：   </p><script type="math/tex; mode=display">\frac{ΣX_i-n\mu}{σ√n} ∼ N(0,1)</script></li><li><p>棣莫弗-拉普拉斯定理<br>当n足够大时，二项分布可视为正态分布。<br>若$X∼B(n,p)$,<br>有$E(X)=np$,$D(x)=np(1-p)$。<br>那么可以标准化X，有：  </p><script type="math/tex; mode=display">\frac{X-E(X)}{√D(X)}∼N(0,1)</script><blockquote><p>二项分布的极限可以是正态分布，也可以是泊松分布，优先选择泊松分布。  </p></blockquote></li></ul><h2 id="统计样本的数值特征和分布"><a href="#统计样本的数值特征和分布" class="headerlink" title="统计样本的数值特征和分布"></a>统计样本的数值特征和分布</h2><ul><li>样本的数值特征<ul><li>样本均值<script type="math/tex; mode=display">\overline{X}=\frac{1}{n}Σx_i</script></li><li>样本方差<script type="math/tex; mode=display">S^2=\frac{1}{n-1}Σ(x_i-\overline{x})^2</script><blockquote><p>n-1</p></blockquote></li></ul></li><li>样本的分布<ul><li>$χ^2$分布<br>如果样本$X_1,X_2,…X_n$服从正态分布，那么$χ^2=Σx_i^2$服从自由度为n的$\chi^2$分布。<br>$χ^2$统计量：  <script type="math/tex; mode=display">\chi^2=\frac{(n-1)S^2}{\sigma^2}</script>分位点：<br>双侧α分位点：$\chi^2_{1-\frac{α}{2}}$,$\chi^2_{\frac{α}{2}}$<br>单侧α分位点：$\chi^2_{1-α}$，$\chi^2_{α}$   </li><li>t分布<br>如果样本$X ∼ N(0,1)$,且$Y ∼ χ^2_{n}$, X,Y独立，那么$t=\frac{X}{√\frac{Y}{n}}$服从自由度为n的t分布。<br>t统计量：  <script type="math/tex; mode=display">t=\frac{x-\overline{μ}}{S}</script>分位点：<br>双侧α分位点：$t_{\frac{α}{2}}$,$t_{-\frac{α}{2}}$<br>单侧α分位点：$t_{α}$,$-t_{α}$  </li><li>F分布<br>设$U ∼ χ^2(n_1)$,$V ∼ χ^2(n_2)$,U,V相互独立，则称$F=\frac{\frac{U}{N_1}}{\frac{V}{N_2}}$服从自由度为$(n_1,n_2)$的F分布。  </li></ul></li></ul><h2 id="样本的点估计法"><a href="#样本的点估计法" class="headerlink" title="样本的点估计法"></a>样本的点估计法</h2><ul><li>矩估计法<br>设X的概率密度函数为$f(x:θ_1,…,\theta_k)$, 用样本1~k阶矩（$E(x^k)$）代替总体1~k阶矩建立k个方程，联立求解，结果是含有A的式子。<ul><li>结论<script type="math/tex; mode=display">μ=\overline{x},~~~~~σ^2=B_2=A_2-A_1^2</script></li></ul></li><li>最大似然估计法<br>设X的概率密度函数为$f(x:θ_1,…,\theta_k)$, 通过如下方法找出参数的估计量：   <ol><li>求解似然函数$L(\theta)=Πf(x)$   </li><li>对似然函数取对数$ln(L(\theta))=ln(Πf(x))$  </li><li>求导或者是偏导数，使每一个结果都等于0：$\frac{\partial ln(L(\theta)}{\partial θ}=\frac{\partial ln(Πf(x))}{\partial θ}=0$    </li><li>求解θ  <blockquote><p>特殊情况： 均匀分布估计a,b的值，需要设最大值最小值函数      </p></blockquote></li></ol><ul><li>统计量的选取  <ul><li>无偏性<br>如果$θ$的估计量 $θ̂$ 的数学期望存在，且$E(θ̂)=θ$，称$θ̂$是$θ$的无偏估计量。</li></ul><ul><li>有效性<br>如果$θ$的估计量 $θ̂_1$,$θ̂_2$的方差存在，且$D(θ̂_1)&lt;D(θ̂_2)$,称$θ̂_1$比$θ̂_2$更有效。  </li><li>相合性*<br>如果$θ$的估计量 $θ̂$以概率趋近于$θ$，称$θ̂$是$θ$的相合估计量。  </li></ul></li></ul></li></ul><h2 id="区间估计"><a href="#区间估计" class="headerlink" title="区间估计"></a>区间估计</h2><p>区间估计遵循以下方法：  </p><ol><li>选取一个合适的统计量    </li><li>找到α分位点   </li><li>反解出关于参数的不等式  </li><li>代值求出不等式，即为置信区间  </li></ol><h2 id="假设检验"><a href="#假设检验" class="headerlink" title="假设检验"></a>假设检验</h2><p>假设检验遵循以下方法：     </p><ol><li>提出原假设和备择假设，备择假设中不能有等于符号   </li><li>找到α分位点，根据备择假设的符号来判断是单边检验还是双边检验 <blockquote><p>拒绝域的符号和备择假设的符号是相同的  </p></blockquote></li><li>找到拒绝域   </li><li>计算统计量的值，并与分位点的值进行比对，看统计量是否落在了拒绝域     </li></ol><h2 id="随机过程的数值特征和平稳性"><a href="#随机过程的数值特征和平稳性" class="headerlink" title="随机过程的数值特征和平稳性"></a>随机过程的数值特征和平稳性</h2><ul><li>数值特征<br>均值函数：$μ_x(t)=E(X(t))$<br>    例如：若 $X(t)=At+B$,那么$μ_x(t)=E(X(t))=tE(A)+E(B)$<br>自相关函数：$R_{xx}(t_1,t_2)=E[X(t_1).X(t_2)]$<br>方差函数：$D_x(t)=R_{xx}(t,t)-[μ_x(t)]^2$  </li><li>平稳性<br>验证随机过程是否具有宽平稳性需要有三步：  </li></ul><ol><li>验证该过程是否是二阶矩过程*  </li><li>求均值函数是否是一个常数  </li><li>求自相关函数$R(t,t+τ)$是否只与τ有关  </li></ol><h2 id="马尔科夫链"><a href="#马尔科夫链" class="headerlink" title="马尔科夫链"></a>马尔科夫链</h2><ul><li><p>概率转移矩阵<br>表示状态由现态转移到n次态的概率 $P=[现态（竖） \backslash 次态（横）]$</p><script type="math/tex; mode=display">P(n)=p^n</script><p>$p$表示一步转移矩阵，$P(n)$为n步转移矩阵</p></li><li><p>转移概率</p><script type="math/tex; mode=display">P_{ij}(m,m+n)=P(X_{m+n}=a_j|X_m=a_i)</script><p>表示马尔科夫链在时刻m，状态$a_i$下在时刻m+n下转移到状态$a_j$的概率  </p><ul><li>利用全概率公式可以推出$P(X_{m+n})$的概率</li><li>利用乘法公式可以推出$P(X_{m},X_{m+n})$的概率</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>复习笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>数字系统与微处理器-常考知识点</title>
    <link href="/2021/04/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%BE%AE%E5%A4%84%E7%90%86%E5%99%A8/"/>
    <url>/2021/04/27/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E6%95%B0%E5%AD%97%E7%B3%BB%E7%BB%9F%E4%B8%8E%E5%BE%AE%E5%A4%84%E7%90%86%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<h1 id="Knowledge-points-of-Digital-Systems-and-Microprocessors"><a href="#Knowledge-points-of-Digital-Systems-and-Microprocessors" class="headerlink" title="Knowledge points of Digital Systems and Microprocessors"></a>Knowledge points of Digital Systems and Microprocessors</h1><blockquote><p>Made for the final test of Brunel University 2020 EE1655:    Digital Systems and Microprocessors<br>Lecturer: Dr.Zhengwen Huang（黄正文）/Dr. Guoquan Li（李国权）<br>*: appeared in all 3-year final tests  </p></blockquote><p> (Given table): the reference is given in the test paper</p><h2 id="Basic-knowledge-of-binary-code-and-Boolean-algebra"><a href="#Basic-knowledge-of-binary-code-and-Boolean-algebra" class="headerlink" title="Basic knowledge of binary code and Boolean algebra"></a>Basic knowledge of binary code and Boolean algebra</h2><p><strong>Conversion between Dec  BCD, Hex and Binary*</strong><br>X-based to Dec:  </p><script type="math/tex; mode=display">∑_{k=0}^na \times x^k</script><p>ec to X-based:<br>Successive division  </p><p><strong>m-in-n/m-out-of-n/m-of-n codes</strong><br>N stands for total number bits<br>M stands for m bits must be set to 1<br>If the number of  1 in a data package is not equal to m, error happens  </p><p><strong>Parity code</strong><br>The number of 1 in a line is consistently to be even/odd.<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225125946.png" alt="">    </p><p><strong>Truth table equivalence*</strong><br>If two Boolean functions share the same truth table, they are equal.  </p><h2 id="Combinational-logic"><a href="#Combinational-logic" class="headerlink" title="Combinational logic"></a>Combinational logic</h2><p><strong>1st and 2nd canonical form*</strong><br>1st canonical form: (.)+(.)<br>the result of Kmap: 0: F, 1:T<br>2nd canonical form: (+).(+)<br>the result of Kmap: 0:T, 1:F<br>Relation:   $F_{1st}+F_{2nd}=1$<br>They share the same Kmap.  </p><p><strong>Conversion between NAND NOR version*</strong><br>1st canonical form to NAND version:   </p><script type="math/tex; mode=display">A.B+C.D=\overline{(!A.!B).(!C.!D)}</script><p>2nd canonical form to NOR version:   </p><script type="math/tex; mode=display">(A+B).(C+D)=\overline{\overline{A+B}+\overline{C+D}}</script><p><strong>Cellular Logic</strong><br>Recursive function   </p><h2 id="Sequential-logic"><a href="#Sequential-logic" class="headerlink" title="Sequential logic"></a>Sequential logic</h2><p><strong>Structure of SRFF</strong><br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225130211.png" alt="">    </p><p><strong>Characteristics of TFF and DFF*</strong><br>TFF:<br>Structure:<br>Asynchronous TFF:  J=K=1 CLK=T<br>Synchronous TFF:    J=K=T CLK=CLK<br>Functionality:<br>T=0 keep the state<br>T=1 change the state<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225130730.png" alt=""><br>DFF:<br>Structure:<br>$J=D$ $K=\overline{D}$<br>Functionality:<br>whenever the current state is, the next state will be D.<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225130846.png" alt="">                    </p><p><strong>Feedback Shift Register*</strong><br>Method: move the head bits to the tail, with possible options.   </p><p><strong>Counter</strong><br>Counter is used to generate a sequence.  </p><p><strong>Circuit design (Transition diagram, P/N state table, Transition table, K-maps)*</strong><br>Transition diagram:<br>Set A=00 B=01 C=11 D=10<br>Input is IA/B/C/D, list the transition table.  </p><h2 id="Digital-System"><a href="#Digital-System" class="headerlink" title="Digital System"></a>Digital System</h2><p><strong>Multiplexer and design*</strong><br>Simplify some variables in Boolean function, the simplified variables will be used for encoder part.<br>The meaning of n to 1: the number of control bits will be 2^k=n  </p><p><strong>Memory and how to determine its size</strong><br>The memory is determined by the number of logic gates which connected to R/W line.<br>The size of memory= number of gates x number of layers bits.<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225131054.png" alt=""></p><h2 id="Introduction-of-PIC"><a href="#Introduction-of-PIC" class="headerlink" title="Introduction of PIC"></a>Introduction of PIC</h2><p><strong>The basic information of PIC16F876A*</strong>, including:<br>The size of Program memory/Code memory is 8k bits, Data memory is 13k bits, Program counter(PCL) is 13k bits and located in data memory.<br>The maximum level of stacks is 8, with 13 bits width.<br>Number of Pins is 40 (DIP40).<br>Harvard Architecture.<br>There are 35 instructions for PIC16F876A.<br>The location and functionality of SFRs:  </p><ul><li>W register: outside of program memory, the data transition station  </li><li>STATUS register: Program memory, determine which bank in program memory will be used  </li></ul><p><strong>Functionality of some assembly language instructions (Given the table)*</strong>, including:  </p><ul><li>BSF: set the file register to be 1  </li><li>BCF: clear the file register to be 0  </li><li>NOP: do nothing but create a 1 bit delay  </li><li>BTFSC: bit check, if file register is cleared, then skip the following line  </li><li>BTFSS: bit check, if file register is set, then skip the following line  </li></ul><p><strong>Conversion between Two’s complement and  Dec*</strong><br>Positive Dec number: convert to binary number, then keep it.<br>Negative Dec number: remove “-“,convert to binary number, do complement on the number, then +1.  </p><p><strong>Conversion between assembly language instructions and machine code*</strong> (Give the table)<br>Structure of machine code:   </p><ul><li>operation code     </li><li>destination     </li><li>file address  </li></ul><p>4 kinds of characters of instruction’s 14-bit Opcoder:  </p><ul><li>K literal </li><li>X don’t care (default to be 0)</li><li>D W register (1 for W register to File register, 0 for File register to W register)</li><li>F  file register’s address</li><li>b  bit address within an 8-bit file register</li></ul><p><strong>Subroutine’s explanation by explaining instructions like CALL, GOTO and RETURN and time consumption*</strong><br>Time/Cycle consumption: Normal execution costs 1 us, GOTO and RETURN instruction costs 2us.  </p><p><strong>Track the value of W register</strong><br><strong>Output Devices*</strong>  </p><ul><li><p>7-Segments:<br>Port A: which 7-segments will be lighten<br>Port B: display the number (0:light, 1:dark)  </p></li><li><p>Keypad:<br>Switch Bounce: There should be a delay to wait the time in order to let the key bounce (about10-3s) be finished, or may cause the hazard.  </p></li></ul><p><strong>ADC</strong><br>Precession and LSB:  $LSB=\frac{Range}{2^k}$ , k is the number of bits<br>Quantity error: ⁺-0.5 LSB</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>复习笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 5 成像理论</title>
    <link href="/2021/04/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/5.%20%E6%88%90%E5%83%8F%E7%90%86%E8%AE%BA/"/>
    <url>/2021/04/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/5.%20%E6%88%90%E5%83%8F%E7%90%86%E8%AE%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-5-成像理论"><a href="#Lecture-5-成像理论" class="headerlink" title="Lecture 5 成像理论"></a>Lecture 5 成像理论</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/35B7C4F7C041A7815C1CD209C38BFE41.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 能量·周期信号的傅里叶变换·采样</title>
    <link href="/2021/04/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/6.%20%E5%91%A8%E6%9C%9F%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/04/23/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/6.%20%E5%91%A8%E6%9C%9F%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 40%;<br>    padding-left: 20%;<br>}</style>  </p><h1 id="能量·周期信号的傅里叶变换·采样"><a href="#能量·周期信号的傅里叶变换·采样" class="headerlink" title="能量·周期信号的傅里叶变换·采样"></a>能量·周期信号的傅里叶变换·采样</h1><h2 id="连续信号的能量"><a href="#连续信号的能量" class="headerlink" title="连续信号的能量"></a>连续信号的能量</h2><h3 id="巴塞瓦尔定理"><a href="#巴塞瓦尔定理" class="headerlink" title="巴塞瓦尔定理"></a>巴塞瓦尔定理</h3><p>信号$x(t)$所带有的能量能够用关于其傅里叶变换$X(jω)$模（频域上的幅值）的积分函数表示：  </p><script type="math/tex; mode=display">E=∫|x(t)|^2dt=\frac{1}{2π}∫|X(jω)|^2dω</script><blockquote><p>$X(jω)$是一个复频率函数表示其带有相位  </p></blockquote><h3 id="能量谱"><a href="#能量谱" class="headerlink" title="能量谱"></a>能量谱</h3><p>一个信号$f(t)$的能量谱函数$P$是频域上各谐波幅值平方的和。  </p><script type="math/tex; mode=display">f(t)=∑|F(nω)|^2</script><p>能量谱密度函数：  </p><script type="math/tex; mode=display">P(ω)=\lim_{T→∞}\frac{|F_T(ω)|^2}{T}</script><h3 id="维纳-辛钦定理"><a href="#维纳-辛钦定理" class="headerlink" title="维纳-辛钦定理*"></a>维纳-辛钦定理*</h3><p>定义复信号$f(t)$的自相关函数$R(τ)$:</p><script type="math/tex; mode=display">R(τ)=\lim_{T→∞}\frac{1}{T}∫f(t)f^*(t-τ)dt</script><p>有如下结论：<br><strong>能量谱密度函数是自相关函数的傅里叶变换。</strong></p><script type="math/tex; mode=display">P(ω)=F[R(τ)]</script><h2 id="时域和频域的对应性质"><a href="#时域和频域的对应性质" class="headerlink" title="时域和频域的对应性质"></a>时域和频域的对应性质</h2><h3 id="卷积与乘法（卷积理论）"><a href="#卷积与乘法（卷积理论）" class="headerlink" title="卷积与乘法（卷积理论）"></a>卷积与乘法（卷积理论）</h3><p><strong>时域中两函数相乘⇔$\frac{1}{2\pi}$频域中两函数的傅里叶变换卷积</strong></p><script type="math/tex; mode=display">f_1(t)f_2(t)⇔\frac{1}{2\pi}F_1(ω)*F_2(ω)</script><p><strong>时域中两函数卷积⇔频域中两函数的傅里叶变换相乘</strong>   </p><script type="math/tex; mode=display">f_1(t)*f_2(t)⇔F_1(ω)F_2(ω)</script><p>应用：</p><ol><li>求谱密度函数</li><li>求$∫_{-∞}^tf(τ)dτ$的傅里叶变换：<br>$∫_{-∞}^tf(τ)dτ=∫_{-∞}^{∞}f(τ)u(t-τ)dτ=f(t)*u(t)⇔F[f(t)]F[u(t)]$</li><li>系统的零状态响应可以表示为$r(t)=f(t)*h(t)⇔F(ω)H(ω)$<br>两个离散序列$x(n)$,$h(n)$的卷积可以表示为卷积和：<script type="math/tex; mode=display">x(n)*h(n)=∑x(m)h(n-m)</script></li></ol><h3 id="周期性和连续性"><a href="#周期性和连续性" class="headerlink" title="周期性和连续性"></a>周期性和连续性</h3><div class="table-container"><table><thead><tr><th>时域</th><th>频域</th></tr></thead><tbody><tr><td>周期信号</td><td>离散频谱</td></tr><tr><td>非周期信号</td><td>连续频谱</td></tr></tbody></table></div><h2 id="一般连续周期信号的傅里叶变换方法及推导"><a href="#一般连续周期信号的傅里叶变换方法及推导" class="headerlink" title="一般连续周期信号的傅里叶变换方法及推导"></a>一般连续周期信号的傅里叶变换方法及推导</h2><p>设一个连续周期信号$f_T(t)$，其可以分解为傅里叶级数(指数形式)：$f_T(t)=∑F(nω_1)e^{jnω_1t}$。<br>对其做傅里叶变换：</p><script type="math/tex; mode=display">\begin{aligned}    F_T(ω) &= F[f_T(t)]\\      & = F[∑F(nω_1)e^{jnω_1t} \\    & = ∑F(nω_1)F[e^{jnω_1t}] \\    ∵ F[1]& =δ(ω)\\     ∴ F[e^{jnω_1t}]&=2πδ(ω-nω_1) \text{ (timeshifting)} \\    ∴ F_T(ω) &= 2πδ(ω-nω_1)∑F(nω_1)\end{aligned}</script><p>即连续周期信号$f_T(t)$傅里叶变换：  </p><script type="math/tex; mode=display">F_T(ω) = 2πδ(ω-nω_1)∑F(nω_1)</script><p>因此如何找到$F(nω_1)$成为了解决连续周期信号的关键。  </p><h3 id="由非周期频谱推导周期频谱"><a href="#由非周期频谱推导周期频谱" class="headerlink" title="由非周期频谱推导周期频谱"></a>由非周期频谱推导周期频谱</h3><p>设周期频谱$F(nω_1)$可以根据周期分解为$n$个非周期子频谱$F_0(ω)$:<br>由$F(nω_1)=\frac{1}{T}∫_{-\frac{T}{2}}^{\frac{T}{2}}f_0(t)e^{-jnω_1t}dt$，有</p><script type="math/tex; mode=display">F(nω_1)=\frac{1}{T}F_0(ω)|_{ω=nω_1}</script><h2 id="常见周期信号的频谱"><a href="#常见周期信号的频谱" class="headerlink" title="常见周期信号的频谱"></a>常见周期信号的频谱</h2><h3 id="单位冲激序列"><a href="#单位冲激序列" class="headerlink" title="单位冲激序列"></a>单位冲激序列</h3><p>由无数个强度为1的冲激信号组成的周期信号$δ_T(t)$：  </p><script type="math/tex; mode=display">\begin{aligned}    F(nω_1)&=\frac{1}{T_1}F_0(ω)|_{ω=nω_1} \\    &=\frac{1}{T_1}×1\\    &=\frac{1}{T_1}\end{aligned}</script><script type="math/tex; mode=display">\begin{aligned}    F(ω)&=2πδ(ω-nω_1)\frac{1}{T_1}\\    &=ω_1δ(ω-nω_1)\end{aligned}</script><p><strong>因此,任何周期信号都可以看做是子信号$f_0(t)$与$δ_T(t)$的卷积。</strong></p><script type="math/tex; mode=display">f(t)=f_0(t)*δ_T(t)↔F(ω)=F_0(ω)F[δ_T(t)]</script><h3 id="周期方波序列"><a href="#周期方波序列" class="headerlink" title="周期方波序列"></a>周期方波序列</h3><p>由若干个方波$G(t)=u(t+τ)-u(t-τ)$组成的周期信号:  </p><script type="math/tex; mode=display">F(nω_1)=\frac{Eτ}{T}Sa(\frac{nω_1τ}{2})</script><script type="math/tex; mode=display">F(ω)=Eτω_1∑Sa(\frac{nω_1τ}{2})δ(ω-nω_1)</script><h3 id="三角函数信号"><a href="#三角函数信号" class="headerlink" title="三角函数信号"></a>三角函数信号</h3><blockquote><p>由$F[1]=δ(ω)$及其时移特性： $F[e^{jnω_1t}]=2πδ(ω-nω_1)$,$F[e^{-jnω_1t}]=2πδ(ω+nω_1)$可以推导。  </p></blockquote><p><strong>正弦信号</strong>：$f(t)=sin(ω_0t)$  </p><script type="math/tex; mode=display">sin(ω_0t)=\frac{1}{2j}(e^{jω_0t}-e^{-jω_0t})</script><script type="math/tex; mode=display">F(ω)=-jπδ(ω-ω_0)+jπδ(ω+ω_0)</script><p><strong>余弦信号</strong>：$f(t)=cos(ω_0t)$  </p><script type="math/tex; mode=display">cos(ω_0t)=(e^{jω_0t}+e^{-jω_0t})</script><script type="math/tex; mode=display">F(ω)=πδ(ω-ω_0)+πδ(ω+ω_0)</script><h2 id="采样与重构"><a href="#采样与重构" class="headerlink" title="采样与重构"></a>采样与重构</h2><h3 id="模拟信号转数字信号"><a href="#模拟信号转数字信号" class="headerlink" title="模拟信号转数字信号"></a>模拟信号转数字信号</h3><p>模拟信号$f(t)$转换为数字信号经过三步：</p><ol><li>取样</li><li>量化</li><li>编码</li></ol><p>其中取样的本质是$f(t)$与一个周期信号$p(t)$相乘。</p><script type="math/tex; mode=display">f_s(t)=f(t)p(t)</script><p>在频域中：  </p><script type="math/tex; mode=display">F_s(ω)=F(ω)*P(t)</script><h3 id="理想取样"><a href="#理想取样" class="headerlink" title="理想取样"></a>理想取样</h3><p>$p(t)$是周期单位冲激信号$δ_T(t)=∑δ(t-nT_s)$。</p><script type="math/tex; mode=display">\begin{aligned}    P(ω)&=ω_s∑δ(ω-nω_s)\\    F_s(ω)&=\frac{1}{2π}F(ω)*P(t) \\    &=\frac{1}{T_s}∑F(ω-nω_s)\end{aligned}</script><p>如果取样频率$ω_s$（表现为冲激信号的间隔）非常的小，那么频域上取样后的信号可能会产生重叠。<br>如果取样频率非常的大，那么信号会丢失非常多的细节，导致失真。  </p><h3 id="方波取样"><a href="#方波取样" class="headerlink" title="方波取样"></a>方波取样</h3><p>$p(t)$是周期方波信号。</p><script type="math/tex; mode=display">\begin{aligned}    F_s(ω)&=\frac{1}{2π}F(ω)*P(t) \\    &=\frac{Eτ}{T_s}∑San(\frac{nω_sτ}{2})F(ω-nω_s)\end{aligned}</script><h3 id="信号复原"><a href="#信号复原" class="headerlink" title="信号复原"></a>信号复原</h3><p>信号复原的基本思路是利用<strong>低通滤波器</strong>在频域内设定过滤出0到$ω_1$内（一个周期内）的信号频谱$F_0(ω)$，用傅里叶反变换得到$f_0(t)$。</p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7.3. 数据量与学习性能</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.3.%20%E6%95%B0%E6%8D%AE%E9%87%8F/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.3.%20%E6%95%B0%E6%8D%AE%E9%87%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="数据量与学习性能"><a href="#数据量与学习性能" class="headerlink" title="数据量与学习性能"></a>数据量与学习性能</h1><p>在某些情况下，获取大量数据来进行机器学习并得到模型是一个非常有效的提升模型性能的办法。<br>2001年Banko 和 Brill试图用不同的算法对一些容易混淆的词汇进行分类，他们用数据集训练这些算法，并绘制了学习曲线。 学习曲线反映出来对于大部分算法，数据集量的提升都能够改进模型的性能。<br>假设有一个需要大量参数的学习算法（通常这样的算法能够拟合更加复杂的模型，因此训练误差会很小），<strong>在特征充足的条件下，采用更多的数据能够减小过拟合的可能性，那么测试误差会接近于训练误差，测试误差也会很小。</strong>  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>07. 机器学习系统设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7.2. 查准率和召回率</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.2.%20%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.2.%20%E6%9F%A5%E5%87%86%E7%8E%87%E5%92%8C%E5%8F%AC%E5%9B%9E%E7%8E%87/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 50%;<br>    padding-left: 20%;<br>}</style></p><h1 id="查准率和召回率"><a href="#查准率和召回率" class="headerlink" title="查准率和召回率"></a>查准率和召回率</h1><h2 id="偏斜类问题"><a href="#偏斜类问题" class="headerlink" title="偏斜类问题"></a>偏斜类问题</h2><p>在上一讲中提到了用一些数学指标来评估算法是非常有效的一种方法，但是如果错误地选用了某些指标就会导致<strong>偏斜类问题</strong>（Skewed Classification）的出现。<br>具体而言，对于癌症分类问题，如果训练了一个模型并用测试集检测出错误率为1%，但实际上测试集中只有0.5%的患者真正得了癌症。<br>这是因为在测试集中相比于正样本（不患癌症），负样本的比例太低，这就是偏斜类问题：即数据集中某一类样本的数量比其他类多很多，在这种情况下，机器学习算法甚至比“总是认为结果是该类”的算法准确度更低。在偏斜类的情况下，实验者无法判断高正确率（比如改动后的算法的准确度(Accurancy)只发生了非常细微的改动：从99.2%提升到了99.5%）究竟是由于类别不均衡还是算法本身造成的。<br>解决偏斜类问题的方法是引入新的数学指标：<strong>查准率</strong>(Precision)和<strong>召回率</strong>(Recall)。</p><h2 id="查准率和召回率的定义"><a href="#查准率和召回率的定义" class="headerlink" title="查准率和召回率的定义"></a>查准率和召回率的定义</h2><p>有如下将测试结果可视化的方法，称为<strong>混淆矩阵</strong>(Confusion matrix)方法：<br>将横轴作为实际的标签，纵轴作为预测的标签，每一格表示“实际为标签i/但是预测为标签j”的频率，做出矩阵，如下图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210217114634.png" alt=""><br>对角线上频率的总和即为训练集的正确率。<br>混淆矩阵能够容易的表现出分类器错误的分类情况。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210323130333.png" alt=""><br>混淆矩阵可以得到查准率（P）和召回率(R)，具体定义为：<br>查准率=是阳性，预测为阳性的数目（真阳性）/预测为阳性=真阳性总数/（真阳性总数+假阳性总数）<br>召回率=是阳性，预测为阳性的数目（真阳性）/阳性总数=真阳性总数/（真阳性总数+假阴性总数）<br>用查准率和召回率检验“总是认为结果是该类”的算法，其召回率为0。  </p><h3 id="阈值、准确率与查准率和召回率"><a href="#阈值、准确率与查准率和召回率" class="headerlink" title="阈值、准确率与查准率和召回率"></a>阈值、准确率与查准率和召回率</h3><p>如果要想在非常确定的情况下才判断确证癌症，就需要对逻辑回归的阈值进行修改（比如$h(x)$大于0.9才判断为癌症），那么模型将具有高查准率，低召回率的特性，且模型的准确率很高。<br>相反，如果下降阈值（比如$h(x)$只要大于0.1就判断为癌症），那么模型将具有低查准率，高召回率的特性，且模型的准确率很低。<br>由此观之，以上的几个指标均与阈值的设定有关，那么如何通过准确率与查准率评价算法在不同阈值下的性能，从而决定阈值的取值？<br>基本的思路是将这两个指标转化为一个指标，从而更方便地对算法进行选择。 基本想法是用两者的均值替代这两者，但是极端情况（比如：极高召回率和极低的查准率）会让均值不能很好的反应算法的性能。 在这里介绍<strong>F值</strong>（或$F_1$值）:  </p><script type="math/tex; mode=display">F=2\frac{PR}{P+R}</script><p>F值能够给予两者中较低的值较大权重，因此<strong>F值越大，查准率和召回率越接近于1，算法性能越好。</strong>    </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>07. 机器学习系统设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7.1. 学习系统构建方法</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.1.%20%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/7.%20%E5%AD%A6%E4%B9%A0%E7%B3%BB%E7%BB%9F%E8%AE%BE%E8%AE%A1%E4%B8%AD%E7%9A%84%E5%AE%9E%E9%99%85%E9%97%AE%E9%A2%98/7.1.%20%E7%B3%BB%E7%BB%9F%E6%9E%84%E5%BB%BA%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 50%;<br>    padding-left: 20%;<br>}</style></p><h1 id="学习系统构建方法"><a href="#学习系统构建方法" class="headerlink" title="学习系统构建方法"></a>学习系统构建方法</h1><h2 id="方法优先级"><a href="#方法优先级" class="headerlink" title="方法优先级"></a>方法优先级</h2><p>假设垃圾邮件中会存在一些故意拼错的单词，如何通过监督机器学习建立一个垃圾邮件分类器？<br>设$x$表示邮件的特征，分类标签$y={0,1}$分别表示不是垃圾邮件和是垃圾邮件。<br>一个简单思路是从邮件中选取100个单词作为分类器决定邮件是否是垃圾邮件的特征。<br>将这100个单词编码按照字典排序，设特征向量$x$是一个100维的向量，每一个维度代表了100个词中的某一个词在一封邮件中出现（1）或者是不出现（0），用数学的表达即为</p><script type="math/tex; mode=display">x_j=\begin{cases}    1 \text{   if appear} \\    0 \text{   if not appear}\end{cases}</script><p>整个过程如下图所示。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212137.png" alt="">  </p><p>事实上，在实际的分类器中，通常会按照训练集中邮件的词频选出10000到50000个单词来作为特征向量的维度。<br>对于上述的垃圾邮件分类器，如何在邮箱的时间内让垃圾邮件分类器具有高准确率？ 下面提供了几种常见的思路：   </p><ol><li>收集更多的数据。（比如：Honeypot Project）    </li><li>用更加复杂的特征向量。（比如包括发件人，邮件的主题等等）    </li><li>简化目前的特征向量，比如“deal”和“deals”，“discount”和“discounts”是否应该合并在同一维度？ 或者考虑大小写以及标点符号。  </li><li>检测故意拼错的单词。  </li></ol><p>这些思路中哪些才是最具效率的？ 怎样用科学和系统的方法从这些改进方法中选择出真正有效率的改进方法？ 这是本章将会聚焦的问题。   </p><h2 id="系统构建的方法"><a href="#系统构建的方法" class="headerlink" title="系统构建的方法"></a>系统构建的方法</h2><ol><li>用最简单的算法构建神经网络，训练并且用验证集验证。  </li><li>画出学习曲线决定是否需要更多的特征或者数据。  </li><li>误差分析：查看被算法分类错误的文件，找出共同的规律。  </li></ol><p>具体而言，对于垃圾邮件分类器，需要查看全部分类错误的邮件，将它们手动分类并确认它们共同的特性。思考这些共性作为特征如何帮助分类器进行识别。<br>这样做的目的是通过简单的分类算法更能够发现错误的识别，从而获取更明显的特征，进而优化算法。  </p><h3 id="数值方法"><a href="#数值方法" class="headerlink" title="数值方法"></a>数值方法</h3><p>此外，在训练过程中返回一个数学结果（比如准确率）是非常有效的。<br>比如：思考是否将“discount/discounted/discounts/discounting”作为同一个特征？<br>基本思路是通过词干提取(Stemming)软件来提取词干，但是这种软件最简单的检查单词前面的几个字母，因此可能会发生误识别的情况（比如“University/Universe”）。那么是否应该应用词干提取软件来提取特征呢？简单的办法是快速运行一下词干提取软件，获取此时的正确率，与不进行词干提取软件时的正确率进行对比。通过对比试验来辅助决策。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>07. 机器学习系统设计</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6.4. 总结：诊断与调试</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.4.%20%E6%9C%AC%E7%AB%A0%E5%9B%9E%E9%A1%BE/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.4.%20%E6%9C%AC%E7%AB%A0%E5%9B%9E%E9%A1%BE/</url>
    
    <content type="html"><![CDATA[<h1 id="总结：-诊断与调试"><a href="#总结：-诊断与调试" class="headerlink" title="总结： 诊断与调试"></a>总结： 诊断与调试</h1><h2 id="回顾：-改进算法性能的思路"><a href="#回顾：-改进算法性能的思路" class="headerlink" title="回顾： 改进算法性能的思路"></a>回顾： 改进算法性能的思路</h2><p>回到本章最开始的改进算法性能的思路：     </p><ol><li>获得更多的数据集</li><li>选用更少的特征以防止过拟合</li><li>获得更多的特征来补充特征集</li><li>增加多项式特征</li><li>增加正则化参数$λ$   </li><li>减小正则化参数$λ$  </li></ol><p>通过这一章的学习，这些思路有各自的功能和局限性：   </p><ol><li>获得更多的数据集            —仅对高方差有效</li><li>选用更少的特征以防止过拟合   —仅对高方差有效</li><li>获得更多的特征来补充特征集   —通常用于高偏差问题</li><li>增加多项式特征              —仅对高偏差有效</li><li>增加或减小正则化参数$λ$     —仅对高偏差有效</li><li>减小正则化参数$λ$           —仅对高方差有效  </li></ol><h2 id="大型神经网络和小型神经网络"><a href="#大型神经网络和小型神经网络" class="headerlink" title="大型神经网络和小型神经网络"></a>大型神经网络和小型神经网络</h2><p>小型神经网络： 计算量简单<br>大型神经网络： 大计算量，更容易出现过拟合现象<br>通常使用一个正则化的大型神经网络的效果要比小型神经网络更好。<br>大型神经网络的隐藏层数目和单元数目可以通过调参进行优化。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>06. 诊断与调试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6.3. 学习曲线</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.3.%20%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.3.%20%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 30%;<br>    padding-left: 40%;<br>}</style></p><h1 id="学习曲线"><a href="#学习曲线" class="headerlink" title="学习曲线"></a>学习曲线</h1><p>学习曲线是一种检查算法是否正常运行的方法。 具体方法如下：<br>改变训练样本的总数$m$, 分别计算一系列的训练误差$J_{train}(\theta)$和交叉验证误差$J_{cv}(\theta)$。得到结论：如果训练样本的总数很小，模型往往能够很好的拟合，随着样本数的增大，假设模型的平均训练误差会逐渐增大。对于验证集，由于验证集当中的样本都是未被训练过的，在训练样本数很低时，模型的泛化程度不高，因此如果训练样本的总数很小时，假设模型的平均验证误差会很高，随着样本数的增大，平均验证误差会逐渐减小。如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/master/img/20210312162734.png" alt="">   </p><h2 id="高偏差和高方差学习曲线"><a href="#高偏差和高方差学习曲线" class="headerlink" title="高偏差和高方差学习曲线"></a>高偏差和高方差学习曲线</h2><h3 id="高偏差学习曲线"><a href="#高偏差学习曲线" class="headerlink" title="高偏差学习曲线"></a>高偏差学习曲线</h3><p>如果模型不能很好的拟合数据，即出现了高偏差。  在训练集总数$m$非常小时，训练误差非常大，随着随着训练集总数$m$的增大，验证误差会逐渐的减小，最终停留在一个较高的水平。 对于训练误差，随着训练集总数$m$的增大，训练误差误差会越来越大，最终趋近于验证误差。  因为模型的参数过少，因此最终验证误差和训练误差会非常的接近。   </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210821152919.png width=80%>     </p><p>从上图可以看出：<strong>如果一个模型具有高偏差的特性，选用更多的训练集数据并不能改善准确度。</strong>   </p><h3 id="高方差学习曲线"><a href="#高方差学习曲线" class="headerlink" title="高方差学习曲线"></a>高方差学习曲线</h3><p>模型在过拟合下，随着训练集总数$m$的增大，由于模型的泛化程度底下，因此训练误差会越来越高，并最终保持在一定水平。  同高偏差学习曲线一样，高方差模型的验证误差很大，并最终保持在一定水平。   </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210821153002.png width=80%>  </p><p>从上图可以看出：<strong>如果一个模型具有高方差的特性，选用更多的训练集数据能够改善准确度。</strong>    </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>06. 诊断与调试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6.2. 方差与偏差</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.2.%20%E6%96%B9%E5%B7%AE%E5%92%8C%E5%81%8F%E5%B7%AE/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.2.%20%E6%96%B9%E5%B7%AE%E5%92%8C%E5%81%8F%E5%B7%AE/</url>
    
    <content type="html"><![CDATA[<h1 id="方差和偏差"><a href="#方差和偏差" class="headerlink" title="方差和偏差"></a>方差和偏差</h1><h2 id="判断方法"><a href="#判断方法" class="headerlink" title="判断方法"></a>判断方法</h2><p>运行一个学习算法时，如果模型表现不理想，有高可能性是发生了欠拟合（<strong>高偏差（Bias）</strong>）或者过拟合（<strong>高方差（Variance）</strong>）问题。 那么如何判断算法究竟出现了哪一种问题？<br>上一讲中已经定义过训练，测试和验证误差。 通常情况下，假设多项式模型中多项式的次数与训练和测试、验证误差的关系如下图所示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212237.png" alt=""><br>通过上图能够判断模型到底出现了欠拟合还是过拟合：<br><strong>如果训练和测试误差都很高，那么有高概率是发生了欠拟合问题。</strong> <strong>如果训练误差低，测试误差高（远大于训练误差），那么有高概率发生了过拟合问题。</strong>    </p><h2 id="偏差和方差与正则化算法"><a href="#偏差和方差与正则化算法" class="headerlink" title="偏差和方差与正则化算法"></a>偏差和方差与正则化算法</h2><p>假设已经得到了一个$d=4$的多项式模型：</p><script type="math/tex; mode=display">h_θ(x)=θ_0+θ_1x+θ_2x^2+θ_3x^3+θ_4x^4</script><p>对其代价函数增加一个正则化项使得参数尽量缩小:   </p><script type="math/tex; mode=display">J_{\theta}=\frac{1}{2m}[\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+λ\Sigma_{j=1}^{m}\theta_j^2]</script><p>下图表示了正则化系数$λ$的大小与拟合情况的关系：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212259.png" alt=""><br><strong>过大的$λ$容易发生欠拟合问题，而过小的$λ$（近似于$λ=0$）则无法起到规避过拟合的作用。</strong><br>如何设置合适的$λ$呢？<br>通过正则化的代价函数$J(θ)$求出最合适的一组$θ$，此时模型的<strong>训练误差$J_{train}(θ)$应当不包含正则化项</strong>，也就是：</p><script type="math/tex; mode=display">J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2</script><p>在加入正则化算法后，测试一系列的$λ$的值，并得到一系列最优化的代价函数，并求到一系列的$Θ$,再用验证集计算验证集误差$J_{cv}(θ)$,最终选择验证集误差最小的那一组$θ$,使用测试集计算出测试误差$J_{test}$。<br>下图表示了$λ$的大小与训练误差和验证误差的关系：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212322.png" alt="">   </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>06. 诊断与调试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6.1. 性能评估</title>
    <link href="/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.1.%20%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/"/>
    <url>/2021/04/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/6.%20%E8%AF%8A%E6%96%AD%E4%B8%8E%E8%B0%83%E8%AF%95/6.1.%20%E6%80%A7%E8%83%BD%E8%AF%84%E4%BC%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h1><h2 id="下一步做什么"><a href="#下一步做什么" class="headerlink" title="下一步做什么"></a>下一步做什么</h2><p>从第一章到现在，我们已经学习了许多中机器学习的方法。但是在面对如今眼花缭乱的算法时，应当如何选择最合适的算法来对数据集进行学习并改进这个算法？<br>思考如下的例子：<br>假设已经用波士顿房价数据集得到了线性回归的代价函数：   </p><script type="math/tex; mode=display">J_{\theta}=\frac{1}{2m}[\Sigma_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+λ\Sigma_{j=1}^{m}\theta_j^2]</script><p>然而使用这个模型对一个新的房价数据集进行预测的时候，发现误差非常的大，如何改进这个算法的性能？<br>有如下几种解决思路：   </p><ol><li>获得更多的数据集</li><li>选用更少的特征以防止过拟合</li><li>获得更多的特征来补充特征集</li><li>增加多项式特征</li><li>增加或减小正则化参数$λ$    </li></ol><p>很多人从如上的解决思路中随机地选择几项对人工智能进行优化，然而对于某一种人工智能算法，上述的解决思路不一定每一种都有效。运用本章讲的一些技巧后，能够对如上的解决思路中每一项的有效性进行判别，从而更高效地调试神经网络。<br>下面将介绍两种评估机器学习性能的方法，它们被称为<strong>机器学习诊断法</strong>(Machine learning diagnostic)。通过运行这些方法，人们可以了解算法在哪里出现了问题，也能告诉人们做什么样的改进尝试才是有意义的。    </p><h2 id="评估假设"><a href="#评估假设" class="headerlink" title="评估假设"></a>评估假设</h2><p>在3.3.中已经介绍过了过拟合现象，因此单纯地得到预测值和标签的距离很小并不能说明这个假设模型是一个好的模型。<br>那么有什么方法能够排除过拟合地评估假设的性能呢？   </p><p>答案是划分测试集和训练集， 具体而言：将数据集划分(Split)为测试集和训练集（通常是以3：7的比例随机选择（Shuffle）），将训练集中的样本进行机器学习，测试集进行验证。<br>从训练集进行线性回归得到最适合的参数$J(θ)$，再将测试集带入其中：   </p><script type="math/tex; mode=display">J_{test}(\theta)=\frac{1}{2m_{test}}[\Sigma_{i=1}^{m_{test}}(h_θ(x_{test}^{(i)})-y_{test}^{(i)})^2+λ\Sigma_{j=1}^{m_{test}}\theta_j^2]</script><p>回归分类中对数据集的划分和验证类型大致同上，只是$J_{test}(\theta)$的形式略有差别。<br>对于回归分类还有另一形式的测试度量叫做<strong>错误分类</strong>(Misclassification Error/ 0-1 misclassification error)。<br>定义预测值和标签的误差$err(h_θ(x),y)$，有：   </p><script type="math/tex; mode=display">err(h_θ(x),y)= \begin{cases}    1  \text{   if     }   h_θ ≥ 0.5, y=0 \text{   or     } h_θ ≤ 0.5, y=1 \\    0  \text{   if     }   h_θ ≥ 0.5, y=1 \text{   or     } h_θ ≤ 0.5, y=0\end{cases}</script><p>定义测试集的误差：</p><script type="math/tex; mode=display">TestError=\frac{1}{m_{test}}∑_{i=1}^{m_{test}}err(h_θ(x^{(i)}_{test}),y^{(i)})</script><h2 id="训练集，测试集和验证集"><a href="#训练集，测试集和验证集" class="headerlink" title="训练集，测试集和验证集"></a>训练集，测试集和验证集</h2><p>如果要从如下的多项式中选择一个作为假设模型：  </p><script type="math/tex; mode=display">h_θ(x)=θ_0+θ_1x</script><script type="math/tex; mode=display">h_θ(x)=θ_0+θ_1x+θ_2x^2</script><script type="math/tex; mode=display">...</script><script type="math/tex; mode=display">h_θ(x)=θ_0+θ_1x+θ_2x^2+...+θ_nx^n</script><p>设$d$表示多项式中$x$的最大次数，要测试它们对于样本的泛化能力（即过拟合的程度，泛化能力低意味着模型过拟合，模型能够很好的拟合当前的数据集，但是对新的数据并不敏感），最简单的思路是可以对每一个模型都投入数据集，然后得到最优化的一组向量$Θ^{(d)}$，并从测试集求出每一个$J_{test}(Θ^{(d)})$，然后看哪一个模型的$J_{test}(Θ^{(d)})$最小。  但是由于我们用测试集拟合了$d$，并选择了一个最好的$d$，因此$Θ^{(d)}$很可能是对泛化误差的乐观假设。<br>解决办法是对一个数据集分为三个部分：训练集，测试集，和<strong>交叉验证集</strong>（以CV表示）。通常的比例是60%作为训练集，20%作为测试集，20%作为交叉验证集。<br>那么定义训练误差，测试误差，验证误差分别为：   </p><script type="math/tex; mode=display">J_{train}(\theta)=\frac{1}{2m}\sum_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2</script><script type="math/tex; mode=display">J_{test}(\theta)=\frac{1}{2m_{test}}\sum_{i=1}^{m_{test}}(h_θ(x_{test}^{(i)})-y_{test}^{(i)})^2</script><script type="math/tex; mode=display">J_{cv}(\theta)=\frac{1}{2m_{cv}}\sum_{i=1}^{m_{cv}}(h_θ(x_{cv}^{(i)})-y_{cv}^{(i)})^2</script><p>现在使用验证集来选择模型：<br>同样地，每一个数据集都投入模型，然后得到最优化的一组向量$Θ^{(d)}$，将这些Θ投入验证集并使用交叉验证得到一系列的$J_{cv}(\theta^{(d)})$,找到最合适的$d$，再放入测试集中运行。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>06. 诊断与调试</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 4 偶极子天线</title>
    <link href="/2021/04/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/4.%20%E5%81%B6%E6%9E%81%E5%AD%90%E5%A4%A9%E7%BA%BF/"/>
    <url>/2021/04/22/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/4.%20%E5%81%B6%E6%9E%81%E5%AD%90%E5%A4%A9%E7%BA%BF/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-4-偶极子天线"><a href="#Lecture-4-偶极子天线" class="headerlink" title="Lecture 4 偶极子天线"></a>Lecture 4 偶极子天线</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/5694F3B43C86B30F56B20322A9C96071.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/2B207B031170016D90FFCCA11DC39411.png" alt="">  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 时域分析方法（微分/差分方程·卷积）</title>
    <link href="/2021/04/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/5.%20%E7%A6%BB%E6%95%A3%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%97%B6%E5%9F%9F%E5%88%86%E6%9E%90%E6%B3%95/"/>
    <url>/2021/04/05/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/5.%20%E7%A6%BB%E6%95%A3%E7%B3%BB%E7%BB%9F%E7%9A%84%E6%97%B6%E5%9F%9F%E5%88%86%E6%9E%90%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 40%;<br>    padding-left: 20%;<br>}</style>  </p><h1 id="时域分析方法（微分-差分方程·卷积）"><a href="#时域分析方法（微分-差分方程·卷积）" class="headerlink" title="时域分析方法（微分/差分方程·卷积）"></a>时域分析方法（微分/差分方程·卷积）</h1><h2 id="微分-差分方程的解"><a href="#微分-差分方程的解" class="headerlink" title="微分/差分方程的解"></a>微分/差分方程的解</h2><blockquote><p>从本节开始，名词系统输入与系统激励等同，系统输出与系统响应等同。<br>从本节开始，在定积分中$∫$表示从-∞到∞的积分，$∑$表示从-∞到∞的和。  </p></blockquote><p>线性时不变系统可以用一个关于激励($e(t)$)和响应($r(t)$)的$n$阶微分/差分方程对其描述。  </p><blockquote><p>$n$阶在电路中的具体表现为$n$个电容/电感。  </p></blockquote><script type="math/tex; mode=display">C_0\frac{d^nr(t)}{dt^n}+C_1\frac{d^{n-1}r(t)}{dt^{n-1}}+...+C_nr(t)=E_0\frac{d^me(t)}{dt^m}+E_1\frac{d^{m-1}e(t)}{dt^{m-1}}+...+E_me(t)</script><p>这个方程的解由<strong>齐次解</strong>和<strong>特解</strong>两部分组成，齐次解与特解的和构成方程的<strong>全解</strong>。  </p><h3 id="齐次解"><a href="#齐次解" class="headerlink" title="齐次解"></a>齐次解</h3><p>当输入全部为0时，得到的方程：$C_0\frac{d^nr(t)}{dt^n}+C_1\frac{d^{n-1}r(t)}{dt^{n-1}}+…+C_nr(t)=0$，称之为特征方程。<br>由特征方程得到的解称为<strong>齐次解</strong>。<strong>齐次解表示系统的零输入响应</strong>。  </p><h4 id="求齐次解"><a href="#求齐次解" class="headerlink" title="求齐次解"></a><strong>求齐次解</strong></h4><ol><li>将特征方程转化为多项式并求解。<br>对于微分方程的特征方程，其$n$阶微分项可以被换元为$α^n$项，最终将特征方程转化为关于$α$的$n$阶多项式。<br>对于差分方程的特征方程，其0阶差分项$y(n)$可以被换元为关于$α$的最高幂项，如此类推，最终将特征方程转化为关于$α$的$n$阶多项式。  </li><li>根据多项式的解的个数和是否有重根，可以在下表中找到齐次解的形式，并带入多项式的解。  </li><li><p>将齐次解带入已知方程的特解（通常是系统的零状态响应），利用对应阶数项系数相等，求出齐次解中的常系数。  </p><p>不同特征根所对应的齐次解（微分方程）  </p></li></ol><div class="table-container"><table><thead><tr><th style="text-align:center">特征根</th><th style="text-align:center">齐次解$y_p(t)$</th></tr></thead><tbody><tr><td style="text-align:center">单实根</td><td style="text-align:center">$e^{αk}$</td></tr><tr><td style="text-align:center">r重实根</td><td style="text-align:center">$∑C_{r-1}t^{r-1} e^{αk}$</td></tr></tbody></table></div><p>   不同特征根所对应的齐次解（差分方程）  </p><div class="table-container"><table><thead><tr><th style="text-align:center">特征根</th><th style="text-align:center">齐次解$y_p(k)$</th></tr></thead><tbody><tr><td style="text-align:center">单实根</td><td style="text-align:center">$Cα^k$</td></tr><tr><td style="text-align:center">r重实根</td><td style="text-align:center">$∑C_{r-1}k^{r-1} α^k$</td></tr></tbody></table></div><h3 id="特解"><a href="#特解" class="headerlink" title="特解"></a>特解</h3><p>当激励为特定的值或者是函数时，方程的解称为<strong>特解</strong>。  </p><h4 id="求特解"><a href="#求特解" class="headerlink" title="求特解"></a><strong>求特解</strong></h4><ol><li>带入具体的激励$e(t)$到系统的微分/差分方程。</li><li>通过0阶项$r(t)$与激励中最高次数项之间系数的关系，用待定系数法猜想系统响应$r(t)$的结构。</li><li>将$r(t)$的结构代回微分/差分方程，利用对应阶数项系数相等建立方程，解出$r(t)$结构中的常系数。  </li></ol><p>如果已知了一些特解，求另一些特解，可以使用<strong>迭代法</strong>。<br>即从$h(0)$开始列出微分方程，直到列到所求的特解对应的微分方程，将已知的特解带入，从而求出未知的特解。 </p><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><h3 id="零状态响应和零输入响应"><a href="#零状态响应和零输入响应" class="headerlink" title="零状态响应和零输入响应"></a>零状态响应和零输入响应</h3><p>在第二讲中对零状态响应和零输入响应以及线性关系进行过介绍，值得注意的是：零状态响应$r_{zs}(t)$和零输入响应$r_{zi}(t)$是相互独立的，即任何的输入只会影响到零状态响应中t的取值，而不会影响零输入响应中t的取值。<br>零输入响应与系统方程的通解有关，零状态响应与系统方程的特解/非齐次解有关。<br>两者可以通过解非齐次的微分/差分方程得到，解微分/差分方程的通用方法是卷积。  </p><h3 id="卷积方法"><a href="#卷积方法" class="headerlink" title="卷积方法"></a>卷积方法</h3><p>在连续系统中，定义$*$ 为卷积符号，定义卷积运算：  </p><script type="math/tex; mode=display">g(t)=f(t)*h(t)=∫f(τ)h(t-τ)dτ</script><p>由于任何信号都可以被分解为$n$个宽为τ，高为$f(nτ)$的门信号，在$τ$非常小的时候可以认为$gate(t)=u’(t)Δτ=δ(t)$，因此任何的信号都可以用与冲激信号的卷积来表示：  </p><script type="math/tex; mode=display">f(t)=∫f(τ)δ(t-τ)dτ</script><h3 id="几何意义"><a href="#几何意义" class="headerlink" title="几何意义"></a>几何意义</h3><p>两个信号$f(t)$$h(t)$卷积的几何意义是： 将其中一个图像左右翻转，然后从$t=0$处向右平移，平移过程中两个函数图像重叠面积的变化即为卷积图像。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210420111839.png" alt="">   </p><h3 id="计算性质"><a href="#计算性质" class="headerlink" title="计算性质"></a>计算性质</h3><p>基本性质：交换律，结合律，分配率。<br>微分和积分特性：</p><script type="math/tex; mode=display">g'(t)=f'(t)*h(t)=f(t)*h'(t)</script><script type="math/tex; mode=display">g^{(n-m)}(t)=f^{(n)}(t)*h^{(-m)}(t)=f^{(-m)}(t)*h^{(n)}(t)</script><p>注：$g^{(n-m)}(t)$表示对$g(t)$作n次微分，m次积分。  </p><h4 id="与冲激函数或阶跃函数卷积"><a href="#与冲激函数或阶跃函数卷积" class="headerlink" title="与冲激函数或阶跃函数卷积"></a><strong>与冲激函数或阶跃函数卷积</strong></h4><ol><li>$f(t)*δ(t)=f(t)$</li><li>$f(t-t_0)*δ(t-t_1)=f(t-t_0-t_1)$</li><li>$f(t)*δ’(t)=f’(t)$</li></ol><h3 id="卷积和"><a href="#卷积和" class="headerlink" title="卷积和"></a>卷积和</h3><p>在离散系统中，定义卷积和：</p><script type="math/tex; mode=display">f(k)=∑f(i)h(k-i)</script><p>任何的离散序列都可以用其自身与单位序列的卷积和表示：</p><script type="math/tex; mode=display">f(t)=∑f(i)δ(k-i)di</script><p>卷积和也同样满足如上的计算性质和一些特殊的卷积结果：  </p><script type="math/tex; mode=display">x(k)*\delta(k)=x(k)</script><script type="math/tex; mode=display">x(k)* δ(k-1)=x(k-1)</script><h2 id="冲激响应和单位序列-取样响应"><a href="#冲激响应和单位序列-取样响应" class="headerlink" title="冲激响应和单位序列/取样响应"></a>冲激响应和单位序列/取样响应</h2><p>一个连续的LIT系统<strong>零状态</strong>下输入单位冲激函数$δ(t)$，所引起的响应称为<strong>单位冲激响应</strong>，记作$h(t)$。<br><strong>冲激响应是$e(t)=δ(t)$时微分方程的特解。</strong><br><strong>连续系统的零状态响应$r_{zs}(t)$可以表示为系统输入$f(t)$与单位冲击响应$h(t)$的卷积</strong>：  </p><script type="math/tex; mode=display">r_{zs}(t)=f(t)*h(t)</script><p>一个离散的LIT系统<strong>零状态</strong>下输入单位序列$δ(k)$，所引起的响应称为<strong>单位取样响应</strong>，记作$h(k)$。<br><strong>连续系统的零状态响应$r_{zs}(k)$可以表示为系统输入$f(k)$与单位冲击响应$h(k)$的卷积</strong>：  </p><script type="math/tex; mode=display">r_{zs}(k)=f(k)*h(k)</script><h2 id="阶跃响应"><a href="#阶跃响应" class="headerlink" title="阶跃响应"></a>阶跃响应</h2><p>一个LIT系统<strong>零状态</strong>下输入单位阶跃函数$u(t)$所引起的响应称为<strong>单位阶跃响应</strong>，记作$g(t)$。<br>由$u(t)=∫δ(t)dt$,</p><script type="math/tex; mode=display">g(t)=∫_{-∞}^t h(t)dt</script><p>卷积积分需要满足条件$f_1(τ)f_2(t-τ)≠0$，由于对阶跃函数$u(t)$，$t&gt;0$，因此阶跃响应通从用于决定卷积积分的上下限。 </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 3 天线的类型与参数</title>
    <link href="/2021/04/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/3.%20%E5%A4%A9%E7%BA%BF%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8F%82%E6%95%B0/"/>
    <url>/2021/04/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/3.%20%E5%A4%A9%E7%BA%BF%E7%9A%84%E7%B1%BB%E5%9E%8B%E4%B8%8E%E5%8F%82%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-3-天线的类型与参数"><a href="#Lecture-3-天线的类型与参数" class="headerlink" title="Lecture 3 天线的类型与参数"></a>Lecture 3 天线的类型与参数</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/3E086B01F0FC442575E5C8E04AE35E39.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/DDE797FAF6B2844E8DA657C1C6B20E7F.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/CE32250C1D3A9273B71F7A64B61D83C0.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/CE0A293BF2868A3247A2C2CE29E150C2.png" alt="">  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3.2. 分类算法的优化</title>
    <link href="/2021/03/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/3.%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/3.2.%20%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <url>/2021/03/30/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/3.%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/3.2.%20%E5%88%86%E7%B1%BB%E7%AE%97%E6%B3%95%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="分类算法的优化"><a href="#分类算法的优化" class="headerlink" title="分类算法的优化"></a>分类算法的优化</h1><h2 id="其他代价函数优化算法"><a href="#其他代价函数优化算法" class="headerlink" title="其他代价函数优化算法"></a>其他代价函数优化算法</h2><p>对于代价函数，它可以被拆分成求$J(θ)$和求$\frac{∂J(θ)}{∂θ_j }$  两个基础的部分  </p><p>事实上，除了基础的梯度下降算法能够求到最小值之外，还有如下的集中基本方法：</p><ol><li>共轭梯度算法（Conjugate Gradient）</li><li>BFGS</li><li>L-BFGS</li></ol><p>这些算法有一些共同的特点：</p><ol><li>这些算法利用线搜索算法（一种智能内循环）不需要手动选择学习率 α。</li><li>收敛的速度高于梯度下降算法</li><li>复杂度高于梯度下降算法</li></ol><h2 id="多分类问题"><a href="#多分类问题" class="headerlink" title="多分类问题"></a>多分类问题</h2><p>对于同一个数据集x，需要分类的目标不只有两种，意味着离散取值y的值不只有0，1两个值。<br>基本思想是<strong>将一个n元分类问题转化为n个二分类问题</strong>。<br>比如对y=1，2，3:<br>可以先将2，3 设置为负类，使用之前的逻辑分类方法就能够将1与（2，3）分开，重复三次，能得到三个逻辑斯蒂函数：$h_θ^i (x)i=1,2,3$。<br>由于$h_θ^i (x)=P(y=i│x; θ)$， 因此$h_θ^i (x)$表示将1设置为正类别，分类器中是1的概率。<br>最后给定函数$max(h_θ^i (x))$， 表示选择出三个当中概率最高的部分，作为判断的结果。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>03. 逻辑回归与正则化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3.1. 激活函数和代价函数</title>
    <link href="/2021/03/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/3.%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/3.1.%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%92%8C%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/"/>
    <url>/2021/03/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/3.%20%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92/3.1.%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E5%92%8C%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 20%;<br>}</style></p><h1 id="逻辑回归、激活函数及其代价函数"><a href="#逻辑回归、激活函数及其代价函数" class="headerlink" title="逻辑回归、激活函数及其代价函数"></a>逻辑回归、激活函数及其代价函数</h1><h2 id="线性回归的可行性"><a href="#线性回归的可行性" class="headerlink" title="线性回归的可行性"></a>线性回归的可行性</h2><p>对分类算法，其输出结果y只有两种结果{0，1}，分别表示负类和正类，代表没有目标和有目标。<br>在这种情况下，如果用传统的方法以线性拟合${h_θ (x)=θ^T X}$，对于得到的函数应当对y设置阈值a，高于a为一类，低于a为一类。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201224223513.png" alt=""><br>对于分类方法，这种拟合的方式极易受到分散的数据集的影响而导致损失函数的变化，以至于对于特定的损失函数，其阈值的设定十分困难。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201224223523.png" alt=""><br>除此之外，${h_θ(x)}$（在分类算法中称为分类器）的输出值很可能非常大或者非常小，并不与{0，1}完全相符</p><h2 id="假设表示"><a href="#假设表示" class="headerlink" title="假设表示"></a>假设表示</h2><p>基于上述情况，要使分类器的输出在[0,1]之间，可以采用假设表示的方法。<br>设$h_θ (x)=g(θ^T x)$，其中$g(z)=\frac{1}{(1+e^{−z} )}$, 称为<strong>逻辑斯蒂函数</strong>（Sigmoid function，又称为<strong>激活函数</strong>，生物学上的S型曲线），有：</p><script type="math/tex; mode=display">h_θ (x)=\frac{1}{(1+e^{−θ^T X} )}</script><p>其两条渐近线分别为h(x)=0和h(x)=1</p><p>在分类条件下，最终的输出结果是：</p><script type="math/tex; mode=display">h_θ (x)=P(y=1│x,θ)</script><p>其代表在给定x的条件下 其y=1的概率<br>有:  </p><script type="math/tex; mode=display">P(y=1│x,θ)+P(y=0│x,θ)=1</script><h2 id="决策边界-Decision-boundary"><a href="#决策边界-Decision-boundary" class="headerlink" title="决策边界(Decision boundary)"></a>决策边界(Decision boundary)</h2><p>对假设函数设定阈值$h(x)=0.5$，<br>当$h(x)≥0.5$ 时，输出结果y=1.<br>根据假设函数的性质，当 $x≥$0时，$h(x)≥0.5$<br>由于之前用$θ^T x$替换x，则当$θ^T x≥0$时，$h(x)≥0.5，y=1$<br>解出 $θ^T x≥0$，其答案将会是一个在每一个$x_i$轴上都有的不等式函数。<br>这个不等式函数将整个空间分成了y=1 和 y=0的两个部分，称之为决策边界。  </p><h2 id="激活函数的代价函数"><a href="#激活函数的代价函数" class="headerlink" title="激活函数的代价函数"></a>激活函数的代价函数</h2><p>在线性回归中的代价函数：</p><script type="math/tex; mode=display">J(θ)=\frac{1}{m}∑_{i=1}^m \frac{1}{2} (h_θ (x^{(i)} )−y^{(i)} )^2</script><p>令$Cost（hθ (x)，y）=\frac{1}{2}(h_θ (x^{(i)} )−y^{(i)} )^2$， Cost是一个非凹函数，有许多的局部最小值，不利于使用梯度下降法。对于分类算法，设置其代价函数为：</p><p>对其化简：</p><script type="math/tex; mode=display">Cost（h_θ (x),y）=−ylog(h_θ (x))−((1−y)log⁡(1−h_θ (x)))</script><p>检验：<br>当 $y=1$时，$−log⁡(h_θ (x))$<br>当 $y=0$时，$−log⁡(1−h_θ (x))$  </p><p>那么代价函数可以写成：  </p><script type="math/tex; mode=display">J(θ)=-\frac{1}{m}[∑_{i=1}^m y^{(i)} log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) log(1−h_θ (x^{(i)}))]</script><p>对于代价函数，采用梯度下降算法求θ的最小值，其更新公式为：</p><script type="math/tex; mode=display">{θ_j≔θ_j−α\frac{∂J(θ)}{∂θ_j}}</script><p>代入梯度：    </p><script type="math/tex; mode=display">θ_j≔θ_j−α∑_{i=1}^m(h_θ (x^{(i)} )−y^{(i)} ) x_j^i</script>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>03. 逻辑回归与正则化</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. 频谱·非周期信号的傅里叶变换</title>
    <link href="/2021/03/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/4.%20%E9%9D%9E%E5%91%A8%E6%9C%9F%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/"/>
    <url>/2021/03/26/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/4.%20%E9%9D%9E%E5%91%A8%E6%9C%9F%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E5%8F%98%E6%8D%A2/</url>
    
    <content type="html"><![CDATA[<style>img{    width: 40%;    padding-left: 20%;}</style>  <h1 id="频谱·非周期信号的傅里叶变换"><a href="#频谱·非周期信号的傅里叶变换" class="headerlink" title="频谱·非周期信号的傅里叶变换"></a>频谱·非周期信号的傅里叶变换</h1><h2 id="信号的频谱"><a href="#信号的频谱" class="headerlink" title="信号的频谱"></a>信号的频谱</h2><p>已经知道信号可以分解为一系列正弦信号或者是数字数信号的和。<br>以各分量（称为各谐波（Harmonics））对应的角频率为横坐标，以各分量的<strong>幅值</strong>或者是<strong>相位</strong>为纵坐标绘制图像，就能得到信号的<strong>频谱图像</strong>。<br>频谱分为两种，<strong>单边频谱（描述三角形式的傅里叶级数）</strong>和<strong>双边频谱（描述指数形式的傅里叶级数）</strong>。<br><strong>要绘制其单边或双边的幅值频谱和相位频谱，才能够完整地描述一个傅里叶级数。</strong><br>单边频谱和双边频谱的关系：<br>单边频谱的幅值是双边频谱的两倍：$A_{uni}=2A_{bil}=√{a_n^2+b_n^2}$。<br>两者相位相同：$ϕ_n=arctan(-\frac{b_n}{a_n})$。<br>例如下图中的三角形式傅里叶级数，可以用单边频谱表示后转换为图中的双边频谱。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/3B514383E2F98F37F7919A3E32FC0BCD.png" alt=""></p><h3 id="周期矩形脉冲信号的频谱"><a href="#周期矩形脉冲信号的频谱" class="headerlink" title="周期矩形脉冲信号的频谱"></a>周期矩形脉冲信号的频谱</h3><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210326205616.png" alt=""><br>对上图的周期脉冲信号求其傅里叶系数，得到：  </p><script type="math/tex; mode=display">F(nω)=\frac{Eτ}{T_1}Sa(nω_1\frac{τ}{2})</script><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210326205539.png" alt=""><br>称相邻两个分量间的距离为谐波距离，谐波距离为$ω_1$，函数与横轴的第一个交点为主瓣宽度：$\frac{2\pi}{\tau}$。<br>定义$ω_1=\frac{2π}{T_1}$,$T_1$为采样周期。 可以发现主瓣宽度不变的前提下，$T_1$越大，谐波距离越小，谐波分布越稠密。当$T_1→∞$时，整个频谱将趋于连续。<br>因此<strong>周期信号的频谱是离散的，非周期信号的频谱是连续的。</strong></p><ul><li>周期信号的功率<br>归一化（R=1$Ω$）的周期信号的平均功率可以由如下的公式表示：  <script type="math/tex; mode=display">P=\frac{1}{T}∫_0^Tf(t)dt=∑F(nω_1)^2</script></li></ul><h2 id="傅里叶变换、反变换的推导"><a href="#傅里叶变换、反变换的推导" class="headerlink" title="傅里叶变换、反变换的推导"></a>傅里叶变换、反变换的推导</h2><p>对指数形式的傅里叶系数参数：  </p><script type="math/tex; mode=display">F(nω_1)=\frac{1}{T}∫_0^Tf(t)e^{-jnω_1t}dt</script><p>两边同时乘上周期：  </p><script type="math/tex; mode=display">TF(nω_1)=∫_0^Tf(t)e^{-jnω_1t}dt</script><p>当$T→∞$时，左边$TF(nω_1)$是一个有界函数，此时频谱连续$nω_1→ω$，定义频谱密度$F(ω)$：  </p><script type="math/tex; mode=display">\begin{aligned}F(ω) &=lim_{T→∞}TF(nω_1)\\&=lim_{T→∞}∫_0^Tf(t)e^{-jnω_1t}dt\\&=∫f(t)e^{-jnω_1t}dt    \end{aligned}</script><p>定义傅里叶变换算子$F[⋅]$:  </p><script type="math/tex; mode=display">F[⋅]=∫⋅e^{-jω_1t}dt</script><p>可得傅里叶变换：  </p><script type="math/tex; mode=display">F[f(t)]=∫f(t)e^{-jω_1t}dt</script><p>变换后的结果一定可以表示为复指数形式：  </p><script type="math/tex; mode=display">F(ω)=|F(ω)|e^{jϕ(ω)}</script><p>称$|F(ω)|$为振幅，$ϕ(ω)$为相位角。<br>对傅里叶变换的指数形式变形：  </p><script type="math/tex; mode=display">\begin{aligned}f(t)& =∑F(ω_1)e^{jω_1t}\\&=∑\frac{F(ω_1)}{ω_1}ω_1e^{jω_1t}    \end{aligned}</script><p>当$T→∞$时，可证明$\lim_{T→∞}\frac{F(nω_1)}{ω_1}=\frac{F(ω)}{2π}$，有：  </p><script type="math/tex; mode=display">f(t)=\frac{1}{2π}∫F(ω)e^{jωt}dω</script><p>将如上式子定义为傅里叶反变换。<br>因此：<br>傅里叶变换：$F[f(t)]=∫f(t)e^{-jnω_1t}dt$<br>傅里叶反变换：$f(t)=\frac{1}{2π}∫F(ω)e^{jωt}dω$<br>此外应用奇偶分解和欧拉公式可以将傅里叶变换分解为：  </p><script type="math/tex; mode=display">F(ω)=2∫f_e(t)cosωtdt-2j∫f_0(t)sinωtdt</script><h2 id="傅里叶变换的性质"><a href="#傅里叶变换的性质" class="headerlink" title="傅里叶变换的性质"></a>傅里叶变换的性质</h2><ol><li>$f(-t)→F(-ω)$</li><li>$f(-t)→F^*(ω)$</li><li>线性</li><li>对偶性： $F(t)→2πf(-ω)$</li><li>变换操作：  <ul><li>尺度变换：$f(at)→\frac{1}{|a|}F(\frac{ω}{a})$</li><li>时移： $f(t-t_0)→F(ω)e^{-jωt_0}$</li><li>综合：$f(at+b)=f(a(t+b/a))→\frac{1}{|a|}F(\frac{ω}{a})e^{-jω\frac{b}{a}}$  </li><li>频移：$F(ω+ω_0)→f(t)e^{-jω_0t}$  </li></ul></li><li>导数：  <ul><li>时域倒数：$f’(t)→jωF(ω)$  </li><li>频域导数：$F’(ω)→-jtf(t)$</li></ul></li><li>积分：<ul><li>时域积分：$∫f(t)dt=πF(0)δ(ω)+\frac{F(ω)}{jω}$  </li></ul></li></ol><p>总结：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210326215249.png" alt="">   </p><h2 id="常见非周期信号的傅里叶变换"><a href="#常见非周期信号的傅里叶变换" class="headerlink" title="常见非周期信号的傅里叶变换"></a>常见非周期信号的傅里叶变换</h2><h3 id="方波-门函数"><a href="#方波-门函数" class="headerlink" title="方波/门函数"></a>方波/门函数</h3><script type="math/tex; mode=display">f(t)=E, -\frac{τ}{2}<t<\frac{τ}{2}</script><script type="math/tex; mode=display">G(t)=f(t)=u(t+\frac{τ}{2})-u(t-\frac{τ}{2})</script><p>由于$f(t)$只在振幅处有值，因此：  </p><script type="math/tex; mode=display">\begin{aligned}   F(ω)=& ∫_{-\frac{τ}{2}}^{\frac{τ}{2}}Ee^{-jωt}dt \\   & =EτSan(\frac{ωτ}{2})\end{aligned}</script><h3 id="直流信号"><a href="#直流信号" class="headerlink" title="直流信号"></a>直流信号</h3><script type="math/tex; mode=display">f(t)=E</script><p>由于直流信号不满足狄利克雷条件中的绝对可积，因此需要考虑其他方法对其做变换。<br>当门函数的$τ→∞$时，可以将门函数视作一个直流信号函数。  </p><script type="math/tex; mode=display">\begin{aligned}  F(ω) &=\lim_{τ→∞}∫^τ_{-τ}Ee^{-jωt}dt \\    &= E\lim_{τ→∞}\frac{2sin(ωτ)}{ω} \\  &=2πEδ(ω)\end{aligned}</script><p>当$E=1$时，可以推导出</p><script type="math/tex; mode=display">F(ω)=2πδ(ω)</script><h3 id="单位冲激函数"><a href="#单位冲激函数" class="headerlink" title="单位冲激函数"></a>单位冲激函数</h3><script type="math/tex; mode=display">F(ω)=∫δ(t)e^{-jωt}dt=1</script><h3 id="单位冲击偶函数"><a href="#单位冲击偶函数" class="headerlink" title="单位冲击偶函数"></a>单位冲击偶函数</h3><script type="math/tex; mode=display">F(ω)=∫δ'(t)e^{-jωt}dt=jω</script><h3 id="单侧指数函数"><a href="#单侧指数函数" class="headerlink" title="单侧指数函数"></a>单侧指数函数</h3><script type="math/tex; mode=display">f(t)=Ee^{-αt}u(t)</script><script type="math/tex; mode=display">\begin{aligned}   F(ω)=& ∫Ee^{-αt}u(t)dt \\   & =∫_0^∞Ee^{-αt}dt \\   & =\frac{E}{α+jω}\end{aligned}</script><p>对其做复指数变换，就能得到其振幅和相位角：  </p><script type="math/tex; mode=display">\begin{aligned}F(ω) &=\frac{E(α-jω)}{α^2+ω^2}\\   &= \frac{E}{√(a^2+ω^2)}e^{-jarctan\frac{ω}{α}}\end{aligned}</script><h3 id="符号函数"><a href="#符号函数" class="headerlink" title="符号函数"></a>符号函数</h3><script type="math/tex; mode=display">sgn(t)=\begin{cases}   1,t>0\\     -1,t<0\end{cases}</script><p>由于不满足狄利克雷条件中的绝对可积（在t=0处不可积），因此需要对函数做变换，使其可积。<br>设$f_1(t)=sgn(t)e^{-α|t|}$</p><script type="math/tex; mode=display">\begin{aligned}   F(ω)&=\lim_{α→0}[∫_{-∞}^{0}-e^{αt-jωt}dt+∫_0^{∞}e^{-αt-jωt}dt]\\     &=-\lim_{α→0}\frac{2jω}{α^2+ω^2}\\     &=\frac{2}{jω}\end{aligned}</script><p>复指数形式：  </p><script type="math/tex; mode=display">F(ω)=\frac{2}{|ω|}e^{⨦\frac{π}{2}j}</script><h3 id="单位阶梯函数"><a href="#单位阶梯函数" class="headerlink" title="单位阶梯函数"></a>单位阶梯函数</h3><p>由$u(t)=\frac{1}{2}(1+sgn(t))$：  </p><script type="math/tex; mode=display">\begin{aligned}   F(ω)&=∫\frac{1}{2}(1+sgn(t))e^{-jωt}dt\\     &=\frac{1}{2}[∫e^{-jωt}dt+∫sgn(t)e^{-jωt}dt\\     &=πδ(ω)+\frac{1}{jω}\end{aligned}</script>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 2 传输线模型</title>
    <link href="/2021/03/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/2.%20%E4%BC%A0%E8%BE%93%E7%BA%BF%E6%A8%A1%E5%9E%8B/"/>
    <url>/2021/03/25/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/2.%20%E4%BC%A0%E8%BE%93%E7%BA%BF%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-2-传输线模型"><a href="#Lecture-2-传输线模型" class="headerlink" title="Lecture 2 传输线模型"></a>Lecture 2 传输线模型</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/0C5F59E0CE623110CFE54C469261C092.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/5B40E0BC5D5BFF59BECBEE0B759683AC.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.7. 神经网络的优化</title>
    <link href="/2021/03/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.7.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E5%8C%96/"/>
    <url>/2021/03/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.7.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E4%BC%98%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="算法优化"><a href="#算法优化" class="headerlink" title="算法优化"></a>算法优化</h1><h2 id="参数展开"><a href="#参数展开" class="headerlink" title="参数展开"></a>参数展开</h2><p>参数展开是一种将矩阵展开为向量的方法，常用于很多高级优化中。<br>例如如下的高级优化：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp">function[jVal,gradient]=costFunction(theta)<br>...<br>optTheta=fminunc(@costFunction,initialTheta,options)<br></code></pre></div></td></tr></table></figure><br>fminuc是一种高级的优化算法。这些高级优化算法的输入值的形式都是参数向量。<br>在神经网络中，很多参数并非是向量的形式，而是完整的矩阵，比如第l层的参数矩阵$Θ^{(l)}$和梯度矩阵$D^{(l)}$(见5.1.)，这时就需要应用参数展开将这些矩阵展开为向量，方法是在Octave中应用<code>[;]</code>表达将所有的元素从矩阵中取出，展开成一个长向量，并应用<code>reshape</code>语法重新合成矩阵。<br>比如如下的10层神经网络：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/master/img/20210204151039.png" alt="">   </p><h2 id="梯度检测"><a href="#梯度检测" class="headerlink" title="梯度检测"></a>梯度检测</h2><p>反向传播算法的实现过程非常的繁琐，因此在与其他算法一同工作的时候可能会产生一些bug，这些bug可能本身不会影响程序的运行，但是最终输出的模型准确度可能会非常低。 因此需要引入梯度检测(Gredient Check)来解决反向传播算法或类梯度下降算法中出现的这类问题。  </p><ul><li>从数值上近似梯度<br>要想求出代价函数$J(\Theta)$在某一点$\theta$的梯度（在二维内反映为该点的斜率），可以在$\theta$的两边取$\theta \plusmn \epsilon, \epsilon \rightarrow 0$,$\theta$处的梯度可以近似的表示为（实数形式）：<script type="math/tex; mode=display">\frac{dJ(θ )}{dθ }≈  \frac{J(θ +ε )-J(θ -ε )}{2ε }</script>称为双侧差分（Two-side difference）。<br>当$\theta$是$\Theta^{(i)}$的展开时，可以用双侧差分来估计所有的偏导数项：<script type="math/tex; mode=display">\frac{∂ J(θ)}{∂ θ_k}≈ \frac{J(θ _k+ε ,θ_1,...,θ_n )-J(θ _k-ε ,\theta_1,...,θ_n  )}{2ε }</script>在Octave中用如下的代码实现：<figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Cpp"><span class="hljs-keyword">for</span> i=<span class="hljs-number">1</span>:n,<br>  thetaPlus=theta;<br>  thetaPlus=thetaPlus(i)+epsilon;<br>  thetaMinus=theta;<br>  thetaMinus(i)=thetaMinus(i)-epsilon;<br>  gradApprox(i)=(J(thetaPlus)-J(thetaMinus))/(<span class="hljs-number">2</span>*epsilon);<br>end;<br>Check gradApprox≈DVec<br></code></pre></div></td></tr></table></figure></li><li>总结流程<ol><li>利用反向传播算法算出$D^{(i)}$的展开向量DVec</li><li>利用双侧差分计算gradApprox</li><li>DVec和gradApprox作比较    </li><li>关闭双侧差分，利用反向传播进行训练（以提高训练时的算法效率）</li></ol></li></ul><h2 id="随机初始化"><a href="#随机初始化" class="headerlink" title="随机初始化"></a>随机初始化</h2><p>在最开始执行高级优化或者是神经网络的梯度下降时，应当对$Θ$设置一些初始值，即初始化$Θ$。<br>在逻辑回归中，将参数全部初始化为0的做法会导致神经网络中一个单元出发的所有的参数都相等，导致神经网络中所有的隐藏单元都在计算相同的特征。正确的做法是对$Θ$随机地设定一些值来初始化它，具体的做法是：<br>设置某个区间$[-ϵ,ϵ]$，使得所有$θ$都在这个区间内随机取到，用Octave代码实现：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp">theta1 = rand(<span class="hljs-number">10</span>,<span class="hljs-number">11</span>)*(<span class="hljs-number">2</span>*init_epsilon)-init_epsilon; <br><span class="hljs-meta">#rand()的作用是随机生成一个mxn的矩阵，矩阵里面所有的元素值都介于0,1之间。</span><br></code></pre></div></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.6. 回顾：神经网络的实现与梯度下降算法</title>
    <link href="/2021/03/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.6.%20%E6%95%B4%E5%90%88%E5%88%B0%E4%B8%80%E8%B5%B7/"/>
    <url>/2021/03/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.6.%20%E6%95%B4%E5%90%88%E5%88%B0%E4%B8%80%E8%B5%B7/</url>
    
    <content type="html"><![CDATA[<h1 id="回顾：神经网络的实现与梯度下降算法"><a href="#回顾：神经网络的实现与梯度下降算法" class="headerlink" title="回顾：神经网络的实现与梯度下降算法"></a>回顾：神经网络的实现与梯度下降算法</h1><h2 id="搭建神经网络"><a href="#搭建神经网络" class="headerlink" title="搭建神经网络"></a>搭建神经网络</h2><h3 id="选择神经网络的架构"><a href="#选择神经网络的架构" class="headerlink" title="选择神经网络的架构"></a>选择神经网络的架构</h3><p>即选择神经元之间的连接模式，和神经网络的层数，每一层的单元数。   </p><ul><li>输出和输入单元<br>输入单元的数目由分类问题中要区分的类别个数，即特征的维度数量所确定。<br>注意：多元分类问题中输出单元应该是一个多维的向量，对应的维度为1。</li><li>隐藏层<br>通常只有一层隐藏层；如果选择构建多个隐藏层，通常情况下每一个隐藏层中的单元数都是相同的。<br>单元数越多越好，但是隐藏单元数的增加会导致计算量的增大。因此每一个隐藏层中隐藏单元的数目通常与输入层的维度，即特征的数目相匹配（是特征数目的整数倍$k=1,2,3…$）。</li></ul><h3 id="训练神经网络"><a href="#训练神经网络" class="headerlink" title="训练神经网络"></a>训练神经网络</h3><ol><li>随机初始化权重，通常初始化为接近于0的值。</li><li>执行前向传播算法，得到$h_θ(x^{(i)})$的值。</li><li>计算代价/损失函数$J(Θ)$。</li><li>执行方向传播算法来计算$\frac{∂}{∂Θ_{jk}^{(l)}}J(Θ)$具体执行方法是用一个循环<code>for i = 1:m</code>对每一个样本执行前向传播和反向传播算法，得到每一个单元的激励值$a^{(l)}$和误差$δ^{(l)}$。</li><li>使用梯度检查，将反向传播算法得到的$\frac{∂}{∂Θ_{jk}^{(l)}}J(Θ)$与用数值近似得到的$J(Θ)$的梯度进行比较，确定两个值是接近的。</li><li>停用梯度检查。  </li><li>用梯度下降算法或者其他的一些高级的优化方法与反向传播算法结合，并最小化$J(Θ)$的$Θ$。  </li></ol><h2 id="梯度下降算法在神经网络中的应用"><a href="#梯度下降算法在神经网络中的应用" class="headerlink" title="梯度下降算法在神经网络中的应用"></a>梯度下降算法在神经网络中的应用</h2><p><img src="![](https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212547.png" alt=""><br>如图所示的参数与$J(Θ)$的关系中（图中只有两个参数），图中每一点的高度表示了$J(Θ)$的值，也代表了在该点的参数取值下，预测值$h_Θ(x^{(i)})$与实际标签$y^{(i)}$的差距。<br>同之前一样，梯度下降算法从随机的一点开始求这一点的梯度（即下降的最快方向），然后沿着梯度方向持续下降，直到得到局部最优点。</p><h2 id="案例：-ALVINN无人驾驶转向"><a href="#案例：-ALVINN无人驾驶转向" class="headerlink" title="案例： ALVINN无人驾驶转向"></a>案例： ALVINN无人驾驶转向</h2><p>Dean Pomerieau使用三层神经网络ALVINN来训练计算机进行无人驾驶。<br>将汽车转向进行量化，左急转和右急转分别对应了坐标轴上仅有的两个极值点。 每隔两秒，ALVINN就会生成一张前方的路况图，并记录驾驶者的行驶方向，在最开始ALVINN的转向是随机的，通过训练路况图和行驶方向的关系，ALVINN最终做出的转向决定与人类驾驶员的转向基本相同。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.5. 代价函数·反向传播</title>
    <link href="/2021/03/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.5.%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/"/>
    <url>/2021/03/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.5.%20%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0.%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD/</url>
    
    <content type="html"><![CDATA[<h1 id="代价函数·反向传播"><a href="#代价函数·反向传播" class="headerlink" title="代价函数·反向传播"></a>代价函数·反向传播</h1><h2 id="回顾"><a href="#回顾" class="headerlink" title="回顾"></a>回顾</h2><p>接下来的讲义主要考虑两种分类问题：第一种是二元分类，如之前的讲义所述，y的取值只能是0或者1，输出层只有一个输出单元，假设函数的输出值是一个实数；第二种是多元分类，y的取值是一个k维的向量，输出层有k个输出单元。</p><h2 id="神经网络的代价函数形式"><a href="#神经网络的代价函数形式" class="headerlink" title="神经网络的代价函数形式"></a>神经网络的代价函数形式</h2><p>假设一个神经网络训练集有m个训练样本：${(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})}$<br>$L$表示神经网络的总层数，$s_l$表示$l$层中神经元的数量（不包括偏置神经元）。<br>在神经网络中使用的代价函数是在逻辑回归中使用的正则化代价函数：  </p><script type="math/tex; mode=display">J(θ)=-\frac{1}{m}[∑_{i=1}^m y^{(i)} log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) log(1−h_θ (x^{(i)}))]+\frac{λ}{2m}∑_{j=1}^n θ_j^2</script><p>略微不同的是，在神经网络中分类标签和假设函数的输出值都变成了k维的向量，因此神经网络中的代价函数变成了：  </p><script type="math/tex; mode=display">J(θ)=-\frac{1}{m}[∑_{i=1}^m ∑_{k=1}^Ky_k^{(i)} log⁡(h_θ(x^{(i)} )_k)+(1−y_k^{(i)}) log(1−h_θ (x^{(i)})_k)]+\frac{λ}{2m}∑_{l=1}^{L-1}∑_{j=1}^{s_l}∑_{j=1}^{s_l+1} (Θ_{ji}^{(l)})_j^2</script><p>解释：  </p><ol><li>用$(h_Θ(x))_i$来表示第i个输出  </li><li>这个代价函数中$∑_{k=1}^K$表示所有的输出单元之和，这里主要是将$y_k$的值与$(h_Θ(x))_k$的大小作比较   </li><li>正则项的作用是去除那些对应于偏置单元的项，具体而言就是不对$i=0$的项进行求和和正则化。  </li></ol><h2 id="代价函数最小化：反向传播算法"><a href="#代价函数最小化：反向传播算法" class="headerlink" title="代价函数最小化：反向传播算法"></a>代价函数最小化：反向传播算法</h2><h3 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h3><p>同之前的线性回归和逻辑回归一样，接下来要求得代价函数的最小值$J(Θ)min$并求出$Θ$。主要的步骤是写出$J(Θ)$并求关于每一个$Θ_{ij}^{(l)}$的偏导项$\frac{∂}{∂Θ_{ij}^{(l)}}J(Θ)$。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210201185117.png" alt=""><br>现在先来讨论如上图所示的神经网络中，只有一个训练样本$(x,y)$的情况：<br>首先先用前向传播算法（见讲义4.2）验证假设函数是否会真的输出结果:    </p><script type="math/tex; mode=display">a^{(1)}=x</script><script type="math/tex; mode=display">z^{(2)}=Θ^{(1)}a^{(1)},并增加一个偏置单元</script><script type="math/tex; mode=display">a^{(2)}=g(z^{2})</script><script type="math/tex; mode=display">z^{(3)}=Θ^{(2)}a^{(2)},并增加一个偏置单元</script><script type="math/tex; mode=display">a^{(3)}=g(z^{3})</script><script type="math/tex; mode=display">z^{(4)}=Θ^{(3)}a^{(3)}</script><script type="math/tex; mode=display">a^{(4)}=g(z^{4})=h_Θ(x)</script><p>接下来，为了计算关于每一个$Θ_{ij}^{(l)}$的偏导项$\frac{∂}{∂Θ_{ij}^{(l)}}J(Θ)$，就要用到<strong>反向传播算法</strong>（Backpropagation）。<br>从直观上说，对于每一个节点，都要计算每个节点的误差：$δ^{(l)}_j$,表示第l层第j个节点的误差。  </p><script type="math/tex; mode=display">δ^{(l)}_j=a_j^{(l)}-y_j=(h_Θ(x))_j-y_j</script><p>y表示训练集中y向量里的第j个元素的值。<br>其向量形式：  </p><script type="math/tex; mode=display">δ^{(l)}=a^{(l)}-y</script><p>这里的$δ^{(l)}$和$a^{(l)}$都是一层每一个误差/输出所构成的向量。<br>具体而言，对于上图所示的4层（$L=4$）神经网络,第四层的误差项：  </p><script type="math/tex; mode=display">δ^{(4)}=a^{(4)}-y</script><p>照例写出前面两层的误差：  </p><script type="math/tex; mode=display">\delta^{(3)}=(Θ^{(3)})^Tδ^{(4)}⋅g'(z^{(3)})</script><script type="math/tex; mode=display">\delta^{(2)}=(Θ^{(2)})^Tδ^{(3)}⋅g'(z^{(2)})</script><p>事实上应用微积分的链式法则，$g’(z^{(3)})=a^{(3)}⋅(1-a^{(3)})$,1是一个每项都为1的向量。<br>反向传播的步骤相当于是从最后一层开始求误差，然后将最后一层的误差传给前一层，反向依次传播。<br>最终将会有： </p><script type="math/tex; mode=display">\frac{∂}{∂Θ_{ij}^{(l)}}J(Θ)=a^{(l)}_iδ^{(l+1)}_i</script><p>此处忽略了正则化项：$λ$。<br>现在将反向传播算法从一个训练样本拓展到一个有m个训练样本：${(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})}$,$L$层的神经网络训练集：      </p><p>定义$Δ_{ij}^{(l)}=0$用于计算$\frac{∂}{∂Θ_{ij}^{(l)}}J(Θ)$,接下来遍历整个训练集：<br>For $i=1$ to $m$:<br>  set $a^{(1)}=x^{(i)}$ #用于将所有的x输入到输入层的激活函数中<br>  用正向传播算法计算$a^{(l)}~for~l=2,3,…,L$<br>  $δ^{(L)}=a^{(L)}-y^{i}$ #计算最后一层的误差<br>  用反向传播算法计算$\delta^{(L-1)}$到$δ^{(2)}$,<br>  $Δ^{(l)}_{ij}:=Δ^{(l)}_{ij}+a_j^{(l)}δ^{(l+1)}_i$<br>  (写成向量的形式：$Δ^{(l)}:=Δ^{(l)}+δ^{(l+1)}(a_j^{(l)})^T$)<br>结束循环后，令  </p><script type="math/tex; mode=display">D^{(l)}_{ij}:=\begin{cases}    \frac{1}{m}Δ^{(l)}_{ij},j=0       \frac{1}{m}Δ^{(l)}_{ij}+λΘ^{(l)}_{ij},j \not=0 \end{cases}</script><p>那么最终：  </p><script type="math/tex; mode=display">\frac{∂}{∂Θ_{ij}^{(l)}}J(Θ)=D^{(l)}_{ij}</script><h3 id="理解"><a href="#理解" class="headerlink" title="理解"></a>理解</h3><ul><li>回顾：前向传播模型<br>前向传播的整个过程可以用下图表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212706.png" alt=""><br>比如：如果洋红色的部分其权重为$Θ_{10}^{(2)}$,红色的权重值为$Θ_{11}^{(2)}$，青色的权重值是$Θ_{12}^{(2)}$， 那么$z_1^{(3)}=Θ_{10}^{(2)} \times 1+Θ_{11}^{(2)} × a_1^{(2)}+Θ_{12}^{(2)}×a_1^{(2)}$。<br>反向传播的过程和前向传播非常类似，只是传播的方向不同。  </li><li>反向传播的理解<br>关注反向传播的代价函数：   <script type="math/tex; mode=display">J(θ)=-\frac{1}{m}[∑_{i=1}^m ∑_{k=1}^Ky_k^{(i)} log⁡(h_θ(x^{(i)} )_k)+(1−y_k^{(i)}) log(1−h_θ (x^{(i)})_k)]+\frac{λ}{2m}∑_{l=1}^{L-1}∑_{j=1}^{s_l}∑_{j=1}^{s_l+1} (Θ_{ji}^{(l)})_j^2</script>对于单个的样本:$(x^{(i)},y^{(i)})$，只有一个输出单元并且忽略正则化，那么这个样本的代价函数：  <script type="math/tex; mode=display">Cost(i)=y^{(i)} log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) log(1−h_θ (x^{(i)}))</script>这个代价函数的功能类似于计算方差，可以近似的看做是方差函数：  <script type="math/tex; mode=display">Cost(i)≈(h_\Theta(x^{(i)})-y^{(i)})^2</script>它反应了样本模型输出值和样本值的接近程度。<br>反向传播中每个节点的误差：$δ^{(l)}_j$,表示第l层第j个节点的误差。有：   <script type="math/tex; mode=display">δ^{(l)}_j=\frac{\partial}{∂z_j^{(l)}}Cost(i)</script>$z_j^{(l)}$与$h_\Theta(x^{(i)})$相关。  </li></ul><p>  反向传播的整个过程可以用下图表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319212735.png" alt=""><br>  例如对$δ^{(2)}_2$，洋红色和红色箭头分别表示两个权重值$Θ_{12}^{(2)}$和$Θ_{22}^{(2)}$，有  </p><script type="math/tex; mode=display">δ^{(2)}_2=Θ_{12}^{(2)} ×δ^{(3)}_1 +Θ_{22}^{(2)} ×δ^{(3)}_2</script>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.4. 多元分类</title>
    <link href="/2021/03/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.4.%20%E5%A4%9A%E5%85%83%E5%88%86%E7%B1%BB/"/>
    <url>/2021/03/21/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.4.%20%E5%A4%9A%E5%85%83%E5%88%86%E7%B1%BB/</url>
    
    <content type="html"><![CDATA[<h1 id="多元分类"><a href="#多元分类" class="headerlink" title="多元分类"></a>多元分类</h1><h2 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h2><p>一对多分类的实质是对一对一分类的拓展。<br>基本方法是建立一个多输出的神经网络，因此<strong>在多元分类中，最终的输出结果将是一个n维的向量</strong>，输出层的每一个输出单元用于判断是否是某一类（例如：是否是行人，是否是自行车），当判断为结果是某一类时，在理想情况下，这个网络会在这一输出单元输出1，其他的输出单元输出0，最终输出的结果是如：$h_Θ(x)≈\left[\begin{smallmatrix} 1 \\\ 0 \\\ 0 \\\ 0 \end{smallmatrix}\right]$之类的向量。<br>以前我们在训练集中用一个整数y来表示分类的标签，在多元分类中，我们使用如上所示的向量来表示分类的标签。<br>现在假设函数的模型应该为：</p><script type="math/tex; mode=display">h_Θ(x^{(i)})≈y^{(i)}</script><p>等式的左右两边输出的结果都是n维的向量。</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 信号的傅里叶级数</title>
    <link href="/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/3.%20%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0/"/>
    <url>/2021/03/20/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/3.%20%E4%BF%A1%E5%8F%B7%E7%9A%84%E5%82%85%E9%87%8C%E5%8F%B6%E7%BA%A7%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="信号的傅里叶级数"><a href="#信号的傅里叶级数" class="headerlink" title="信号的傅里叶级数"></a>信号的傅里叶级数</h1><h2 id="信号变换"><a href="#信号变换" class="headerlink" title="信号变换"></a>信号变换</h2><p>分解、响应、叠加是信号与系统中最基础的信号处理方式。对信号的变换思路来源于时域内的信号$f(t)$是以时间为变量的函数方程，在时域内噪声和有用信号往往是同时发生的，难以将噪声从信号中剥离，因此需要对信号进行变换，将信号从时域变换到频域（以频率为自变量的空间，频域中的信号可以表示为$H(ω)$），通过频率的不同就能利用滤波器将噪声剥离。  </p><h2 id="正交分解"><a href="#正交分解" class="headerlink" title="正交分解"></a>正交分解</h2><h3 id="正交函数与正交函数集"><a href="#正交函数与正交函数集" class="headerlink" title="正交函数与正交函数集"></a>正交函数与正交函数集</h3><p>在信号领域，如果两个信号在$(t_1,t_2)$内有$∫_{t_1}^{t_2}f_1(t)f_2(t)dt=0$，称两个信号是正交的。<br>如果有n个函数构成的函数集：$\{ϕ_1(t),…,ϕ_n(t)\}$在$(t_1,t_2)$内有：  </p><script type="math/tex; mode=display">∫_{t_1}^{t_2}ϕ_i(t)ϕ_j(t)dt=\begin{cases}  0,i\not=j \\ K_i \not= 0, i=j\end{cases}</script><p>称这是一个正交函数集。<br>如果在这个函数集以外找不到任何的另外一个函数满足其与集内函数两两正交，称这个函数集是一个完备的正交函数集。<br><strong>三角函数集$\{1,cosnΩt,sinnΩt\}$就是一个完备的正交函数集。</strong></p><h3 id="信号的正交分解"><a href="#信号的正交分解" class="headerlink" title="信号的正交分解"></a>信号的正交分解</h3><p>正交分解是最简单的一种信号分解方式，任何一个函数$f_1(t)$都可以用$n$个两两正交的函数的线性组合来近似。 有：  </p><script type="math/tex; mode=display">f_1(t)=∑C_iϕ_i(t)+f_e(t)</script><p>这样的分解方式称为信号的<strong>正交分解</strong>，即将目标信号$f_1(t)$分解为若干个正交信号的线性组合和误差信号$f_e(t)$，简化表示方法：    </p><script type="math/tex; mode=display">f_2(t)=∑C_iϕ_i(t)</script><p>此时的$f_2(t)$不在具有限定性，是一个任意的函数。进一步得到任何一个信号$f_1(t)$都可以用一个加权的信号$f_2(t)$与误差信号$f_e(t)$表示：  </p><script type="math/tex; mode=display">f_1(t)=C_{12}f_2(t)+f_e(t)</script><p>$C_{12}$是$f_2(t)$的权重，称为相关系数。$f_e(t)$是拟合误差。<br>判断拟合是否准确的标准是拟合误差的均方值，当拟合误差的均方值最小时，信号拟合度最高，均方值表示为：  </p><script type="math/tex; mode=display">\overline{ɛ^2}=\overline{f^2_e(t)}=\frac{1}{t_2-t_1}∫_{t_1}^{t_2}f_e^2(t)dt</script><p>对其求导令方程等于0，可以解出：  </p><script type="math/tex; mode=display">∫_{t_1}^{t_2}\frac{d}{dC_{12}}[f_1^2(t)-2C_{12}f_2(t)f_1(t)+f_2^2(t)C_{12}^2]dt=0</script><p>要使方程为0，必须每一项都为0，最终解得：  </p><script type="math/tex; mode=display">C_{12}=\frac{∫_{t_1}^{t_2}f_1(t)f_2(t)dt}{∫_{t_1}^{t_2}f_2^2(t)dt}</script><p>但是正交分解依赖于$f_2(t)$的选取，如果于$f_2(t)$选取的不恰当，拟合度往往不高，在分解时容易丢失$f_1(t)$中有用的信息，因此需要其他更加准确的方法对信号进行分解。通过数学方法可知，当$f_2(t)$是一个完备正交集的线性组合时，此时的拟合效果是最好的。  </p><h2 id="信号的傅里叶级数-1"><a href="#信号的傅里叶级数-1" class="headerlink" title="信号的傅里叶级数"></a>信号的傅里叶级数</h2><p>周期信号$f(t)$在一个周期内可以展开为在完正交信号空间中的无穷级数。而三角函数集正好就是一个完备正交集，因此将信号分解为三角函数集是一种理想的正交分解方法。  高等数学中，任何满足有界可积，有有限个间断点（狄利赫里条件）的函数都可以被描述为傅里叶级数：  </p><script type="math/tex; mode=display">f(t)=a_0+∑_{n=1}^{∞}[a_ncos(nω_1t)+b_nsin(nω_1t)]</script><p>在信号中，$a_0$称为直流分量，是函数在周期内的均值。  </p><script type="math/tex; mode=display">a_0=\frac{1}{T}∫_{t_0}^{t_0+T}f(t)dt</script><blockquote><p>有时定义傅里叶级数的第一项为$\frac{a_0}{2}$，此时$a_0=\frac{2}{T}∫_{t_0}^{t_0+T}f(t)dt$。  </p></blockquote><p>$a_n$称为基波分量，是一个偶函数:  </p><script type="math/tex; mode=display">a_n=\frac{2}{T}∫_{t_0}^{t_0+T}f(t)cos(nω_1t)dt</script><p>$b_n$称为谐波分量，是一个奇函数:  </p><script type="math/tex; mode=display">b_n=\frac{2}{T}∫_{t_0}^{t_0+T}f(t)sin(nω_1t)dt</script><h4 id="傅里叶级数的三角变形"><a href="#傅里叶级数的三角变形" class="headerlink" title="傅里叶级数的三角变形"></a><strong>傅里叶级数的三角变形</strong></h4><ul><li>余弦函数形式<script type="math/tex; mode=display">f(t)=c_0+∑_{n=1}^∞c_ncos(nω_1t+ϕ_n)</script>其中$c_0=a_0$,$c_n=√{a_n^2+b_n^2}$，$ϕ_n=arctan(-\frac{b_n}{a_n})$。  </li></ul><h4 id="参数"><a href="#参数" class="headerlink" title="参数"></a><strong>参数</strong></h4><ul><li>幅值<script type="math/tex; mode=display">|F(nω_1)|=√{a_n^2+b_n^2}</script></li><li>相位  <script type="math/tex; mode=display">ϕ_n=acrtan(-\frac{b_n}{a_n})</script></li></ul><h3 id="傅里叶级数的指数形式"><a href="#傅里叶级数的指数形式" class="headerlink" title="傅里叶级数的指数形式"></a>傅里叶级数的指数形式</h3><p>周期函数能够被分解为指数信号的线性组合，因此： </p><script type="math/tex; mode=display">f(t)=∑F(nω_1)e^{jnω_1t}</script><p>其中：   </p><script type="math/tex; mode=display">F(nω_1)=\frac{1}{T}∫_0^Tf(t)e^{-jnω_1t}dt</script><p>代入欧拉公式：  </p><script type="math/tex; mode=display">F(nω_1)=\frac{1}{T}∫_0^Tf(t)cos(nω_1t)-jf(t)sin(nω_1t)dt</script><p>可以得到</p><script type="math/tex; mode=display">F(nω_1)=\frac{1}{2}(a_n-jb_n)</script><script type="math/tex; mode=display">a_n=F_n+F_{-n}</script><script type="math/tex; mode=display">b_n=j(F_n-F_{-n})</script><p>需要注意的是负的频率/角频率$-ω_1$实际并不存在，只用作数学分析。  </p><h4 id="参数-1"><a href="#参数-1" class="headerlink" title="参数"></a><strong>参数</strong></h4><ul><li>幅值<script type="math/tex; mode=display">|F(nω_1)|=\frac{1}{2}√{a_n^2+b_n^2}</script><strong>指数形式的幅值是三角形式幅值的$\frac{1}{2}$。</strong><br>指数形式的傅里叶级数的幅值函数是一个<strong>偶函数</strong>。  </li><li>相位<script type="math/tex; mode=display">ϕ_n=acrtan(-\frac{b_n}{a_n})</script>指数形式的傅里叶级数的相位函数是一个<strong>奇函数</strong>。</li></ul><h3 id="奇偶周期函数的傅里叶级数"><a href="#奇偶周期函数的傅里叶级数" class="headerlink" title="奇偶周期函数的傅里叶级数"></a>奇偶周期函数的傅里叶级数</h3><p>只需要将奇偶性带入$a_n$,$b_n$即可。<br>对于奇谐/偶谐函数则需要分n的奇偶性进行讨论。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.3. 神经单元的逻辑函数功能</title>
    <link href="/2021/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.3.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0/"/>
    <url>/2021/03/20/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.3.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B8%8E%E9%80%BB%E8%BE%91%E5%87%BD%E6%95%B0/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 50%;<br>    padding-left: 20%;<br>}</style></p><h1 id="神经单元的逻辑函数功能"><a href="#神经单元的逻辑函数功能" class="headerlink" title="神经单元的逻辑函数功能"></a>神经单元的逻辑函数功能</h1><p>思考下面一个例子：<br>如果$x_1,x_2$都为二进制数，如图有四个样本分布在样本空间内，<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101151549.png" alt=""><br>那么假设函数可以写成：</p><script type="math/tex; mode=display">y=x_1 XNOR x_2</script><p>那么神经网络是否可以生成这样的函数呢？ </p><h2 id="简单逻辑函数的实现——AND-OR-NOT"><a href="#简单逻辑函数的实现——AND-OR-NOT" class="headerlink" title="简单逻辑函数的实现——AND,OR,NOT"></a>简单逻辑函数的实现——AND,OR,NOT</h2><p>为了解决这个问题，我们从AND函数入手：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101151722.png" alt=""><br>如图，输入层有两个特征$x_1$和$x_2$，他们是二进制数。目标函数为$y=x_1 AND x_2$.  </p><p><strong>观察激活函数$y=g(x)$,我们发现当$x=4$时，$y=0.99$,当$x=-4$时，$y=0.01$</strong><br>由上述激活函数的性质，为了计算这样的神经网络，首先先增加一个偏置单元 【+1】，对每个单元赋予权重：-30，20,20<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101152043.png" alt=""><br>列出真值表：  </p><script type="math/tex; mode=display">\begin{array}{lcr}x_1 & x_2 & h_θ(x) \\\    0 & 0 & g(-30)≈0 \\\   0 & 1 & g(-10)≈0  \\\  1 & 0 & g(-10)≈0  \\\  1 & 1 & g(10)≈1 \\\  \end{array}</script><p>观察最后一列，我们发现最后一列的输出事实上很接近与AND函数的结果，那么可以认为$h_θ(x) ≈ x_1 AND x_2$</p><p>那么同理，下图的神经网络最终可以生成一个类似于OR函数的假设函数。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101152850.png" alt="">  </p><p>下图的神经网络最终可以生成一个类似于NOT函数的假设函数。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101153145.png" alt=""><br>可以发现NOT是通过给对应的单元施加一个较大的负数来实现的。</p><h2 id="复杂逻辑函数的实现"><a href="#复杂逻辑函数的实现" class="headerlink" title="复杂逻辑函数的实现"></a>复杂逻辑函数的实现</h2><p>下面我们来试试生成如下的函数：  </p><script type="math/tex; mode=display">h_θ(x)=(NOT x_1)AND(NOT x_2)</script><p>分析：<br>要想使$h_θ(x)=1$,那么当且仅当$x_1=x_2=0$时成立，最终的神经网络如下图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101154246.png" alt="">   </p><p>现在我们可以应付本节一开头的问题了——如何使神经网络生成$y=x_1 XNOR x_2$？<br>分析： </p><script type="math/tex; mode=display">x_1XNORx_2=NOT(X_1 XOR X_2)=(x_1 AND x_2)OR((NOT x_1) AND (NOT x_2))</script><p>以逻辑表达式形式书写：</p><script type="math/tex; mode=display">h_θ(x)=(x_1.x_2)+\overline{x_1}.\overline{x_2}</script><p>将它分层：<br>第一层： 获取$x_1$和$x_2$<br>第二层：计算  $a_1^{(2)}=x_1.x_2$  和  $a_2^{(2)}=\overline{x_1}.\overline{x_2}$.<br>第三层：计算  $a_1^{(2)}+a_2^{(2)}$.<br>通过这一节的前半部分，我们已经知道了每一层所需要的函数的神经网络构建方法，最终的神经网络将是：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210101155720.png" alt="">   </p><blockquote><p>实例： 可视化Minst手写字符数据集识别</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 系统概述</title>
    <link href="/2021/03/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/2.%20%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/"/>
    <url>/2021/03/19/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/2.%20%E7%B3%BB%E7%BB%9F%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="系统概述"><a href="#系统概述" class="headerlink" title="系统概述"></a>系统概述</h1><h2 id="系统的类型"><a href="#系统的类型" class="headerlink" title="系统的类型"></a>系统的类型</h2><p>系统可以用数学模型和框图来表示。<br>系统$H[·]$的基本数学模型是:   </p><script type="math/tex; mode=display">y(⋅)=H[f(⋅)]</script><p>称$y(⋅)$是系统的输出，$f(⋅)$是系统的输入。<br>因此对输入的处理与系统本身无任何关系。<br>按照系统的数学模型类型，系统可以分为即时系统（输出（称为系统的响应）仅与当前的输入（称为系统的激励）有关）和动态系统（响应与过去和现在的激励都有关系），离散系统（激励和响应都是离散信号）和连续系统（激励和响应都是连续信号）。  </p><p>本课程主要讨论动态系统。  </p><h2 id="系统的框图模型"><a href="#系统的框图模型" class="headerlink" title="系统的框图模型"></a>系统的框图模型</h2><p>表示系统基本功能的常用单元有：积分器（连续）/延迟单元（离散），加法器，数乘器，延时器。<br>它们的框图如下图（《信号与线性系统分析》）所示。<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319202256.png" alt=""><br>通常的系统方程是左边为系统的输出结果，右边为系统的输入结果。<br>给定已知框图，写出对应的方程的流程通常是：  </p><ol><li>找到系统中的数个加法器，通过分析加法器的来源信号列出等式。  </li><li>将等式进行处理，最终得到$f(t)$与$y(t)$的方程。  </li></ol><h2 id="线性时不变系统的特性"><a href="#线性时不变系统的特性" class="headerlink" title="线性时不变系统的特性"></a>线性时不变系统的特性</h2><h3 id="线性"><a href="#线性" class="headerlink" title="线性"></a>线性</h3><p>线性包含两个内容： 齐次性和可加性。<br>若系统满足：  </p><script type="math/tex; mode=display">H[af(·)]=aH[f(·)]</script><p>称系统$H(·)$具有齐次性。<br>若系统满足：  </p><script type="math/tex; mode=display">H[f_1(·)+f_2(·)]=H[f_1(·)]+H[f_2(·)]</script><p>称系统$H(·)$具有可加性。<br>若以上两点系统$H(·)$都满足，即：</p><script type="math/tex; mode=display">H[C_1f_1(·)+C_2f_2(·)]=C_1H[f_1(t)]+C_2H[f_2(t)]</script><p>称系统是线性的。<br><strong>动态系统的线性判别</strong><br>动态系统的响应$y(·)$与初始状态$x(0)$和系统激励$f(·)$相关，称<strong>输入信号为0（$f(t)=0$）时，仅有初始状态引起的响应叫零输入响应$y_{zi}$</strong>； <strong>初始状态为0（$x(0)=0$）时，仅由输入信号引起的响应叫零状态响应$y_{zs}$</strong>。线性系统的全响应可以分解为这两种响应，称为线性系统的分解特性。<br>如果系统有多个初始状态或/和多个输入信号，对于每一个输入的零状态响应和对于每一个零输入响应都呈现线性，称为零状态/零输入线性。<br><strong>如果一个系统具有分解特性、零状态/零输入线性特性，则该系统是线性系统。</strong><br>因此求解一个动态系统是否是线性系统的步骤：  </p><ol><li>判断系统的零状态响应和零输入响应，将其相加判断是否满足分解性。  </li><li>令$f_3(t)=f_1(t)+f_2(t)$，带入零状态响应和零输入响应，看两者是否分别满足线性。  </li></ol><h3 id="时不变性"><a href="#时不变性" class="headerlink" title="时不变性"></a>时不变性</h3><p>如果系统的参数都是不随着时间变化的常数，称这样的系统是时不变系统。<br>判断方法：系统的输出与激励时移的时间无关，即：  </p><script type="math/tex; mode=display">y(t-τ)=H[f(t-τ)],y(t)=H[f(t)]</script><p><strong>动态系统的时不变性判别</strong>  </p><ol><li>找出系统的零状态。  </li><li>带入$f(t-τ)$，看系统结果是否是$y(t-τ)$。  </li></ol><h3 id="因果性"><a href="#因果性" class="headerlink" title="因果性"></a>因果性</h3><p>如果视激励为响应产生的原因，零状态响应是激励的结果，那么响应不应该出现于激励之前。 换句话说，系统的响应不应该与未来的激励有关，而只与现在和过去的激励有关。<br>称这样的系统为因果系统，因果系统只在以时间为变量的系统中出现。<br>对于系统输出$y(t_r)$,如果系统输入$x(t_i)$导致$t_i&gt;t_r$，此时系统的因果性被破坏，系统不具有因果性。  </p><h3 id="稳定性"><a href="#稳定性" class="headerlink" title="稳定性"></a>稳定性</h3><p>如果系统的激励是有界的，且零状态响应也是有界的，称这样的系统是稳定系统。  </p><h2 id="LTI系统分析方法概述"><a href="#LTI系统分析方法概述" class="headerlink" title="LTI系统分析方法概述"></a>LTI系统分析方法概述</h2><h3 id="描述系统的方法"><a href="#描述系统的方法" class="headerlink" title="描述系统的方法"></a>描述系统的方法</h3><ul><li>输入-输出法<br>只把输入变量和输出变量作为描述的因素，系统内部的结构视作黑箱。  </li><li>状态变量法<br>状态变量法用两个方程描述系统：  <ol><li>状态方程：描述系统内部状态与输入的关系。  </li><li>输出方程： 描述系统内部响应与输入和状态变量之间的关系。  </li></ol></li></ul><h3 id="求解系统方程的方法"><a href="#求解系统方程的方法" class="headerlink" title="求解系统方程的方法"></a>求解系统方程的方法</h3><ul><li>时域分析法<br>直接分析时间变量函数。连续系统通常由微分方程描述，离散系统通常由差分方程描述。因此直接求解对应的以时间为变量的方程。此外还有卷积方法。  </li><li>变换法<br>对时间变量函数转换为某个域中以其他因素作为变量的函数。  </li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.2. 前向传播模型</title>
    <link href="/2021/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.2.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B/"/>
    <url>/2021/03/19/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.2.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E6%9C%AC%E6%A8%A1%E5%9E%8B/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 20%;<br>}</style></p><h1 id="前向传播模型"><a href="#前向传播模型" class="headerlink" title="前向传播模型"></a>前向传播模型</h1><h2 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h2><ul><li>假设： 大脑对于不同功能（听觉，视觉，触觉的处理）的实现是依赖于同样的学习方法  </li><li>依据： 神经重接实验  </li><li>神经元模型<br>神经网络模拟了大脑中的神经元或者是神经网络。先来看大脑中的神经元构成，我们会发现神经元有很多的输入通道（树突），同时通过轴突给其他的神经元传递信号。  将神经元简单抽象：一个计算单元，它从输入端接收一定数目的信息，并作一些处理，并将结果传递给其他的神经元。</li></ul><p>在计算机中，我们构建一个逻辑单元，它从输入端接收数据集X，并作处理来生成一个激活函数$h_θ (x)=\frac{1}{1+e^{-θ^T X}}$<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201229183932.png" alt=""><br>在这个模型之上，输入端会额外增加一个$x_0=1$，称为偏置单元。<br>在神经网络中，$Θ$称为模型的权重，$g(z)=\frac{1}{1+e^{-z}}$称为激活函数。  </p><p>神经网络是一组神经元连接在一起的集合，如图所示<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201229184740.png" alt=""><br>第一层称为输入层，我们在这一层输入全部的特征，最后一层称为输出层，这一层的神经元输出假设的最终结果，中间的层称为隐藏层，隐藏层可能不止有一层。<br>统一地，$a_i^{(j)}$将表示第j层的第i个激活项（激活指计算并输出结果），同时，第j层到第j+1层之间的映射由参数矩阵$Θ^{(j)}$确定，那么上图就可以用公式表示为：</p><script type="math/tex; mode=display">a_1^{(2)}=g(Θ_{10}^{(1)}x_0+Θ_{11}^{(1)}x_1+Θ_{12}^{(1)}x_2+Θ_{13}^{(1)}x_3)</script><script type="math/tex; mode=display">a_2^{(2)}=g(Θ_{20}^{(1)}x_0+Θ_{21}^{(1)}x_1+Θ_{22}^{(1)}x_2+Θ_{23}^{(1)}x_3)</script><script type="math/tex; mode=display">a_3^{(2)}=g(Θ_{30}^{(1)}x_0+Θ_{31}^{(1)}x_1+Θ_{32}^{(1)}x_2+Θ_{33}^{(1)}x_3)</script><script type="math/tex; mode=display">h_{Θ}(x)=g(Θ_{10}^{(2)}a_0^{(2)}+Θ_{11}^{(2)}a_1^{(2)}+Θ_{12}^{(2)}a_2^{(2)}+Θ_{13}^{(2)}a_3^{(2)})</script><p>如果一个网络在第j层有$s_j$个单元，且在第j+1层有$s_j+1$个单元，那么矩阵$Θ^{(j)}$的维度为$s_{j+1} \times (s_j+1)$</p><h2 id="神经网络的向量化-前向传输-Forward-propagation"><a href="#神经网络的向量化-前向传输-Forward-propagation" class="headerlink" title="神经网络的向量化:前向传输(Forward propagation)"></a>神经网络的向量化:前向传输(Forward propagation)</h2><p>对如上的等式，现在将$g()$中的线性加权组合以$z^{(2)}_1,z^{(2)}_2,z^{(2)}_3$表示，那么就有：</p><script type="math/tex; mode=display">a_1^{(2)}=g(z_1^{(2)})</script><script type="math/tex; mode=display">a_2^{(2)}=g(z_2^{(2)})</script><script type="math/tex; mode=display">a_3^{(2)}=g(z_3^{(2)})</script><p>现在就能够定义三个向量使得上述等式转化为向量乘法：<br>$x= \left[\begin{smallmatrix} x_0 \\\ x_1 \\\ x_2 \\\ x_3 \end{smallmatrix}\right]$, $z^{(2)}=\left[\begin{smallmatrix} z_1^{(2)}\\\ z_2^{(2)}\\\ z_3^{(2)}\end{smallmatrix}\right]=Θ^{(1)}x$，$a^{(2)}=\left[\begin{smallmatrix} a_1^{(2)}\\\ a_2^{(2)}\\\ a_3^{(2)}\end{smallmatrix}\right]$  </p><p>那么上述等式最终就可以转化成：</p><script type="math/tex; mode=display">z^{(2)}=Θ^{(1)}x</script><script type="math/tex; mode=display">a^{(2)}=g(z^{(2)})</script><p>对于隐藏层的偏置单元，增加一项$a_0^{(2)}=1$.<br>最后计算$z^{(3)}=Θ^{(2)}a^{(2)}$,那么最终得到的假设模型将会是：    </p><script type="math/tex; mode=display">h_{Θ}(x)=a^{(3)}=g(z^{(3)})</script><p>单看layer2 和 layer3，事实上，这两层做的就是逻辑回归，但输入进逻辑回归的特征不再是原始的特征x，而是通过原始特征生成的特征$a$。<br>而$a$与$x$之间的关系通过θ来定义。 因此可以通过改变$θ$来改变输入层和隐藏层之间的关系。</p><blockquote><p>下一章将说明如何调整$θ$的值来优化假设函数。</p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Lecture 1 电磁场</title>
    <link href="/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/1.%20%E7%94%B5%E7%A3%81%E5%9C%BA/"/>
    <url>/2021/03/18/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A9%E7%BA%BF%E4%B8%8E%E9%80%9A%E4%BF%A1%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/1.%20%E7%94%B5%E7%A3%81%E5%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="Lecture-1-电磁场"><a href="#Lecture-1-电磁场" class="headerlink" title="Lecture 1 电磁场"></a>Lecture 1 电磁场</h1><p><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/E80207522EEFEE067950951FFD5E839A.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/AF6658951704208DE281DD37FF8491AA.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/00752E0A714B34826A010DBEF98453E5.png" alt=""><br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/DEE68BF7F8500DABB1114ED34D0A715E.png" alt="">  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>天线与通信传输原理</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5.1. 神经网络的背景</title>
    <link href="/2021/03/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.1.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%83%8C%E6%99%AF/"/>
    <url>/2021/03/18/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/5.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/5.1.%20%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E8%83%8C%E6%99%AF/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 20%;<br>}</style></p><h1 id="神经网络的背景知识"><a href="#神经网络的背景知识" class="headerlink" title="神经网络的背景知识"></a>神经网络的背景知识</h1><h2 id="激活函数算法的局限性"><a href="#激活函数算法的局限性" class="headerlink" title="激活函数算法的局限性"></a>激活函数算法的局限性</h2><p>假设一个数据集拥有非常多的原始特征和数据量，执行激活函数算法，那么次方项、交叉项会非常的多，计算量非常的大，最终的拟合结果也不好。<br>计算机视觉中的例子：<br>计算机读取到的是图片所对应的像素强度的矩阵。 </p><blockquote><p>对于灰度图像来说，像素强度就是每一个像素的灰度值。<br>对于RGB彩色图像来说，图片上的一个像素以三个值（R,G,B）/三维向量 来进行表示  </p></blockquote><p>如果现在设计一个分类器，使得计算机能够区分一个图片的主体是否为汽车。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/472E9216086782CF8029F2818CA1027A.png" alt=""><br>以图中的pixel1 和 pixel2的位置为例，我们可以把所有数据集中pixel1和pixel2的像素强度投射到坐标轴上，如图使用一个非线性假设来对图像进行分类。<br>如果对于一个50*50像素的图片数据集，那么训练集中将包含至少2500个原始特征（7500 RGB），这时候用激活函数算法计算量会非常的大。  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>05. 神经网络</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>✨【置顶】本站说明</title>
    <link href="/2021/03/15/%E7%BD%AE%E9%A1%B6/"/>
    <url>/2021/03/15/%E7%BD%AE%E9%A1%B6/</url>
    
    <content type="html"><![CDATA[<h2 id="说明"><a href="#说明" class="headerlink" title="说明"></a>说明</h2><p>1️⃣ 建议点击右上角【📚分类】查看文章<br>2️⃣ 由于本站暂未在中国大陆备案，因此会出现偶发性无法访问的情况，此时请先通过科学上网访问，在浏览器留下cookies之后便可正常访问本站⚡<br>3️⃣ 电脑端Chrome/Edge 等Chromium浏览器可以点击左下角的铃铛🔔订阅我的博客<br>4️⃣ 本博客所有文章全部为我手工编写。请尊重我的劳动成果，转载请注明出处，谢谢📖</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>电路与器件-常考知识点</title>
    <link href="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E8%B7%AF%E4%B8%8E%E5%99%A8%E4%BB%B6/"/>
    <url>/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E7%94%B5%E8%B7%AF%E4%B8%8E%E5%99%A8%E4%BB%B6/</url>
    
    <content type="html"><![CDATA[<h1 id="电路与器件"><a href="#电路与器件" class="headerlink" title="电路与器件"></a>电路与器件</h1><blockquote><p>针对Brunel University 2020: EE1618 Devices and Circuits的期末复习笔记<br>Lecturer: Dr. Ruiheng Wu（武瑞恒）/Dr. Chunsing Lai（赖俊升）  </p></blockquote><h2 id="电学部分知识点"><a href="#电学部分知识点" class="headerlink" title="电学部分知识点"></a>电学部分知识点</h2><h3 id="静态电路分析"><a href="#静态电路分析" class="headerlink" title="静态电路分析"></a>静态电路分析</h3><h4 id="1-Y-Delta-形电路转换"><a href="#1-Y-Delta-形电路转换" class="headerlink" title="1. Y- $\Delta$ 形电路转换"></a>1. Y- $\Delta$ 形电路转换</h4><p>现推方法：<br>从Y电路的两个节点看整个电路，必然只有两个电阻被串联使用<br>从$\Delta$ 电路的两个节点看整个电路，电路呈现一个电阻与两个串联电阻并联的情况<br>列出两个电路的方程，求解即可<br>公式：  </p><script type="math/tex; mode=display">R_3=\frac{R_a R_b}{R_A+R_B+R_C}</script><blockquote><p>注：$R_3$是Y- $\Delta$ 形电路中属于Y的，且在$\Delta$电路中 $R_a$与$R_b$中间的电阻  </p><p>当$R_A=R_B=R_C$时，  </p><script type="math/tex; mode=display">R_Y=\frac{R_Δ}{3}</script></blockquote><h4 id="2-最大功率传输定理"><a href="#2-最大功率传输定理" class="headerlink" title="2. 最大功率传输定理"></a>2. 最大功率传输定理</h4><p>最大功率传输定理针对的是某一部分的最大功率<br>当负载$R_L$的电阻值与内电路电阻值相等时，有负载的功率最大<br>结合戴维南定理，可以将$R_L$外的所有部分等效为一个内电路，当<br>$R_L=R_{Th}$ 时有$R_L$的功率最大。  </p><h3 id="动态电路元件"><a href="#动态电路元件" class="headerlink" title="动态电路元件"></a>动态电路元件</h3><h4 id="1-电容"><a href="#1-电容" class="headerlink" title="1. 电容"></a>1. 电容</h4><ul><li><p>连接方式<br>   串联：</p><script type="math/tex; mode=display">\frac{1}{C_t}=\frac{1}{C_1}+\frac{1}{C_2}+...+\frac{1}{C_n}</script><p>   并联：</p><script type="math/tex; mode=display">C_t=C_1+C_2+...+C_n</script></li><li><p>动态响应方程<br>  时间常数：  </p><script type="math/tex; mode=display">\tau = RC</script><p>  未充电： 断路<br>  充电阶段：</p><script type="math/tex; mode=display">v_C(t)=E(1-e^{-\frac{t}{τ}})</script><script type="math/tex; mode=display">i_C(t)=\frac{E}{R}e^{-\frac{t}{τ}}</script><p>  充电完成：短路（理想）<br>  开关断开的瞬间:</p><script type="math/tex; mode=display">u(0_+)=u(0_-)</script><p>  放电阶段：  </p><script type="math/tex; mode=display">v_C(t)=Ee^{-\frac{t}{τ}}</script><script type="math/tex; mode=display">i_C=\frac{E}{R}e^{-\frac{t}{τ}}</script><p>  放电完成： 断路</p></li><li><p>交流电路响应<br>阻抗：  </p><script type="math/tex; mode=display">Z_c=X_c=-\frac{1}{ωC}j=\frac{V_m}{I_m}</script><blockquote><p>j是虚数单位</p></blockquote><p>随着频率的增加，阻抗会逐渐减小</p></li></ul><h4 id="2-电感"><a href="#2-电感" class="headerlink" title="2. 电感"></a>2. 电感</h4><ul><li>电感的定义<script type="math/tex; mode=display">L=\frac{Φ}{I}</script></li><li>连接方式<br>串联：<script type="math/tex; mode=display">L_t=L_1+L_2+...+L_n</script>并联：<script type="math/tex; mode=display">\frac{1}{L_t}=\frac{1}{L_1}+\frac{1}{L_2}+...+\frac{1}{L_n}</script></li><li><p>动态响应方程<br> 时间常数：  </p><script type="math/tex; mode=display">\tau = \frac{L}{R}</script><p>  未充电： 短路<br>  充电阶段：</p><script type="math/tex; mode=display">v_L(t)=Ee^{-\frac{t}{τ}}</script><script type="math/tex; mode=display">i_L(t)=\frac{E}{R}（1-e^{-\frac{t}{τ}}）</script><p>  充电完成：断路（理想）<br>  开关断开的瞬间:</p><script type="math/tex; mode=display">i(0_+)=i(0_-)</script><p>  放电阶段：  </p><script type="math/tex; mode=display">v_L(t)=Ee^{-\frac{t}{τ}}</script><script type="math/tex; mode=display">i_L=\frac{E}{R}e^{-\frac{t}{τ}}</script><blockquote><p>注：放电过程应当与L并联一个电阻以保护整个电路的安全，因此此处的R的阻值与原来相比已经发生了变化  </p></blockquote><p>  放电完成： 短路</p></li><li><p>交流电路响应<br>阻抗： </p><script type="math/tex; mode=display">Z_L=X_L= ωL=\frac{V_m}{I_m}</script><p>随着频率的增加，阻抗会逐渐增加</p></li><li><p>谐振<br>当电路处于谐振状态时， 有：  <strong>$-X_c=X_L$</strong><br>根据该公式可以求出谐振频率。<br>在谐振电路中：$I=\frac{E}{R}$<br>谐振的时候功率因子为1.<br>品质因数（Q）：</p><script type="math/tex; mode=display">Q=\frac{Q(power)}{P}=\frac{X_L}{R}（串联）=\frac{R}{X_c}(并联)</script></li></ul><h3 id="交流电基础"><a href="#交流电基础" class="headerlink" title="交流电基础"></a>交流电基础</h3><ol><li><p>复角表达<br>以 $v=V_msin(\omega t+ θ)$为例：</p><script type="math/tex; mode=display">v=V_msin(\omega t+ θ) →V_{rms} ∠θ</script><script type="math/tex; mode=display">V_{rms}=\frac{V_m}{\sqrt{2}}</script><script type="math/tex; mode=display">V=V_{rms}=V_{rms} ∠θ</script><blockquote><p>相位角相同才能用复角表示</p></blockquote></li><li><p>RLC-交流电电路的功率<br>平均功率/有功功率：</p><script type="math/tex; mode=display">P=V_{rms}I_{rms}cos\theta=\frac{V_{m}I_{m}}{2}cos\theta</script><blockquote><p>在不含LC的交流电电路中：$P=V_{rms}I_{rms}=\frac{V_{m}I_{m}}{2}$  </p></blockquote><script type="math/tex; mode=display">P=I_{rms}^2R</script><p>功率因子：</p><script type="math/tex; mode=display">cos\theta=\frac{P}{S}</script><p>视在功率：</p><script type="math/tex; mode=display">S=V_{rms}I_{rms}</script><script type="math/tex; mode=display">S=I_{rms}^2Z</script><p>无功功率：</p><script type="math/tex; mode=display">Q=V_{rms}I_{rms}sin\theta</script><script type="math/tex; mode=display">Q=I_{rms}^2X</script><script type="math/tex; mode=display">Q=\sqrt{S^2-P^2}</script><blockquote><p>一般采用通过计算P和S的方式来计算Q  </p></blockquote></li></ol><h3 id="无源滤波器"><a href="#无源滤波器" class="headerlink" title="无源滤波器"></a>无源滤波器</h3><ol><li><p>增益<br>功率增益：</p><script type="math/tex; mode=display">A_{p}=\frac{P_o}{P_i}</script><p>对数形式：</p><script type="math/tex; mode=display">A_{p}=10lg(\frac{P_o}{P_i})</script><blockquote><p>10  </p></blockquote><p>电压增益：</p><script type="math/tex; mode=display">A_{v}=\frac{V_o}{V_i}</script><p>对数形式：</p><script type="math/tex; mode=display">A_{v}=20lg(\frac{V_o}{V_i})</script><blockquote><p>20  </p></blockquote></li><li><p>滤波器电路的连接和功能  </p><ul><li>根据电容和电感频率响应的特性具体问题具体分析  </li><li>截止频率在$X_L=R$或者$X_C=R$时</li><li>相位角：$\theta=arctan(\frac{f_{cutoff}})$</li><li>在截止频率时，相位角为45°</li><li>无源带通滤波器的结构是高通和低通滤波器并联</li></ul></li></ol><h3 id="变压器"><a href="#变压器" class="headerlink" title="变压器"></a>变压器</h3><ol><li><p>变压器的性质</p><ul><li>变压器可以变换<strong>阻抗</strong>，<strong>电压</strong>，<strong>电流</strong></li><li>变压器的耦合系数：<script type="math/tex; mode=display">k=\frac{Φ_m}{Φ_p}</script><blockquote><p>$Φ_m$：次级磁通量，$Φ_p$：初级磁通量  </p></blockquote></li></ul><p>初级电动势：</p><script type="math/tex; mode=display">e_p=N_p \frac{d \Phi_p}{dt}=L_p\frac{d i_p}{dt}</script><p>次级电动势：</p><script type="math/tex; mode=display">e_s=N_s \frac{d \Phi_m}{dt}=kN_s \frac{d \Phi_p}{dt}</script></li><li><p>互感系数（Mutual Inductance）  </p><script type="math/tex; mode=display">M=N_s\frac{d \Phi_m}{di_p}=N_s \frac{d \Phi_p}{di_s}</script><script type="math/tex; mode=display">M=k\sqrt{L_p L_s}</script><p>有，</p><script type="math/tex; mode=display">e_p=M\frac{di_p}{dt}   和  e_p=M\frac{di_s}{dt}</script><blockquote><p>注意下标  </p></blockquote></li><li><p>比例关系  </p><script type="math/tex; mode=display">a=\frac{N_p}{N_s}=\frac{e_p}{e_s}=\frac{i_s}{i_p}</script></li></ol><h2 id="电子元件部分知识点"><a href="#电子元件部分知识点" class="headerlink" title="电子元件部分知识点"></a>电子元件部分知识点</h2><h3 id="半导体原理"><a href="#半导体原理" class="headerlink" title="半导体原理"></a>半导体原理</h3><ol><li>半导体类型<br>N型半导体： 填入电子<br>P型半导体： 抽去原有的电子  </li><li>PN结及性质<br>PN结： P型半导体和N型半导体拼接在一起，使得电流的方向仅能从P极到N极<br>正向偏置： 电流由P到N，P-N结的电阻非常的小，可视为短路<br>反向偏置： 电流由N到P，P-N结的电阻非常大，可视为断路  </li></ol><h3 id="二极管电路"><a href="#二极管电路" class="headerlink" title="二极管电路"></a>二极管电路</h3><ol><li><p><strong>二极管的单向导通性</strong><br>对于理想二极管，顺箭头方向可视为导线，逆箭头方向可视为断路  </p></li><li><p><strong>二极管电路分析</strong><br>先假设二极管是导通的，求出二极管所在支路的电流方向，如果解出电流方向为逆箭头方向，则实际的二极管处于反向偏置状态，假设错误；如果解出的电流方向为顺箭头方向，则二极管处于正向偏置状态，假设正确，以此来判断电路中的二极管是否处于导通状态  </p><blockquote><p>错误的假设情况下 需要重新计算电路</p></blockquote></li><li><p>非理想二极管的等效模型<br>非理想的二极管可以等效为一个理想的二极管和一个0.7V的直流电压源串联  </p></li><li><p>二极管的应用</p><ul><li><strong>半波整流器</strong><br>结构：交流电源和二极管串联<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123418.png" alt=""><br>分析：交流电源的某一方向可以通过二极管，达到整流器的作用</li><li><strong>全波/桥式整流器</strong><br>结构：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123320.png" alt=""><br>分析： 无论是交流电源的前半期还是后半期，流过电阻的电流始终是同一个方向 </li></ul><ul><li>全波/变压器整流器<br>结构：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123456.png" alt=""><br>分析： 变压器的输出端被分成了两段，在交流电的前半期还是后半期，电流都能通过其中的一半电路，流过电阻的电流是同一个方向<blockquote><p>由于引入了变压器，这种整流器的噪声非常的大</p><ul><li>并联限流器<br>结构：二极管和直流电压源E串联<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123629.png" alt=""><br>分析：当$|V_{sin}|<E$时，二极管导通$V_{out}=E$     当$|V_{sin}|>E$时，二极管导通$V_{out}=V_{sin}$</li><li><strong>峰值限流器</strong><br>结构：二极管和（电容器||电阻）结构串联<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123629.png" alt=""><br>分析： 在交流电源的前半期，二极管导通，电容器断路，处于充电状态<br>  在交流电源的后半期，二极管断开，电容器放电维持电路的工作  </li></ul></blockquote></li></ul></li></ol><h3 id="运算放大器"><a href="#运算放大器" class="headerlink" title="运算放大器"></a>运算放大器</h3><ol><li><p>放大器的增益<br> 线性增益： 输出与输入的比值是一个定值<br> <strong>电压增益</strong>： $A_v=\frac{V_o}{V_i}$<br><strong>电流增益</strong>:  $A_i=\frac{I_o}{I_i}$<br> <strong>功率增益</strong>:  $A_P=\frac{P_o}{P_i}=A_vA_i$<br> <strong>增益的指数形式</strong>: $A_p=10lg{\frac{P_o}{P_i}}$  </p><blockquote><p>10  </p></blockquote><p>$A_v=20lg{\frac{V_o}{V_i}}$  </p><blockquote><p>20  </p></blockquote><p> 饱和状态： 对于有两个电源的运算放大器，输出电压不会超过最大/最小饱和电压  </p></li><li><p><strong>理想放大器的直流线性等效模型</strong>  </p><ul><li><p><strong>电压等效模型</strong><br>结构:<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123821.png" alt=""><br>分析：</p><script type="math/tex; mode=display">\frac{V_s}{V_i}=\frac{R_s+R_i}{R_i} \tag{1}</script><script type="math/tex; mode=display">\frac{A_{V_o}V_i}{V_o}=\frac{R_O+R_L}{R_L} \tag{2}</script><script type="math/tex; mode=display">A_v=\frac{V_o}{V_s}=\frac{V_o}{V_i}\frac{V_i}{V_s}=\frac{A_{V_o}}{(1+\frac{R_s}{R_i})(1+\frac{R_O}{R_L})}</script><blockquote><p>对于理想的运算放大器:<br>$A_o=∞,R_i=∞,R_o=0$  </p></blockquote></li><li><p><strong>电流等效模型</strong><br>结构： </p><p>分析：</p></li></ul></li></ol><ol><li><p><strong>级联放大器的增益计算</strong></p><ul><li><strong>一般形式</strong>：<script type="math/tex; mode=display">A_t=\Pi A_i</script></li><li><strong>指数形式</strong>：<script type="math/tex; mode=display">A_t =\Sigma A_i</script></li></ul></li><li><p>运算放大器的符号和端口</p><ul><li>pin1：反相输入端</li><li>pin2：同相输入端 </li><li>pin3：输出端</li></ul></li><li><p><strong>运算放大器电路分析</strong></p><ul><li><strong>虚短路和虚接地</strong><br>在线性应用当中，电流从+ 流向 -时（同相输入）运算放大器的同相输入端和反相输入端之间可以认为是短路的，称为虚短路。<br>当电流从-流向+时（反相输入），反相输入端相当于接地，称为虚接地。</li><li><p><strong>反相输入的运算法放大器电路分析</strong><br>   电路图:<br>   <img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123925.png" alt=""><br>   如图，<br>   由虚接地$V_-=0$:</p><script type="math/tex; mode=display">i_1=\frac{V_i}{R_1}</script><script type="math/tex; mode=display">i_2=\frac{-V_o}{R_2}</script><p>   同时，$i_1=i_2$<br>   电压增益：<strong>$A_v=\frac{V_o}{V_i}=-\frac{R_2}{R_1}$</strong>  </p><blockquote><p>反向放大器使用负反馈牺牲增益来增加精度  </p></blockquote><p> <strong>反相加法放大器（2个输入电阻的情况）</strong>：  </p><script type="math/tex; mode=display">i_1=\Sigma_{x=1}\frac{V_x}{R_x} \tag{1}</script><script type="math/tex; mode=display">i_2=\frac{-V_o}{R_f} \tag{2}</script><script type="math/tex; mode=display">i_1=i_2 \tag{3}</script><script type="math/tex; mode=display">V_o=-R_f \Sigma_{x=1}\frac{V_x}{R_x}</script></li><li><p>同相输入的运算放大器电路分析    </p><div class="hljs code-wrapper"><pre><code>  电路图:</code></pre></div><p>   <img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225123941.png" alt=""><br>   如图，<br>   由虚短路$V_+=V_-=V_i$:  </p><script type="math/tex; mode=display">i_1=\frac{0-V_i}{R_1}</script><script type="math/tex; mode=display">i_2=\frac{V_o-V_i}{R_2}</script><p>   同时，$i_1=i_2$<br>   电压增益：<strong>$A_v=\frac{V_o}{V_i}=1+\frac{R_2}{R_1}$</strong>  </p><div class="hljs code-wrapper"><pre><code>  **同相加法放大器（2个输入电阻的情况）**：</code></pre></div><p>   设输入节点电压为$V_n$, 有：</p><script type="math/tex; mode=display">\frac{V_o}{V_n}=1+\frac{R_f}{R_b} \tag{1}</script><p>   由<em>叠加定理</em>：  </p><script type="math/tex; mode=display">V_n=\frac{R_2}{R_1+R_2}V_1+\frac{R_1}{R_1+R_2}V_2 \tag{2}</script><script type="math/tex; mode=display">V_o=(1+\frac{R_f}{R_b}) (\frac{R_2}{R_1+R_2}V_1+\frac{R_1}{R_1+R_2}V_2)</script></li></ul></li></ol><h3 id="三极管电路"><a href="#三极管电路" class="headerlink" title="三极管电路"></a>三极管电路</h3><ol><li>三极管电路的符号和三种模式 <ul><li>三极管有PNP和NPN型两种，无论是哪一种，三极管的箭头永远是在基极（B）和发射极（E）两端，由P型半导体指向N型半导体(即激活态下三极管BE的电流方向)</li><li>三种模式： <strong>激活态</strong>（相当于放大器）、截止态、饱和态（CE之间短路） </li></ul></li><li><p>激活状态下的电路分析  </p><ul><li><p>电流关系  </p><script type="math/tex; mode=display">i_E=i_B+i_c</script><script type="math/tex; mode=display">\frac{i_C}{i_B}=\beta</script><blockquote><p>当$β&gt;100$时，通常可以认为$i_C=i_E$  </p><script type="math/tex; mode=display">V_{BE}=0.7V</script><p>$V_B$和$V_E$的孰大孰小由半导体类型决定  </p><p>善用<em>戴维南等效定理</em>，对复杂的三极管电路进行化简</p></blockquote></li></ul><ul><li><strong>KVL在直流三极管电路下的应用</strong><br>如果E最后未接地而接的电源，则可以对BE间进行KVL分析，列出方程，结合电流关系解出方程 </li></ul></li></ol><h3 id="反馈模型"><a href="#反馈模型" class="headerlink" title="反馈模型"></a>反馈模型</h3><ol><li><strong>反馈模型的结构</strong><br> <img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124457.png" alt=""><br>开环增益：当电路中没有反馈结构B时候的输入与输出之比：$A=\frac{x_o}{x_i}$</li><li><strong>反馈放大器的闭环增益</strong>  <script type="math/tex; mode=display">A_f=\frac{x_o}{x_i}=\frac{A}{1+AB}</script>推导：<script type="math/tex; mode=display">x_o=Ax_i \tag{1}</script><script type="math/tex; mode=display">x_f=Bx_o \tag{2}</script><script type="math/tex; mode=display">x_s=x_f+x_i=x_i+ABx_i \tag{3}</script><script type="math/tex; mode=display">A_f=\frac{x_o}{x_i}=\frac{A}{1+AB}</script></li><li><strong>反馈放大器的优点</strong><br>当$AB$足够大时，$A_f=\frac{1}{B}$,<br>反馈电路（B）通常是由无源器件（RLC）组成，因此此时的增益十分稳定而且可以直接精确地计算得出，即：<ul><li>准确</li><li>可预测</li><li>稳定 </li></ul></li></ol><h3 id="电闸管"><a href="#电闸管" class="headerlink" title="电闸管"></a>电闸管</h3><ol><li><p><strong>肖克利二极管</strong>  </p><ul><li><p>结构<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124603.png" alt=""><br>两个PNP，NPN三极管串联，其中：<br>$B_1 →C_2$ 且 $C_1 →B_2$<br>$E_1=A,E_2=K$</p></li><li><p>特性曲线<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124629.png" alt=""><br>当AK之间的电压非常小时,流过肖克利二极管的电流$I_A$非常小，即肖克利二极管表现大电阻的特性<br>当$V_{AK}=V_{BR}$时，A的三极管很容易饱和，此时会回落到某个电压，此后肖克利二极管可视为小电阻或者导线</p></li></ul></li><li><p><strong>锯齿波发生器</strong></p><ul><li>结构<br>肖克利二极管和电容器并联<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124651.png" alt=""></li><li>分析<br>肖克利二极管和电容器两端的电压相等，设为$V_C$,<br>当$V_C<V_{BR}$时，肖克利二极管表现大电阻特性，电容器充电  当$V_C>V_{BR}$时，肖克利二极管表现小电阻特性（相当于短路），电容器迅速放电</li></ul></li><li><p><strong>SCR整流器</strong></p><ul><li>结构<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124913.png" alt=""><br>两个三极管串联，其中：<br>$B_1 →C_2$ 且 $C_1 →B_2$<br>$E_1=A,E_2=K，B_2=G$</li><li><p>原理<br>给$B_2$一个非常小的电流$i_G$,</p><script type="math/tex; mode=display">i_{B2}=i_G</script><script type="math/tex; mode=display">i_{C2}=\beta_2 i_G=i_{B1}</script><script type="math/tex; mode=display">i_{C1}=\beta_1 i_{C2}=\beta_1 \beta_2 i_G=i_{B2}</script><script type="math/tex; mode=display">...</script><p>最终$i_{B2}$会非常大  </p></li><li><p>IG0=0时的特性曲线<br>同肖克利二极管</p></li></ul></li></ol><h3 id="标准电源调节"><a href="#标准电源调节" class="headerlink" title="标准电源调节"></a>标准电源调节</h3><ol><li><strong>线性调节公式</strong><script type="math/tex; mode=display">Line Regulation=\frac{\frac{\Delta V_{out}}{V_{out}}\times 100\%}{ΔV_{in}}</script></li><li><strong>串联电压调节器</strong><br>结构：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225125122.png" alt=""></li><li><strong>调整晶体管电路</strong><br>结构：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201225124950.png" alt=""><br>原理：<br>肖克利二极管为运算放大器的+提供稳压的作用。<br>当$V_{out}$因为各种原因上升时，与之相连接的分压器$R_2-R_3$会分走一部分电压，对于放大器的反相输入端$V_-=\frac{R_3}{R_2+R_3}$,$V_-$上升，对于整个运算放大器的输入端，有：<script type="math/tex; mode=display">V_{in}(↓)=V_+(-)-V_-(↑)</script>因此输出端$V_{out}=V_{B}$下降，对于可控晶体管，其$V_B(↓)$导致$V_E(↓)$,最终调整$V_{out}(↓)$。<br>与此同时，$V_C(↓)$使得$V_{REF}(↑)$,使得$V_+$上升，但由于肖克利二极管的存在$V_+$的上升幅度不明显。</li></ol>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>复习笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 信号概述</title>
    <link href="/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/1.%20%E4%BF%A1%E5%8F%B7%E6%A6%82%E8%BF%B0/"/>
    <url>/2021/03/15/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/1.%20%E4%BF%A1%E5%8F%B7%E6%A6%82%E8%BF%B0/</url>
    
    <content type="html"><![CDATA[<h1 id="信号概述"><a href="#信号概述" class="headerlink" title="信号概述"></a>信号概述</h1><h2 id="按照时间特性的信号分类"><a href="#按照时间特性的信号分类" class="headerlink" title="按照时间特性的信号分类"></a>按照时间特性的信号分类</h2><h3 id="确定信号和随机信号"><a href="#确定信号和随机信号" class="headerlink" title="确定信号和随机信号"></a>确定信号和随机信号</h3><ol><li>确定信号<br>除了间断点外，对于一个确定的时间$t$,都能有一个确定的值$f(t)$与之对应。  </li><li>随机信号<br>又分为稳定的和不稳定的随机信号。  </li><li>伪随机信号  </li></ol><h3 id="连续时间信号和离散时间信号"><a href="#连续时间信号和离散时间信号" class="headerlink" title="连续时间信号和离散时间信号"></a>连续时间信号和离散时间信号</h3><ol><li><p>连续时间信号<br>除了间断点外，在任何时间$t$都能找到一个与之对应的值$f(t)$。<br>连续时间信号的值域可以是连续的，也可以是不连续的。<br>例如模拟信号：<strong>x轴连续，y轴也连续（可以取到任意值）</strong>。  </p></li><li><p>离散时间信号<br>只有在离散的点$n$上存在对应的值$x(n)$。<br>离散时间信号的定义域是离散的，对值域不做定义。<br>数字信号是一种<strong>x轴离散，y轴离散的信号</strong>。<br>均匀的离散信号通常称为序列。  </p></li></ol><p>模拟信号和数字信号的转换：<br>模拟信号经过取样使得x轴离散后，在通过量化使得y轴也离散，进而得到数字信号。  </p><h3 id="周期信号和非周期信号"><a href="#周期信号和非周期信号" class="headerlink" title="周期信号和非周期信号"></a>周期信号和非周期信号</h3><p>周期信号是在实数域每隔一定时间T/或者整数N，按规律重复变化的信号。  </p><script type="math/tex; mode=display">f(t)=f(t+mT),m ∈Z</script><script type="math/tex; mode=display">x(n)=x(n+mN),m ∈Z</script><h3 id="常见的时间连续信号"><a href="#常见的时间连续信号" class="headerlink" title="常见的时间连续信号"></a>常见的时间连续信号</h3><ul><li>指数信号  </li><li>正弦信号<br>衰减的正弦信号：<script type="math/tex; mode=display">f(t)=ke^{-at}sinωt \text{ t>=0}</script></li><li>复指数信号  </li><li>采样信号  <script type="math/tex; mode=display">sinc(x)=\frac{sinx}{x}</script></li><li>奇异信号  <ul><li>单位阶跃信号  <script type="math/tex; mode=display">u(t)=\begin{cases}    0 ~t<0\\    1 ~t>0\\    \end{cases}</script>注意: 当$t=0$时，定义$u(0)=0.5$（《信号与线性系统分析》）。<br>变化：<br>左移的阶梯信号： $u(t+t_0)=\begin{cases}<br>  0 ~t<0\\  1 ~t>0\\<br>\end{cases}$<br>右移的阶梯信号：$u(t-t_0)=\begin{cases}<br>  0 ~t<0\\  1 ~t>0\\<br>\end{cases}$<br>门信号：$g(t)=u(t+\frac{\tau}{2})-u(t-\frac{\tau}{2})$<br>符号函数： $sig(t)=2u(t)-1$  </li><li>单位冲激函数和冲击偶函数<br>推导：<br>面积为1，宽为$τ$，高为$\frac{1}{τ}$的门函数，其对称轴是$x=0$。<br>令$τ→0$,得到宽为$0$，高为$∞$的<strong>单位冲激函数</strong>$δ(t)$，即：  <script type="math/tex; mode=display">δ(t)=lim_{τ→0}\frac{1}{τ}[u(t+\frac{τ}{2})-u(t-\frac{τ}{2})]</script>有：  <script type="math/tex; mode=display">u'(t)=δ(t)</script>任意的信号都可以被分解为有权的单位冲激信号。<br>冲激函数的表示：<br><img src="https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210319194902.png" alt=""><br>如上图，其中$(n)$表示强度为$n$的冲激函数，即$nδ(t)$。<br>性质：  <ol><li>赋值性  <script type="math/tex; mode=display">∫δ(t)f(t)dt=f(0)</script></li><li>偶函数  <script type="math/tex; mode=display">δ(t)=δ(-t)</script></li><li>缩放<script type="math/tex; mode=display">δ(at)=\frac{1}{|a|}δ(t)</script>证明思路都是利用函数相等=积分相等，分情况讨论得到。<br>对单位冲激函数求导，得到<strong>冲击偶</strong>函数，即$δ’(t)$。<br>性质：  </li><li>赋值性  <script type="math/tex; mode=display">∫δ'(t)f(t)dt=-f'(0)</script><script type="math/tex; mode=display">f(t)δ'(t)=f(0)δ'(t)-f'(0)δ(t)</script></li><li>奇函数  <script type="math/tex; mode=display">δ'(t)=-δ'(t)</script></li></ol></li></ul></li></ul><h3 id="常见的时间离散信号"><a href="#常见的时间离散信号" class="headerlink" title="常见的时间离散信号"></a>常见的时间离散信号</h3><ul><li>单位采样信号  <script type="math/tex; mode=display">δ(n)=\begin{cases}    0,n\not ={0} \\       1, n=0 \\      \end{cases}</script>任何的非连续信号都能够用单位采样信号表示。  </li><li>单位阶梯信号  <script type="math/tex; mode=display">u(n)=\begin{cases}    0,n≧{0} \\       1, n<0 \\      \end{cases}</script>$δ(n)$是$u(n)$的差分信号。  <script type="math/tex; mode=display">δ(n)=u(n)-u(n-1)</script></li><li>方波序列  </li><li>斜坡序列  </li><li>单边指数序列</li><li>正弦序列<br>正弦函数到正弦序列的转换：<br>令$t=nT_s$， 有$f(t)=sin(ω_0t)=sin(ω_0T_sn)=x(n)$<br>令$Ω_0=ω_0T_s$，得到：  <script type="math/tex; mode=display">x(n)=sin(Ωn)</script>注意：  <ol><li>$T_s$表示的是采样的间隔时间，周期$T=nT_s$。  </li><li>对于周期序列，有$x(n)=x(n+N)$。</li><li>如果$\frac{2π}{Ω}$不为有理数，那么正选序列不具有周期。  </li></ol></li></ul><h2 id="信号的基本处理"><a href="#信号的基本处理" class="headerlink" title="信号的基本处理"></a>信号的基本处理</h2><h3 id="加法和乘法"><a href="#加法和乘法" class="headerlink" title="加法和乘法"></a>加法和乘法</h3><ul><li>对于连续信号<br>函数直接相加或者是相乘。<br>注意： 两个周期连续信号相加不一定是一个周期信号  </li><li>对于离散信号<br>两个序列的对应位置相加或者是相乘。  <h3 id="积分和微分"><a href="#积分和微分" class="headerlink" title="积分和微分"></a>积分和微分</h3></li><li><p>对于连续信号<br>先做信号分解，对每一段分别积分或者微分。  </p></li><li><p>对于离散信号<br>只有累积（$z(n)=∑x(k)$）和差分（$Δx(n)=x(n+1)-x(n)$或$Δx(n)=x(n)-x(n-1)$）。</p><h3 id="平移、反转和尺度变换"><a href="#平移、反转和尺度变换" class="headerlink" title="平移、反转和尺度变换"></a>平移、反转和尺度变换</h3><p>平移遵循<strong>左加右减</strong>的原则。<br>横坐标展缩遵循<strong>a&gt;1,图像压缩，a&lt;1，图像扩展</strong>的原则。<br>由于离散信号$x(an)$当且仅当$ak$是一个整数的时候才有定义，如果对其进行展缩，通常会丢失原信号$x(n)$的部分信息，因此离散信号通常不做展缩。  </p></li><li>作图方法<br>一种方法是将信号每一段的分段函数都求出，并将$at+b$代入分段函数及其范围，得到新的函数图像。<br>已知$f(t)$,求$f(at+b)$的图像：基本思路是令$τ=at+b$，反解出$t$的方程，从图像上选择几个关键点，将图像上这些点原来$t$轴的值到$τ$中，得到新的$t$值。<br>已知$f(at+b)$,求$f(t)$的图像： 基本思路是从图像选择几个关键点，将图像上这些点原来$t$轴的值到$τ$中，得到新的$t$值。  </li></ul><h3 id="信号分解"><a href="#信号分解" class="headerlink" title="信号分解"></a>信号分解</h3><ul><li>奇偶分解<script type="math/tex; mode=display">\begin{aligned}  f(t)=f_e(t)+f_o(t) \\  f_e(t)=\frac{1}{2}[f(t)+f(-t)]\\  f_o(t)=\frac{1}{2}[f(t)-f(-t)]\end{aligned}</script></li><li>复分解  <script type="math/tex; mode=display">f(t)=f_r(t)+jf_i(t)</script></li><li>直流交流分解  <script type="math/tex; mode=display">f(t)=f_A(t)+f_D(t)</script><script type="math/tex; mode=display">f_D(t)=\frac{1}{T}∫^{t_0+T}_{t_0}f(t)dt</script></li></ul>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>《机器学习》 周志华 1-5章笔记</title>
    <link href="/2021/03/13/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89(1)/"/>
    <url>/2021/03/13/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%EF%BC%88%E8%A5%BF%E7%93%9C%E4%B9%A6%EF%BC%89(1)/</url>
    
    <content type="html"><![CDATA[<h1 id="《机器学习》-周志华-1-5章笔记"><a href="#《机器学习》-周志华-1-5章笔记" class="headerlink" title="《机器学习》 周志华 1-5章笔记"></a>《机器学习》 周志华 1-5章笔记</h1><blockquote><p>作者为博主的同事 黄欣迪   </p></blockquote><h2 id="第一章-绪论"><a href="#第一章-绪论" class="headerlink" title="第一章 绪论"></a>第一章 绪论</h2><ul><li><p>1.1 引言  </p><p>什么是机器学习？ 机器学习是致力于研究如何通过计算的手段，利用经验来改善系统自身的性能<br>经验——数据 模型——算法 通过相应的算法分析数据——得出结论<br>一些文献用“模型”指全局性结果（决策树） 用“模式”指局部性结果（一条规则）  </p></li><li><p>1.2 基本术语  </p><p>进行机器学习的前提是要有数据，例如给细胞的数据，并对给定细胞的大小，形态等进行记录<br>这组记录的集合称为一个“数据集”，其中每一条记录是关于一个事件或对象的描述，称为一个“示例”或“样本”<br>对于细胞的描述，如大小、形状，称为“属性”或“特征”<br>属性上的取值例如圆形、椭圆形，称为“属性值”<br>属性张成的空间称为“属性空间”、“样本空间”或“输入空间”<br>例如大小、形状、颜色张成的三维空间对于每一个样本都能找到对应的坐标向量，称为“特征向量”<br>从数据中学得模型的过程称为“学习”或“训练”<br>对于潜在规律自身，称为“真相”或“真实”<br>本书有时将模型称为“学习器”<br>拥有了标记信息的示例，称为“样例”<br>如果预测的是离散值，称为“分类” 若为二分类，则是正类和反类 预测的是连续值，称为“回归”<br>监督学习和无监督学习 前者是分类和回归是前者的代表 聚类是后者的代表<br>泛化模型是我们所想要找到的，强泛化模型可以更好适用于整个样本空间  </p></li><li><p>1.3 假设空间  </p><p>泛化学习：通过对训练集中瓜的学习已获得对没有见过的瓜进行判断的能力<br>假设空间：对所有假设组成的空间进行搜索，搜索目标是找到与训练集fit的假设  </p></li><li><p>1.4 归纳偏好  </p><p>偏好：对于不同的模型，它的偏好是不一样的，例如有一个模型更偏好某一特征，它会根据将该特征进行结果的认定<br>任何一个有效的机器学习模型必有其归纳偏好，否则会被假设空间中看似在训练集中“等效”的假设所迷惑<br>算法A优于算法B P9 具体论证 算法A和算法B的期望相同 与算法无关  </p></li><li><p>1.5 发展历程  </p></li><li>1.6 应用现状</li><li>1.7 阅读材料  <h2 id="第二章-模型评估与选择"><a href="#第二章-模型评估与选择" class="headerlink" title="第二章 模型评估与选择"></a>第二章 模型评估与选择</h2></li><li><p>2.1 经验误差与过拟合  </p><p>分类错误的样本占样本总数的比例称为“错误率”<br>m个样本中a个错误  </p><script type="math/tex; mode=display">E=\frac{a}{m}</script><p>相对的精度=1-错误率<br>过拟合的定义为学习器将训练集的自身特点当作了所有潜在样本的性质，这样会导致泛化性下降<br>难以在机器学习的过程中避免过拟合  </p></li><li><p>2.2 评估方法  </p><p>测试集尽量不要出现在训练集当中  </p></li><li><p>2.2.1 留出法  </p><p>将数据集D划分为两个互斥的集合 一个为训练集S 另一个为测试集T<br>划分尽量保持数据分布的一致性 分层采样<br>一般而言测试集至少含30个样例<br><strong>$\frac{2}{3}$到$\frac{4}{5}$的样本用于训练 其余样本用于测试</strong></p></li><li><p>2.2.2 交叉验证法  </p><p>数据集D划分为k个大小相似的互斥子集 每个子集都尽可能保持数据分布的一致性 P26<br>D——D1 D2 D3…. D10<br>D1 D2….D9 训练集  D10 测试集<br>D1 D2….D8 D10 训练集 D9 测试集<br>10次10折交叉验证<br>留一法：交叉验证法的特例——只留下一个样本作为测试集  </p></li><li><p>2.2.3 自助法  </p><p>给定包含m个样本的数据集D 对它进行采样产生数据集D’ 每次随机从D中挑选一个样本 将其拷贝到D’中 重复执行m次<br>得到了包含m个样本的数据集D’ m次采样中始终不被采集到的概率是</p><script type="math/tex; mode=display">(1-\frac{1}{m})^m</script><p>极限值约为0.368 即D中约有36.8%的样本没有在D’中出现<br>用D/D’作为测试集（/表示集合减法) 这样的测试结果叫做“包外估计”<br>自助法适用于数据量较小的数据集 留出法和交叉验证法适用于数据量足够的数据集  </p></li><li><p>2.2.4 调参与最终模型  </p><p>调参往往需要设定一个步长 在对应步长内取值 因为无法在实数范围内取完所有值<br>测试数据：模型在实际使用中遇到的数据  </p></li><li><p>2.3 性能度量  </p><p>定义：衡量模型泛化能力的评价标准<br>性能度量反映了任务需求——不同的性能度量导致不同的评判结果——模型的好坏是相对的<br>回归任务最常用的性能度量是“均方误差”</p><script type="math/tex; mode=display">E(f;D)=\frac{1}{m}\sum_{m=1}^{m}(f(x_i)-y_i)^2</script><p>对于数据分布D和概率密度p(‘) 均方误差为  </p><script type="math/tex; mode=display">E(f;D)=\int_{x\sim D} (f(x)-y)^2p(x)dx</script><p>以下主要是分类任务中常用的性能度量  </p></li><li><p>2.3.1 错误率与精度  </p><p>错误率和精度是分类任务中最常用的两种性能度量 既可以适用于二分类任务 也能适用于多分类任务<br>对样例集D 分类错误率定义为  </p><script type="math/tex; mode=display">E(f;D)=\frac{1}{m}\sum_{i=1}^{m}\prod_{}(f(x_i)\neq{y_i})^2</script><p>精度定义为  </p><script type="math/tex; mode=display">acc(f;D)=\frac{1}{m}\sum_{i=1}^{m}\prod_{}(f(x_i)\neq{y_i})^2=1-E(f;D)</script></li><li><p>2.3.2 查准率、查全率与F1  </p><p>实例：在信息检索中，经常关心的是“检索出的信息中有多少比例是用户感兴趣的”“用户感兴趣的信息中有多少被检索了出来”<br>“查准率”(precision)和“查全率”(recall)是更为适用于此类需求的性能变量<br>对于二分类问题 可将样例根据真实类别与学习器预测类别的组合划分为四种情形<br>真正例 假正例 真反例 假反例 令其为 TP、FP、TN、FN TP+FP+TN+FN=样例总数<br>查准率P与查全率R分别定义为  </p><script type="math/tex; mode=display">P=\frac{TP}{TP+FP}</script><script type="math/tex; mode=display">R=\frac{TP}{TP+FN}</script><p>查全率和查准率除了在一些简单任务中都比较高以外 一般一个高另一个低<br>画出模型实时的P-R图可以判断该模型的性能 如果P-R曲线被另一个模型包裹 那么可以认为被包裹的模型性能差<br>最终可以根据比较P-R曲线围成面积的大小来确定模型性能的好坏(该值不容易估算)<br>平衡点(Break-Event Point, 简称BEP)：查准率=查全率时的取值(平衡点大 学习性能优)<br>但更常用的是F1度量  </p><script type="math/tex; mode=display">F1=\frac{2*P*R}{P+R}=\frac{2*TP}{样例总数+TP-TN}</script><p>如果在实际问题中对查准率和查全率的偏重不同的话 引入Fβ  </p><script type="math/tex; mode=display">\frac{1}{F1}=\frac{1}{2}(\frac{1}{P}+\frac{1}{R})</script><script type="math/tex; mode=display">\frac{1}{F_\beta}=\frac{1}{1+\beta^2}(\frac{1}{P}+\frac{\beta^2}{R})（\beta>1 查全率影响大）（\beta<1 查准率影响大）</script><p>以上公式可以看出F1是基于查准率和查全率的调和平均定义的<br>Fβ则是基于加权调和平均定义的 与算术平均和集合平均相比 调和平均更重视较小值<br>考虑实际情况中需要在n个二分类混淆矩阵上综合考察查全率和查准率<br>做法一：在各个混淆矩阵中分别计算P和R 计算平均值 代入F1<br>做法二：计算TP、FP、TN、FN的平均值 代入P和R 再代入F1  </p></li><li><p>2.3.3 ROC与AUC  </p><p>学习器一般是为测试样本产生一个实值或概率预测 使用该预测值与分类阈值进行比较 若大于阈值则为正类 反之为反类<br>预测结果的好坏决定了学习器的泛化能力<br>该分类过程相当于在排序中以某个截断点将样本分为两个部分 前一部分判做正例 后一部分判做反例<br>ROC曲线则是以排序本身的好坏来判定学习器泛化性能的<br>ROC曲线全称是“受试者工作特征”(Receiver Operating Characteristic)<br>ROC曲线的定义<br>纵轴：“真正例率”  </p><script type="math/tex; mode=display">TPR=\frac{TP}{TP+FN}</script><p>横轴：“假正例率”  </p><script type="math/tex; mode=display">FPR=\frac{FP}{TN+FP}</script><p>真正问题中对于有限个测试样例<br>设给定m+个正例 m-个反例进行排序<br>首先将分类阈值设为最大——所有样例均预测为反例 初始的真正例率和假正例率均为0 初始坐标(0,0)<br>现在预测一个样本 如果为真正例 标记点的坐标为  </p><script type="math/tex; mode=display">(x,y+\frac{1}{m^+})</script><p>如果为假正例 标记点的坐标为  </p><script type="math/tex; mode=display">(x+\frac{1}{m^-},y)</script><p>进行学习器比较时 若一个学习器的ROC曲线被另一个学习器的曲线完全包住 则可断言后者的性能优于前者 若两个学习器的ROC曲线发生交叉 则不能断言<br>同样 如果要比较两个学习器 较为合理的判据是比较ROC曲线下的面积 即AUC<br>AUC可以估算为  </p><script type="math/tex; mode=display">AUC=\frac{1}{2}\sum_{i=1}^{m-1}(x_{i+1}-x_i)*(y_i+y_{i+1})</script><p>但在实际问题中如何考虑排序的误差  </p><script type="math/tex; mode=display">l_{rank}=\frac{1}{m^+m^-}\sum_{x^+\in{D^+}}\sum_{x^+\in{D^+}}(\prod_{}(f(x^+)<f(x^-))+\frac{1}{2}\prod_{}(f(x^+)=f(x^-)))</script><script type="math/tex; mode=display">AUC=1-l_{rank}</script><p>理解：如果正例的预测值小于反例 则记一个罚分 如果正例的预测值等于反例 则记0.5个罚分  </p></li><li><p>2.3.4 代价敏感错误率与代价曲线  </p><p>实际问题中 对于不同类型的错误所造成的后果不同<br>例如在医疗诊断中，错误地把患者诊断为健康人与错误地把健康人诊断为患者的结果不同<br>对于这类问题可以将预测错误的cost设为cost1和cost2<br>代入之前的公式可以计算出总体代价最小时的错误率<br>在非均等代价下 ROC曲线不能直接反映出学习器的期望总体代价 这时需要使用代价曲线<br>具体可见P36  </p></li><li><p>2.4 比较检验（以下为各种概率论中的假设检验）  </p></li><li><p>2.5 偏差和方差  </p><p>泛化误差可以分解为偏差、方差与噪声之和 P45  </p></li></ul><h2 id="第三章-线性模型"><a href="#第三章-线性模型" class="headerlink" title="第三章 线性模型"></a>第三章 线性模型</h2><ul><li><p>3.1 基本形式  </p><p>给定由d个属性描述的示例  </p><script type="math/tex; mode=display">x=(x_1;x_2...;x_d)</script><p>其中xi是x在第i个属性上的取值<br>线性模型学习的是通过属性的线性组合来进行预测的函数 即  </p><script type="math/tex; mode=display">f(x)=w_1x_1+w_2x_2+w_3x_3+.....+w_dx_d+b</script><p>一般用向量写成  </p><script type="math/tex; mode=display">f(x)=w^Tx+b</script><p>w和b学得后 模型就得以确定</p></li><li><p>3.2 线性回归  </p><p>给定数据集  </p><script type="math/tex; mode=display">D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}</script><p>其中  </p><script type="math/tex; mode=display">x_i=(x_{i1};x_{i2};...;x_{id}), y_i\in{R}</script><p>线性回归试图学得一个线性模型以尽可能准确的预测实值输出标记<br>首先可以将离散型属性通过连续化将其转化为连续值<br>例如二值属性“身高” 高=1  矮=0<br>线性回归试图学得  </p><script type="math/tex; mode=display">f(x_i)=wx_i+b, 使得f(x_i)\approx{y_i}</script><p>均方误差是回归任务中最常用的性能度量 所以试图让均方误差最小化<br>具体推导过程 P54<br>一个属性只有一个权重 d个属性就会有d个权重<br>可以考虑广义的情况 比如lny  </p></li><li><p>3.3 对数几率回归  </p><p>对数几率函数  </p><script type="math/tex; mode=display">y=\frac{1}{1+e^{-z}}</script><p>也就称为sigmoid函数<br>预测值z 通过z来找y y是逼近0或者1 由此判断预测为正或反  </p></li><li><p>3.4 线性判别分析  </p><p>线性判别分析(Linear Discriminant Analysis LDA)是一种经典的线性学习方法，主要用于二分类问题<br>目标 同类别的方差最小 不同类别的方差最大<br>(该方法应用比较少)  </p></li><li><p>3.5 多分类学习  </p></li><li><p>3.6 类别不平衡问题  </p><p>过采样：不能重复采样 会造成过拟合<br>欠采样：去除一些样本 让正反例数量接近 然后再进行学习  </p></li><li><p>3.7梯度下降法(补充)  </p></li></ul><h2 id="第四章-决策树"><a href="#第四章-决策树" class="headerlink" title="第四章 决策树"></a>第四章 决策树</h2><ul><li><p>4.1 基本流程  </p><p>决策树的生成是一个递归过程  学习目的是为了产生一棵泛化能力强 即处理未见示例能力强的决策树  </p></li><li><p>4.2 划分选择  </p><p>最关键的是如何选择最优化分属性 希望随着划分过程的进行 决策树的分支结点所包含的样本尽可能属于同一类别<br>即结点的“纯度”越来越高  </p></li><li><p>4.2.1 信息增益  </p><p>“信息熵”(information entropy)是度量样本集合纯度最常用的一种指标<br>假定当前样本集合D中第K类样本所占比例为$P_k(k=1,2,…,|y|)$，则D的信息熵定义为  </p><script type="math/tex; mode=display">Ent(D)=-\sum_{K=1}^{|y|}p_klog_2P_k</script><p>Ent(D)的值越小 D的纯度越高<br>什么是熵：对一种事物的不确定性就叫熵 比如买西瓜 不知道买哪一个是好瓜 这就是熵<br>信息：消除这种不确定性的事物（调整概率、排除干扰、确定情况）<br>噪音：不能消除某人对某件事情不确定性的事物<br>数据：信息+噪音<br>假设一件事情有八种等可能的结果 相当于抛三枚硬币 熵为3bit<br>若每种情况概率分布不相等(一般分布)  </p><script type="math/tex; mode=display">A=\frac{1}{2}|B=\frac{1}{3}|C=\frac{1}{6}</script><script type="math/tex; mode=display">P(A)=\frac{1}{2}(log_26-log_23)</script><script type="math/tex; mode=display">P(B)=\frac{1}{3}(log_26-log_22)</script><script type="math/tex; mode=display">P(C)=\frac{1}{6}(log_26-log_21)</script><script type="math/tex; mode=display">Ent(D)=P(A)+P(B)+P(C)</script><p>得知信息的前后 不确定性的变化——熵的差额 就是信息的量<br>例如ABCD四道选择题 等可能的话熵为2bit<br>如果知道C有一半可能是正确的 那么  </p><script type="math/tex; mode=display">P(A)=P(B)=P(D)=\frac{1}{6}|P(C)=\frac{1}{2}</script><p>现在的熵为  </p><script type="math/tex; mode=display">\frac{1}{6}log_26+\frac{1}{6}log_26+\frac{1}{2}log_22+\frac{1}{6}log_26=1.79</script><p>所以 知道C有一半可能正确的条件后 现在的不确定性是1.79 那么信息量就是0.21<br>西瓜数据集2.0 P76<br>17个样例 8个好瓜 9个坏瓜 一般分布<br>先算出信息熵 根节点  </p><script type="math/tex; mode=display">Ent(D)=\frac{8}{17}log_2\frac{17}{8}+\frac{9}{17}log_2\frac{17}{9}=0.998</script><p>然后计算每一个特征不同的信息增益<br>三种色泽 先算每一种的Ent 然后分权 相加 与根结点的熵作差 得到有关色泽的信息增益  </p><script type="math/tex; mode=display">Ent(D_1)=\frac{3}{6}log_2\frac{6}{3}+\frac{3}{6}log_2\frac{6}{3}=1.000</script><script type="math/tex; mode=display">Ent(D_2)=\frac{4}{6}log_2\frac{6}{4}+\frac{2}{6}log_2\frac{6}{2}=0.918</script><script type="math/tex; mode=display">Ent(D_3)=\frac{1}{5}log_2\frac{5}{1}+\frac{4}{5}log_2\frac{5}{4}=0.722</script><script type="math/tex; mode=display">Gain(D,色泽)=Ent(D)-\sum_{v=1}^3\frac{|D^v|}{D}Ent(D^v)=0.998-(\frac{6}{17}*1.000+\frac{6}{17}*0.918+\frac{5}{17}*0.722)=0.109</script><p>根据计算的结果信息增益越高 作为第一轮选择<br>以此类推  </p></li><li><p>4.2.2 增益率(C4.5算法)</p><p>信息增益准则对可取值数目较多的属性有所偏好<br>所以C4.5决策树算法 是先计算Gain 也就是分权后相加的熵 再用该改值除以IV(a)  </p><script type="math/tex; mode=display">Gain_ratio(D,a)=\frac{Gain(D,a)}{IV(a)}=\frac{0.109}{\frac{6}{17}log_2\frac{17}{6}+\frac{6}{17}log_2\frac{17}{6}+\frac{5}{17}log_2{17}{5}}</script><p>使用增益率方法时 先选出信息增益前五位的信息 随后利用该方法进行进一步筛选  </p></li><li><p>4.2.3 基尼指数(CART算法)  </p><p>Classification and Regression 该方法既可以进行分类也可以进行回归<br>例子：首先先进行统计 西瓜2.0数据集<br>第一个特征色泽 分别统计在青绿这一信息中 是好瓜的个数和不是好瓜的个数<br>乌黑中 是好瓜的个数和不是好瓜的个数 以此类推<br>如果统计中有缺失值例如？？？ 直接跳过<br>CART都是二叉树的模型 衡量纯度的方法<br>Gini index 抽两次 抽得样本中不同的概率来衡量纯度<br>例如B站 P59  </p><script type="math/tex; mode=display">Gini index=1-(\frac{105}{105+39})^2-(\frac{39}{105+39})^2</script><p>基尼指数越大 表示这两个大概率是不同的 所以纯度就下降<br>希望基尼指数越大越好<br>补充：基尼指数的计算代码  </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gini_index_single</span>(<span class="hljs-params">a,b</span>):</span>  <br>    single_gini=<span class="hljs-number">1</span>-((a/(a+b))**<span class="hljs-number">2</span>)-((b/(a+b))**<span class="hljs-number">2</span>)  <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span>(single_gini,<span class="hljs-number">2</span>)  <br><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gini_index</span>(<span class="hljs-params">a,b,c,d</span>):</span>  <br>    zuo = gini_index_single(a,b)  <br>    you = gini_index_single(c,d)  <br>    gini_index = zuo*((a+b)/(a+b+c+d))<br>                   +you*((c+d)/(a+b+c+d))  <br>    <span class="hljs-keyword">return</span> <span class="hljs-built_in">round</span> (gini_index,<span class="hljs-number">2</span>)  <br></code></pre></div></td></tr></table></figure><p>补充回归问题<br>SKlearn 计算每一个阈值所对应均方值的最小值  </p></li><li><p>4.3 剪枝处理  </p></li><li><p>4.3.1 预剪枝  </p><p>目的是防止过拟合<br>首先将之前的西瓜数据集2.0分为5/5的训练集以及3/4的测试集<br>根据5/5的训练集先生成一颗决策树 采用的是信息增益准则<br>引入验证集之后 对于一个结点 先计算不划分该结点时的准确率<br>对于这个例子 5/5的训练集我们认为第一个结点脐部全为好瓜 对于测试集 准确率为42.9%<br>划分后 我们获得的标记和测试集进行比较 准确率为71.4%<br>所以我们决定对脐部进行划分 之后的特征也由此类推<br>这样的方法确实可以防止过拟合的产生 但也带来了欠拟合的风险  </p></li><li><p>4.3.2 后剪枝  </p><p>后剪枝主要是在生成决策树之后 自下而上的进行判断<br>这样的方法能够有效的防范欠拟合的的风险<br>但因为是在生成决策树之后进行 所以训练时间的开销会比未剪枝和预剪枝要大得多  </p></li><li><p>4.4 连续与缺失值  </p><p>连续值处理<br>C4.5算法采用二分法 例子：西瓜数据集3.0<br>对于该方法主要计算两个取值 1、信息增益 2、划分点<br>对于每一个划分点进行计算 找到信息增益最大的点 以及最大的信息增益即可<br>缺失值处理<br>对于有缺失值的数据来说 计算信息增益时我们只需要计算该特征下无缺失值所获得的信息增益 再用它来乘以无缺失值数据所占比例即可<br>例如有在色泽特征下 有14个无缺失值的数据 一共有17个数据  </p><script type="math/tex; mode=display">Gain=\frac{14}{17}*Gain(14)</script><p>其他方法<br>离散值<br>1、众数填充 2、相关性最高的列填充<br>连续值<br>1、中位数 2、相关性最高的列做线性回归进行估计  </p></li></ul><ul><li><p>4.5 多变量决策树  </p><p>单变量决策树生成的函数图像的分割线总是与函数轴垂直或平行<br>多变量决策树生成的函数图像的分割线相对复杂 一般是曲线<br>多变量的分界点主要是对于特征的线性组合进行分割  </p></li></ul><h2 id="第五章-神经网络"><a href="#第五章-神经网络" class="headerlink" title="第五章 神经网络"></a>第五章 神经网络</h2><ul><li><p>5.1 神经元模型  </p><p>这本书主要讲的是神经网络和机器学习两个学科领域的交叉部分<br>M-P神经元模型 神经元接收到来自n个其他神经元传递过来的输入信号 这些输入信号通过带权重的链接进行传递<br>神经元接收到的总输入值将与神经元的阈值进行比较 然后通过激活函数处理以产生神经元的输出<br>常用sigmoid函数作为激活函数 把这样的多个神经元进行链接 就得到了神经网络  </p></li><li><p>5.2 感知机与多层网络  </p><p>感知机(perceptron)由两层神经元组成 输入层接收外界输入信号后传递给输出层 输出层是M-P神经元 亦称“阈值逻辑单元”<br>感知机能容易地实现逻辑与、或、非运算 假设  </p><script type="math/tex; mode=display">y=f(\sum_iw_ix_i-\theta)</script><p>激活函数为阶跃函数 可以很容易地实现三种运算<br>例：与运算 令$w_1=w_2=1$, $\theta$=2 仅当$x_1=x_2=1$时候 y=1<br>一般情况下 给定训练数据集 权重wi以及阈值theta可以通过学习得到<br>我们也可以设定阈值$\theta$ 为一个固定的输入-1,0的“哑结点”(dummy node)所对应的连接权重$w_n+1$<br>那么就只用对权重进行学习<br>对于权重的调整 对训练样例(x,y) 若当前的感知机的输出为y’那么权重调整为  </p><script type="math/tex; mode=display">w_i\gets{w_i}+\Delta{w_i}</script><script type="math/tex; mode=display">\Delta{w_i}=\eta(y-y')x_i</script><p>其中$\eta$为学习率 是一个0-1之间的数 从调整方程可以看出 若感知机对于样本的预测是正确的 那么w不发生变化<br>反之进行权重调整<br>感知机的学习能力非常有限 因为它只拥有一层功能神经元<br>因为上述问题都是线性可分的(linearly separable) 所以存在一个线性超平面能将它们分开 这样感知机的学习过程一定会收敛(converge) 以求得适当的权向量w<br>反之 若问题不是线性可分的 感知器的权重将无法收敛 发生震荡 这时就需要多层神经元来解决问题<br>若引入两层的感知机 则可以解决亦或问题<br>输出层与输入层之间的一层神经元被称为隐层或隐含层(hidden layer) 隐含层和输出层神经元都是拥有激活函数的功能神经元<br>对于“多层前馈神经网络”来说 每层神经元与下一层神经元全互连 神经元之间不存在同层连接 也不存在跨层连接<br>输入层：仅接收输入，不进行函数处理<br>隐层和输出层包含功能神经元 单隐层指只含有一层隐层的网络 单隐层网络也被称为两层网络<br>神经网络的学习过程 就是根据训练数据来调整神经元之间的“连接权”(connection weight)以及每个功能神经元的阈值  </p></li><li><p>5.3 误差逆传播算法(反向传播算法)  </p><p>误差逆传播(BackPropagation, 简称BP)算法就是其中的代表 BP算法不仅可用于多层前馈神经网络 还可以用于其他神经网络<br>BP算法是什么样的<br>给定训练集  </p><script type="math/tex; mode=display">D={(x_1,y_1),(x_2,y_2),...,(x_m,y_m)}, x_i\in{R^d},y_i\in{R^d}</script><p>即输入示例有d个属性描述 输出l维实质向量(如图所示)<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210313002507.png" alt=""><br>假设隐层和输出层神经元都是用sigmoid函数<br>对于训练例$(x_k,y_k)$ 假定神经网络的输出为$y’_k=(y’_{1k},y’_{2k},…,y’_{lk})$ 即  </p><script type="math/tex; mode=display">y'_{jk}=f(\beta_j-\theta_j)</script><p>则网络在$(x_k,y_k)$上的均方误差为  </p><script type="math/tex; mode=display">E_k=\frac{1}{2}\sum_{j=1}^l(y'_{jk}-y_{jk})^2</script><p>图中的网络有(d+l+1)q+l个参数需确定：输入层到隐层的d<em>q个权值、隐层到输出层的q</em>l个权值、q个隐层神经元的阈值、l个输出层神经元的阈值<br>BP是一个迭代学习算法 对于参数进行更新的规则与之前类似 任意参数v的更新估计式为  </p><script type="math/tex; mode=display">v\gets{v}+\Delta{v}</script><p>推导隐层到输出层的连接权$w_{hj}$  </p></li></ul>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>大学物理下-常考知识点</title>
    <link href="/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86(%E4%B8%8B)/"/>
    <url>/2021/03/12/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0/%E5%A4%A7%E5%AD%A6%E7%89%A9%E7%90%86(%E4%B8%8B)/</url>
    
    <content type="html"><![CDATA[<h1 id="大学物理下"><a href="#大学物理下" class="headerlink" title="大学物理下"></a>大学物理下</h1><blockquote><p>整理重邮常考的知识点  </p><p>参考书目为《物理学 （上）》 东南大学 第六版  </p></blockquote><h2 id="导体和介质"><a href="#导体和介质" class="headerlink" title="导体和介质"></a>导体和介质</h2><h3 id="导体的性质"><a href="#导体的性质" class="headerlink" title="导体的性质"></a>导体的性质</h3><ol><li>自由电荷分布在导体表面  </li><li>静电平衡时，导体内部电场为0  </li><li>导体表面与叠加电场垂直  </li><li>越尖锐的表面，电荷积聚越多  </li></ol><h3 id="电位移矢量"><a href="#电位移矢量" class="headerlink" title="电位移矢量"></a>电位移矢量</h3><script type="math/tex; mode=display">\vec{D}=ɛ_0ɛ_r\vec{E}</script><h3 id="静电屏蔽"><a href="#静电屏蔽" class="headerlink" title="静电屏蔽"></a>静电屏蔽</h3><ol><li>将物体放入导体壳（法拉第笼）内部，导体壳内部的物体不会受到外电场的影响  </li><li>将法拉第笼接地，里面放入电荷，导体壳内部的电荷不会对外界有影响</li></ol><h3 id="极化电场"><a href="#极化电场" class="headerlink" title="极化电场"></a>极化电场</h3><p>  真空中的电场$E_0$进入介质后，电场大小变为$E=ɛ_rE_0$,定义电位移矢量$D=ɛ_0ɛ_rE_0$。极化强度：$\vec{P}=\frac{∑\vec{p}}{Δv}$,它在数值上与电荷面密度$σ$相同。<br>  电极化率：  </p><script type="math/tex; mode=display">\chi_E=ɛ_r-1=\frac{P}{ɛ_0E}</script><blockquote><p>$ɛ_r&lt;1$</p></blockquote><h3 id="电容器"><a href="#电容器" class="headerlink" title="电容器"></a>电容器</h3><p>  电容器的最大能量：</p><script type="math/tex; mode=display">W=\frac{1}{2}CU^2</script><p>  电场的能量密度：</p><script type="math/tex; mode=display">w_E=\frac{1}{2}ɛE^2</script><h2 id="恒定磁场"><a href="#恒定磁场" class="headerlink" title="恒定磁场"></a>恒定磁场</h2><ul><li>电场与磁场的对偶性  </li></ul><div class="table-container"><table><thead><tr><th>\</th><th>磁场</th><th>电场</th></tr></thead><tbody><tr><td>高斯定理</td><td>$∫\vec{B}.d\vec{S}=0$</td><td>$∫\vec{B}.d\vec{S}=\frac{∑q_{in}}{ɛ_0}$</td></tr><tr><td>安培定理</td><td>$∫\vec{B}.d\vec{l}=μ_0I$</td><td>$∫\vec{E}.d\vec{S}=0$</td></tr><tr><td>结论</td><td>无源有旋</td><td>有源无旋</td></tr></tbody></table></div><h3 id="左-右手定则"><a href="#左-右手定则" class="headerlink" title="左/右手定则"></a>左/右手定则</h3><div class="table-container"><table><thead><tr><th style="text-align:center">右手定则</th><th style="text-align:center">左手定则</th></tr></thead><tbody><tr><td style="text-align:center">判断电流产生的磁场</td><td style="text-align:center">判断导体受到的安培力</td></tr><tr><td style="text-align:center">判断感应电流的方向</td><td style="text-align:center">/</td></tr></tbody></table></div><h3 id="洛伦兹力的应用"><a href="#洛伦兹力的应用" class="headerlink" title="洛伦兹力的应用"></a>洛伦兹力的应用</h3><p>  洛伦兹力提供向心力，不做功  </p><script type="math/tex; mode=display">F_l=qBv=m\frac{v^2}{R}=F_向</script><ol><li>磁聚焦</li><li>回旋加速器</li><li>霍尔效应</li></ol><h3 id="磁介质"><a href="#磁介质" class="headerlink" title="磁介质"></a>磁介质</h3><p>  磁化强度：$M=\frac{∑m}{ΔV}$,m表示磁矩<br>  磁场强度：$B=\mu_0\mu_rH$<br>  磁化率：  </p><script type="math/tex; mode=display">χ_r=\mu_r-1</script><script type="math/tex; mode=display">M=(\mu_r-1)H</script><blockquote><p>$\mu_r$没有大小限制  </p></blockquote><p>  若$\mu_r<1$, 称介质为抗磁质     若$\mu_r>1$, 称介质为顺磁质<br>  若$\mu_r&gt;&gt;1$, 称介质为铁磁质  </p><h2 id="电磁感应"><a href="#电磁感应" class="headerlink" title="电磁感应"></a>电磁感应</h2><h3 id="涡旋电场"><a href="#涡旋电场" class="headerlink" title="涡旋电场"></a>涡旋电场</h3><p>  涡旋电场是有变化的磁场所产生的电场。  </p><script type="math/tex; mode=display">∮E_Bd\vec{l}=-\frac{dΦ_B}{dt}</script><script type="math/tex; mode=display">∯E_Bd\vec{S}=0</script><p>  结论：涡旋电场是无源有旋的电场  </p><h3 id="自感"><a href="#自感" class="headerlink" title="自感"></a>自感</h3><p>  自感系数：  </p><script type="math/tex; mode=display">L=\frac{Φ}{I}</script><p>  通过自感产生的电势：  </p><script type="math/tex; mode=display">ϵ_L=-\frac{dΦ}{dt}=-L\frac{di}{dt}</script><h3 id="互感"><a href="#互感" class="headerlink" title="互感"></a>互感</h3><p>  互感系数：  </p><script type="math/tex; mode=display">M=\frac{Φ_{21}}{I_1}</script><p>   其中$Φ_{21}$表示在2中由1产生的磁通量，$I_1$是1的电流  </p><h3 id="磁场能"><a href="#磁场能" class="headerlink" title="磁场能"></a>磁场能</h3><p>  自感耗能：  </p><script type="math/tex; mode=display">W_m=\frac{1}{2}LI^2</script><p>  整个电路的能量：  </p><script type="math/tex; mode=display">\int_0^t ϵIdt=\frac{1}{2}LI^2+I^2Rt</script><p>  能量密度：</p><script type="math/tex; mode=display">W=\frac{1}{2}LI^2=\frac{B^2V}{2μ}</script><p>  V为螺线管/螺绕环的体积  </p><script type="math/tex; mode=display">w_M=\frac{W}{V}=\frac{B^2}{2μ}=\frac{1}{2}BH</script><p>  由$B=\mu_0\mu_rH$,  </p><script type="math/tex; mode=display">w_m=\frac{1}{2}\frac{B^2}{\mu_0\mu_r}=\frac{1}{2}\mu_0\mu_rH^2</script><h2 id="麦克斯韦方程"><a href="#麦克斯韦方程" class="headerlink" title="麦克斯韦方程"></a>麦克斯韦方程</h2><h3 id="光的两大特性"><a href="#光的两大特性" class="headerlink" title="光的两大特性"></a>光的两大特性</h3><script type="math/tex; mode=display">C=\frac{1}{\sqrt{\mu_0ɛ_0}}</script><p>表示光速是恒定的  </p><p>由折射光介质比$n=\frac{C}{V}$，有  </p><script type="math/tex; mode=display">n=\frac{1}{\sqrt{\mu_rɛ_r}}</script><p>表示光是一种电磁波  </p><h3 id="位移电流"><a href="#位移电流" class="headerlink" title="位移电流"></a>位移电流</h3><p>位移电流是假想出来的电流，它遵循所有的电传导定律<br>全电流是<strong>传导电流</strong>和<strong>位移电流</strong> （以及运流电流*）的总称</p><h3 id="麦克斯韦方程组的积分形式"><a href="#麦克斯韦方程组的积分形式" class="headerlink" title="麦克斯韦方程组的积分形式"></a>麦克斯韦方程组的积分形式</h3><div class="table-container"><table><thead><tr><th style="text-align:center">名称</th><th style="text-align:center">方程</th><th style="text-align:center">结论</th></tr></thead><tbody><tr><td style="text-align:center">电场中的高斯定理</td><td style="text-align:center">$∮\vec{D}.d\vec{S}=∫_D ρdV=q$</td><td style="text-align:center">静电场有源</td></tr><tr><td style="text-align:center">电场中的安培环路定理</td><td style="text-align:center">$∮\vec{E}.d\vec{l}=-∫\frac{∂B}{\partial t}dS+0$</td><td style="text-align:center">涡旋电场有旋，静电场无旋</td></tr><tr><td style="text-align:center">磁场中的高斯定理</td><td style="text-align:center">$∮\vec{B}.d\vec{S}=0$</td><td style="text-align:center">磁场无源</td></tr><tr><td style="text-align:center">磁场中的安培环路定理</td><td style="text-align:center">$∮\vec{H}.d\vec{l}=∫(j_c+\frac{\partial D}{∂t})dS$</td><td style="text-align:center">磁场有旋</td></tr></tbody></table></div>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>复习笔记</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>计算机结构基础-课堂笔记</title>
    <link href="/2021/03/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/1.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%9F%BA%E7%A1%80/"/>
    <url>/2021/03/04/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E4%B8%8E%E6%8E%A5%E5%8F%A3/1.%20%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BB%93%E6%9E%84%E5%9F%BA%E7%A1%80/</url>
    
    <content type="html"><![CDATA[<h1 id="计算机结构基础"><a href="#计算机结构基础" class="headerlink" title="计算机结构基础"></a>计算机结构基础</h1><blockquote><p>讲义复习<br>BUL EE2623 Computer Architecture and Interface<br>Dr. Takebumi Itagaki   </p></blockquote><h2 id="冯诺依曼架构"><a href="#冯诺依曼架构" class="headerlink" title="冯诺依曼架构"></a>冯诺依曼架构</h2><p>组成部分： CPU/ALU,I/O, Buses, Main Memory<br>特征： 所有的部分都通过总线连接<br>总线的类别： 数据总线，地址总线，控制总线</p><h2 id="数制"><a href="#数制" class="headerlink" title="数制"></a>数制</h2><p>十六进制，十进制，八进制，二进制的相互转化。</p><h3 id="二进制整数的表达和运算"><a href="#二进制整数的表达和运算" class="headerlink" title="二进制整数的表达和运算"></a>二进制整数的表达和运算</h3><h4 id="Unsigned"><a href="#Unsigned" class="headerlink" title="Unsigned"></a>Unsigned</h4><p>  不表示负数，因此第一位比特位到最后一位都可以用来表示数   </p><ul><li><p>逻辑运算<br>AND（乘法）  OR（加法）  NOT（取反）  XOR（取异）</p><h4 id="Signed"><a href="#Signed" class="headerlink" title="Signed"></a>Signed</h4><p>可以表示正数，负数，0， 第一位比特位表示正负号：0为正，1为负。<br>因此表示范围折半，以8比特为例，Unsigned表示的范围为0~255，而Signed表示的范围为-128~127（中间有0，故不是128）。   </p><ul><li>转换<br>转换为Signed的方法是先找到十进制绝对值对应的二进制数，取反码后+1得到二补码，即Signed Number。  </li><li>加减法<br>二补码的加法是<strong>异或运算</strong>，比特相同取0，不同取1。<br>减法看做是与负数相加。   </li></ul><p>加法要注意判断是否发生溢出，有两种思路可以判断是否发生了溢出。    </p></li></ul><ol><li>转换为十进制加减法，看是否发生了溢出</li><li>遵循两个原则：<br>a. 进位值的比特位数与数据的比特位数相同<br>b. 如果进位值的前两位是”01”或者是”10”，那么就发生了溢出。</li></ol><ul><li>乘法<br>类似于十进制乘法：第一行的所有位与第二行的每一个比特位分别相乘并作移位，最后相加。 单个比特位的乘法遵循：“除了$1×1=1$外，其余结果都为0。（与0相乘都为0。）”     </li></ul><h3 id="二进制浮点数的表达"><a href="#二进制浮点数的表达" class="headerlink" title="二进制浮点数的表达"></a>二进制浮点数的表达</h3><h4 id="IEEE-754"><a href="#IEEE-754" class="headerlink" title="IEEE 754"></a><strong>IEEE 754</strong></h4><p>IEEE 754是用来表示二进制浮点数的标准，<strong>基于二进制</strong>。其中有32位，64位，128位表示方法，以32位为例：32位浮点数的表示方法为：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Width of Bits</th><th style="text-align:center">1</th><th style="text-align:center">8</th><th style="text-align:center">23</th></tr></thead><tbody><tr><td style="text-align:center">Content</td><td style="text-align:center">Sign</td><td style="text-align:center">Exponent</td><td style="text-align:center">Fraction</td></tr><tr><td style="text-align:center">bias: +127</td></tr></tbody></table></div><ul><li>Bias<br>为了让Signed更方便的进行比较，将Signed转换成二进制后的指数部分人为地加一个Bias使得指数部分转变到Unsigned的范围内（0和255特殊处理）便于比较。<br>Bias的值规定是exp位十进制数的中位数或中间两个数的平均数。<br>IEEE 754 能够表示0， 正规数（Exp部分不为0），非正规数（Exp部分为0，如果Exp小于0则把Exp划到0后，剩下的部分进入小数部分），无穷和其他未规定的计算结果（NaN）。   </li><li>十进制转IEEE754<ol><li>确定正负</li><li>小数部分（$2^{-k}$）和整数部分（$2^{k}$）分别写出二进制形式（负数不需要转化为补码），合并，中间以小数点隔开</li><li>将小数点移动到第一位和第二位末尾，假设移动距离为$x$，后面的指数部分写作$2^x$。</li><li>取现在的小数部分，并在末尾补0直到小数部分的总比特数为23位。  </li><li>取现在的指数部分$x+bias$，并转换为二进制填入Exp中。  </li></ol></li><li>IEEE754转十进制  <script type="math/tex; mode=display">(-1)^5M2^{-23}2^{exponent-127}</script></li><li><p>运算规定<br>规定如下的情况结果会是Not A Number(e全是1，f=0)：  </p><ol><li>$⨦0 ÷ ⨦0$  </li><li>$∞-∞$  </li><li>$⨦∞÷⨦∞$  </li><li>$⨦∞ × 0$<br>规定如下的情况结果会是无穷(e全是1,f$̸=$0)：  </li><li>$∞ × ∞$  </li><li>$∞ + ∞$  </li><li>$nonezero ÷ 0$<br>规定$n ÷ ∞=0$(e全是0,f全是0)。  </li></ol></li><li><p>范围  </p><ul><li>最大正数：<br>$(2-2^{-23}）2^{127}≈2^{127}$<br>(0 | 1111 1111 | 1111 1111 11111 1111 1111 111)   </li><li><p>最小非正规数：<br>$2^{-150}$<br>(0 | 0000 0000 | 0000 0000 0000 0000 0000 001)</p></li><li><p>最小正数：<br>$2^{-126}$<br>(0 | 0000 0001 | 0000 0000 0000 0000 0000 000)  </p></li></ul></li></ul><h4 id="IBM-Float-System"><a href="#IBM-Float-System" class="headerlink" title="IBM Float System"></a><strong>IBM Float System</strong></h4><p>IBM Float System是基于<strong>基于十六进制</strong>的浮点数表示方法。<br>32位IBM 浮点数的表示方法为：</p><div class="table-container"><table><thead><tr><th style="text-align:center">Width of Bits</th><th style="text-align:center">1</th><th style="text-align:center">7</th><th style="text-align:center">24</th></tr></thead><tbody><tr><td style="text-align:center">Content</td><td style="text-align:center">Sign</td><td style="text-align:center">Exponent</td><td style="text-align:center">Fraction</td></tr><tr><td style="text-align:center">bias: +64</td></tr></tbody></table></div><ul><li><p>IBM Float转十进制</p><script type="math/tex; mode=display">(-1)^5\frac{M}{2^{24}}2^{exponent-64}</script></li><li><p>范围<br>$16^{-88}$-$16^{64}$</p></li></ul><h2 id="内存"><a href="#内存" class="headerlink" title="内存"></a>内存</h2><h3 id="分级存储"><a href="#分级存储" class="headerlink" title="分级存储"></a>分级存储</h3><p>由于CPU的速度受到内存读取速度的牵制，因此有必要将内存进行分级，读写速度越快的内存越靠近CPU，但是由于成本等原因，其储存空间越小。   将内存可以大致分为几层：  </p><ul><li>CPU内部的寄存器：用于存放临时数据，读写速度非常快，储存空间非常小，断电消失。  </li><li>CPU外部的存储（RAM）： 用于存放程序和数据，读写速度相对快，储存空间相对大，断电消失。  </li><li>外部的永久储存（硬盘）：读写速度慢，储存空间大，断电可以保存。  <h3 id="数据的组织"><a href="#数据的组织" class="headerlink" title="数据的组织"></a>数据的组织</h3><script type="math/tex; mode=display">\begin{array}{c}bit & 1  \\byte & 4  \\word & 8   \\Longword & 16 \end{array}</script>在主存储器中，每一个Byte都对应了一个地址，但是英特尔和摩托罗拉有两种不同的存放数据的方式，一种(Intel)是先存最低位（LSB），再存最高位(MSB)，称为小端模式（Small Endian）另一种（摩托罗拉）是先存最高位（MSB），再存最低位（LSB），称为大端模式（Big Endian）。<br>具体而言，小端的LSB被存储到最小的地址，然后下一个字节被存储到更大的地址，直到MSB被存储到最大的地址。<br>大端的MSB被存储到最小的地址，然后下一个字节被存储到更小的地址，直到LSB被存储到最大的地址。<br>因此数据在两种机器间必须先要转换，才能存放再另一种机器中。  </li></ul><h3 id="程序与指令"><a href="#程序与指令" class="headerlink" title="程序与指令"></a>程序与指令</h3><h4 id="CPU中模块的连接方式"><a href="#CPU中模块的连接方式" class="headerlink" title="CPU中模块的连接方式"></a>CPU中模块的连接方式</h4><p>寄存器： 数据总线<br>ALU： 地址总线<br>控制单元(CU): 控制总线</p><h4 id="寄存器"><a href="#寄存器" class="headerlink" title="寄存器"></a>寄存器</h4><p>寄存器可以分为用户可见（数据寄存器，地址寄存器，条件寄存器 ）和不可见的两种寄存器。<br>状态和控制寄存器：<br>PC（指针）：指向下一条指令对应的地址<br>MAR（内存地址寄存器），MBR（内存缓冲寄存器）：将指令从内存放入缓冲区，协调CPU与存储的速度。<br>指令寄存器： 存放当前的指令  </p><h4 id="指令的运行"><a href="#指令的运行" class="headerlink" title="指令的运行"></a>指令的运行</h4><ol><li>将PC指向的内容移到MAR,PC指向下一条指令</li><li>将MAR的内容移到MBR</li><li>将MBR的内容移到IR</li><li>将IR的控制内容交给CU，地址内容交给MAR</li><li>将MAR的内容移到MBR</li><li>ALU执行</li><li>ALU返回结果到指定内存<br>有两种执行指令的方式：   </li></ol><ul><li><p>硬件连接（Hardwiring）<br>一种指令对应一个硬件<br>优点：<br>快速，一个时钟内就能够解码一条指令</p></li><li><p>Micro-Programming<br>每条指令都转换成最原始的指令（Micro-instructions），对应了一个指定的门或者触发器等等，在CU中被执行。<br>因此Micro-Programming 是仅次于逻辑电路的第二层级，它也被称作固件，将软件与硬件连接起来。<br>优点：    </p><ol><li>可以创建任何复杂的指令或指令集</li><li>灵活，能够允许用户进行micro-program</li><li>有更高级的语言层</li></ol></li></ul><h2 id="栈和缓存"><a href="#栈和缓存" class="headerlink" title="栈和缓存"></a>栈和缓存</h2><h3 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h3><p>原则：后进先出<br>入栈（Push）： 将新节（node）放入栈顶<br>出栈（Pop）： 将栈顶节移除栈<br>溢出： 节数量超过了栈能够容纳的最大限度<br>优点： </p><ol><li>分配简单  </li><li>当函数退出的时候栈会自动回收    </li></ol><p>缺点：  </p><ol><li>有溢出可能</li><li>由于函数结束后栈会自动回收，因此如果有别的函数想要使用当前函数的返回值时，就必须要在当前函数执行结束前复制返回值以避免被回收。  </li></ol><p>使用栈结构与使用寄存器结构相比：   </p><ol><li>指令更小，因为操作对象（操作数）不需要指定地址</li><li>执行速度更慢，因为堆栈在外部内存中    </li></ol><h3 id="缓冲"><a href="#缓冲" class="headerlink" title="缓冲"></a>缓冲</h3><p>原则： 先进后出<br>溢出： 写速度大于读速度<br>空缓冲： 读速度大于写速度<br>缓冲分为两种：线形缓冲和环形缓冲（应用：视频处理）。<br>缓冲区大小的影响：  </p><ul><li>缓冲区过大  </li></ul><ol><li>启动时间长  </li><li>填满缓冲区的时间也长  </li></ol><ul><li>缓冲区过小  </li></ul><ol><li>更容易溢出  </li><li>如果缓冲区不够容纳所有的中断，系统会出错  </li></ol><h2 id="拓扑结构（物理）"><a href="#拓扑结构（物理）" class="headerlink" title="拓扑结构（物理）"></a>拓扑结构（物理）</h2><div class="table-container"><table><thead><tr><th style="text-align:left">类型</th><th style="text-align:left">优点</th><th style="text-align:left">缺点</th></tr></thead><tbody><tr><td style="text-align:left">Liner</td><td style="text-align:left">1. 连接简单 <br>2.用线短</td><td style="text-align:left">1. 如果主线断所有都断  <br>2. 主线断时难以查错  <br>3. 两端需要端子</td></tr><tr><td style="text-align:left">Ring</td><td style="text-align:left">1.加入简单</td><td style="text-align:left">1. 一处断，处处断</td></tr><tr><td style="text-align:left">Star*</td><td style="text-align:left">1. 连接简单  <br>2.设备之间不会有干扰  <br>3.简单查错  <br>4.加入和移除新设备简单</td><td style="text-align:left">1. 需要更多的线  <br>2. Hub断，所有断  <br>3.成本高(因为需要Hub)</td></tr><tr><td style="text-align:left">Tree*</td><td style="text-align:left">1.点对点的连线</td><td style="text-align:left">1.难以布线  <br>2.主线断，处处断</td></tr></tbody></table></div><h2 id="拓扑协议"><a href="#拓扑协议" class="headerlink" title="拓扑协议*"></a>拓扑协议*</h2><h3 id="以太网"><a href="#以太网" class="headerlink" title="以太网"></a>以太网</h3><p>如果网络没人广播，目标就广播。如果有人广播，目标等待其他人结束广播后广播。  </p><h3 id="本地会话"><a href="#本地会话" class="headerlink" title="本地会话"></a>本地会话</h3><p>如果目标需要传输和发送空令牌，数据就会附加到空令牌上，在Token Ring中传输直到找到接收者。   </p><h3 id="ATM"><a href="#ATM" class="headerlink" title="ATM"></a>ATM</h3><p>所有的数据以固定大小的小包传送，通常在两个局域网间使用。  </p><h2 id="I-O-接口"><a href="#I-O-接口" class="headerlink" title="I/O 接口"></a>I/O 接口</h2><p>I/O 接口的功能是为CPU和总线提供一个标准的借口。同时兼容各种I/O设备的借口需求，并且释放CPU对于I/O设备的管理。   </p><h3 id="I-O的控制方式"><a href="#I-O的控制方式" class="headerlink" title="I/O的控制方式"></a>I/O的控制方式</h3><ol><li>程序I/O<br>在I/O执行命令时，CPU一直等待并检测I/O是否完成任务，直到I/O执行完成。<br>特点：<br>程序I/O损失了CPU大部分的计算力，是一种低下的连接方式。   </li><li>中断I/O<br>CPU发出一个指令到I/O，之后做其他的任务直到I/O完成操作。 I/O完成操作后，会发出中断指令中断CPU当前的任务。 CPU处理完来自I/O的任务后，继续执行之前的任务。   </li><li>DMA<br>由于冯诺依曼架构中内存，I/O，存储都通过总线连接，使得数据在I/O 与内存之间能够直接传输数据成为可能。<br>整块数据在I/O与内存之间的传送在DMA控制器的控制下完成，仅在传输数据块的开始和结束时才需要CPU干预。<br>DMA会在CPU不使用总线时接管总线。    <h3 id="I-O接口的类型"><a href="#I-O接口的类型" class="headerlink" title="I/O接口的类型"></a>I/O接口的类型</h3>PCI，ATA，ISA，USB等等……</li></ol><h2 id="串行和并行连接"><a href="#串行和并行连接" class="headerlink" title="串行和并行连接"></a>串行和并行连接</h2><p>串行连接： 一比特一时钟发送数据<br>并行连接： 所有的比特会一起发送   </p><h3 id="串行连接的方式"><a href="#串行连接的方式" class="headerlink" title="串行连接的方式"></a>串行连接的方式</h3><ol><li>串行连接的时分复用<br>CPU在每一个单位时间内都处理不同并行通道内的一个数据包。  每个通道的前几个比特是用来与系统进行时间同步的。<br>例子： GSM（2G），TD-CMDA（3G）</li><li>Teletype<br>Teletype的一个数据包内通常包括： Start bit， Content， Stop Bit， Parity Bit。<br>串行需要信号去控制数据传输的暂停和恢复以适配不同速度的数据流。   </li></ol><h3 id="硬件-UART"><a href="#硬件-UART" class="headerlink" title="硬件-UART"></a>硬件-UART</h3><p>UART 遵循先进先出原则，传输异步信号。   </p><h3 id="并行连接"><a href="#并行连接" class="headerlink" title="并行连接"></a>并行连接</h3><p>并行连接往往需要不止一条数据线传输，因此体积会更大，同时数据传输更容易受到线长的限制。<br>并行连接一般有4种Pins： Data Pins, Control Pins, Status Pins, Ground Pins。      </p><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><ol><li>通常串行传输比并行传输速度更快。   </li><li>串行传输不易出现Clock Skew（时钟信号在不同组件中到达的时间有差异）。</li><li>串行传输占用空间更少。</li><li>串行线路不容易受到周围线路的影响。</li><li>串行线路避免内Crosstalk（数据在传输时对另外的线路产生影响）。   </li><li>串行线路由于Pin数更少，因此更便宜。   </li></ol><h2 id="并行算法"><a href="#并行算法" class="headerlink" title="并行算法"></a>并行算法</h2><h3 id="并行算法的类型"><a href="#并行算法的类型" class="headerlink" title="并行算法的类型*"></a>并行算法的类型*</h3><ol><li>Pipline<br>在执行第一个任务的同时准备后面的任务。<br>所有的任务都不可能比整个任务链的处理速度更快，先前的任务必须要完成后才能完成之后的任务。 但是大多数的算法都不会有太长的计算链。   </li></ol><h3 id="并行计算"><a href="#并行计算" class="headerlink" title="并行计算"></a>并行计算</h3><p>并行计算体现在两点：  </p><ol><li>一个处理器执行时分复用（多线程）       </li><li>拥有不止一个处理器 （多核心）<br>弗莱因分类法将并行计算机按照指令和数据流分为四类：SISD，MISD，SIMD，MIMD。 即单/多指令，单/多数据流。<br>通常n个并行处理器比n倍快的单个处理器效率更慢，但是并行系统更便宜。    <h3 id="基本定律"><a href="#基本定律" class="headerlink" title="基本定律"></a>基本定律</h3>阿姆达尔定律: 理想中对整个系统最大的改进是对系统中的部分进行改进。<br>古斯塔夫森定律*:  $S_{latency}=1-p+sp$<br>$S_{latency}$： 整个任务执行延迟的理论加速。<br>$s$：受益于系统资源改善的部分的加速。<br>$p$：整个任务中，相对于改进前受益于改善后的部分所占的百分比。     </li></ol><h3 id="并行计算的层级"><a href="#并行计算的层级" class="headerlink" title="并行计算的层级"></a>并行计算的层级</h3><ol><li>比特层级<br>加倍字长。 部分需要两个字长才能运行的指令（需要两个时钟）变成一个字，进而在一个时钟内就能运行。     </li><li>指令层级<br>基础的分量级处理器只能在一个时钟内运行不到一个指令。<br>对这些指令重排，并整合成指令群。现代处理器还将pipline分成了多级，因此在一个时钟内可以运行一条指令。<br>超标量处理器有多个处理单元，因此可以在一个时钟内运行多条指令。但是指令来源于同一个指令流。多核处理器也可以在一个时钟内运行多条指令，但指令来源于多个指令流。      </li><li>任务层级<br>将任务分成多个子任务并交给不同的处理器运行。   </li></ol><h3 id="并行计算的例子"><a href="#并行计算的例子" class="headerlink" title="并行计算的例子*"></a>并行计算的例子*</h3><ol><li>分布式计算<br>与并行计算并无太多区别，可以理解为并行计算。   </li><li>网格计算<br>通过Internet将不同的计算机连接（需要中间件兼容），但是由于Internet的低带宽高延迟特性，因此性能往往不好。  </li><li>可重构计算（FGPA）<br>将一个可编程门</li><li>GPU</li><li>向量处理器</li></ol><h2 id="哈佛架构"><a href="#哈佛架构" class="headerlink" title="哈佛架构"></a>哈佛架构</h2><p>和冯诺依曼架构最大的不同是：内存被分为了两部分：Program Memory（静态内存）和 Data Memory（动态内存）。</p><h3 id="与冯诺依曼架构对比"><a href="#与冯诺依曼架构对比" class="headerlink" title="与冯诺依曼架构对比"></a>与冯诺依曼架构对比</h3><ol><li>哈佛架构的CPU可以在同一时间读取指令和数据（同时性），且指令和数据不会在fetch时竞争（独立性）。     </li><li>哈佛架构允许Program Memory 和 Data Memory的储存介质不同。    </li><li>哈佛架构允许像访问数据一样访问指令储存器的内容。</li><li>冯诺依曼架构中代码被视为数据，数据也被看作代码。 因此冯诺依曼架构允许从硬盘中读取和执行程序。<br>现代的处理器通常是哈佛架构和冯诺依曼架构的混合架构，通常被视作是改进的哈佛架构。   如：x86，ARM， PowerPC。     </li></ol><h2 id="校验码"><a href="#校验码" class="headerlink" title="校验码"></a>校验码</h2><h3 id="奇偶校验码"><a href="#奇偶校验码" class="headerlink" title="奇偶校验码"></a>奇偶校验码</h3><p>在数据包后加上一个校验位，使得所有的比特位中1的总数为奇数/偶数。<br>缺点： 无法探测错误的位置。 对于两位以上的错误，无法矫正错误。   </p><h3 id="汉明码"><a href="#汉明码" class="headerlink" title="汉明码"></a>汉明码</h3><p>在一串$d$位数据的$2^{n-1}$位上加入校验位，校验位的数量$c$满足：$2^c-1&gt;=d$。<br>第$n$个校验码的校验条件满足： 从第$2^n$位开始，使用偶校验检测$2^n$位，再跳过$2^n$位，再检测$2^n$位，重复直到检测最后一位。<br><strong>数据和校验码的位置序号是相反的</strong>,数据的比特位编号是从右到左依次减小，校验码的比特位是从右到左依次增大<br>缺点： 当只有一个校验码出错时，有50%的概率是数据出错，有50%的概率是校验码自己出错，无法确定。  有两个比特出错时可以检验，但无法校正。  </p><h3 id="前向纠错码"><a href="#前向纠错码" class="headerlink" title="前向纠错码"></a>前向纠错码</h3><p>前向纠错是一种差错控制方式，它是指信号在被送入传输信道之前预先按一定的算法进行编码处理，加入带有信号本身特征的冗码，在接收端按照相应算法对接收到的信号进行解码，从而找出在传输过程中产生的错误码并将其纠正的技术。<br>前向纠错码分为两种：卷积码（一个比特一个比特地处理）和块码（一个块一个块地处理）。 块纠错码的代表是里得-所罗门码。   </p><h3 id="循环冗余校验"><a href="#循环冗余校验" class="headerlink" title="循环冗余校验"></a>循环冗余校验</h3><p>循环冗余校验是利用里得-所罗门码进行校验的一种方式，具体是将整个数据包的每一位转换成多项式的系数（值）和次数（位置）。在伽罗瓦域中以输入值作为被除数做多项式除法，得到的余数作为校验的结果。<br>循环冗余校验不能检测恶意插入的错误。   </p><h3 id="哈希函数"><a href="#哈希函数" class="headerlink" title="哈希函数"></a>哈希函数</h3><p>将原数据输入哈希函数，得到的将是一个哈希值序列的信息摘要。对原数据任何的更改都会导致哈希值序列发生改变，因此可以检测恶意或偶然出现的错误。     </p><h3 id="应用"><a href="#应用" class="headerlink" title="应用"></a>应用</h3><p>Internet—和校验<br>数字卫星电视信号—循环冗余校验<br>硬盘—循环冗余校验<br>条形码<br>快速响应矩阵（QR二维码）—循环冗余校验     </p><h2 id="CPU的类型"><a href="#CPU的类型" class="headerlink" title="CPU的类型"></a>CPU的类型</h2><p>CPU按照指令集的复杂程度可以分为5类架构：<br>Complex/ Reduced/ Minimal/ One/ Zero Instruction Set Computer  </p><h3 id="CISC"><a href="#CISC" class="headerlink" title="CISC"></a>CISC</h3><p>每一条指令都能够运行一些复杂的低层级的操作，比如算术运算或者从内存加载等等，所有的操作都在一条指令内被执行。<br>优点： 一些复杂或者高级的操作（例如循环）能够直接被整合为一条指令。<br>缺点： 从简单的指令加载复杂的操作并不一定能够提高电脑的性能。<br>常见的CISC处理器架构： x86<br>现代x86处理器能够解码并将指令划分到动态的缓冲微操作中，以便能够在单线程中运行更大的负指令集，同时精简了并行计算。   </p><h3 id="RISC"><a href="#RISC" class="headerlink" title="RISC"></a>RISC</h3><p>RISC 的设计遵循： 如果简化的指令集能够使得每条指令更快的运行，那么简化的指令集就能提高性能。<br>特点：     </p><ol><li>基本上大多数的指令都有相似的结构和固定的长度。通常为一个字长加上固定比特位的操作码。   </li><li>寄存器大多相似且通用（浮点寄存器除外），能够简化编译设计。   </li><li>简单的地址模型。  </li><li>硬件支持的数据类型更少。<br>优点：有更好的pipeline stagesstages 和更快的时钟频率 因此更高效。<br>常见的RISC处理器架构： ARM 和 PowerPC     </li></ol><h3 id="MISC"><a href="#MISC" class="headerlink" title="MISC"></a>MISC</h3><p>处理器有很少的基本操作和对应的操作码，通常基于栈结构。<br>优点： 指令和解码单元更小，因此单个指令的运行速度更快。<br>缺点： 指令更依赖于串行结构，减少了并行计算。<br>常见的MISC处理器架构： INMOS</p><h3 id="OISC-和-ZISC"><a href="#OISC-和-ZISC" class="headerlink" title="OISC 和 ZISC"></a>OISC 和 ZISC</h3><p>OISC： 只使用一条指令，不需要操作码。<br>ZISC： 基于纯模式匹配而不需要微指令。   </p><h2 id="特殊化处理器"><a href="#特殊化处理器" class="headerlink" title="特殊化处理器*"></a>特殊化处理器*</h2><h3 id="Cell-Processor"><a href="#Cell-Processor" class="headerlink" title="Cell Processor"></a>Cell Processor</h3><p>Cell Processor是一种拥有很多sub-processor的处理单元，其特征在于：</p><ol><li>所有的子处理器都是独立的，但是公用一个总线，在通信上并不是独立的。  </li><li>只要任务的粒度（Granularity）能够让所有的子处理器都能够同时工作，那么任务就能够被快速处理。  </li></ol><h3 id="GPU"><a href="#GPU" class="headerlink" title="GPU"></a>GPU</h3><p>GPU是一种用于加速建图和图像处理的专门化处理器。 GPU内部高度并行化。<br>功能： 加速渲染多边形和纹理匹配， 解码高清视频等等。  </p><h3 id="DSP"><a href="#DSP" class="headerlink" title="DSP"></a>DSP</h3><p>专门化的数字信号处理器，用于声音、图像、雷达系统。<br>功能： 数字信号与模拟信号的转换和处理。<br>DSP 的指令集优化用于处理数学运算、特殊的地址模型、特殊化的循环控制。<br>DSP 中的数学计算常常是Fixed-point 计算。<br>DSP 不支持虚拟内存和内存保护。   </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>计算机结构与接口</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0. 课程简介</title>
    <link href="/2021/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/"/>
    <url>/2021/03/01/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/%E4%BF%A1%E5%8F%B7%E4%B8%8E%E7%B3%BB%E7%BB%9F/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h1><p>课程： BUL 2021： EE2622 Fundamentals of Signals and Systems<br>授课教师： Dr. Ruiheng Wu/ Zheng Luo (Assistant)  </p><h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>《信号与线性系统分析》 第四版 吴大正主编 高等教育出版社<br>《信号与系统》 第二版 奥本海姆编 电子工业出版社  </p><h2 id="笔记结构"><a href="#笔记结构" class="headerlink" title="笔记结构"></a>笔记结构</h2><p>笔记按照课程内容顺序按数字编号，内容包括课堂笔记总结、知识点总结以及期末题目分析等等。  </p>]]></content>
    
    
    <categories>
      
      <category>学习笔记</category>
      
      <category>信号与系统</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1.5. 多项式拟合和正规方程</title>
    <link href="/2021/02/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.5.%20%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88%E5%92%8C%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/"/>
    <url>/2021/02/26/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.5.%20%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%8B%9F%E5%90%88%E5%92%8C%E6%AD%A3%E8%A7%84%E6%96%B9%E7%A8%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="多项式拟合和正规方程"><a href="#多项式拟合和正规方程" class="headerlink" title="多项式拟合和正规方程"></a>多项式拟合和正规方程</h1><h2 id="特征点的创建和合并"><a href="#特征点的创建和合并" class="headerlink" title="特征点的创建和合并"></a>特征点的创建和合并</h2><p>对于一个特定的问题，可以产生不同的特征点，<strong>通过对问题参数的重新定义和对原有特征点的数学处理合并拆分，能够得到更加优秀的特征点。</strong></p><h2 id="多项式回归"><a href="#多项式回归" class="headerlink" title="多项式回归"></a>多项式回归</h2><p>对于更多更加常见的数学模型，其拟合往往是非线性关系的，这时候就需要考虑引用多项式来进行拟合，如：$h(x)=θ_0+θ_1 x+θ_2 x^2+θ_3 x^3$  </p><h2 id="正规方程算法"><a href="#正规方程算法" class="headerlink" title="正规方程算法"></a>正规方程算法</h2><p>在微积分中，对于函数$f(x,y)$，其局部最值往往是在$f_x=0$ 且$f_y=0$处取得。<br>因此，对于代价函数$J(θ)$，求$J(θ)$对每一个$θ_i$的偏导数，令它们都为0，即：</p><script type="math/tex; mode=display">\frac{∂J(θ)}{∂θ_i}=0~for~i=0,1,2,…,n</script><p>称为<strong>正规方程</strong>(Regular expression)。正规方程提供了一种直接求出最小值的方法，而不需要依赖迭代进行一步一步地运算。 </p><h3 id="正规方程的矩阵形式"><a href="#正规方程的矩阵形式" class="headerlink" title="正规方程的矩阵形式"></a>正规方程的矩阵形式</h3><p>对于数据集$\{(x^{(1)},y^{(1)}),(x^{(2)},y^{(2)}),…,(x^{(m)},y^{(m)})\}$,  其中每一个$x^{(i)}$都是一个向量：$x^{(i)}=\left[\begin{smallmatrix}x_0^{(i)} \\\ x_1^{(i)} \\\ …\\\ x_n^{(i)}\end{smallmatrix}\right]$ 构建<strong>设计矩阵</strong>（Design matrix）$X=\left[\begin{smallmatrix}<br>(x^{(1)})^T \\\ (x^{(2)})^T \\\ … \\\ (x^{(m)})^T<br>\end{smallmatrix}\right]$  和值向量 $y=\left[\begin{smallmatrix}  y^{(1)} \\\ y^{(2)} \\\ … \\\ y^{(m)}  \end{smallmatrix}\right]$<br>将代价函数转化为矩阵方程的形式，再对其求导，令其等于0，得到代价函数取得最小值时的$θ$：</p><script type="math/tex; mode=display">θ=(X^TX)^{-1}X^Ty</script><p>对比梯度下降算法：<br>正规方程算法不需要学习率和迭代，但<strong>对大规模数量（万数量级以上）的特征点（n），工作效率十分低下</strong>。对于一些如分类算法等等更加复杂的算法，正规方程法并不适用于求它们在极值处的θ值。  </p><h3 id="正规方程的不可逆性"><a href="#正规方程的不可逆性" class="headerlink" title="正规方程的不可逆性"></a>正规方程的不可逆性</h3><p>在使用正规方程时，要注意的问题是，<strong>如果设计矩阵X不可逆（为奇异矩阵），正规方程会无法使用。</strong>  </p><p>设计矩阵为奇异矩阵的常见情况：</p><ol><li>x-I 不满足线性关系  </li><li>正在运行的学习算法中，特征点的数量大于样本点的数量（使得$m≤n$）  </li></ol><p>当设计矩阵X不可逆时，应当尝试删除一些特征点，或者考虑正规化（Regularation）。<br>但是总体而言，<strong>矩阵X不可逆的情况是极少数的。</strong></p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>01. 线性回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1.4. 优化和调试方法</title>
    <link href="/2021/02/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.4.%20%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/"/>
    <url>/2021/02/25/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.4.%20%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="优化和调试方法"><a href="#优化和调试方法" class="headerlink" title="优化和调试方法"></a>优化和调试方法</h1><h2 id="特征缩放"><a href="#特征缩放" class="headerlink" title="特征缩放"></a>特征缩放</h2><p>对于某些不具有比较性的样本特征$x_i$ （比如对其他的x来说$x_i$ 相当大或者相当小），梯度下降的过程可能会非常漫长，并且可能来回波动才能最后收敛到全局的最小值。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822121924.png width=50%><br>在这样的情况下，可以对$x_i$ 进行缩放（如 $x_i≔αx_i$  或者 $x_i=x_i/α$），使得$x_i$ 与其他的$x$具有可比性，以增加梯度下降的效率。<br><strong>通常将$x$缩放至⟦-1,1⟧</strong>的区间内。（只表示一个大致的范围，这不是绝对的。）</p><h2 id="均值归一"><a href="#均值归一" class="headerlink" title="均值归一"></a>均值归一</h2><p>将$x_i$  替换为$x_i−μ_i$ 使得特征值具有为0的平均值（对$x_0$ 不适用）</p><script type="math/tex; mode=display">x_i:=(x_i−μ_i)/s_i</script><p>定义$μ_i$  为训练集$X$ 的平均值，$s_i=|x_imax−x_imin |$, 表示$x_i$ 的取值范围（近似值），或者直接设置为$s_i$ 的标准差。</p><h2 id="学习率-Learning-rate"><a href="#学习率-Learning-rate" class="headerlink" title="学习率(Learning rate)"></a>学习率(Learning rate)</h2><p>有如下的两种方法可以判断梯度下降算法是否已经处于收敛：</p><ol><li><p>绘制$min_θJ(θ)-batch$的图像<br>以迭代次数为横轴，以此时使得$J(θ)$局部最小时$θ$的值（即$min_θJ(θ)$）为纵轴绘制图像。<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822121634.png width=50%><br>这样的做法需要在固定的迭代周期（比如每迭代100次穿插）时暂停学习，并求得此时的$θ$，然后绘制图像。<br>原则：在固定的迭代周期之后$θ$的值都应该减小，这样的图像能够通过直观地表现变化率来表现梯度下降是否收敛（变化率为0）。  </p></li><li><p>自动收敛测试<br>如果$J(θ)$在某一次迭代之后的下降值小于某个设定好的阈值$ε$后，就能够判断算法已经达到了收敛。<br>$ε$的设定具有技巧性，所以通常采取1.中的方法进行观测。  </p></li></ol><h3 id="常见问题"><a href="#常见问题" class="headerlink" title="常见问题"></a>常见问题</h3><p>常见的α过大的$min_θJ(θ)-batch$的图像：  </p><ul><li><p>α过大,导致代价函数无法收敛<br><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822121842.png width=50%>   </p></li><li><p>α过小，导致代价函数收敛速度过慢</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>01. 线性回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1.3. 多变量线性回归</title>
    <link href="/2021/02/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.3.%20%E5%A4%9A%E5%8F%98%E9%87%8F%E9%A2%84%E6%B5%8B/"/>
    <url>/2021/02/24/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.3.%20%E5%A4%9A%E5%8F%98%E9%87%8F%E9%A2%84%E6%B5%8B/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 30%;<br>    padding-left: 20%;<br>}</style></p><h1 id="多变量线性回归"><a href="#多变量线性回归" class="headerlink" title="多变量线性回归"></a>多变量线性回归</h1><h2 id="多元线性回归"><a href="#多元线性回归" class="headerlink" title="多元线性回归"></a>多元线性回归</h2><p>对于多个特征量(Features)，规定符号表示：<br>$n$ 特征的总数量<br>$x^{(i)}$  第i个训练样本的输入特征向量，$i$表示的是一个索引(Index)<br>$x_j^i$  第i个训练样本中特征向量的第j个值  </p><p>此时的假设函数不再是单纯的 $h_θ (x)=θ_0+θ_1 x$ 的形式。<br>对于多个特征量，此时的假设函数为：   </p><script type="math/tex; mode=display">h_θ (x)=θ^T x=θ_0+θ_1 x^{(1)}+θ_2 x^{(2)}+…+θ_n x^{(n)}</script><p>对这个样本进行简化：<br>定义$x_0^i=1$, 定义参数向量：$x=\left[\begin{smallmatrix} x_0 \\\ x_1 \\\ … \\\ x_n \end{smallmatrix}\right]n$，系数向量：$θ=\left[\begin{smallmatrix}θ_0 \\\ θ_1 \\\ … \\\ θ_n \end{smallmatrix}\right]$<br>有：   </p><script type="math/tex; mode=display">h_θ (x)=θ^T x</script><p>这就是假设函数的向量形式。   </p><h2 id="梯度下降算法在多元线性回归中的应用"><a href="#梯度下降算法在多元线性回归中的应用" class="headerlink" title="梯度下降算法在多元线性回归中的应用"></a>梯度下降算法在多元线性回归中的应用</h2><p>对于假设函数：</p><script type="math/tex; mode=display">\begin{aligned}h_θ(x)  & =  θ^T x \\\  & =θ_0+θ_1 x^{(1)}+θ_2 x^{(2)}+…+θ_n x^{(n)} \\\       \end{aligned}</script><p>和损失函数：   </p><script type="math/tex; mode=display">J(θ_0,θ_1,…,θ_n)=\frac{1}{2m} ∑_{i=1}^m(h_θ (x^{(i)} )−y^{(i)} )^2</script><p>此时的梯度下降算法：<br>Repeat\{</p><script type="math/tex; mode=display">θ_j≔θ_j−α\frac{∂J(θ)}{∂θ_j}</script><p>\}<br>对$\frac{∂J(θ)}{∂θ_j}$进行等价变形：<br>Repeat\{</p><script type="math/tex; mode=display">θ_j≔θ_j−α\frac{1}{m}∑_{i=1}^m(h_θ (x^{(i)} )−y^{(i)})  x_j^i</script><p>\}</p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>01. 线性回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1.2. 梯度下降算法</title>
    <link href="/2021/02/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.2.%20%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/"/>
    <url>/2021/02/23/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.2.%20%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 40%;<br>    padding-left: 20%;<br>}</style></p><h1 id="梯度下降算法"><a href="#梯度下降算法" class="headerlink" title="梯度下降算法"></a>梯度下降算法</h1><p>在开始之前规定几个符号所代表的意义：<br>$m$ 训练集中训练样本的数量<br>$X$  输入变量<br>$Y$  输出变量<br>$(x,y)$ 训练样本<br>$(x^i,y^i)$第i个训练样本（i表示一个索引）  </p><h2 id="监督学习算法的流程"><a href="#监督学习算法的流程" class="headerlink" title="监督学习算法的流程"></a>监督学习算法的流程</h2><p>提供训练集&gt;学习算法得到$h$（假设函数：用于描绘$x$与$y$的关系）&gt;预测$y$ 的值  </p><h2 id="假设函数"><a href="#假设函数" class="headerlink" title="假设函数"></a>假设函数</h2><p><strong>假设函数(Hypothesis function)</strong>——$h$是用来表示某一个数据集可能存在的线性/非线性关系的函数。对于线性拟合，其假设函数为：  </p><script type="math/tex; mode=display">h_θ(x)=θ_1x+θ_0</script><p>其中$θ$是假设函数当中的参数。<br>如果不考虑截距项$θ_0$，$h_θ(x)$可以简化为：</p><script type="math/tex; mode=display">h_θ(x)=θ_1x</script><h2 id="代价-损失函数"><a href="#代价-损失函数" class="headerlink" title="代价/损失函数"></a>代价/损失函数</h2><p><strong>代价函数</strong>（Cost/Loss function），在统计学上称为均方根误差函数。当假设函数中的系数$θ$取不同的值时，$\frac{1}{2m}$倍假设函数预测值$h_θ(x^{(i)})$和真实值$y^{(i)}$的差的平方的和之间的函数关系表示为代价函数$J$。</p><script type="math/tex; mode=display">J(θ_0,θ_1)= \frac{1}{2m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})^2</script><blockquote><p>取1/2的原因是便于消除求导之后产生的2倍,同时也可以进一步缩小$θ$  </p><p>线性回归的代价函数的自变量有两个：$θ_1$和$θ_0$，因此该函数是三维的函数。线性回归的代价函数图像如下图所示：<br> <img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131130651.png" alt="">  </p></blockquote><p><strong>代价函数在几何上表示为数据集空间内的各点到假设函数的欧式距离的平方的平均值的一半。</strong><br>要想使得数据能够被假设函数很好地拟合，那么代价函数要尽量地小。<strong>当代价函数取到它的最小值即</strong>$J(θ_1)_{min}$<strong>时，此时的填入假设函数的</strong>$θ$<strong>对数据的拟合程度是最好的</strong>。<br>对于线性的代价函数，假设函数对数据集的拟合程度越高，对应的$(θ_0,θ_1)$越接近代价函数图像等高线的中心。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131132852.png" alt="">   </p><h2 id="梯度下降算法（Gradient-Descent）"><a href="#梯度下降算法（Gradient-Descent）" class="headerlink" title="梯度下降算法（Gradient Descent）"></a>梯度下降算法（Gradient Descent）</h2><h3 id="梯度"><a href="#梯度" class="headerlink" title="梯度"></a>梯度</h3><p>在微积分中，函数$f(x,y)$在$(x_0,y_0)$处是函数值增加最快的方向是<strong>梯度（Gradient）</strong>的方向，<strong>梯度的反方向是函数值减小最快的方向。</strong><br>$f(x,y)$在$(x_0,y_0)$处的梯度：  </p><script type="math/tex; mode=display">▿f|_{(x_0,y_0)}=(\frac{∂}{∂x}f(x_0,y_0),\frac{∂}{∂y}f(x_0,y_0))</script><h3 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h3><p>梯度下降算法是一种求解代价函数最小值的方法，它可以用在<strong>多维任意的假设函数</strong>当中。<br>简而言之，梯度下降算法求得$J(θ_1)_{min}$的主要思路是：   </p><ol><li>给定$θ_0$和$θ_1$的初始值，通常令$θ_0=0$，$θ_1=0$。</li><li>不断改变$θ_0$和$θ_1$的值使得$J(θ_0,θ_1)$的值逐渐变小，直到找到$J(θ_0,θ_1)$的最小值或者局部最小值。<br>如果从一个初始值出发，寻找附近的最小值，重复该过程，得到上图，最后得到的值为局部最优解。  <blockquote><p>将梯度下降算法类比为爬山，从一个点开始，不断寻找“下山”的路线，最后找到一个“下山”的出口。  </p></blockquote></li></ol><p>当改变初始值时，会找到另一条“下山”的路径，找到第二个局部最优解（局部最小值）。  </p><p><img src = https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20210822101757.png width=80%>  </p><p>对于线性回归的代价函数而言，只存在一个局部最小值。（见线性回归代价函数的图像）  </p><h3 id="表示"><a href="#表示" class="headerlink" title="表示"></a>表示</h3><p>梯度下降算法可以表示为：<br>Repeat untill convergence\{  </p><script type="math/tex; mode=display">θ_j:=θ_j-α\frac{∂J(θ_0,θ_1)}{∂θ_j},j=0~and~j=1</script><p>\}<br>解释：    </p><ol><li>:=  表示赋值运算符</li><li>α称为<strong>学习率</strong>，用来控制下降的<strong>步长</strong>（Padding），即更新的幅度：  <ul><li>α太小，同步更新的速率会非常的慢     </li><li>α过大，同步更新时可能会越过最小值点   </li></ul></li><li>$\frac{∂J(θ_0,θ_1)}{∂θ_j}$是代价函数的梯度：<script type="math/tex; mode=display">\frac{∂J(θ_0,θ_1)}{∂θ_0}=\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})</script><script type="math/tex; mode=display">\frac{∂J(θ_0,θ_1)}{∂θ_1}=\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x^{(i)}</script><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131135144.png" alt=""><br>△在代价函数中（以简化的代价函数为例），无论初始值在最小值点的左侧还是右侧，通过同步更新都能够使该点被移动到最小值，在最小值点，由于导数值为0，最终同步更新停止在了$θ_j=θ_j$，此时的$θ_j$即为极小值点。  </li></ol><h3 id="同步更新"><a href="#同步更新" class="headerlink" title="同步更新"></a>同步更新</h3><p><strong>同步更新</strong>（Simulaneous update）是梯度下降算法中用于处理多个参数$θ$的方式。  </p><script type="math/tex; mode=display">temp0:θ_0:=θ_0-α\frac{∂J(θ_0,θ_1)}{∂θ_0}</script><script type="math/tex; mode=display">temp1:θ_1:=θ_1-α\frac{∂J(θ_0,θ_1)}{∂θ_1}</script><script type="math/tex; mode=display">θ_0:=temp0</script><script type="math/tex; mode=display">θ_1:=temp1</script><p>这个更新方程能够同时更新$θ_0$和$θ_1$。<br>更新的方法是计算赋值号右边带入$θ_1$和$θ_2$的值进行计算，得到的两个值分别储存在temp0和temp1中，从上到下进行赋值。  </p><p>对于简化的代价函数：  </p><script type="math/tex; mode=display">θ_1：=θ_1-αJ'(θ_1)</script><script type="math/tex; mode=display">\frac{dJ(θ_1)}{dθ_1} =\frac{d}{dθ_1}(\frac{1}{2m}Σ(h_θ(x_i)-y_i))^2)</script><p>将梯度代回代价函数中就得到了<strong>批量梯度下降</strong>算法的基本形式：<br>重复如下的更新方程，直到$θ_0$和$θ_1$都收敛 </p><script type="math/tex; mode=display">θ_0:=θ_0-α\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})</script><script type="math/tex; mode=display">θ_1:=θ_1-α\frac{1}{m}∑_{i=1}^m(h_θ(x^{(i)})-y^{(i)})x^{(i)}</script><blockquote><p>本节学习的梯度下降算法在每一轮迭代时都要对数据集中所有的数据进行求和，因此称为批量梯度下降算法。这种算法在数据集的数据量非常大时，执行算法所消耗的计算量相当大。因此在大数据集学习时，采用另一种梯度下降的方式，称为随机梯度下降。<br>关于随机梯度下降的的内容：<a href="https://l61012345.top/2021/08/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/13.%20%E5%A4%A7%E8%A7%84%E6%A8%A1%E5%AD%A6%E4%B9%A0/13.2.%20%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D%E7%AE%97%E6%B3%95/">13.2. 随机梯度下降算法</a></p></blockquote>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>01. 线性回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2.4. 向量化</title>
    <link href="/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.4.%20%E5%90%91%E9%87%8F%E5%8C%96/"/>
    <url>/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.4.%20%E5%90%91%E9%87%8F%E5%8C%96/</url>
    
    <content type="html"><![CDATA[<h1 id="向量化"><a href="#向量化" class="headerlink" title="向量化"></a>向量化</h1><p>对于求和的算法，有时可以转换为矩阵的乘法来进行计算<br>E.g.  </p><script type="math/tex; mode=display">H(θ)(x)=∑_{j=0}^nθ_j x_j</script><p>如果直接求和，求和的过程会非常冗长<br>而设计两个向量$θ$ $x$<br>则有线性回归假设函数的向量形式：</p><script type="math/tex; mode=display">h(x)=θ^T x</script><p>对更新函数：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20201224232957.png" alt=""></p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>02. Octave语言初步</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2.3. 控制和定义语句</title>
    <link href="/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.3.%20%E6%8E%A7%E5%88%B6%E5%92%8C%E5%AE%9A%E4%B9%89%E8%AF%AD%E5%8F%A5/"/>
    <url>/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.3.%20%E6%8E%A7%E5%88%B6%E5%92%8C%E5%AE%9A%E4%B9%89%E8%AF%AD%E5%8F%A5/</url>
    
    <content type="html"><![CDATA[<h1 id="控制和定义语句"><a href="#控制和定义语句" class="headerlink" title="控制和定义语句"></a>控制和定义语句</h1><p>for i=1:10,<br>Indices=a : b 从a到b的索引<br>Break Continue 与C语言相同<br>While, end 结构体 同C语言  </p><p>选择结构：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> condition,    <br>command   <br>end   <br></code></pre></div></td></tr></table></figure><br>分支选择结构：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp"><span class="hljs-keyword">if</span> condition,   <br>command;   <br>elseif condition,   <br>Command;  <br></code></pre></div></td></tr></table></figure><br>循环结构：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp"><span class="hljs-keyword">while</span> condition，  <br>Conmand;  <br> end  <br></code></pre></div></td></tr></table></figure><br>定义函数：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp">function y=function(x)  <br>command with Y,x;  <br></code></pre></div></td></tr></table></figure><br>保存为function.m文件  </p><p>返回多个值的函数：<br><figure class="highlight cpp"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs cpp">function [y1,y2]=function(x)  <br>Command with y1,y2,x;  <br></code></pre></div></td></tr></table></figure><br>加载函数：<br>定位到m文件目录下  </p><p><code>addpath（&#39;path&#39;）</code>: 加入Octave路径  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>02. Octave语言初步</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2.2. 数据计算和绘制</title>
    <link href="/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.2.%20%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E5%92%8C%E7%BB%98%E5%88%B6%E5%9B%BE%E5%83%8F/"/>
    <url>/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.2.%20%E6%95%B0%E6%8D%AE%E8%AE%A1%E7%AE%97%E5%92%8C%E7%BB%98%E5%88%B6%E5%9B%BE%E5%83%8F/</url>
    
    <content type="html"><![CDATA[<h1 id="数据计算和绘制"><a href="#数据计算和绘制" class="headerlink" title="数据计算和绘制"></a>数据计算和绘制</h1><h2 id="对元素的操作"><a href="#对元素的操作" class="headerlink" title="对元素的操作"></a>对元素的操作</h2><p><code>A.\*B</code> A矩阵和B矩阵的每一个元素对应相乘<br><code>.</code> 对每一个元素进行运算操作<br><code>abs(A)</code> 对A每一个元素取绝对值<br><code>v+1</code> 对向量v里面的每一个元素+1<br><code>A’</code> 矩阵A的转置<br><code>pinv(A)</code>对A求逆矩阵，不可逆时即为伪逆矩阵<br><code>max(A)</code> A中最大的元素的值<br><code>max(A,[], DI)</code> A中DI维度下元素最大的值（1 列 2 行）<br><code>ind()</code> 某个元素的位置<br><code>magic(n)</code> 返回n*n的幻方<br><code>find(condition)</code>查找对应条件的元素，并返回一个向量<br><code>sum(A)</code>A所有元素的和<br><code>prod(A)</code>A所有元素的乘积<br><code>ceil(A)</code> 对A向上取整<br><code>floor(A)</code>对A每个元素向下取整<br><code>flipud(A)</code>对A上下翻转  </p><h2 id="绘制图像"><a href="#绘制图像" class="headerlink" title="绘制图像"></a>绘制图像</h2><p><code>Plot(x,y,&#39;r&#39;)</code> 绘制关于x，y的图像 r表示y的函数是红色的（默认为蓝色）<br><code>hold on</code> 保存octave内存中的旧函数图像<br><code>xlabel(&#39;&#39;)</code>添加横轴标签<br><code>ylabel（‘’）</code>添加纵轴标签<br><code>legend(&#39;&#39;,&#39;&#39;)</code> 图例<br><code>title（‘’）</code>添加标题<br><code>print -dpng &#39;xx.png&#39;</code> 在当前路径下以png保存当前图像<br><code>close</code> 关闭当前图像<br><code>figure(1)</code>; 标记图像（多开图像窗口）<br><code>subplot(1,2,1)</code> 把图像分成1x2的网格 从第一个格图开始画图<br><code>axis([0.5 1 -1 1])</code>横轴0.5~1 纵轴-1~1<br><code>clf</code> 清除一幅图像<br><code>imagesc(A)</code>可视化矩阵<br><code>colorbar</code> 添加颜色条<br><code>colormap gray</code>  生成黑白图像<br><code>,</code>依次执行每一个命令  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>02. Octave语言初步</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2.1. 基本命令</title>
    <link href="/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.1.%20%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/"/>
    <url>/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/2.%20Octave%E8%AF%AD%E8%A8%80%E5%88%9D%E6%AD%A5/2.1.%20%E5%9F%BA%E6%9C%AC%E5%91%BD%E4%BB%A4/</url>
    
    <content type="html"><![CDATA[<h1 id="基本命令"><a href="#基本命令" class="headerlink" title="基本命令"></a>基本命令</h1><h2 id="基本运算"><a href="#基本运算" class="headerlink" title="基本运算"></a>基本运算</h2><p>代数运算：+ - * / sqrt（）<br>布尔运算：且：&amp;&amp;  或：||  非：！<br>赋值：=  </p><h2 id="基础命令"><a href="#基础命令" class="headerlink" title="基础命令"></a>基础命令</h2><p><code>disp()</code> 显示（）内的命令到屏幕<br><code>sprintf()</code>用法同c语言中的printf<br><code>format lone</code> 显示变量的更多小数位数<br><code>formate short</code> 显示变量的更少小数位数（4位）<br><code>help fuction</code> 显示function 函数的帮助文档  </p><h2 id="矩阵的快速操作"><a href="#矩阵的快速操作" class="headerlink" title="矩阵的快速操作"></a>矩阵的快速操作</h2><p><code>[a b; c d;]</code> 2x2矩阵<br>[]矩阵符号<br>；换行<br>快速建立步长相等的行向量：  起始参数：步长（默认为1）：终止参数<br><code>ones(a,b)</code> 快速生成axb的矩阵，且所有元素为1<br><code>zeros(a,b)</code>快速生成axb的矩阵，且所有元素为0<br><code>rand(a,b)</code>快速生成axb的矩阵，且所有元素的值为在（0，1）内的随机数<br><code>randn(a,b)</code>快速生成axb的矩阵，且所有元素的值为服从正态分布的随机数<br><code>hist()</code> 快速绘制变量的直方图<br><code>eye(a)</code> 快速生成axa的单位矩阵<br><code>size(row,column)</code>返回矩阵的大小，并将大小存入一个1x2的矩阵中<br><code>length(A)</code>返回向量A的最大维度的值<br><code>rref(A)</code> 求解矩阵A的阶梯型</p><h2 id="文件操作"><a href="#文件操作" class="headerlink" title="文件操作"></a>文件操作</h2><p><code>pwd</code> 返回Octave当前指向的路径<br><code>cd &#39;path&#39;</code> 使Octave指向path路径<br><code>ls</code> 返回Octave当前指向的路径下所有的文件名称  </p><p><code>Load (&#39;file.dat&#39;)</code>  加载file.dat文件<br>*file.dat 是一个编写好的仅有数据（用固定格式aaa bbb ccc）的文件<br><code>Who</code> 返回Octave当前内存中所有的变量<br><code>Whos</code> 返回Octave当前内存中所有的变量和对应的维度、数据类型、数据大小<br><code>Clear varible</code> 清除varible变量<br><code>Clear</code> 清除内存中所有的变量<br><code>Varible1=varible2(a:b)</code>将varible2中的a到b位数据赋给varible1<br><code>Save file.mat varible</code> 将varible存入file.mat中<br><code>Save file.txt varible ascii</code> 将varible存入file.txt中 编码为ascii  </p><h2 id="索引"><a href="#索引" class="headerlink" title="索引"></a>索引</h2><p><code>varible(a,b)</code>定位到varible中的（a，b）变量<br><code>C=[A B]</code> 生成[A B]矩阵（B在A右边）<br><code>C=[A;B]</code> 生成[A B]矩阵（B在A下边）  </p>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>02. Octave语言初步</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1.1. 什么是机器学习</title>
    <link href="/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.1.%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    <url>/2021/02/22/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E2%80%94%E2%80%94%E5%90%B4%E6%81%A9%E8%BE%BE/1.%20%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92/1.1.%20%E4%BB%80%E4%B9%88%E6%98%AF%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="什么是机器学习"><a href="#什么是机器学习" class="headerlink" title="什么是机器学习"></a>什么是机器学习</h1><h2 id="机器学习的定义"><a href="#机器学习的定义" class="headerlink" title="机器学习的定义"></a>机器学习的定义</h2><blockquote><p>A computer  program is said to learn from experience E with respect to some task T and some performance measure P, if its performance on T, as measured by P, improves with experience E.    ——Tom Mitchelle  </p></blockquote><p>简言之，机器学习通过完成任务（T）得到经验（E），进而提升性能（P）。<br>例如：一个自我对弈的跳棋学习机器：E ：自我对弈的棋局 T：下跳棋 P：与新对手玩跳棋时的获胜概率  </p><h2 id="机器学习的主要算法类型"><a href="#机器学习的主要算法类型" class="headerlink" title="机器学习的主要算法类型"></a>机器学习的主要算法类型</h2><ul><li><strong>监督学习</strong>（Supervised）<br>人教会计算机完成任务。<br>根据统计数据做直线或曲线拟合/分离数据，来预测结果。<br>其中包括了两大问题：  <ul><li><strong>回归</strong>（Regression）<br>给算法做一个数据集，包含正确答案，（比如房价-年），用线性/非线性回归方程拟合数据,预测数据。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131124639.png" alt=""></li><li><strong>分类问题</strong>（<strong>逻辑回归</strong>问题）（Classification/Logical regression）<br>用实数对出现的可能状况分类<br>（比如：1和0表示患乳腺癌/不患乳腺癌 ；1表示患乳腺癌A，2表示患乳腺癌B，0表示不患乳腺癌），在多维坐标系中（每一个维度表示不同的属性），然后用线性或非线性的函数将不同类的数据分开。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131124726.png" alt=""></li></ul></li><li><strong>无监督学习</strong>（Unsupervised）<br>计算机自己学习，经典的算法分为两大类：    <ul><li><strong>聚类算法</strong><br>对并不明确分类的数据集，计算机根据数据特征自动将数据分为几个簇<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210131124803.png" alt=""></li><li><strong>鸡尾酒会算法</strong>（Cocktail party）<br>略，这里只对鸡尾酒会问题和解决方法作一个概述：<br>鸡尾酒会问题是在计算机语音识别 领域的一个问题。<br>当前语音识别技术已经可以以较高精度识别一个人所讲的话，但是当说话的人数为两人或者多人时，语音识别率就会极大的降低，这一难题被称为鸡尾酒会问题。<br>对于的给定混合信号，分离出鸡尾酒会中 同时说话的每个人的独立信号。<br>鸡尾酒问题的解决方法是把两个收音器分别放在两个人的附近，每个收音器且与两个人的距离是不等距的，如此来分离两个人的声音。</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>机器学习基础课程——吴恩达</category>
      
      <category>01. 线性回归</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>Hexo搭建博客记录</title>
    <link href="/2021/02/20/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/hexo%E5%8D%9A%E5%AE%A2%E7%97%9B%E7%82%B9/"/>
    <url>/2021/02/20/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/hexo%E5%8D%9A%E5%AE%A2%E7%97%9B%E7%82%B9/</url>
    
    <content type="html"><![CDATA[<h1 id="Hexo搭建博客记录"><a href="#Hexo搭建博客记录" class="headerlink" title="Hexo搭建博客记录"></a>Hexo搭建博客记录</h1><p>搭建这个博客前前后后花了大概一周左右的时间，基本上把能踩的雷全都踩过了，现在记录一下搭建过程中的问题和解决办法。</p><h2 id="Github-Pages-相关问题"><a href="#Github-Pages-相关问题" class="headerlink" title="Github Pages 相关问题"></a>Github Pages 相关问题</h2><h3 id="Github-Pages-无法创建页面-显示“Pages-build-faild”-但是没有任何报错信息"><a href="#Github-Pages-无法创建页面-显示“Pages-build-faild”-但是没有任何报错信息" class="headerlink" title="Github Pages 无法创建页面 显示“Pages build faild” 但是没有任何报错信息"></a>Github Pages 无法创建页面 显示“Pages build faild” 但是没有任何报错信息</h3><p>第一个遇到的问题是Github Pages 始终反馈无法创建（build）页面，反馈邮件当中没有任何关于错误的信息。<br>debug非常多次之后发现是由于Git 把所有的代码都同步到了项目里：<br>自己用的VS Code来写的博客。自己的VS Code里面本来就设置好了git，因此就直接用VS Code里面的git把项目里面所有的文件都提交上去了……<br>所以解决办法是不要用VS Code里面的git来提交代码，正确的做法是用git bash里的<code>hexo g</code>生成文件后，用<code>hexo d</code>提交。  </p><h3 id="Github-Pages-反馈邮件“You-are-attempting-to-use-a-Jekyll-theme-which-is-not-supported-by-GitHub-Pages-”"><a href="#Github-Pages-反馈邮件“You-are-attempting-to-use-a-Jekyll-theme-which-is-not-supported-by-GitHub-Pages-”" class="headerlink" title="Github Pages 反馈邮件“You are attempting to use a Jekyll theme, which is not supported by GitHub Pages.”"></a>Github Pages 反馈邮件“You are attempting to use a Jekyll theme, which is not supported by GitHub Pages.”</h3><p>本地build正常，但是同步到github pages后会收到来自github的邮件：   </p><blockquote><p>You are attempting to use a Jekyll theme, which is not supported by GitHub Pages. Please visit <a href="https://pages.github.com/themes/">https://pages.github.com/themes/</a> for a list of supported themes. If you are using the “theme” configuration variable for something other than a Jekyll theme, we recommend you rename this variable throughout your site. For more information, see <a href="https://help.github.com/en/articles/adding-a-jekyll-theme-to-your-github-pages-site">https://help.github.com/en/articles/adding-a-jekyll-theme-to-your-github-pages-site</a>.      </p></blockquote><p>这个问题是由更换主题时直接clone的主题，导致项目下面有两个repo造成的。<br>解决方法有两个：</p><ol><li>直接在主题的release页面中下载发布的压缩包，解压之后放theme里【推荐】</li><li>在git中使用submodule：<code>git submodule add url</code></li></ol><h3 id="Github-Pages-显示-404-“There-isn’t-a-GitHub-Pages-site-here-”"><a href="#Github-Pages-显示-404-“There-isn’t-a-GitHub-Pages-site-here-”" class="headerlink" title="Github Pages 显示 404 “There isn’t a GitHub Pages site here.”"></a>Github Pages 显示 404 “There isn’t a GitHub Pages site here.”</h3><p>这个问题是由Github 里博客对应的项目名称不是username.github.io造成的，解决方法是把项目的名字命名为username.github.io     </p><h3 id="Github-Pages-显示“The-custom-domain-for-your-GitHub-Pages-site-is-pointed-at-an-outdated-IP-address-You-must-update-your-site’s-DNS-records-if-you’d-like-it-to-be-available-via-your-custom-domain-”"><a href="#Github-Pages-显示“The-custom-domain-for-your-GitHub-Pages-site-is-pointed-at-an-outdated-IP-address-You-must-update-your-site’s-DNS-records-if-you’d-like-it-to-be-available-via-your-custom-domain-”" class="headerlink" title="Github Pages 显示“The custom domain for your GitHub Pages site is pointed at an outdated IP address. You must update your site’s DNS records if you’d like it to be available via your custom domain.”"></a>Github Pages 显示“The custom domain for your GitHub Pages site is pointed at an outdated IP address. You must update your site’s DNS records if you’d like it to be available via your custom domain.”</h3><p>原因是因为在云解析DNS控制台中没有加入github给的DNS或DNS已经失效。<br>解决方法是在[<a href="https://docs.github.com/en/github/working-with-github-pages/managing-a-custom-domain-for-your-github-pages-site]页面的">https://docs.github.com/en/github/working-with-github-pages/managing-a-custom-domain-for-your-github-pages-site]页面的</a><br>“6 To confirm that your DNS record configured correctly, use the dig command, replacing EXAMPLE.COM with your apex domain. Confirm that the results match the IP addresses for GitHub Pages above. “中找到github提供的DNS，然后加入到云解析DNS控制台的解析记录中。<br>同时还要删除很多教程中提到的用<code>ping username.github.io</code>ping出来的ip地址。  </p><h3 id="Github-Pages-显示“Domain’s-DNS-record-could-not-be-retrieved-”"><a href="#Github-Pages-显示“Domain’s-DNS-record-could-not-be-retrieved-”" class="headerlink" title="Github Pages 显示“Domain’s DNS record could not be retrieved.”"></a>Github Pages 显示“Domain’s DNS record could not be retrieved.”</h3><p>原因是网站的解析设置有问题造成的，在解析控制台中的解析记录要注意解析类型和主机记录的对应关系：<br>A类对应@，CNAME对应www或者别的。<br>还有可能是项目中的CNAME文件和github settings中custom domain设置的域名前面加了www.等其他东西。<br>同时解析线路一定要选择默认。    </p><h2 id="博客访问问题"><a href="#博客访问问题" class="headerlink" title="博客访问问题"></a>博客访问问题</h2><h3 id="无梯访问username-github-io-显示“已拒绝连接”"><a href="#无梯访问username-github-io-显示“已拒绝连接”" class="headerlink" title="无梯访问username.github.io 显示“已拒绝连接”"></a>无梯访问username.github.io 显示“已拒绝连接”</h3><p>解决办法是更换为自己的域名，可以在阿里云，腾讯云之类的地方购买自己的域名，然后在github上对应项目的设置中Custom domain一项中填写自己买的域名（前面不要加www.之类的，就是纯域名）。<br>同时解析线路一定要选择默认。   </p><h3 id="访问博客显示“连接已关闭”"><a href="#访问博客显示“连接已关闭”" class="headerlink" title="访问博客显示“连接已关闭”"></a>访问博客显示“连接已关闭”</h3><p>通常是由于github pages在build和分发的过程中出错导致的，要去github上对应的项目的设置中看github pages的报错信息，具体问题具体分析。  </p><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><h3 id="git-频繁要求输入邮箱和用户名"><a href="#git-频繁要求输入邮箱和用户名" class="headerlink" title="git 频繁要求输入邮箱和用户名"></a>git 频繁要求输入邮箱和用户名</h3><p>  这个问题是由于_config.yml末尾的deploy: repo:中设置的是https网址导致的<br>  正确的填写方法是用SSH链接：<br>  <figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs JAVA">deploy:<br>type: <span class="hljs-string">&#x27;git&#x27;</span><br>repo: git<span class="hljs-meta">@github</span>.com:username/username.github.io.git<br>branch: master<br></code></pre></div></td></tr></table></figure></p><h3 id="博客中的LaTeX-MathJaX公式显示混乱"><a href="#博客中的LaTeX-MathJaX公式显示混乱" class="headerlink" title="博客中的LaTeX/MathJaX公式显示混乱"></a>博客中的LaTeX/MathJaX公式显示混乱</h3><p>这个是由于renderer-marked的转义与markdown本身出现了冲突所造成的。<br>解决方法：  </p><ol><li>卸载原来的公式渲染引擎改用kramed<figure class="highlight bash"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs bash">npm uninstall hexo-renderer-marked --save<br>npm install hexo-renderer-kramed --save<br></code></pre></div></td></tr></table></figure></li><li>然后在node_modules\kramed\lib\rules\inline.js目录下把第11行的escape变量的值做相应的修改： <figure class="highlight"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//  escape: /^\\([\\`*&#123;&#125;\[\]()#$+\-.!_&gt;])/,</span><br>escape: /^\\([`*\[\]()#$+\-.!_&gt;])/<br></code></pre></div></td></tr></table></figure> 这一步是在原基础上取消了对\,{,}的转义(escape)。<br> 同时把第20行的em变量也要做相应的修改。    <figure class="highlight java"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs java"><span class="hljs-comment">//  em: /^\b_((?:__|[\s\S])+?)_\b|^\*((?:\*\*|[\s\S])+?)\*(?!\*)/,</span><br>em: /^\*((?:\*\*|[\s\S])+?)\*(?!\*)/<br></code></pre></div></td></tr></table></figure></li><li>执行<code>hexo clean</code>再用<code>hexo g</code>重新生成</li></ol><h3 id="页面中的LaTeX-MathJaX矩阵无法换行，只有一列"><a href="#页面中的LaTeX-MathJaX矩阵无法换行，只有一列" class="headerlink" title="页面中的LaTeX/MathJaX矩阵无法换行，只有一列"></a>页面中的LaTeX/MathJaX矩阵无法换行，只有一列</h3><ol><li>行内矩阵不能用<code>\begin&#123;matrix&#125;</code>，要用<code>\begin&#123;smallmatrix&#125;</code>，括号用<code>\left[</code>和<code>\right]</code>表示</li><li>由于渲染问题，换行符<code>\\</code>要改为<code>\\\</code> 同时注意前后都要空格</li></ol><h3 id="页面中的表格无法显示"><a href="#页面中的表格无法显示" class="headerlink" title="页面中的表格无法显示"></a>页面中的表格无法显示</h3><p>这是由于mathjax不支持markdown中的表格语法造成的，正确的写法是用数组array代替:<br><figure class="highlight livescript"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs livescript">$$<br><span class="hljs-string">\begin&#123;array&#125;&#123;c|lcr&#125;</span><br>n &amp; <span class="hljs-string">\text&#123;Left&#125;</span> &amp; <span class="hljs-string">\text&#123;Center&#125;</span> &amp; <span class="hljs-string">\text&#123;Right&#125;</span> <span class="hljs-string">\\</span><br><span class="hljs-string">\hline</span><br><span class="hljs-number">1</span> &amp; <span class="hljs-number">0.24</span> &amp; <span class="hljs-number">1</span> &amp; <span class="hljs-number">125</span> <span class="hljs-string">\\</span><br><span class="hljs-number">2</span> &amp; -<span class="hljs-number">1</span> &amp; <span class="hljs-number">189</span> &amp; -<span class="hljs-number">8</span> <span class="hljs-string">\\</span><br><span class="hljs-number">3</span> &amp; -<span class="hljs-number">20</span> &amp; <span class="hljs-number">2000</span> &amp; <span class="hljs-number">1</span>+<span class="hljs-number">10i</span><br><span class="hljs-string">\end&#123;array&#125;</span><br>$$<br></code></pre></div></td></tr></table></figure></p>]]></content>
    
    
    <categories>
      
      <category>技术杂谈</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>7. 总结</title>
    <link href="/2021/01/30/Machine%20Learning-NAU/7.%20%E6%80%BB%E7%BB%93/"/>
    <url>/2021/01/30/Machine%20Learning-NAU/7.%20%E6%80%BB%E7%BB%93/</url>
    
    <content type="html"><![CDATA[<h1 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h1><ol><li>分类是将标签赋予给输入图像的过程。</li><li>选择特征是一门艺术。   </li><li>选择好的特征能够让分类器更好的工作。（有些分类器需要很长的工作时间。）</li><li>用测试集对分类器进行性能评估是重要的一步。   </li></ol>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 大作业-创建一个交通标志分类器</title>
    <link href="/2021/01/29/Machine%20Learning-NAU/6.%20%E6%9C%80%E5%90%8E%E5%A4%A7%E4%BD%9C%E4%B8%9A/"/>
    <url>/2021/01/29/Machine%20Learning-NAU/6.%20%E6%9C%80%E5%90%8E%E5%A4%A7%E4%BD%9C%E4%B8%9A/</url>
    
    <content type="html"><![CDATA[<h1 id="Traffic-Sign-Recognition"><a href="#Traffic-Sign-Recognition" class="headerlink" title="Traffic Sign Recognition"></a>Traffic Sign Recognition</h1><p>Traffic-sign recognition (TSR) is a technology by which a vehicle is able to recognize the traffic signs<br>put on the road e.g. “speed limit” or “children” or “turn ahead”. This is a very important technology<br>in self-driving cars.<br>This project will give you the chance to train different models using various features to classify traffic<br>signs.<br>The project is divided into 3 difficulty levels. Beginner, Expert and Bonus.   </p><h2 id="Beginner-Level"><a href="#Beginner-Level" class="headerlink" title="Beginner Level"></a>Beginner Level</h2><p>For this level we use the Chinese Traffic Sign Database (Traffic Sign Recogntion Database (ia.ac.cn)).<br>This is available as a zip file in your project folder under the name “Dataset_1.zip”.<br>This dataset consists of 5998 images belonging to 58 classes. Each image is named “XXX_yyyy.png”.<br>Here XXX represent the class (traffic sign type) and yyyy represents the image number within each<br>class.<br>For the beginner level, we make use of the “starter.py” code, which you can find in the project<br>directory.<br>Follow along with the tasks and fill in the blanks of the given code to complete beginner level.<br>Follow the tasks with “starter.py” and fill in the missing code for each section.</p><h3 id="T1-Reading-images"><a href="#T1-Reading-images" class="headerlink" title="T1: Reading images."></a>T1: Reading images.</h3><ul><li>Change the dataset_path to point to the unzipped Dataset_1/images folder in your<br>computer.</li><li>The given loop will go through all the files in the folder, variable i gives each file name.</li><li>Complete the code to read the images and append them to list X</li><li>The labels for each image has been already appended to list y for you<br>At the end of T1, you should have X, y with 5998 entries on each.<h3 id="T2-Pre-processing-images"><a href="#T2-Pre-processing-images" class="headerlink" title="T2: Pre-processing images."></a>T2: Pre-processing images.</h3></li><li>Given loop will go through all images in X and resize them to 48x48 pixels.</li><li>Complete the code to convert the images to grayscale. (Hint: use the cvtColor function in<br>opencv)</li><li>Complete the code to append the pre-processed images to X_processed list.<br>At the end of T2, you should have X_processed with 5998 entires of resized and grayscale images.<br>T3: Calculating Features and Splitting train/test sets.</li><li>Install skimage using anaconda. (you can follow the same instructions given for installing<br>sklearn with the package name “scikit-image”)</li><li>The given code will use skimage and extract hog features for you.</li><li>Write code to split X_features and y into training and testing sets. Make use of the<br>“sklearn.model_selection.train_test_split” to do this. Use a 80-20 split and make sure to<br>shuffle the samples.<br>At the end of T3, you should have x_train, x_test, y_train and y_test. Training sets should have 4798<br>samples and the test sets should have 1200 samples.<br>T4: Training and testing the classifier.</li><li>Use the sklearn SVM package to train a classifier using x_train and y_train.</li><li>Use the x_test and y_test to evaluate the classifier and print the accuracy value.<h2 id="Expert-Level"><a href="#Expert-Level" class="headerlink" title="Expert Level:"></a>Expert Level:</h2>We will build upon the beginner level code to try out different techniques and improve our model.<br>The same dataset will be used here.<br>Complete the following tasks,<h3 id="T1-Different-pre-processing-techniques"><a href="#T1-Different-pre-processing-techniques" class="headerlink" title="T1: Different pre-processing techniques"></a>T1: Different pre-processing techniques</h3>What are other pre-processing steps you can use?<br>Examples: Keep 3 channels (RGB), add a gaussian blur to reduce noise, etc.<br>Try few other pre-processing techniques and evaluate how they affect accuracy<h3 id="T2-Different-features"><a href="#T2-Different-features" class="headerlink" title="T2: Different features"></a>T2: Different features</h3>What are other feature extraction methods you can use?<br>Explore some other feature extraction methods given in skimage (Module: feature —<br>skimage v0.19.0.dev0 docs (scikit-image.org))<br>Try few other feature extraction methods and evaluate how they affect accuracy, you can<br>also try different packages here (no need to stick with skimage)<h3 id="T3-Different-Classification-Models"><a href="#T3-Different-Classification-Models" class="headerlink" title="T3: Different Classification Models"></a>T3: Different Classification Models</h3>What are other classification models you can use?<br>Try other classifiers including but not limited to; RandomForrest, kNN and Decision Tree.<br>For each classifier, change parameters and evaluate how the parameters affect accuracy.<h2 id="Bonus-Level"><a href="#Bonus-Level" class="headerlink" title="Bonus Level"></a>Bonus Level</h2>This level is for you to apply what you learned to a more challenging dataset from scratch. The<br>dataset is, German Traffic Sign Recognition Benchmark (GTSRB) (German Traffic Sign Benchmarks<br>(rub.de)). This is available in the “Dataset_2.zip” file.<br>This dataset is already split into training and testing sets for you.<h3 id="Task"><a href="#Task" class="headerlink" title="Task"></a>Task</h3>Write a python program to load the images from this dataset, into X, y. Then do suitable preprocessing, feature extraction and model training to develop a Traffic Sign Recognition system.<br>Report on the methods used and the results obtained by your Traffic Sign Recognition system.</li></ul><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">from</span> cv2 <span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><span class="hljs-keyword">from</span> skimage.feature <span class="hljs-keyword">import</span> hog<br><span class="hljs-keyword">from</span> skimage.feature <span class="hljs-keyword">import</span> canny<br><span class="hljs-keyword">from</span> skimage.feature <span class="hljs-keyword">import</span> local_binary_pattern<br><br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm<br><span class="hljs-keyword">import</span> sklearn.naive_bayes <span class="hljs-keyword">as</span> sk_bayes<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><br><span class="hljs-keyword">import</span> datetime<br><br><span class="hljs-comment"># load the dataset</span><br>dataset_path = <span class="hljs-string">&quot;Dataset_1\\images\\&quot;</span><br>X = []  <span class="hljs-comment"># 图像集</span><br>y = []  <span class="hljs-comment"># 标签集</span><br>print(<span class="hljs-string">&quot;Loading from the dataset...&quot;</span>)<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> glob.glob(dataset_path + <span class="hljs-string">&#x27;*.png&#x27;</span>, recursive=<span class="hljs-literal">True</span>):<br>    label = i.split(<span class="hljs-string">&quot;images&quot;</span>)[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>:<span class="hljs-number">4</span>]  <span class="hljs-comment"># 根据文件名开头划分标签</span><br>    y.append(label)<br>    img = cv2.imread(i)<br>    X.append(img)  <span class="hljs-comment"># 加载图像</span><br><br><span class="hljs-comment"># Preprocess</span><br>x_prossessed = []<br>print(<span class="hljs-string">&quot;Preprocessing the images...&quot;</span>)<br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> X:<br>    x = cv2.imread(x)<br>    temp_x = cv2.resize(x, (<span class="hljs-number">48</span>, <span class="hljs-number">48</span>))<br>    <span class="hljs-comment"># 图像处理部分，给出了如下三种图像处理的方式，可以组合，也可以单独使用，不需要的直接注释掉然后append（36行）对应的结果就行</span><br>    <span class="hljs-comment"># convert to gray 转换为灰度图</span><br>    x_process_gray = cv2.cvtColor(temp_x, cv2.COLOR_BGR2GRAY)<br>    <span class="hljs-comment"># gave the gaussian blur 高斯滤波</span><br>    x_process_gau = cv2.GaussianBlur(x_process_gray, (<span class="hljs-number">5</span>, <span class="hljs-number">5</span>), <span class="hljs-number">0</span>)<br>    <span class="hljs-comment"># gave the medianBlur 中值滤波</span><br>    x_process_md = cv2.medianBlur(x_process_gau, <span class="hljs-number">3</span>)<br>    x_prossessed.append(x_process_md)<br><br><span class="hljs-comment"># calculate features</span><br><span class="hljs-comment"># 提取特征，给出了下面的三种方法，三选一，选一个取消注释。</span><br>X_features = []<br>print(<span class="hljs-string">&quot;Calculating features...&quot;</span>)<br><span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> x_prossessed:<br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    # Hog features : 提取图像的直方图信息</span><br><span class="hljs-string">    x_feature_hog = hog(x,</span><br><span class="hljs-string">                    orientations=8,</span><br><span class="hljs-string">                    pixels_per_cell=(10, 10),</span><br><span class="hljs-string">                    cells_per_block=(1, 1),</span><br><span class="hljs-string">                    visualize=False,</span><br><span class="hljs-string">                    multichannel=False)</span><br><span class="hljs-string">    X_features.append(x_feature_hog)</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>    <span class="hljs-string">&#x27;&#x27;&#x27;</span><br><span class="hljs-string">    # canny features： 提取图像的边缘特征</span><br><span class="hljs-string">    x_feature_canny = canny(np.array(x), sigma=1.0)</span><br><span class="hljs-string">    X_features.append(x_feature_canny)</span><br><span class="hljs-string">    &#x27;&#x27;&#x27;</span><br>   <br>    <span class="hljs-comment"># LBP features: 对光照有很强的鲁棒性</span><br>    x_feature_lbp = local_binary_pattern(x, <span class="hljs-number">8</span>, <span class="hljs-number">1.0</span>, method=<span class="hljs-string">&#x27;default&#x27;</span>)<br>    X_features.append(x_feature_lbp)<br>    <br><span class="hljs-comment"># 把X_features 转换为长向量</span><br>images = np.array(X_features).reshape((<span class="hljs-built_in">len</span>(np.array(X_features)), -<span class="hljs-number">1</span>))<br><br><span class="hljs-comment"># 划分训练集和测试集</span><br>print(<span class="hljs-string">&quot;Trainning the dataset...&quot;</span>)<br>x_train, x_test, y_train, y_test = train_test_split(images,<br>                                                    y,<br>                                                    test_size=<span class="hljs-number">0.2</span>,<br>                                                    shuffle=<span class="hljs-literal">True</span>)<br><br><span class="hljs-comment"># 分类器，下面给出了三种分类器</span><br>acc = []  <span class="hljs-comment"># 创建一个列表用于存放准确率</span><br>timecosts = []  <span class="hljs-comment"># 创建一个列表用于存放耗时</span><br><span class="hljs-comment"># 支持向量机分类器</span><br>print(<span class="hljs-string">&quot;Trainning by svm...&quot;</span>)<br>time1 = (datetime.datetime.now())  <span class="hljs-comment"># 第一个时间戳</span><br>clf1 = svm.SVC()<br>clf1.fit(x_train, y_train)  <span class="hljs-comment"># 数据拟合</span><br>time2 = (datetime.datetime.now())  <span class="hljs-comment"># 第二个时间戳</span><br>acc_svm = clf1.score(x_test, y_test)  <span class="hljs-comment"># 计算准确率</span><br>acc.append(acc_svm)<br>timecost = <span class="hljs-built_in">str</span>(time2 - time1)  <span class="hljs-comment"># 计算时间差</span><br>timecosts.append(timecost)<br><br><span class="hljs-comment"># 伯努利分布的朴素贝叶斯分类器</span><br>print(<span class="hljs-string">&quot;Trainning by BN...&quot;</span>)<br>time1 = (datetime.datetime.now())  <span class="hljs-comment"># 第一个时间戳</span><br>clf2 = sk_bayes.BernoulliNB(alpha=<span class="hljs-number">1.0</span>,<br>                            binarize=<span class="hljs-number">0.0</span>,<br>                            fit_prior=<span class="hljs-literal">True</span>,<br>                            class_prior=<span class="hljs-literal">None</span>)<br>clf2.fit(x_train, y_train)  <span class="hljs-comment"># 数据拟合</span><br>time2 = (datetime.datetime.now())  <span class="hljs-comment"># 第二个时间戳</span><br>acc_NB = clf2.score(x_test, y_test)  <span class="hljs-comment"># 计算准确率</span><br>acc.append(acc_NB)<br>timecost = <span class="hljs-built_in">str</span>(time2 - time1)  <span class="hljs-comment"># 计算时间差</span><br>timecosts.append(timecost)<br><br><span class="hljs-comment"># KNN分类器 k=1 (对于这个KNN，k越大，越不行)</span><br>print(<span class="hljs-string">&quot;Trainning by KNN...&quot;</span>)<br>time1 = (datetime.datetime.now())  <span class="hljs-comment"># 第一个时间戳</span><br>clf3 = KNeighborsClassifier(n_neighbors=<span class="hljs-number">1</span>)<br>clf3.fit(x_train, y_train)  <span class="hljs-comment"># 数据拟合</span><br>time2 = (datetime.datetime.now())  <span class="hljs-comment"># 第二个时间戳</span><br>acc_KNN = clf3.score(x_test, y_test)  <span class="hljs-comment"># 计算准确率</span><br>acc.append(acc_KNN)<br>timecost = <span class="hljs-built_in">str</span>(time2 - time1)  <span class="hljs-comment"># 计算时间差</span><br>timecosts.append(timecost)<br><br>clfname = [<span class="hljs-string">&#x27;SVM&#x27;</span>, <span class="hljs-string">&#x27;NB&#x27;</span>, <span class="hljs-string">&#x27;KNN&#x27;</span>]<br>print(<span class="hljs-string">&quot;---------result-------------&quot;</span>)<br>print(<span class="hljs-string">&quot;accurancy is:&quot;</span>)<br>print(clfname)  <span class="hljs-comment"># 输出分类器的名字</span><br>print(acc)  <span class="hljs-comment"># 输出准确率</span><br>print(<span class="hljs-string">&quot;timecost:&quot;</span>)<br>print(timecosts)<br><br>print(<span class="hljs-string">&quot;Displaying the Confusion Matrixes&quot;</span>)<br><span class="hljs-comment"># 显示混淆矩阵</span><br><span class="hljs-comment"># 混淆矩阵显示有点慢 但是三张都可以显示 【要关闭当前之后才能显示下一张】</span><br><span class="hljs-comment"># svm算法的混淆矩阵</span><br>print(<span class="hljs-string">&quot;cm of svm&quot;</span>)<br>cm1 = metrics.plot_confusion_matrix(clf1, x_test, y_test)  <span class="hljs-comment"># 创建混淆矩阵</span><br>plt.get_current_fig_manager().window.state(<span class="hljs-string">&#x27;zoomed&#x27;</span>)<br>plt.show()  <span class="hljs-comment"># 显示混淆矩阵</span><br><br><span class="hljs-comment"># BN算法的混淆矩阵</span><br>print(<span class="hljs-string">&quot;cm of bn&quot;</span>)<br>cm2 = metrics.plot_confusion_matrix(clf2, x_test, y_test)  <span class="hljs-comment"># 创建混淆矩阵</span><br>plt.get_current_fig_manager().window.state(<span class="hljs-string">&#x27;zoomed&#x27;</span>)<br>plt.show()  <span class="hljs-comment"># 显示混淆矩阵</span><br><br><span class="hljs-comment"># KNN的混淆矩阵</span><br>print(<span class="hljs-string">&quot;cm of knn&quot;</span>)<br>cm3 = metrics.plot_confusion_matrix(clf3, x_test, y_test)  <span class="hljs-comment"># 创建混淆矩阵</span><br>plt.get_current_fig_manager().window.state(<span class="hljs-string">&#x27;zoomed&#x27;</span>)<br>plt.show()  <span class="hljs-comment"># 显示混淆矩阵</span><br><br></code></pre></div></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>6. 人脸识别与感知机</title>
    <link href="/2021/01/29/Machine%20Learning-NAU/6.%20%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B8%8E%E6%84%9F%E7%9F%A5%E6%9C%BA/"/>
    <url>/2021/01/29/Machine%20Learning-NAU/6.%20%E4%BA%BA%E8%84%B8%E8%AF%86%E5%88%AB%E4%B8%8E%E6%84%9F%E7%9F%A5%E6%9C%BA/</url>
    
    <content type="html"><![CDATA[<h1 id="人脸识别与感知机"><a href="#人脸识别与感知机" class="headerlink" title="人脸识别与感知机"></a>人脸识别与感知机</h1><h2 id="早期人脸识别技术"><a href="#早期人脸识别技术" class="headerlink" title="早期人脸识别技术"></a>早期人脸识别技术</h2><p>最早的人脸识别技术由Sung Kah Kay (MIT), Henry Rowley (CMU)运用ANN识别得来，方法大致为：</p><ul><li>将有人脸图像分割为$20 × 20 px$的矩阵块</li><li>对每个块运用亮度矫正和直方图均衡</li><li>放入神经网络学习，检测每一个矩阵块是否为人脸，如果不是，则平移矩阵块，并不断缩小矩阵的大小，再次检测。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210223201717.png" alt="">   </li></ul><h3 id="Viola-Jones-人脸检测方法"><a href="#Viola-Jones-人脸检测方法" class="headerlink" title="Viola-Jones 人脸检测方法"></a>Viola-Jones 人脸检测方法</h3><p><strong>Viola-Jones 人脸检测方法</strong> （Viola Jones Face detection）是Paul viola 和 Michael J Jones共同提出的一种人脸检测框架。它极大的提高了人脸检测的速度和准确率。 目前的人脸识别设备大多采用这种方法。<br>这种方法主要提取了4类最基本的特征。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210223202823.png" alt=""><br>右图： 特征A主要是用于检测双眼，特征C主要用于检测额头的部位。   </p><ul><li>特征的加强与感知机<br>Viola-Jones 人脸检测方法使用了加强的特征，具体方法为：   <ol><li>称一个简单的分类器叫做<strong>单特征感知机</strong>（single-feature perceptron），对每一种特征都使用一种不同的单特征感知机，得到加权的一些数据，如果有K个特征，就要用K个不同的单特征感知机。  </li><li>对之前获得的数据进行加权。  </li><li>训练所有的K个单特征感知器。  </li><li>在此阶段选择一个最佳分类器。  </li><li>与先前选择的其他分类器组合。  </li><li>重新加权新得到的所有数据。</li><li>再次学习所有K个分类器，选择最佳分类器，合并，重新加权。</li><li>重复执行，直到选择了T个分类器。   </li></ol></li></ul><p>在当时，运用这种方法训练5k张人脸和9.5k张非人脸图像花费了一周的时间，最后的结果是一个38层的感知机，它提取了6060个特征。    </p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 特征</title>
    <link href="/2021/01/28/Machine%20Learning-NAU/5.%20%E7%89%B9%E5%BE%81/"/>
    <url>/2021/01/28/Machine%20Learning-NAU/5.%20%E7%89%B9%E5%BE%81/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 30%;<br>}</style></p><h1 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h1><h2 id="特征的选择"><a href="#特征的选择" class="headerlink" title="特征的选择"></a>特征的选择</h2><p>曾在第四讲中提到过特征的选择，特征的选取可以从颜色、形状、直方图等等来提取。<br>好的特征应该具有如下的性质：  </p><ul><li>计算简便</li><li>鲁棒性</li><li>储存小</li><li>好的区分度</li><li>更优的距离度量    <h3 id="NP-hard！"><a href="#NP-hard！" class="headerlink" title="NP hard！"></a>NP hard！</h3>尝试试所有的特征组合是一种在直觉上认为的简便方案，它是一种非确定性多项式(Non-Deterministic polynomial Hard，NP hard)问题，该问题在理论上能够用一种称为贪心算法(Greedy approach)的方法尝试解决：     <ul><li>对于F 个可能的特征，选择其中能给出最高准确率的一个特征X</li><li>对于剩下的 F-1个可能的特征，选择与特征X组合能够给出最高准确率的一个特征。</li><li>重复上述过程，直到选择出所有的特征。  </li></ul></li></ul><h3 id="PCA"><a href="#PCA" class="headerlink" title="PCA"></a>PCA</h3><p>主成分分析（Principal Component Analysis，PCA）是另一种选择出更好的一组特征的方法。<br>设$y ∈ R^k$是图像(或者上一级的特征向量)$x ∈ R^d$的特征向量，$k&lt;&lt;d$，有：   </p><script type="math/tex; mode=display">y=W^Tx</script><ul><li><p>$W$<br>$W$是一个$d × k$的正交矩阵，由x计算得到。<br>设均值矩阵$E[x]=0$,协方差矩阵$E[xx^T]=C_x$,如下是计算$W$的方法：<br>设回复向量（recovered vector）$x_r=Wy$,误差$ε =x-x_r=x-WW^Tx$,</p><script type="math/tex; mode=display">\begin{aligned}    |ϵ|^2 & = ϵ^Tϵ \\      & =(x-WW^TX)^T(X-WW^Tx) \\    & =x^Tx-x^TWW^Tx-x^TWW^Tx+x^TWW^TWW^Tx \\    & =x^Tx-x^TWW^Tx\end{aligned}</script><p>令$k=1$,此时$W$是一个向量:</p><script type="math/tex; mode=display">\begin{aligned}  E[ ϵ^Tϵ] & =E[x^Tx-x^Tww^Tx]\\  & =E[x^Tx]-W^TC_xW\end{aligned}</script><p>那么需要找到使得$E[ ϵ^Tϵ]$最小的$w$，这一步与求$max_w w^TC_xw$等价。<br>设$J=\frac{w^TC_xw}{W^TW}$以正规化W：<br>令$\frac{dJ}{dw}=0$，得到：</p><script type="math/tex; mode=display">\frac{2C_xw}{w^Tw}-[\frac{w^TC_xw}{w^Tw}]·\frac{2w}{w^Tw}=0</script><script type="math/tex; mode=display">C_xw=Jw</script><p>这个公式正好是协方差矩阵$C_x$的特征值方程公式，即:$w$为协方差矩阵$C_x$的特征向量，$J$是它的特征值。    </p><p>如果对$C_x$进行特征分解(Eigen composition),得到一组特征值，将特征值从大到小排序，从中选取k个最大的特征值所对应的特征向量，组成矩阵$W$。  </p><script type="math/tex; mode=display">W=[w_1 |w_2 |...|w_k]</script><p>w称为主成分，所有的主成分两两正交。<br>最终得到的PCA是：  </p><script type="math/tex; mode=display">y=W^T(x-E[x])</script><p>PCA将依据数据的分布，改变样本空间的坐标原点和坐标轴（表示原来的特征），并将所有的坐标轴变更为主成分，如图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210222144956.png" alt=""><br>y事实上是x的压缩集，改变后的y中的元素都是不相关的。   </p></li></ul><p>整个PCA过程中，k的选取十分的重要，通常k的选取遵循如下的规则：<br>记 $λ$是$C_x$特征分解后得到的从大到小特征值，有:    </p><script type="math/tex; mode=display">\frac{∑^kλ_i}{∑^dλ_i}≈90\%</script><p>即前k个特征值的和大约是总的特征值和的0.9左右。   </p><ul><li>案例<br>1990年 Turk 和 Pentland应用PCA算法对人脸图像进行处理，称为特征子脸技术。特征子脸技术的基本思想是：从统计的观点，寻找人脸图像分布的基本元素，即人脸图像样本集协方差矩阵的特征向量，以此近似地表征人脸图像。这些特征向量称为特征脸(Eigenface)。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210222150404.png" alt="">   </li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>5. 课后练习-使用更多的分类器</title>
    <link href="/2021/01/28/Machine%20Learning-NAU/5.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0-%E6%89%8B%E5%86%99%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/"/>
    <url>/2021/01/28/Machine%20Learning-NAU/5.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0-%E6%89%8B%E5%86%99%E5%AD%97%E7%AC%A6%E8%AF%86%E5%88%AB/</url>
    
    <content type="html"><![CDATA[<h1 id="课后练习-5"><a href="#课后练习-5" class="headerlink" title="课后练习 5"></a>课后练习 5</h1><h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks:"></a>Tasks:</h2><ul><li>Study k-Nearest Neighbours classifiers sklearn.neighbors.KNeighborsClassifier — scikit-learn<br>0.24.1 documentation (scikit-learn.org)</li><li>Study RandomForrest classifiers sklearn.ensemble.RandomForestClassifier — scikit-learn<br>0.24.1 documentation (scikit-learn.org)</li><li>Study Naïve Bayes classifiers 1.9. Naive Bayes — scikit-learn 0.24.1 documentation (scikitlearn.org)<h2 id="Programming-exercise"><a href="#Programming-exercise" class="headerlink" title="Programming exercise:"></a>Programming exercise:</h2>This tutorial will use the MNIST dataset which was explored in tutorial 3.<h3 id="Q1-Train-a-k-Nearest-Neighbours-classifier-for-handwritten-digit-recognition-with-MNIST-dataset"><a href="#Q1-Train-a-k-Nearest-Neighbours-classifier-for-handwritten-digit-recognition-with-MNIST-dataset" class="headerlink" title="Q1. Train a k-Nearest Neighbours classifier for handwritten digit recognition with MNIST dataset."></a>Q1. Train a k-Nearest Neighbours classifier for handwritten digit recognition with MNIST dataset.</h3>Try different parameter settings and study how the performance varies.</li><li>Plot the accuracy vs k while changing the number of neighbours (k) with values [1, 3, 5, 7, 9]<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.neighbors <span class="hljs-keyword">import</span> KNeighborsClassifier<br><br>digits = datasets.load_digits()<br>labels = digits.target<br><br>data = images.reshape(<span class="hljs-built_in">len</span>(images), -<span class="hljs-number">1</span>)<br>x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=<span class="hljs-number">0.2</span>, shuffle=<span class="hljs-literal">False</span>)<br>g = [<span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">5</span>, <span class="hljs-number">7</span>, <span class="hljs-number">9</span>]<br>accurancy = []<br><span class="hljs-keyword">for</span> g_ <span class="hljs-keyword">in</span> g:<br>    clf = KNeighborsClassifier(n_neighbors = g)<br>    clf.fit(x_train, y_train)<br>    acc = clf.predict(x_test, y_test)<br>    accurancy.append(acc)<br><br>plt.plot(g, accurancy)<br>plt.show()<br></code></pre></div></td></tr></table></figure><h3 id="Q2-Train-a-RandomForrest-classifier-for-handwritten-digit-recognition-with-MNIST-dataset"><a href="#Q2-Train-a-RandomForrest-classifier-for-handwritten-digit-recognition-with-MNIST-dataset" class="headerlink" title="Q2. Train a RandomForrest classifier for handwritten digit recognition with MNIST dataset."></a>Q2. Train a RandomForrest classifier for handwritten digit recognition with MNIST dataset.</h3>Try different parameter settings and study how the performance varies.</li><li>Plot the accuracy vs max_depth while changing the max depth parameter with values [1, 2, 4, 8, 16]<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForrest<br><br>digits = datasets.load_digits()<br>labels = digits.target<br><br>data = images.reshape(<span class="hljs-built_in">len</span>(images), -<span class="hljs-number">1</span>)<br>x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=<span class="hljs-number">0.2</span>, shuffle=<span class="hljs-literal">False</span>)<br>g = [<span class="hljs-number">1</span>, <span class="hljs-number">2</span>, <span class="hljs-number">4</span>, <span class="hljs-number">8</span>, <span class="hljs-number">16</span>]<br>accurancy = []<br><span class="hljs-keyword">for</span> g_ <span class="hljs-keyword">in</span> g:<br>    clf = RandomForrest(max_depth = g)<br>    clf.fit(x_train, y_train)<br>    acc = clf.predict(x_test, y_test)<br>    accurancy.append(acc)<br>plt.plot(g, accurancy)<br>plt.show()<br></code></pre></div></td></tr></table></figure><h3 id="Q3-Train-a-Gaussian-Naive-Bayes-classifier-for-handwritten-digit-recognition-with-the-MNIST-dataset"><a href="#Q3-Train-a-Gaussian-Naive-Bayes-classifier-for-handwritten-digit-recognition-with-the-MNIST-dataset" class="headerlink" title="Q3. Train a Gaussian Naive Bayes classifier for handwritten digit recognition with the MNIST dataset."></a>Q3. Train a Gaussian Naive Bayes classifier for handwritten digit recognition with the MNIST dataset.</h3><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn.ensemble <span class="hljs-keyword">import</span> RandomForrest<br><br>digits = datasets.load_digits()<br>labels = digits.target<br><br>data = images.reshape(<span class="hljs-built_in">len</span>(images), -<span class="hljs-number">1</span>)<br>x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=<span class="hljs-number">0.2</span>, shuffle=<span class="hljs-literal">False</span>)<br>clf1 = sk_bayes.BernoulliNB(alpha=<span class="hljs-number">1.0</span>,<br>                            binarize=<span class="hljs-number">0.0</span>,<br>                            fit_prior=<span class="hljs-literal">True</span>,<br>                            class_prior=<span class="hljs-literal">None</span>)<br>clf1.fit(x_train, y_train)  <br>acc_BN = clf1.score(x_test, y_test) <br>acc.append(acc_BN)<br></code></pre></div></td></tr></table></figure></li><li>Plus： Displaying the wrong images  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-comment"># 显示错误的图片</span><br>clf = RandomForrest(max_depth = g)<br>clf.fit(x_train, y_train)<br>predictions = clf.predict(x_test)<br><span class="hljs-comment"># clf.predict_proba() 显示每张图有多少概率是哪个标签</span><br>print(predictions) <span class="hljs-comment"># 这样会输出所有图片的预测标签</span><br>print(y_test)<br></code></pre></div></td></tr></table></figure><h3 id="Q4-Do-a-comparison-between-the-four-classifiers-SVM-–-Tutorial-3-kNN-RandomForrest-and-NaiveBayes-by-plotting-the-best-performing-accuracy-value-for-each-classifier-in-a-bar-chart"><a href="#Q4-Do-a-comparison-between-the-four-classifiers-SVM-–-Tutorial-3-kNN-RandomForrest-and-NaiveBayes-by-plotting-the-best-performing-accuracy-value-for-each-classifier-in-a-bar-chart" class="headerlink" title="Q4. Do a comparison between the four classifiers (SVM – Tutorial 3, kNN, RandomForrest and NaïveBayes) by plotting the best performing accuracy value for each classifier in a bar chart."></a>Q4. Do a comparison between the four classifiers (SVM – Tutorial 3, kNN, RandomForrest and NaïveBayes) by plotting the best performing accuracy value for each classifier in a bar chart.</h3></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. 课后练习-MNIST 手写训练集</title>
    <link href="/2021/01/27/Machine%20Learning-NAU/4.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0-MNIST/"/>
    <url>/2021/01/27/Machine%20Learning-NAU/4.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0-MNIST/</url>
    
    <content type="html"><![CDATA[<h1 id="课后练习3"><a href="#课后练习3" class="headerlink" title="课后练习3"></a>课后练习3</h1><h2 id="Tasks"><a href="#Tasks" class="headerlink" title="Tasks"></a>Tasks</h2><ol><li>Familiarize yourself with the MNIST dataset: MNIST handwritten digit database, Yann LeCun, Corinna Cortes and Chris Burges. [<a href="http://yann.lecun.com/exdb/mnist/">http://yann.lecun.com/exdb/mnist/</a>]  </li><li>Familiarize yourself with sklearn package: scikit-learn: machine learning in Python — scikitlearn 0.24.1 documentation [scikit-learn.org]  </li></ol><h2 id="Programming-exercise"><a href="#Programming-exercise" class="headerlink" title="Programming exercise"></a>Programming exercise</h2><h3 id="Q1-Use-the-fetch-openml-function-found-in-sklearn-datasets-to-load-the-mnist-784-dataset-into-python-This-will-load-X-and-y-variables-for-you"><a href="#Q1-Use-the-fetch-openml-function-found-in-sklearn-datasets-to-load-the-mnist-784-dataset-into-python-This-will-load-X-and-y-variables-for-you" class="headerlink" title="Q1. Use the fetch_openml function found in sklearn.datasets to load the mnist_784 dataset into python. This will load X and y variables for you."></a>Q1. Use the fetch_openml function found in sklearn.datasets to load the mnist_784 dataset into python. This will load X and y variables for you.</h3><ul><li>Print the dimensions of the variables returned by the function.</li><li>Write a python script to find how many distinct values are present in y?</li><li>Select one sample from X for each distinct y value.</li><li>Resize each sample to represent the 28x28 pixel image.</li><li>Display all the selected images in one diagram using subplots in matplotlib. The following<br>code gives you an example of how to do this,<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">fig = plt.figure()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>, <span class="hljs-number">11</span>):<br>fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, i)<br>plt.imshow(images[i])<br>plt.show()<br></code></pre></div></td></tr></table></figure>Solutions:<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> sklearn,datasets <span class="hljs-keyword">import</span> fetch_openml<br>images,labels = fetch_openml(<span class="hljs-string">&#x27;mnist_784&#x27;</span>,version=<span class="hljs-number">1</span>, return_x_y=true, as_frame=false)<br><span class="hljs-comment"># load 70000 28x28=784 handwriting images</span><br><span class="hljs-comment"># print(images.shape)</span><br><span class="hljs-comment">#&gt;&gt; (7000,784)</span><br></code></pre></div></td></tr></table></figure>or <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br>digits = datasets.load_digits() <span class="hljs-comment">#load the mnist dataset which already in sklearn</span><br>images = digits.images <span class="hljs-comment">#access  1797 8x8 images in mnist by print(images.shape)</span><br>labels = digits.target <span class="hljs-comment">#access 1797 labes </span><br><span class="hljs-comment"># print(images.shape)</span><br><span class="hljs-comment">#&gt;&gt; (1797,8,8)</span><br></code></pre></div></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br>digits = datasets.load_digits() <span class="hljs-comment">#load the mnist dataset which already in sklearn</span><br>images = digits.images <span class="hljs-comment">#access  1797 8x8 images in mnist by print(images.shape)</span><br>labels = digits.target <span class="hljs-comment">#access labels</span><br><br>np.unique(labels) <span class="hljs-comment"># summerize the labels</span><br>print(np.unique(labels).shape)<br><br>fig = plt.figure()<br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">10</span>):<br>    fig.add_subplot(<span class="hljs-number">2</span>, <span class="hljs-number">5</span>, i+<span class="hljs-number">1</span>) <span class="hljs-comment"># creat a batch of subplot with 2 rows 5 columns</span><br>    <span class="hljs-comment"># i means the position in the subplot</span><br>    plt.imshow(images[i])<br>plt.show() <span class="hljs-comment"># display the subplot</span><br></code></pre></div></td></tr></table></figure><h3 id="Q2-Use-sklearn-to-train-a-digit-classifier"><a href="#Q2-Use-sklearn-to-train-a-digit-classifier" class="headerlink" title="Q2. Use sklearn to train a digit classifier."></a>Q2. Use sklearn to train a digit classifier.</h3></li><li>Split the X and y into a training set and testing set of 80-20 split.</li><li>Train a Support Vector Machin (SVM) for classification of the digits using the training set.<br>The following code shows how to train a model using sklearn.<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">clf = svm.SVC()<br>clf.fit(x_train, y_train)<br></code></pre></div></td></tr></table></figure></li><li>Test the model using the test set.</li><li>Experiment with different parameter values for the SVM and see how it performs. Try<br>changing the gamma value to be [0.0001, 0.0005, 0.001, 0.005, 0.01]</li><li>Plot the accuracy value with respect to the change in gamma above.</li><li>Plot the confusion matrix<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">import</span> matplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> sklearn.model_selection <span class="hljs-keyword">import</span> train_test_split<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> svm<br><span class="hljs-keyword">from</span> sklearn <span class="hljs-keyword">import</span> metrics<br><br>digits = datasets.load_digits() <span class="hljs-comment"># load the mnist dataset which already in sklearn</span><br>data = digits.images <span class="hljs-comment"># access  1797 8x8 images in mnist, print(images.shape)</span><br>labels = digits.target <span class="hljs-comment"># access 1797 labels</span><br><br>images = data.reshape((<span class="hljs-built_in">len</span>(data),-<span class="hljs-number">1</span>)) <span class="hljs-comment"># reshaape the 8x8 matrixes into 64x1 vectors</span><br><br>x_train,x_test,y_train,y_test = train_test_split(images,labels, test_size = <span class="hljs-number">0.2</span>, shuffle = false) <span class="hljs-comment"># 20% will be test set</span><br><span class="hljs-comment"># x:images y:labels</span><br><br>clf = svm.SVC() <span class="hljs-comment"># create the svm classifier</span><br>clf.fit(x_train, y_train) <span class="hljs-comment"># fit the data  within vectors</span><br><br>acc = clf.score(x_test, y_test) <span class="hljs-comment"># do the test and retrun the accurancy</span><br>disp = metrics.plot_confusion_matrix(clf,x_test,y_test) <span class="hljs-comment"># add into confusion matrix</span><br>print(acc) <span class="hljs-comment"># print the accurancy</span><br>sklearn.metrics.ConfusionMatrixDisplay(disp) <span class="hljs-comment"># display the confusion matrix</span><br><br>g_ = [<span class="hljs-number">0.0001</span>,<span class="hljs-number">0.0005</span>,<span class="hljs-number">0.001</span>,<span class="hljs-number">0.005</span>,<span class="hljs-number">0.01</span>] <span class="hljs-comment"># list of gamma</span><br>scores = [] <span class="hljs-comment"># list of accurancy</span><br><span class="hljs-keyword">for</span> g <span class="hljs-keyword">in</span> g_:<br>    clf = svm.SVC(gamma = g) <span class="hljs-comment"># create the svm classifier,specify the gamma</span><br>    clf.fit(x_train, y_train) <span class="hljs-comment"># fit the data  within vectors</span><br><br>    acc = clf.score(x_test, y_test) <span class="hljs-comment"># do the test and retrun the accurancy</span><br>    scores.append(acc)<br><br><br><br>print(g_) <span class="hljs-comment"># print the accurancy</span><br>print(scores)<br><br>plt.plot(g_, scores)<br>plt.show()  <br></code></pre></div></td></tr></table></figure></li></ul><p>```</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>4. 分类器</title>
    <link href="/2021/01/27/Machine%20Learning-NAU/4.%20%E5%88%86%E7%B1%BB%E5%99%A8/"/>
    <url>/2021/01/27/Machine%20Learning-NAU/4.%20%E5%88%86%E7%B1%BB%E5%99%A8/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 30%;<br>}</style></p><h1 id="分类器"><a href="#分类器" class="headerlink" title="分类器"></a>分类器</h1><h2 id="分类器概述"><a href="#分类器概述" class="headerlink" title="分类器概述"></a>分类器概述</h2><p>设$S=\{ω_1,ω_2,..,ω_c\}$是表示所有特征标签ω的集合，x表示数据集空间$R^n$中的特征向量，定义：<strong>分类器</strong>（Classifier）是一种能够使$R^n→S$的函数$f$。分类器能够将特征标签（labels）指定到特征向量。  </p><ul><li>图像识别的基本流程<br>输入图像—&gt;预处理-&gt;获取特征-&gt;分类<h2 id="特征"><a href="#特征" class="headerlink" title="特征"></a>特征</h2><strong>特征</strong>(Features)是不同类别的数据具有的用于识别其自身的属性。在机器学习中，要想对数据集进行识别和分类就必须要提取数据集的特征。<br>特征的提取并不是越多越好，不相关的特征（称为噪声（Noise features））会降低识别的准确度；具有高相关性的特征（比如：长发和女性）会让模型出现过拟合（Generalization）和模型冗余之类的其他问题。  </li><li><p>决策边界<br><strong>决策边界</strong>（Decision boundary）是二元分类中能够依据特征的分布来分出两类的边界。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208145142.png" alt="">   </p></li><li><p>过拟合问题（Generalization）<br>如果一个模型虽然可以穿过所有的数据点，但是其图像波动很大，其同样也不能描述数据的分布，（其数据的分布是无法被泛化处理），称为过拟合，或者说这个算法具有高方差的特性。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208150529.png" alt=""></p></li></ul><h2 id="贝叶斯分类器"><a href="#贝叶斯分类器" class="headerlink" title="贝叶斯分类器"></a>贝叶斯分类器</h2><p><strong>贝叶斯分类器</strong>(Bayes’ classifier)被理论证明是目前最好的分类器。贝叶斯分类器依赖于模式识别(Pattern recognition)<br>想象如下的情形：我们已经测量了用于识别男女性别的特征，现在要根据这些特征来对一个未知的人判断其性别。如果你对其不做任何的测量，那么你是否还能进行分类？<br>₋答案是：如果我们知道男女性别的比例，比如男性/总的人群:$P{ω_1}=58.8%$。将频率视为概率，那么这个概率被称为<strong>先验概率</strong>（Prior probability），由于是男性的概率大于是女性的概率，因此我们将这个识别目标<strong>总是判断为概率最高的标签</strong>——即男性，那么我们判断其为男性的正确率为58.8%。<br>如何去优化这个正确率？——对识别目标进行观测：<br>假设已经观测到目标的特征$X$，对标签集$Ω$,计算所有的如果具有特性$x$,识别目标为标签$ω_i$的概率，并从中找到最大的条件概率，目标特征的标签$ω^*$即为最大的条件概率。用数学公式表达为：   </p><script type="math/tex; mode=display">ω^*=arg_{ω_i}~maxP(ω_i|x)</script><p>由计算得出的概率$P(ω_i|x)$称为<strong>后验概率</strong>(Posteriori)。<br>由贝叶斯公式：  </p><script type="math/tex; mode=display">P(A|B)=\frac{P(B|A)×P(A)}{P(B)}</script><p>那么后验概率可以转化为：</p><script type="math/tex; mode=display">P(ω_i|x)=\frac{P(x|ω_i)·P(ω_i)}{P(x)}</script><p>带入分类器公式：   </p><script type="math/tex; mode=display">ω^*=arg_{ω_i}~max\frac{P(x|ω_i)·P(ω_i)}{P(x)}</script><p>由于$P(x)$是一个常数，那么最大值函数可以被简化为求$P(x|ω_i)·P(ω_i)$的最大值：  </p><script type="math/tex; mode=display">ω^*=arg_{ω_i}~maxP(x|ω_i)·P(ω_i)</script><p>这就是贝叶斯分类器公式。    </p><ul><li><p>特殊情况<br>如果先验概率是均等的：</p><script type="math/tex; mode=display">P(ω_i)=P(ω_1)=...=P(ω_n)=C</script><p>那么分类器公式还能被简化为：  </p><script type="math/tex; mode=display">ω^*=arg_{ω_i}~maxP(x|ω_i)</script><p>称为最大可能公式（Maximunm Likelihood）。   </p><p>如果分类器中只有两个标签$ω_1,ω_2$:<br>那么设定：   </p><script type="math/tex; mode=display">g(x)=P(ω_1|x)-P(ω_2|x)</script><p>如果$g(x)&gt;0$则判断为$ω_1$,反之判断为另一类。$g(x)$称为判别函数（Discriminant function）。   </p></li><li><p>代价/损失（Cost）<br>设对于标签集$\{ω_1,ω_2,…,ω_c\}∈C$,$λ_{ij}$是分类器判断为$ω_i$但实际上的标签是$ω_j$所作出的<strong>代价</strong>（Cost）。<br>规定在$λ$中，当$i=j$时，$λ_{ij}=0$。<br>那么二元的贝叶斯分类器的代价函数为：   </p><script type="math/tex; mode=display">\frac{P(x|ω_1)}{P(x|ω_2)}>\frac{λ_{12}-λ_{22}}{λ_{21}-λ_{11}}·\frac{P(ω_2)}{P(ω_1)}.......ω_1</script><script type="math/tex; mode=display">\frac{P(x|ω_1)}{P(x|ω_2)}<\frac{λ_{12}-λ_{22}}{λ_{21}-λ_{11}}·\frac{P(ω_2)}{P(ω_1)}.......ω_2</script><p>如果$λ_{12}=λ_{21}=1$且$λ_{11}=λ_{22}=0$,称$P(x|ω_i)P(ω_i)$为MAP方程。</p></li></ul><blockquote><p>贝叶斯分类器被证明是理论上误差最小的分类器。     </p></blockquote><p>运用贝叶斯分类器需要知道在有特征$x$的条件下是分类标签$ω_i$的概率——$P(ω_i|x)$，称为可能性（Likelyhood）。在实际运用当中，一般是从数据集中估计这个概率（采用抽样检测等方法），这个估计出的概率通常是不准确的。<br>这个抽样检测的原则是：<strong>如果要创建一个D维（D是特征向量X的维度，即特征的数量）的直方图，一般而言至少需要$10^D$的训练样本。</strong></p><h2 id="朴素贝叶斯分类器"><a href="#朴素贝叶斯分类器" class="headerlink" title="朴素贝叶斯分类器"></a>朴素贝叶斯分类器</h2><p>解决贝叶斯分类器需要的训练样本数量大的问题的其中一个办法是假设所有的特征之间是独立的，根据概率论，有：</p><script type="math/tex; mode=display">P(XY)=P(X)P(Y)</script><p>假设特征向量$x=[x_1,x_2,…,x_D]^T$，有：</p><script type="math/tex; mode=display">ω^*=arg_{ω_j}~maxP(x|ω_j)P(ω_j)</script><script type="math/tex; mode=display">ω^*=arg_{ω_j}~maxP(ω_j)Π_{i=1}^DP(x_i|ω_j)</script><blockquote><p>在实际中，由于$P(x_i|ω_j)∈[0,1]$，因此$Π_{i=1}^DP(x_i|ω_j)$的乘积可能会下溢（非常趋近0）。因此对两边取log函数将乘法项目转为加法项防止下溢。   </p></blockquote><script type="math/tex; mode=display">ω^*=arg_{ω_j}~max~log[P(ω_j)]+∑_{i=1}^Dlog[P(x_i|ω_j)]</script><p>这种分类器公式称为朴素贝叶斯分类器（Naive Bayes）   </p><h2 id="K邻近算法"><a href="#K邻近算法" class="headerlink" title="K邻近算法"></a>K邻近算法</h2><p>K邻近算法（K-Nearest Neighbor,KNN）是一种不依赖概率而直接求得决策边界的办法。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210215095611.png" alt=""><br>如上图，设想现在样本空间内有两类样本，新加入一个x到样本空间内，设定$k=5$,计算x到样本空间内所有点的距离，最终取5个距离x最近的样本点，这五个样本点中哪一种类别的样本点多x就是哪一种类别。<br>通常情况下，标签数和K是都是奇数。<br>有数学证明在训练样本足够多的条件下， KNN的错误概率相比于贝叶斯更小。   </p><script type="math/tex; mode=display">P(error_{KNN})⪙P(error_{Bayes})</script><ul><li>距离度量（Distance Metrics）<br>设定距离度量函数$D(x,y)$,具有非负性、唯一性、和三角矢量性。   <script type="math/tex; mode=display">D_p(x,y)=(∑_{i=1}^n|x_i-y_i|^p)^{1/p}</script>x,y为向量。p称为范数（Norm）。<br>为了避免x，y的数值过于悬殊，人为地添加权重$w_i$，有：  <script type="math/tex; mode=display">D_p(x,y)=(∑_{i=1}^nw_i|x_i-y_i|^p)^{1/p}</script></li></ul><h2 id="其他分类器"><a href="#其他分类器" class="headerlink" title="其他分类器"></a>其他分类器</h2><ul><li>神经网络<br>神经网络是目前最热门的分类器方法，它模拟了神经元的传递过程，即输入信号——处理信号——接收信号。 </li><li>向量机（Support vector machine,SVM）<br>向量机的目的是为了找到一个线性的决策边界。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210215102440.png" alt="">  </li></ul><h2 id="性能评估"><a href="#性能评估" class="headerlink" title="性能评估"></a>性能评估</h2><p>现在要对一个分类器的效果进行评估，方法是用另一组数据集去测试分类器的性能。在实际运用中，通常把训练集划分为两部分：训练集和测试集。 测试集不会被训练。 将测试集放入分类器后，分类器得出的标签和测试集中的标签进行对比。   </p><h3 id="混淆矩阵"><a href="#混淆矩阵" class="headerlink" title="混淆矩阵"></a>混淆矩阵</h3><p>有如下将测试结果可视化的方法，称为<strong>混淆矩阵</strong>(Confusion matrix)方法：<br>将横轴作为实际的标签，纵轴作为预测的标签，每一格表示“实际为标签i/但是预测为标签j”的频率，做出矩阵，如下图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210217114634.png" alt=""><br>对角线上频率的总和即为训练集的正确率。<br>混淆矩阵能够容易的表现出分类器错误的分类情况。  </p><h3 id="交叉验证"><a href="#交叉验证" class="headerlink" title="交叉验证"></a>交叉验证</h3><p><strong>交叉验证</strong>（K-fold cross validation）能够最大程度的避免测试集发生的“偶然正确（称为福禄克测试，Fluke test）”，具体的做法是：<br>将数据集平均分为k份，取其中一份为测试集，剩下的为训练集。重复上述步骤直到每一份都被做过训练集。 最终分类器的准确率为所有测试的准确率的平均值。    </p><h3 id="错误类型与ROC曲线"><a href="#错误类型与ROC曲线" class="headerlink" title="错误类型与ROC曲线"></a>错误类型与ROC曲线</h3><ul><li><p>FRR<br>False Reject Rate， 表示目标正确却识别为错误的概率。   </p></li><li><p>FAR<br>False Accept Rate， 表示目标错误却识别为正确的概率。</p></li><li><p>FTE<br>Failure to Enroll Rate, 无法识别的概率。</p></li></ul><p>理想条件下，FRR和FAR都应该等于0。不断地改变分类器的阈值，将横轴为FAR,纵轴为1-FRR，作出<strong>ROC曲线</strong>(受试者工作特征曲线, Receiver operating characteristic curve)。这条曲线始终在y=x以上。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210217121830.png" alt=""><br>理想条件下，ROC曲线应该是一个L形状，即FAR=FRR=0。<br>ROC曲线围成的下夹面积，即AUC表示了系统的强壮性，AUC越大越好。<br>EER(Equal error rate)，也就是FPR=FNR的值，由于FNR=1-TPR，可以画一条从（0,1）到（1,0）的直线，找到直线与ROC曲线的交点。 交点越靠近(1,1)越好。</p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 图像处理</title>
    <link href="/2021/01/26/Machine%20Learning-NAU/3.%20%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/"/>
    <url>/2021/01/26/Machine%20Learning-NAU/3.%20%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 60%;<br>    padding-left: 30%;<br>}</style></p><h1 id="图像处理"><a href="#图像处理" class="headerlink" title="图像处理"></a>图像处理</h1><h2 id="成像原理与数字化"><a href="#成像原理与数字化" class="headerlink" title="成像原理与数字化"></a>成像原理与数字化</h2><ul><li>小孔成像（Pinhole）<br>小孔成像的基本原理如下图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207142920.png" alt="">    </li><li>透镜成像<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207143053.png" alt="">  </li><li><p>CCD/CMOS（电荷耦合）成像<br>在CCD成像当中，通过透镜后的像会呈现在CMOS上，COMS会将呈现数字化，这一过程中有两个重要的步骤：  </p><ol><li><strong>抽样</strong>（Sampling）<br>将图像转化为有限的单位像素，如图所示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207144301.png" alt="">    </li><li><strong>量化</strong>（Quantization）<br>用整数表示单位像素的值，对于8bit而言，单位像素的明暗程度以0~255的灰度值来表示，0表示黑色，255表示白色。  </li></ol><p>现在，一幅黑白的图像中的每一个单位像素点都用一个整数来表示其黑白的程度，那么整张图片就可以用一个只有整数的矩阵来表示（单通道）。<br>对于彩色的图像，通常以RGB（红色、绿色、蓝色）的三种程度（三通道）来进行量化，因此彩色图片的一个单位像素点以一个三维的向量，通常是$[R,G,B]$来表示。最终三个矩阵表示一幅彩色图像，这个过程叫做张量（Tensor）。  </p><h2 id="点处理-Point-Processing"><a href="#点处理-Point-Processing" class="headerlink" title="点处理(Point Processing)"></a>点处理(Point Processing)</h2><p>图像的点处理是： 设定图像上一个像素值$r(x,y)$,经过处理$s(x,y)=T(r(x,y))$后，得到同一位置的像素$s(x,y)$。<br>注意：</p></li></ul><ol><li>$(x,y)$表示坐标。</li><li>不同的图像处理库其坐标系统的原点设置不同，y的取值设定也不同。  </li><li>$T$只能是单调（通常是单调递增）的函数。<h3 id="常见的点处理变换"><a href="#常见的点处理变换" class="headerlink" title="常见的点处理变换"></a>常见的点处理变换</h3></li></ol><ul><li><p>阈值变换(Thresholding)<br>函数图像<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207152536.png" alt=""><br>阈值函数可分为两种：软阈值函数（左）和硬阈值函数/二值化函数(Hard thresholding/Binarization，右),它们的作用都是将像素转换成黑白像素。<br>图像中的$m$点称为阈值，高于阈值的像素将会被强化为近黑色/黑色的像素值，低于阈值的像素值将被弱化为近白色/白色的像素值。  </p></li><li><p>像素反转</p><script type="math/tex; mode=display">s=L-1-r</script><p>$L$表示最大的像素值。<br>作用是将像素值进行翻转，白色变为黑色，黑色变为白色。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207154347.png" alt="">  </p></li><li><p>对数变换  </p><script type="math/tex; mode=display">s=clog(1+r)</script><p>对数变换能够扩展低灰度值（突出过曝区域的细节）而压缩高灰度值（突出过暗区域的细节），从而增强图像的清晰度。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207154929.png" alt="">   </p></li><li><p>幂变换</p><script type="math/tex; mode=display">s=cr^γ</script><p>$γ$是幂指数，显示器中的伽玛校正(Gamma Correction)即调整该值使得显示器整体偏亮或偏暗。 当$0&lt;γ&lt;1$时，显示器偏暗，$γ&lt;1$时，显示器偏亮。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207155330.png" alt=""><br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207155454.png" alt="">   </p></li><li><p>折线(Piecewise Linear Curves)<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207155745.png" alt="">   </p></li></ul><h3 id="亮度直方图-Historgram"><a href="#亮度直方图-Historgram" class="headerlink" title="亮度直方图(Historgram)"></a>亮度直方图(Historgram)</h3><p>亮度直方图的横轴是像素值，纵轴是该像素值内的像素点个数，它反映了黑白图像整体的像素分布情况。<br>如果直方图在白色区域内比较集中，图像偏亮，直方图窄黑色区域内比较集中，图像偏暗。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207160828.png" alt=""><br>图像在直方图上的最大分布范围（即横轴的宽度）称为对比度(Contrast)，直方图窄的图像对比度低。通常情况下，对比度越高图像越清晰。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207160857.png" alt="">    </p><ul><li>直方图均衡(Historgram equalization)<br>直方图均衡是一种用于增强图像对比度的同时均衡图像亮度的方法（即拉宽和拖平直方图）。<br>直方图可以视为反映了每一个像素值在整个图像的占比关系（$\frac{n_w}{n}$，n表示图像像素点总数，$n_w$表示像素值为w的像素点数量），因此整个直方图可以被概率分布函数化：  <script type="math/tex; mode=display">p_r(w)=p(r=w)=\frac{n_w}{n},w=0,1,...,255</script>应用变换：  <script type="math/tex; mode=display">s=T(r)=(L-1)\int_0^rp_r(w)dw</script>使得:  <script type="math/tex; mode=display">P_s(s)=P_r(r)|\frac{dr}{ds}|=\frac{1}{L-1}</script><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207162034.png" alt=""><br>由于w并不是连续的，因此最终的直方图并非是完全扁平的矩形。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207164743.png" alt=""></li><li>局部增强(Local enhancement)<br>对局部的一些像素群（例如以某个像素为中心$9 × 9$或$3 × 3$的像素）应用直方图均衡的方法称为局部增强。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210207163241.png" alt="">   <h2 id="相邻处理（Neighborhood-Processing）"><a href="#相邻处理（Neighborhood-Processing）" class="headerlink" title="相邻处理（Neighborhood Processing）"></a>相邻处理（Neighborhood Processing）</h2>与点处理比较，虽然相邻处理的输入值仍然是一个像素值，但是输出值确实一个围绕输入像素值的像素集。（如下图所示）<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208124611.png" alt=""><br>常见的一些相邻处理的方法：  </li><li>均值滤波  </li><li>最值滤波  </li><li>中值滤波（像素值按大小排列，取排序位于中间位置的像素值作为中值滤波后的像素值）<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208124649.png" alt=""><br>▲上面的三张图依次是：原图（有一些细小噪点）、求平均、求中位数后的输出。  </li></ul><h3 id="滤波（Filtering）"><a href="#滤波（Filtering）" class="headerlink" title="滤波（Filtering）"></a>滤波（Filtering）</h3><p>滤波是一种应用于相邻处理的常见方法。<br>设以某个像素为中心的像素方阵称为<strong>核矩阵</strong>(Kernel/Mask matrix),以$W$记，核矩阵中的每一个像素值以$w(u,v)$表示。 将核矩阵照射至图像的某一区域$r$，使被照射区域中的像素值与对应的核矩阵中同位置的像素值一一相乘后全部相加，最后用一常数$C$调整，该过程被称为滤波。    </p><script type="math/tex; mode=display">s(x,y)=C∑_{(u,v)∈W}w(u,v)r(x+u,y+v)</script><p>整个过程可以用下图来表示：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208130628.png" alt=""><br>一次滤波结束后，核矩阵平移$α$个像素单位（称为<strong>步长</strong>(Padding)），照射图像的另一个区域，重复上述过程。    </p><ul><li><p>均值滤波<br>其核矩阵如下：   </p><script type="math/tex; mode=display">\frac{1}{n}×\begin{bmatrix} 1&1&...&1\\...&...&...&...\\ 1&1&...&1 \\ 1&1&...&1\end{bmatrix}</script><p>n表示方阵元素的数量。<br>这样最终的输出结果是取像素点周围领域的平均值作为响应输出，最终的图像会被模糊化。  </p></li><li><p>高斯滤波(Gaussian Filtering)<br>高斯滤波的核矩阵内的元素在三维上符合标准高斯/标准正态分布，且最高点在核矩阵中心处，如下图所示。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208131837.png" alt=""><br>其具体的计算公式为：  </p><script type="math/tex; mode=display">G(x,y)=\frac{1}{2πσ^2}e^{-\frac{x^2+y^2}{2σ^2}}</script><p>$σ$是标准高斯分布中的方差，$σ$较小时，图像的峰值窄且高。<br>例如当$σ=1.4$时，其核矩阵可以取：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208132110.png" alt=""><br>高斯滤波的作用是<strong>将图像模糊化</strong>，使图像呈现一种毛玻璃的质感。运用高斯滤波处理图像的方法又被称为<strong>高斯模糊</strong>(Gaussian Blurring)。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208132748.png" alt=""><br><strong>高斯模糊的重要作用是将图像中的噪点通过模糊化图像的方法移除。</strong></p></li></ul><h2 id="卷积"><a href="#卷积" class="headerlink" title="卷积"></a>卷积</h2><p><strong>卷积</strong>(Convolution)是一种常用于图像处理的方法。<br>设核矩阵(又被称为卷积核)的像素分布可以表示为$h$,原图的像素分布表示为$f$，卷积有如下公式：</p><script type="math/tex; mode=display">g(x)=\int_{-∞}^∞f(τ)h(x-τ)dτ</script><ul><li>卷积核的正则化<br>如果要使得图像的整体亮度在卷积前后不发生改变，卷积核必须被正则化，即卷积核内所有元素的和必须是1。</li></ul><h2 id="边缘检测"><a href="#边缘检测" class="headerlink" title="边缘检测"></a>边缘检测</h2><p>边缘（Edges）是图像中像素值变化急剧(Sharply)的部分，常见的边缘有如下图所示的四大类。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208134126.png" alt=""><br>边缘检测是以特殊的卷积核（称为算子（Operator））对图像进行处理。<br>常见的算子有如下几种：  </p><ul><li><p>Roberts算子<br>Roberts算子是两个能够强化图像的边缘部分的核矩阵：</p><script type="math/tex; mode=display">G_x=\begin{bmatrix}  +1&0\\0&-1   \end{bmatrix}</script><script type="math/tex; mode=display">G_y=\begin{bmatrix}  0&+1\\-1&0   \end{bmatrix}</script><p><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208133900.png" alt="">    </p></li><li><p>索伯算子(Sobel’s Operator)<br>Sobel算子的两个卷积核形式：  </p><script type="math/tex; mode=display">\begin{bmatrix} -1&0&+1\\-2&0&+2\\-1&0&+1 \end{bmatrix}</script><script type="math/tex; mode=display">\begin{bmatrix}+1&+2&+1\\0&0&0\\-1&-2&-1\end{bmatrix}</script><p>两个卷积核的特征是卷积核正中的纵列或行列为0，用于检测图像的纵向/横向边缘。<br>PIL或者是OpenCV中有对应的库可以执行Sobel边缘检测。<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208140605.png" alt="">    </p></li><li><p>拉普拉斯算子(Laplacian operator)<br>函数$F(x,y)$的梯度可由梯度公式得到：  </p><script type="math/tex; mode=display">G(x,y)=\frac{∂F(x,y)}{∂x}cos(σ)+\frac{∂F(x,y)}{∂y}sin(σ)</script><p>定义拉普拉斯算子（一阶）$▿f|(x_0,y_0)=(f_x(x_0,y_0),f_y(x_0,y_0))$，其二阶形式：</p><script type="math/tex; mode=display">▿^2f(x,y)=\frac{∂^2f(x,y)}{∂x^2}+\frac{∂^2f(x,y)}{∂y^2}</script><p>在x方向上可以近似由差分表示：  </p><script type="math/tex; mode=display">\frac{∂^2f(x,y)}{∂x^2}=f(x+1,y)+f(x-1,y)-2f(x,y)</script><p>在y方向上同理，最终得到二阶拉普拉斯算子的表达式：</p><script type="math/tex; mode=display">▿^2f(x,y)=f(x+1,y)+f(x-1,y)+f(x,y+1)+f(x,y-1)-4f(x,y)</script><p>得到拉普拉斯算子的卷积核形式：  </p><script type="math/tex; mode=display">\begin{bmatrix}  0&1&0\\1&-4&1\\0&1&0\end{bmatrix}</script></li><li><p>拉普拉斯-高斯算子（LoG operator）<br>由表达式：  </p><script type="math/tex; mode=display">▽^2g(x,y)=-\frac{1}{2πσ^4}(2-\frac{x^2+y^2}{σ^2})e^{-\frac{x^2+y^2}{2σ^2}}</script><p>所得到的算子的卷积核形式：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210208141000.png" alt="">   </p></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>3. 课后练习-图像处理</title>
    <link href="/2021/01/26/Machine%20Learning-NAU/3.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/"/>
    <url>/2021/01/26/Machine%20Learning-NAU/3.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<p><style><br>img{<br>    width: 40%;<br>    padding-left: 10%;<br>}</style></p><h1 id="课后练习2"><a href="#课后练习2" class="headerlink" title="课后练习2"></a>课后练习2</h1><p>Required libs:Numpy PIL Scipy Matplotlib cv2</p><h2 id="Q1-Write-a-python-script-to-open-the-“lena-png”-file-using-opencv"><a href="#Q1-Write-a-python-script-to-open-the-“lena-png”-file-using-opencv" class="headerlink" title="Q1. Write a python script to open the “lena.png” file using opencv."></a>Q1. Write a python script to open the “lena.png” file using opencv.</h2><ul><li>Display the opened image in a new window named “Display Lena”</li><li>Save the image to a new file named “lena_resaved.png”<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/lena.png" alt="">  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> cv2 <span class="hljs-keyword">as</span> cv<br>img = cv.imread(<span class="hljs-string">&quot;lena.png&quot;</span>) <span class="hljs-comment"># cv2.imread(&#x27;path&#x27;)  read the img</span><br>cv.imshow(<span class="hljs-string">&quot;Display Lena&quot;</span>,img) <span class="hljs-comment">#cv2.imshow(windowname,path)</span><br>cv.waitkey(<span class="hljs-number">0</span>) <span class="hljs-comment">#to let the window display until clicking/pressing</span><br>cv.imwrite(<span class="hljs-string">&quot;lena_resaved.png&quot;</span>,img) <span class="hljs-comment">#cv2.imwrite(filename,path,params)</span><br></code></pre></div></td></tr></table></figure><h2 id="Q2-Use-PIL-and-Matplotlib-libraries-for-Q2"><a href="#Q2-Use-PIL-and-Matplotlib-libraries-for-Q2" class="headerlink" title="Q2. Use PIL and Matplotlib libraries for Q2."></a>Q2. Use PIL and Matplotlib libraries for Q2.</h2>Use “lena.png” to perform following operations and save the images:  </li><li>Crop a section from the image whose vertices are (100,100), (100,400), (400,100), (400,400).<br>(hint: convert the cv2 image into PIL Image)  </li><li>Rotate the cropped image by 45 degrees counter-clockwise.</li><li>Perform histogram equalization on lena.png. (hint: use ImageOps.equalize from PIL)</li><li>Use matplotlib to plot the histogram figure for both original image and processed image.<br>(hint: use histogram() function in PIL)  </li><li>Perform Max Filtering, Min Filtering, and Median Filter on lena.png. (hint: PIL.ImageFilter)  </li><li>Perform Gaussian Blur with sigma equal to 3 and 5. (hint: PIL.ImageFilter)<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/bee.png" alt=""> <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> Image <br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageOps <br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageFilter <span class="hljs-keyword">as</span> <span class="hljs-built_in">filter</span><br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> pyplot <span class="hljs-keyword">as</span> plt  <br><br>pil_img=Image.<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;lena.png&quot;</span>) <span class="hljs-comment">#open img in pil </span><br><span class="hljs-comment">#(in cv2 lib, img is opened as array)</span><br><span class="hljs-comment"># load cv img: Image.fromarray()</span><br>pil_img.show() <span class="hljs-comment"># show the img</span><br>img_crop = pil_img.crop((<span class="hljs-number">100</span>,<span class="hljs-number">100</span>,<span class="hljs-number">300</span>,<span class="hljs-number">300</span>)) <span class="hljs-comment">#crop((start point,hight,width))</span><br>img_crop.show() <span class="hljs-comment">#show the img</span><br><br>img_rota = img_crop.rotate(<span class="hljs-number">45</span>) <span class="hljs-comment">#rotate(degree)</span><br>img_rota.show()<br><br>img_eql=ImageOps.equalize(pil_img) <br><span class="hljs-comment">#ImageOps.equalize(path) histogram equalize the imge</span><br><br>plt.plot(<span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,<span class="hljs-number">256</span>),img_eql.histogram()) <br><span class="hljs-comment">#pyplot(aix,img) plot someting   </span><br><span class="hljs-comment">#img.histogram()  return the histogram</span><br>plt.show()<br>plt.show(rang(<span class="hljs-number">0</span>,<span class="hljs-number">256</span>),pil_img.histogram())<br>plt.show()  <br><br>img_max = pil_img.<span class="hljs-built_in">filter</span>(<span class="hljs-built_in">filter</span>.maxfilter()) <br><span class="hljs-comment">#filter.(Imagefilter.parm()) add filters</span><br>img_max.show()<br><br>img_min=pil_img.<span class="hljs-built_in">filter</span>(<span class="hljs-built_in">filter</span>.minfilter())<br>img_min.show()<br><br>img_mid=pil_img.<span class="hljs-built_in">filter</span>(<span class="hljs-built_in">filter</span>.medianfilter())<br>img_mid.show()<br><br><br>img_gus3=pil_img.<span class="hljs-built_in">filter</span>(<span class="hljs-built_in">filter</span>.gaussianblur(radius=<span class="hljs-number">3</span>))<br>img_gus3.show()<br><br>img_gus10=pil_img.<span class="hljs-built_in">filter</span>(<span class="hljs-built_in">filter</span>.gaussianblur(radius=<span class="hljs-number">10</span>))<br>img_gus10.show()<br><br></code></pre></div></td></tr></table></figure><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210210191614.png" alt=""></li></ul><h2 id="Q3-Colour-space-conversion-Use-Python-OpenCV-functions-to-perform-following-operations-on"><a href="#Q3-Colour-space-conversion-Use-Python-OpenCV-functions-to-perform-following-operations-on" class="headerlink" title="Q3. Colour space conversion. Use Python OpenCV functions to perform following operations on"></a>Q3. Colour space conversion. Use Python OpenCV functions to perform following operations on</h2><p>“bee.png” and save the images at each step.</p><ul><li>Read the image.</li><li>Convert the image to HSV(<strong>Hu Satuation Value:包含了三个通道：单色(H)，饱和度(S)，灰度(V)</strong>) color space.</li><li>Perform histogram equalization on V channel by cv2.equalizeHist().</li><li>Convert the result image to BGR color space.</li><li>Show the image by cv2.imshow() and save the image.<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> cv2<br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageOps <br><span class="hljs-keyword">from</span> PIL <span class="hljs-keyword">import</span> ImageFilter <span class="hljs-keyword">as</span> <span class="hljs-built_in">filter</span><br><br>bee_img = cv2.imread(<span class="hljs-string">&quot;bee.png&quot;</span>)<br>bee_hsv = cv2.cvtColor(bee_img,cv2.COLOR_BGR2HSV)<br>bee_hsv.imshow()<br><br>bee_hsv[:,:,<span class="hljs-number">2</span>]= cv2.equalizeHist(bee_hsv[:,:,<span class="hljs-number">2</span>])<br><span class="hljs-comment"># 2 presents the channel 2: V</span><br>bee_rgb = cv2.cvtColor(bee_hsv,cv2.COLOR_HSV2BGR)<br>cv2.imshow(<span class="hljs-string">&quot;norm&quot;</span>,bee_rgb)<br><br>bee_img[:,:,<span class="hljs-number">2</span>]= cv2.equalizeHist(bee_rgb[:,:,<span class="hljs-number">2</span>])<br>bee_img = cv2.cvtColor(bee_hsv,cv2.COLOR_HSV2BGR)<br>cv2.imshow(<span class="hljs-string">&quot;rgb&quot;</span>,bee_img)<br></code></pre></div></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 数学方法</title>
    <link href="/2021/01/25/Machine%20Learning-NAU/2.%20%E6%95%B0%E5%AD%A6%E6%96%B9%E6%B3%95/"/>
    <url>/2021/01/25/Machine%20Learning-NAU/2.%20%E6%95%B0%E5%AD%A6%E6%96%B9%E6%B3%95/</url>
    
    <content type="html"><![CDATA[<h1 id="数学方法"><a href="#数学方法" class="headerlink" title="数学方法"></a>数学方法</h1><h2 id="矩阵的运算"><a href="#矩阵的运算" class="headerlink" title="矩阵的运算"></a>矩阵的运算</h2><h3 id="矩阵的乘法"><a href="#矩阵的乘法" class="headerlink" title="矩阵的乘法"></a>矩阵的乘法</h3><p>矩阵的乘法规则：前一矩阵的行乘后一矩阵的纵列若A是一个$m \times n$的矩阵，B是一个$a \times b$的矩阵，那么矩阵乘法$A \times B$的结果将会是一个$n \times a$的矩阵</p><blockquote><p>要注意$A × B=0 ⇏A=0 ~or~ B=0$<br>$AB \not ={} BA$,但是$(AB)C=A(BC)$</p></blockquote><p>矩阵与向量的乘法可以改写,用如下例子来做表示：<br>$A=\left[\begin{smallmatrix}<br>1 &amp; 2 &amp; 1 \\\ -1 &amp; 0 &amp; 2<br>\end{smallmatrix}\right] B=\left[\begin{smallmatrix}1 \\\ -1 \\\ 1\end{smallmatrix}\right]$<br>有$A\times B=1×\left[\begin{smallmatrix}1 \\\ -1\end{smallmatrix}\right]+(-1)×\left[\begin{smallmatrix}2 \\\ 0\end{smallmatrix}\right]+1\times \left[\begin{smallmatrix}1 \\\ 2\end{smallmatrix}\right]$<br>称B是A的一组线性组合</p><h3 id="转置、对称"><a href="#转置、对称" class="headerlink" title="转置、对称"></a>转置、对称</h3><p>$A^T$表示A的转置，即A行列交换后的矩阵。<br>有$(AB)^{T}=B^{T}A^{T}$<br>方阵：A为一个正方形矩阵:$m×m$<br>单位矩阵：\对角线上的元素为1，其余元素为0的方阵，有$AI=IA=A$<br>若$A^T=A$,称A是一个对称矩阵(Symmetric matrix)，若$A^T=-A$，称A是一个交错矩阵(Skew-symmectric matrix)</p><h3 id="矩阵的逆"><a href="#矩阵的逆" class="headerlink" title="矩阵的逆"></a>矩阵的逆</h3><p>有矩阵$A^{-1}A=I$,称矩阵$A^{-1}$为矩阵A的逆。奇异矩阵不可逆。运算规律：</p><ol><li>$(AB)^{-1}=B^{-1}A^{-1}$</li><li>$(A^T)^{-1}=(A^{-1})^{T}$</li><li>$(A^{-1})^{-1}=A$</li></ol><h3 id="矩阵方程的解法"><a href="#矩阵方程的解法" class="headerlink" title="矩阵方程的解法"></a>矩阵方程的解法</h3><p>对于任何一个线性方程组可以改写成：</p><script type="math/tex; mode=display">Ax=b</script><p>A是系数矩阵，x是参数向量，b是方程组右边组成的常数向量<br>解方程只需要求出$x=Ab$</p><ul><li>线性无关<br>如果A的列向量$a_1,a_2,a_3…a_n$的线性组合为0：</li></ul><script type="math/tex; mode=display">\sum λ_ia_i=0</script><p>称这些向量是线性无关的。<br>A中线性无关列向量的最大数目表示A的秩(Rank)<br>$Nul(A)$表示线性齐次方程$Ax=0$的解集，它的维度称为零度(Nullity)<br>如果 $RanK(A)+Nullity(A)=columns~of~A$，可以判断A是可逆的。</p><h3 id="正交-Orthogonal-Perpenticular"><a href="#正交-Orthogonal-Perpenticular" class="headerlink" title="正交(Orthogonal/Perpenticular)"></a>正交(Orthogonal/Perpenticular)</h3><p>两个向量$x,y$,如果$x^Ty=0$，称这两个向量是正交的。<br>如果一个向量集$b_1,b_2,b_3…b_n$中的任意两个元素 $b_i^Tb_j=\begin{cases}<br>1, i=j \\ 0, i \not =j<br>\end{cases}$<br>称这个向量集是标准正交集(Orthonormal)<br>若矩阵Q，$Q^TQ=I$称Q是正交的，它所有的列向量都是正交的</p><h3 id="行列式计算"><a href="#行列式计算" class="headerlink" title="行列式计算"></a>行列式计算</h3><p>det(A)或者|A|记作A的行列式,在Python中可以用numpy库中的函数进行运算。计算性质：</p><ol><li>$det(AB)=det(A)det(B)$</li><li>$det(A^{-1})=\frac{1}{det(A)}$<br>所以det(A)=0时，A不可逆</li><li>$det(A^T)=det(A)$</li><li>$det(kA)=k^ndet(A)$,$A_{n \times n}$</li><li>$det(A)=Πλ_i$</li></ol><h3 id="特征值-特征向量"><a href="#特征值-特征向量" class="headerlink" title="特征值/特征向量"></a>特征值/特征向量</h3><p>若有$Ax=λx$,λ称为A的特征值(Eigenvalue)，x称为A的特征向量(Eigenvector)</p><blockquote><p>特征值可能是一个复数，矩阵的特征向量/特征值可能有几个是相同的<br>$kλ$和$kx$仍然是A的特征值和特征向量，所以默认解出的特征向量的模长(Norm)为1。</p></blockquote><ul><li>求解特征值/特征向量<br>通过$det(A-λI)=0$，求解$λ$,再代回$Ax-λx=0$求解x</li><li><p>谱分解(Spectral Theorem)<br>A所有的特征值和特征向量可以写成一个矩阵方程：</p><script type="math/tex; mode=display">A \begin{bmatrix}  x_1&x_2&...&x_n\end{bmatrix}=\begin{bmatrix}  x_1&x_2&...&x_n\end{bmatrix}\begin{bmatrix}  λ_1 &&&&\\ &λ_2\\&&λ_3\\&&&...\end{bmatrix}</script><p>$\begin{bmatrix}<br>λ_1 &amp;&amp;&amp;&amp;\\ &amp;λ_2\\&amp;&amp;λ_3\\&amp;&amp;&amp;…<br>\end{bmatrix}$ 称为A的对角矩阵(Diagonal matrix)$Λ$<br>记作$AE=EΛ$<br>如果E是可逆矩阵，$A=EΛE^{-1}$<br>如果A是对称矩阵，有$E^{-1}=E^T$,$A=EΛE^T$<br>在机器学习中，A常常是对称的，而且所有的特征值都是实数</p></li></ul><h3 id="迹-Trace"><a href="#迹-Trace" class="headerlink" title="迹(Trace)"></a>迹(Trace)</h3><p>矩阵A的\对角线元素的总和称为A的迹：</p><script type="math/tex; mode=display">tr(A)=\sum a_{ii}</script><p>它在数值上也等于所有特征值的和：</p><script type="math/tex; mode=display">tr(A)=\sum λ_{i}</script><p>计算性质：</p><ol><li>$tr(AB)=tr(BA)$</li><li>$tr(A+B)=tr(A)+tr(B)$</li></ol><h3 id="伪逆矩阵-Pseudo-inverse"><a href="#伪逆矩阵-Pseudo-inverse" class="headerlink" title="伪逆矩阵(Pseudo-inverse)"></a>伪逆矩阵(Pseudo-inverse)</h3><p>当A不可逆时，要解决$Ax=b$,转写为$x=A^{-1}b$的形式求解x看似不可能，因此构造矩阵$A^{+}$,使得$x=A^{+}b,Ax-b$的模长最小，$A^+$称为A的伪逆矩阵。</p><script type="math/tex; mode=display">A^+=(A^TA)^{-1}A^T</script><script type="math/tex; mode=display">A^+A=(A^TA)^{-1}A^TA=I</script><script type="math/tex; mode=display">AA^+=A (A^TA)^{-1}A^T\not=I</script><p>在Python中<code>pinv(A)</code>可以实现求解伪逆矩阵</p><h3 id="矩阵的导数"><a href="#矩阵的导数" class="headerlink" title="矩阵的导数"></a>矩阵的导数</h3><p>矩阵的导数满足如下性质：</p><ol><li>$\frac{d}{dx}Ax=A^T$</li><li>$\frac{dx}{dx}=I$</li><li>$\frac{y^Tx}{dx}=\frac{dx^Ty}{dx}=y$</li><li>$\frac{d(x^TAx)}{dx}=\begin{cases}<br>(A+A^T)x,\text{A is square}\\2Ax,\text{A is symmetrix}<br>\end{cases}$</li><li>$\frac{d(u^T(x)~v(x))}{dx}=[\frac{du^T}{dx}]v+[\frac{dv^T}{dx}]u$</li><li>$\frac{d~tr(A)}{dA}=I$</li><li>$\frac{det(A)}{dA}=det(A)(A^{-1})^T$</li></ol><ul><li><p>伪逆矩阵证明当A为奇异矩阵时，求解$Ax=b$:定义误差(error)$e=Ax-b$，要使得$|e|$尽可能小：设$y=|e|^2$，有：</p><script type="math/tex; mode=display">\begin{aligned}  y & =e^Te \\  & =(Ax-b)^T(Ax-b) \\  & =(Ax)^T(Ax)-(Ax)^Tb-b^T(Ax)+b^Tb \\  & =x^TA^TAx-2b^T(Ax)+b^Tb \\\end{aligned}</script><p>对y求导：$\frac{dy}{dx}=2A^TAx-2A^Tb+0$</p><blockquote><p>第一项，$A^TA$是一个对称矩阵，可以应用#4.<br>第二项，应用#3<br>第三项，$b^Tb$是一个常数</p></blockquote><p>令$\frac{dy}{dx}=2A^TAx-2A^Tb=0$：</p><script type="math/tex; mode=display">A^TAx=A^Tb</script><script type="math/tex; mode=display">(A^TA)^{-1}A^Tb=A^+b</script></li></ul><p>在Python中，<code>linalg.solve(A,B)</code>能够求解$x=A^+b$     </p><h2 id="概率论的基础概念"><a href="#概率论的基础概念" class="headerlink" title="概率论的基础概念"></a>概率论的基础概念</h2><ul><li>随机变量<br>随机实验是一种能够产生随机结果的可重复性实验，样本空间$S$表示随机实验中所有可能出现的结果构成的集合，事件(Event)是样本空间S的子集。<br>随机变量(Random variables)是将S对应到实数集的一种函数，概率分布函数(MPF)表示X在样本空间中所发生的概率与X之间的关系。概率密度函数(PDF)表示样本空间中概率分布的稠密程度。    </li><li><p>常见的随机分布<br>*具体翻阅概率论笔记，此处不再赘述。<br>两点分布(Bernouli)<br>几何分布(Geometric)<br>二项分布(Binomial)<br>泊松分布(Poisson)<br>均匀分布(Uniform)<br>指数分布(Exponential)<br>双指数分布(Laplace/Double Exponential): $F(x)=\frac{λ}{2}e^{-λ|x|},λ&gt;0$<br>正态分布(Gaussian/Normal)  </p></li><li><p>其他分布函数概念<br>联合概率密度/联合分布函数(Joint PDF)<br>边缘分布函数(Marginal PDF)<br>条件概率函数(Conditional PDF)   </p></li></ul><h2 id="贝叶斯公式"><a href="#贝叶斯公式" class="headerlink" title="贝叶斯公式"></a>贝叶斯公式</h2><p>  全概率公式的逆公式，表示已知B事件发生的概率下，在A中某一个划分下发生的概率：</p><script type="math/tex; mode=display">P(A_i|B)=\frac{P(A_i)P(B|A_i)}{P(B)}=\frac{P(A_i)P(B|A_i)}{ΣP(A_i)P(B|A_i)}</script>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>2. 课后练习-数学方法</title>
    <link href="/2021/01/25/Machine%20Learning-NAU/2.%20a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/"/>
    <url>/2021/01/25/Machine%20Learning-NAU/2.%20a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="Math-Fundamentals-PDF"><a href="#Math-Fundamentals-PDF" class="headerlink" title="Math Fundamentals(PDF)"></a>Math Fundamentals(PDF)</h1><p><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/6059DD76E50982B30ABBD29933ACF908.png" alt=""><br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/Page1(1" alt="">.jpg)<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/EFA4476CFD3B735B19412D28A35D1BC5.png" alt="">     </p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 课后练习-机器学习简介和Python的基本操作</title>
    <link href="/2021/01/23/Machine%20Learning-NAU/1.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/"/>
    <url>/2021/01/23/Machine%20Learning-NAU/1.a%20%E8%AF%BE%E5%90%8E%E7%BB%83%E4%B9%A0/</url>
    
    <content type="html"><![CDATA[<h1 id="课后练习1"><a href="#课后练习1" class="headerlink" title="课后练习1"></a>课后练习1</h1><p>Solve the questions below by writing a Python function or script.   </p><h2 id="Q1-Add-up-the-numbers-from-100-to-200-and-output-their-sum-using-while-and-for-loops"><a href="#Q1-Add-up-the-numbers-from-100-to-200-and-output-their-sum-using-while-and-for-loops" class="headerlink" title="Q1. Add up the numbers from 100 to 200 and output their sum, using while and for loops."></a>Q1. Add up the numbers from 100 to 200 and output their sum, using while and for loops.</h2><p>for loop:<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">total = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">100</span>,<span class="hljs-number">201</span>): <span class="hljs-comment">#注意range不包括右边项</span><br>    total+=i<br>print(<span class="hljs-string">&quot;for loop sum:&quot;</span>,total)    <br></code></pre></div></td></tr></table></figure><br>while loop:<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">total=<span class="hljs-number">0</span><br>counter = <span class="hljs-number">100</span><br><span class="hljs-keyword">while</span> counter &lt; <span class="hljs-number">201</span>:<br>    total= total+counter <span class="hljs-comment">#++不能在python当中使用</span><br>    counter+=<span class="hljs-number">1</span> <span class="hljs-comment">#while 循环里面没有自增加</span><br>print(<span class="hljs-string">&#x27;for loop sum:&#x27;</span>,total)<br></code></pre></div></td></tr></table></figure></p><h2 id="Q2-Read-a-string-from-console-and-output-its-length-swap-its-cases（转换大小写）-convert-it-to-lower-case-and-upper-case-and-reverse-it-Hint-try-string-slice-with-step-1"><a href="#Q2-Read-a-string-from-console-and-output-its-length-swap-its-cases（转换大小写）-convert-it-to-lower-case-and-upper-case-and-reverse-it-Hint-try-string-slice-with-step-1" class="headerlink" title="Q2. Read a string from console and output its length, swap its cases（转换大小写）, convert it to lower case and upper case, and reverse it. (Hint: try string slice with step -1)"></a>Q2. Read a string from console and output its length, swap its cases（转换大小写）, convert it to lower case and upper case, and reverse it. (Hint: try string slice with step -1)</h2><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">s= <span class="hljs-built_in">input</span>(<span class="hljs-string">&quot;enter the string:&quot;</span>)<br>print(<span class="hljs-string">&quot;the length of the string:&quot;</span>,<span class="hljs-built_in">len</span>(s))<br><br>swap=<span class="hljs-built_in">str</span>.swapcase(s) <span class="hljs-comment">#str.swapcase() 转换大小写</span><br><br>print(<span class="hljs-string">&quot;swapcase is :&quot;</span>,swap)<br>print(<span class="hljs-string">&quot;lowercase:&quot;</span>,<span class="hljs-built_in">str</span>.lower(s)) <span class="hljs-comment">#str.lower/upper()</span><br>print(<span class="hljs-string">&quot;uppercase:&quot;</span>,<span class="hljs-built_in">str</span>.upper(s)) <br><br>print(<span class="hljs-string">&quot;reverse order:&quot;</span>,s[::-<span class="hljs-number">1</span>]) <span class="hljs-comment">#[起点:终点：步长]</span><br></code></pre></div></td></tr></table></figure><h2 id="Q3-Read-a-string-from-console-Split-the-string-on-space-delimiter-”-”-and-join-using-a-hyphen-”-”"><a href="#Q3-Read-a-string-from-console-Split-the-string-on-space-delimiter-”-”-and-join-using-a-hyphen-”-”" class="headerlink" title="Q3. Read a string from console. Split the string on space delimiter (” ”) and join using a hyphen (”-”)."></a>Q3. Read a string from console. Split the string on space delimiter (” ”) and join using a hyphen (”-”).</h2><p>(Example: input the string, ”this-is a string” and output as ”this is-a-string”)<br><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">s=<span class="hljs-string">&quot;hello world&quot;</span><br>print(<span class="hljs-string">&quot;replace:&quot;</span>,<span class="hljs-built_in">str</span>.replace(s,<span class="hljs-string">&quot;&quot;</span>,<span class="hljs-string">&quot;-&quot;</span>)) <span class="hljs-comment">#str.replace(string,&quot;&quot;,&quot;&quot;)交换前后元素</span><br></code></pre></div></td></tr></table></figure></p><h2 id="Q4-Learn-the-Python-list-operations-and-follow-the-commands-below"><a href="#Q4-Learn-the-Python-list-operations-and-follow-the-commands-below" class="headerlink" title="Q4. Learn the Python list operations and follow the commands below:"></a>Q4. Learn the Python list operations and follow the commands below:</h2><ul><li>Initialize an empty list L.  </li><li>Add 12, 8, 9 to the list.  </li><li>Insert 9 to the head of the list;  </li><li>Double the list. (e.g. change L = [1, 2, 3] to L = [1, 2, 3, 1, 2, 3])  </li><li>Remove all 8 in the list.  </li><li>Reverse the list.  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">L=[]<br>print(L)<br><br>L.append(<span class="hljs-number">12</span>) <span class="hljs-comment">#List.append() 列表在末尾添加</span><br>L.append(<span class="hljs-number">8</span>)<br>L.append(<span class="hljs-number">9</span>)<br>print(L)<br><br>L.insert(<span class="hljs-number">0</span>,<span class="hljs-number">9</span>) <span class="hljs-comment">#list.insert(position,element) 在列表的指定位置添加一个元素</span><br>L=[<span class="hljs-number">9</span>]+L <span class="hljs-comment">#另一种方式</span><br><br>L=L+L<br>print(L)<br>L=L*<span class="hljs-number">2</span> <span class="hljs-comment">#另一种方法</span><br>L=L.extend(L) <span class="hljs-comment">#list.extend(list) 在列表的末尾添加一个列表</span><br>print(L)   <br><br>number_eights=L.count(<span class="hljs-number">8</span>) <br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>,number_eight):<br>    L.remove(<span class="hljs-number">8</span>)  <span class="hljs-comment">#list.remove(element) 在列表中移除第一个【element】元素</span><br><span class="hljs-comment">#另一种解决办法</span><br><span class="hljs-keyword">while</span> <span class="hljs-number">8</span> <span class="hljs-keyword">in</span> L:<br>     L.remove(<span class="hljs-number">8</span>)<br><br>L.reverse() <span class="hljs-comment">#list.reverse() 列表内倒序</span><br>print(L)<br></code></pre></div></td></tr></table></figure><h1 id="Q5-Learn-Python-matrix-operations-by-completing-the-following-tasks"><a href="#Q5-Learn-Python-matrix-operations-by-completing-the-following-tasks" class="headerlink" title="Q5. Learn Python matrix operations by completing the following tasks:"></a>Q5. Learn Python matrix operations by completing the following tasks:</h1></li><li>Create a 3x2 matrix named A, with all ones.</li><li>Create a 3x2 matrix named B, where $𝐵 =\begin{bmatrix} 1&amp;2\\ 3&amp;4 \\ 5&amp;6 \end{bmatrix}$  </li><li>Print A and B.</li><li>Transpose A to be a 2x3 matrix.</li><li>Multiply matrix A with matrix B and store the output in matrix C.</li><li>Print the dimensions of C.<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np <span class="hljs-comment">#import packagename 加载库  import packagename as nickname 加载并替换库的名字</span><br>A=np.ones(<span class="hljs-number">3</span>,<span class="hljs-number">2</span>) <span class="hljs-comment">#numpy.ones(row,line)</span><br>print(A)  <br><br>B=np.array([[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">3</span>,<span class="hljs-number">4</span>],[<span class="hljs-number">5</span>,<span class="hljs-number">6</span>]]) <span class="hljs-comment">#numpy.array() 创建矩阵，用法同左边</span><br>print(B)<br><br>print(A,B)<br><br>A=A.reshape((<span class="hljs-number">2</span>,<span class="hljs-number">3</span>)) <span class="hljs-comment">#numpy.reshape((row,line)) 重新改写矩阵的大小</span><br>A=np.transpose(A) <span class="hljs-comment">#numpy.transpose(matrix) 返回转置矩阵</span><br>print(A)<br><br>C=A @ B <span class="hljs-comment">#@ 矩阵叉乘</span><br>print(C.shape) <span class="hljs-comment">#matrix.shape 矩阵的大小</span><br></code></pre></div></td></tr></table></figure><h1 id="Q6-Use-𝑀-for-the-following-tasks"><a href="#Q6-Use-𝑀-for-the-following-tasks" class="headerlink" title="Q6. Use 𝑀 for the following tasks,"></a>Q6. Use 𝑀 for the following tasks,</h1><script type="math/tex; mode=display">𝑀 =\begin{bmatrix}−2&−4&2 \\ −2&1&2 \\ 4&2&5 \end{bmatrix}</script></li><li>Calculate the eigenvalues and eigenvectors for M. (hint: use numpy.linalg.eig)    </li><li>Use matplotlib to plot the eigenvalues in a graph.    </li><li>Save the eigenvalues into a file named “eig.npy” (hint: use numpy.save).   </li><li>Load the saved file into a new variable called load_eig and print the values.   <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">from</span> matplotlib <span class="hljs-keyword">import</span> plot <span class="hljs-keyword">as</span> plt<br>M=[[-<span class="hljs-number">1</span>,-<span class="hljs-number">4</span>,<span class="hljs-number">2</span>],[-<span class="hljs-number">2</span>,<span class="hljs-number">1</span>,<span class="hljs-number">2</span>],[<span class="hljs-number">4</span>,<span class="hljs-number">2</span>,<span class="hljs-number">5</span>]]<br>eignval,eignvect=np.linalg,eig(M) <span class="hljs-comment">#numpy.linalg,eig(Matrix) 返回两个值，第一个是特征值，第二个是特征向量</span><br>print(eignval)<br><br>plt.plot(eignval)<br><br>np.save(<span class="hljs-string">&quot;eig&quot;</span>,eigval) <span class="hljs-comment">#numpy.save(&quot;filename&quot;,value) 将值在当前目录下以“filename.npy”储存</span><br><br>load.eig=np.load(<span class="hljs-string">&quot;eigval.npy&quot;</span>) <span class="hljs-comment">#numpy.load(&quot;path&quot;) 返回加载的文件</span><br></code></pre></div></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>课后练习</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>1. 机器学习简介和Python的基本操作</title>
    <link href="/2021/01/23/Machine%20Learning-NAU/1.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B%E5%92%8CPython%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/"/>
    <url>/2021/01/23/Machine%20Learning-NAU/1.%20%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AE%80%E4%BB%8B%E5%92%8CPython%E7%9A%84%E5%9F%BA%E6%9C%AC%E6%93%8D%E4%BD%9C/</url>
    
    <content type="html"><![CDATA[<h1 id="机器学习简介和Python的基本操作"><a href="#机器学习简介和Python的基本操作" class="headerlink" title="机器学习简介和Python的基本操作"></a>机器学习简介和Python的基本操作</h1><h2 id="Before-the-course…"><a href="#Before-the-course…" class="headerlink" title="Before the course…"></a>Before the course…</h2><ul><li>Software and environment: Anaconda and Opencv  </li><li>Ultimate Project: Traffic Sign Recognition   </li><li>There’s a individual Quiz on lecture 5  </li></ul><h2 id="人工智能的产生"><a href="#人工智能的产生" class="headerlink" title="人工智能的产生"></a>人工智能的产生</h2><p>lines of codes programming forces people to find a way to teach the program to do things.<br>example: makeup transfer<br>example: auto ping-pong machine</p><h2 id="计算机视觉简介"><a href="#计算机视觉简介" class="headerlink" title="计算机视觉简介"></a>计算机视觉简介</h2><p>计算机视觉可以大致的被分为三个大类：  </p><ul><li>3D建模(3D Construction)<br>例子：敦煌莫高窟的3D建模（来自武汉大学）  </li><li>图像渲染(Image Rendering)<br>例子：Google Pixel<br>其搭载的增强现实算法能够对周围的图像进行实时渲染  </li><li>图像检测(Pattern Recongnition)<br> 例子：都灵的图像识别装置<br> 人们穿戴对应的设备行走，设备能够识别他周围的物品   </li></ul><p>计算机视觉可以在各个领域帮助到人们，在医学领域帮助医生识别X光片，在自动驾驶领域，自动驾驶汽车依靠车身上的传感器和相机识别道路上的物体，在体育竞技领域，计算机视觉能够帮助人们更好的训练运动员的运动姿势。世界上第一张人脸检测的图片由Dr.Sung Kah Kay在1996年完成。    </p><p>计算机科学的知识架构：<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210123230629.png" alt="">  </p><h2 id="Python-的基本操作"><a href="#Python-的基本操作" class="headerlink" title="Python 的基本操作"></a>Python 的基本操作</h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><p>  Python 不需要编译，是机器学习的首选语言之一，有非常多的库能够被调用。<br>  Python支持超大的数字运算<br>  编译环境（IDE）：Anaconda， 适用于大数据环境    </p><blockquote><p>不要使用 Python 2.x  </p></blockquote><ul><li>Python的IDE思路：REPL<br><img src="https://raw.githubusercontent.com/l61012345/Pic/master/img/20210123231447.png" alt=""><br>Reading： 读取来自键盘等的输入<br>Evalueate： 将输入进行Evaluate，其结果通常是一个数值，这个数值最终会被编译器输出（Print）<br>在输出后，这个程序将等待下一次的输入，形成一个循环  <h3 id="赋值和函数定义"><a href="#赋值和函数定义" class="headerlink" title="赋值和函数定义"></a>赋值和函数定义</h3>Python可以不用声明变量的类型，直接对其进行赋值，其变量的赋值类型取决于赋值<br>Python支持同时对多个变量进行赋值：  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">a,b=c,d <br>```  <br><br>定义函数的结构：  <br>``` Python<br>   <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">functionname</span>(<span class="hljs-params">variable</span>):</span>  <br>      <span class="hljs-keyword">return</span> value<br>    <span class="hljs-comment"># 也可以不需要返回值</span><br></code></pre></div></td></tr></table></figure> 另一种定义方式：  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">    function= <span class="hljs-keyword">lambda</span> return_variable: options  <br>```  <br>例如：  <br>  ``` Python<br>   S= <span class="hljs-keyword">lambda</span> x: x*x  <br></code></pre></div></td></tr></table></figure>在Python中，函数的定义和调用有如下特点：</li></ul><ol><li>嵌套调用：<br><code>funcationname(funcationname(variable))</code>  </li><li>在Python中，变量可以传递给函数，<strong>函数也可以传递给变量</strong>。<br>例如：  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">function</span> (<span class="hljs-params">n</span>):</span><br>    n*n<br>    <span class="hljs-keyword">return</span> n<br>foo=function(<span class="hljs-number">5</span>)<br><span class="hljs-comment"># 此时foo的类型是一个函数</span><br>foo(<span class="hljs-number">10</span>)<br><span class="hljs-comment"># &gt;&gt; 100</span><br></code></pre></div></td></tr></table></figure></li><li>可以在定义函数的部分嵌套定义其他函数：  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">function</span>(<span class="hljs-params">variable1</span>):</span><br>  <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">subfuntion</span>(<span class="hljs-params">variable2</span>):</span><br>     <span class="hljs-keyword">return</span> variable2<br> <span class="hljs-keyword">return</span> variable1<br></code></pre></div></td></tr></table></figure><h3 id="条件结构-if-else"><a href="#条件结构-if-else" class="headerlink" title="条件结构(if-else)"></a>条件结构(if-else)</h3>条件语句的基本结构： <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">if</span> conditon:<br>  options<br></code></pre></div></td></tr></table></figure>例如：<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">compare</span>(<span class="hljs-params">a,b</span>):</span><br>  <span class="hljs-keyword">if</span> a&gt;b:<br>    <span class="hljs-keyword">return</span> a<br>  <span class="hljs-keyword">return</span> b<br>compare(<span class="hljs-number">3</span>,<span class="hljs-number">4</span>)<br><span class="hljs-comment">#&gt;&gt; 4</span><br></code></pre></div></td></tr></table></figure>在条件语句中可以同时并存多个条件：<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">if</span> condition1:<br>  options<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> condition2:<br>  options<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>  condtion3:<br>  options<br><span class="hljs-keyword">else</span>:<br>  options<br></code></pre></div></td></tr></table></figure><h3 id="循环结构"><a href="#循环结构" class="headerlink" title="循环结构"></a>循环结构</h3></li><li>通过函数定义的返回值来进行循环 (recursion)<br>例如：  <figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">factorial</span>(<span class="hljs-params">n</span>):</span><br>  <span class="hljs-keyword">if</span> n==<span class="hljs-number">1</span>:<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>  <span class="hljs-keyword">return</span> n*factorial(n-<span class="hljs-number">1</span>)<br>factorial(<span class="hljs-number">5</span>)<br><span class="hljs-comment">#&gt;&gt; 120</span><br><span class="hljs-comment">#5*4*3*2*1</span><br></code></pre></div></td></tr></table></figure></li><li><p>通过for循环语句来进行循环(for-range) </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-keyword">for</span> innnervariable <span class="hljs-keyword">in</span> <span class="hljs-built_in">list</span> <span class="hljs-comment">#usually is range(a,b) a to b do n++</span><br>options<br></code></pre></div></td></tr></table></figure><p>例如：  </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">factorial</span>(<span class="hljs-params">n</span>):</span><br> <span class="hljs-keyword">for</span> x <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,n+<span class="hljs-number">1</span>)<br>   result=result*n<br> <span class="hljs-keyword">return</span> result<br> factorial(<span class="hljs-number">5</span>) <br> <span class="hljs-comment">#&gt;&gt; 120  </span><br></code></pre></div></td></tr></table></figure><blockquote><p>要注意 <code>range(a,b)</code> 是不包括b的：  </p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span> (<span class="hljs-number">0</span>,<span class="hljs-number">4</span>)<br>   print(a) <br><span class="hljs-comment">#&gt;&gt; 3  </span><br></code></pre></div></td></tr></table></figure><p>这样的循环结构没有自增加（<code>x++</code>）的存在</p></blockquote></li><li><p>通过while语句进行循环</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-keyword">while</span> (condition):<br>  options<br></code></pre></div></td></tr></table></figure><p>例如：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">gcd</span>(<span class="hljs-params">a,b</span>):</span> <span class="hljs-comment">#最大公约数</span><br>  <span class="hljs-keyword">while</span> (b&gt;<span class="hljs-number">0</span>):<br>    r=a&amp;b<br>    a,b=b,r<br> <span class="hljs-keyword">return</span> a<br></code></pre></div></td></tr></table></figure><h3 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h3><p>在Pyhton中，字符串由双引号””或者单引号’’定义。<br>字符串支持加减法：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-string">&#x27;hello&#x27;</span>+<span class="hljs-string">&#x27;world&#x27;</span><br><span class="hljs-comment">#&gt;&gt; &#x27;helloworld&#x27;</span><br></code></pre></div></td></tr></table></figure><p>也支持乘法（重复多次）：</p><figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-string">&#x27;hello&#x27;</span>*<span class="hljs-number">3</span><br><span class="hljs-comment">#&gt;&gt; &#x27;hellohellohello&#x27; </span><br></code></pre></div></td></tr></table></figure><ul><li>字符串的传递<br>字符串可以传值给变量（类型是字符串），可以通过[起点：终点：步长]访问字符串中的特定位置的字符。<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">a=<span class="hljs-string">&#x27;helloworld&#x27;</span><br>print(a[<span class="hljs-number">2</span>])<br><span class="hljs-comment">#&gt;&gt;&#x27;l&#x27;</span><br>print(a[<span class="hljs-number">0</span>:<span class="hljs-number">4</span>])<br><span class="hljs-comment">#&gt;&gt;&#x27;hello&#x27;</span><br>&gt; Python 中的序号是从<span class="hljs-number">0</span>开始的<br>print(a[::-<span class="hljs-number">1</span>] )<br><span class="hljs-comment">#&gt;&gt;&#x27;dlrowolleh&#x27;</span><br>b=<span class="hljs-string">&#x27;abcdefghijklmnopqrstuvwxyz&#x27;</span><br>print(a[<span class="hljs-number">1</span>:<span class="hljs-number">15</span>:<span class="hljs-number">2</span>])<br><span class="hljs-comment">#&gt;&gt;&#x27;bdfhjln&#x27;</span><br></code></pre></div></td></tr></table></figure><code>len()</code>函数将返回字符串的长度<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-built_in">len</span>(hello)<br><span class="hljs-comment">#&gt;&gt; 5</span><br></code></pre></div></td></tr></table></figure>[]默认的访问顺序是从左到右，负号（-）表示从右到左的访问顺序。   <h3 id="列表"><a href="#列表" class="headerlink" title="列表"></a>列表</h3>列表（list）是一种参数类型，例如：<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">x=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br><span class="hljs-built_in">type</span>(x)<br><span class="hljs-comment">#&gt;&gt; list</span><br></code></pre></div></td></tr></table></figure>列表用[]来表示，列表也可以嵌套。<br>列表中的元素可以是任何类型。<br>和字符串一样，可以用[]来访问列表中特定的某一个或者多个元素。    </li><li>列表的操作  </li></ul><ol><li>append()<br><code>append()</code>函数将在列表最后一位加上()内的字符串后，输出整个字符串<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">x=[<span class="hljs-number">1</span>,<span class="hljs-number">2</span>,<span class="hljs-number">3</span>,<span class="hljs-number">4</span>]<br>x.append(<span class="hljs-number">2</span>)<br>print(x)<br><span class="hljs-comment">#&gt;&gt;[1,2,3,4,2]</span><br></code></pre></div></td></tr></table></figure></li><li>列表理解（list comprehension）<br>在列表的[]中填入生成列表的方法：<br>例如：<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python">x=[a <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">8</span>)]<br><span class="hljs-built_in">print</span> x<br><span class="hljs-comment">#&gt;&gt; [1,2,3,4,5,6,7]</span><br>y=[square(a) <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> x]<br><span class="hljs-built_in">print</span> y<br><span class="hljs-comment">#&gt;&gt;[1,4,9,16,25,36,49]</span><br></code></pre></div></td></tr></table></figure>可以利用列表理解来过滤某些元素:<figure class="highlight python"><table><tr><td class="gutter hljs"><div class="hljs code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></div></td><td class="code"><div class="hljs code-wrapper"><pre><code class="hljs Python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">iseven</span>(<span class="hljs-params">n</span>):</span><br>    <span class="hljs-keyword">return</span> n%<span class="hljs-number">2</span>==<span class="hljs-number">0</span><br>x=[a <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">1</span>,<span class="hljs-number">8</span>)]<br>y=[square(a) <span class="hljs-keyword">for</span> a <span class="hljs-keyword">in</span> x <span class="hljs-keyword">if</span> iseven(a)]<br><span class="hljs-built_in">print</span> y<br><span class="hljs-comment">#&gt;&gt;[4,16,36]  </span><br></code></pre></div></td></tr></table></figure></li></ol></li></ol>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  <entry>
    <title>0. 课程简介</title>
    <link href="/2021/01/22/Machine%20Learning-NAU/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/"/>
    <url>/2021/01/22/Machine%20Learning-NAU/0.%20%E8%AF%BE%E7%A8%8B%E7%AE%80%E4%BB%8B/</url>
    
    <content type="html"><![CDATA[<h1 id="课程简介"><a href="#课程简介" class="headerlink" title="课程简介"></a>课程简介</h1><p>课程：NUS2021: OTH927 Artificial Intelligence &amp; Machine Learning<br>（新加坡国立大学 2021 对外交流项目）<br>授课教师：Dr. Terence Sim (tsim@comp.nus.edu.sg) / Sanka Rasnayaka(Assistant) /Karen Boh(Assistant)  </p><p>本课程分为两部分： Lecture 和 Tutorial， 其中 Tutorial 内容为编程习题课。  </p>]]></content>
    
    
    <categories>
      
      <category>Machine Learning-NUS 2021</category>
      
      <category>讲义</category>
      
    </categories>
    
    
  </entry>
  
  
  
  
</search>
