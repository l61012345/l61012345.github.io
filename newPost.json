{"title":"8.1 激活函数、代价函数和决策边界","id":"2021/03/28/8. 支持向量机/8.1. 激活函数、代价函数和决策边界/","date_published":"03/28/2021","summary":"img{    width: 50%;    padding-left: 20%;}\n\n 逻辑回归的代价函数的线性拟合逻辑回归的激活函数：$h(x)=\\frac{1}{1+e^{-θ^Tx}}$。对于单个样本$(x,y)$，逻辑回归的代价函数是：$-ylog(h_θ (x))−((1−y)log⁡(1−h_θ (x)))$，将$y=1$与$y=0$时的代价函数作出，并用线性进行拟合得到$Cost_1(z)$与$Cost_0(z)$（$z=θ^Tx$）两个线性的代价函数，两者的函数图像大致如此。支持向量机是线性化的逻辑回归。  \n支持向量机的代价函数逻辑回归的代价函数：  \nJ(θ)=min\\frac{1}{m}[∑_{i=1}^m y^{(i)} -log⁡(h_θ(x^{(i)} ))+(1−y^{(i)}) -log(1−h_θ (x^{(i)}))]+\\frac{λ}{2m}∑θ^2将$-log$项替换为线性的与$Cost_1(z)$和$Cost_0(z)$，并去除$\\frac{1}{m}$项（并不会改变最终结果）得到支持向量机的代价函数：  \nJ(θ)=min[∑_{i=1}^m y^{(i)} Cost_1(z))+(1−y^{(i)})Cost_0(z))]在支持向量机中，通常通过给前项附加权重$C$而非给正则化项附加权重$λ$的方法来防止过拟合，得到正则化的支持向量机的代价函数：  \nJ(θ)=minC[∑_{i=1}^m y^{(i)} Cost_1(z))+(1−y^{(i)})Cost_0(z))]+\\frac{1}{2}∑θ^2支持向量机的激活函数与逻辑回归不同的是，逻辑回归的$h(x)$输出的是概率，而支持向量机的激活函数直接给出了预测的结果：  ","url":"https://l61012345.top/2021/03/28/8.%20%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/8.1.%20%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0%E3%80%81%E4%BB%A3%E4%BB%B7%E5%87%BD%E6%95%B0%E5%92%8C%E5%86%B3%E7%AD%96%E8%BE%B9%E7%95%8C/","tags":[],"categories":["机器学习基础课程——吴恩达","8. 支持向量机"]}