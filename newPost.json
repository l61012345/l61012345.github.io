{"title":"TensorFlow 入门项目：训练一个VGG模型","id":"2021/09/25/技术杂谈/使用tensorflow/","date_published":"09/25/2021","summary":"TensorFlow 入门项目：训练一个VGG模型同NUS的交通标志分类器项目一样，搭建一个训练器的算法思路基本相同。基本步骤为：\n\n读取数据集，加载数据集中的图像和标签\n划分训练集和测试集\n定义分类器，此处需要定义使用的Google的VGG模型\n将训练集放入分类器训练，并用测试集输出评价\n输出设定的评价标准\n保存模型\n\n整个过程需要的函数库如下所示：12345678910import globimport matplotlib.pyplot as pltimport numpy as npimport tensorflow as tfimport osfrom cv2 import cv2from sklearn.model_selection import train_test_splitfrom tensorflow.keras import Model, Sequential, layers, modelsfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateaufrom tensorflow.keras.preprocessing.image import ImageDataGenerator在正式进行训练之前，可以利用tf中的tf.config.experimental.list_physical_devices(&#39;GPU&#39;)查找并选择使用GPU，写法是固定的。12345#调用GPUgpus = tf.config.experimental.list_physical_devices(&#x27;GPU&#x27;)if gpus:    for gpu in gpus:        tf.config.experimental.set_memory_growth(gpu, True)\n加载数据集这一部分的思路与NUS项目中使用Sklearn创建交通标志分类器的思路几乎完全相同：定义两个list用于分别存放图像集和标签集。遍历整个数据集，对于图像，使用cv2.imread()将图像转为np.array格式后存放到list即可。对于图像所对应的标签，此处使用的是split()函数对文件路径、或者是文件名中含有的标签信息进行提取。如果标签在数据集中以.csv或者.exls的表格文件储存，则需要调用pandas函数库进行处理。需要注意的是，图像需要用cv2.resize()保证每张图片的大小相同，即矩阵的大小是相等的。  \n1234567891011121314151617181920212223# 定义容器x = []  # 图像集y = []  # 标签集ImgHight = 64 # 图片高度ImgWidth = 64 # 图片宽度# 加载数据集dataset_root = &#x27;dataset/cells in urinary sample/**/&#x27;for i in glob.glob(dataset_root + &#x27;*.bmp&#x27;, recursive=True):    img = cv2.imread(i)    img_resize = cv2.resize(img, (ImgWidth, ImgHight))  # 裁剪图像    x.append(img_resize)    label = i.split(&quot;\\\\&quot;)[2][0:3]  # 分词找标签    y.append(int(label))# 错误代码if len(x) == 0:    print(&#x27;Missing files&#x27;)elif len(y) == 0:    print(&quot;missing names&quot;)print(&quot;reading completed&quot;)\n由于tf只支持标签和图像都为np.array格式，因此需要将标签和图像列表都转换为np.array格式。此外还需要将图像列表转为一个长向量，以便输入分类器进行拟合。123# 把标签和图像转为nparry格式x = np.array(x).reshape(-1, ImgHight, ImgWidth, 3)  # 转为1维长向量y = np.array(y)同样地，此处使用Sklearn中的train_test_split()函数对数据集进行随机划分，划分为测试集和训练集两部分。12345# 划分训练集和测试集x_train, x_test, y_train, y_test = train_test_split(x,                                                    y,                                                    test_size=0.4,                                                    shuffle=True)\n加载模型此处使用tf.keras.applications.vgg16.VGG16()来加载TensorFlow中预制的VGG算法模型。由于数据集的量比较小，因此设置数据输入到最后的四层。123456789print(&quot;Loading the model..&quot;)# VGG16预训练网络covn_base = tf.keras.applications.vgg16.VGG16(weights=&#x27;imagenet&#x27;,                                              include_top=False)covn_base.trainable = True# 冻结前面的层，训练最后四层for layers in covn_base.layers[:-4]:    layers.trainable = False    对每一层，都需要用tf.keras.layers中的函数指定每一层的用途和相关的参数（比如激活函数，池化方法等等）。由于采用的是预制的标准VGG16算法，因此最后4层每一层的设置遵循标准VGG16的结构。123456789101112# 构建模型model = tf.keras.Sequential()model.add(covn_base)model.add(tf.keras.layers.GlobalAveragePooling2D())model.add(tf.keras.layers.Dense(256, activation=&#x27;relu&#x27;))model.add(tf.keras.layers.Dropout(0.2))model.add(tf.keras.layers.Dense(1, activation=&#x27;softmax&#x27;))model.summary()# 编译模型，初始学习率0.001model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),              metrics=[&quot;accuracy&quot;])对于大数据集，在训练后期，当loss不再明显时，减小学习率以加大学习的压力。12345# 监视&#x27;val_loss&#x27;，当两个epoch的loss不变时，学习率减小为1/10reduce_lr = ReduceLROnPlateau(monitor=&#x27;val_loss&#x27;,                              factor=0.1,                              patience=2,                              verbose=1)将训练集的图像和标签输入到分类器中拟合，拟合过程指定训练的轮数epochs，批数等等。使用TensorFlow2.0特性validation_data()导入测试集图像和标签，训练器在每一轮训练后会使用测试集进行测试，并返回准确率、loss到history中。123456789# 开始训练history = model.fit(    x_train,    y_train,    batch_size=128,    epochs=15,    validation_data=(x_test, y_test),)print(&quot;train complieted&quot;)","url":"https://l61012345.top/2021/09/25/%E6%8A%80%E6%9C%AF%E6%9D%82%E8%B0%88/%E4%BD%BF%E7%94%A8tensorflow/","tags":[],"categories":["技术杂谈"]}