---
title: 数字图像处理部分-知识点总结
category_bar: true
date: 2023/1/1
categories: 
- 学习笔记
- 智能系统和数字图像处理应用
---
# 数字图像处理部分
## 离散化过程
离散化(discretization)需要完成对光学信息空间位置的离散化（即对应信息的位置的离散化）和对每一个像素单元中光学信息强度的离散化（即对应信息的强度的离散化）。  
和大部分信息的数字化一样，这一过程可以大致分为两步将光学信息转换为数字图像：采样(sampling)和量化(quantization)。采样负责对离散空间信息，量化则是进一步对强度值进行离散化。  

### 灰度值和RGB值
#### 灰度图像  
对于黑白图像，或者又称为灰度图像(grey image)，光学信息的强度可以被一个值描述，这个值描述了一个像素区域内的信息有多黑/有多白，这个值称为灰度值(gray-scale value)。  
通常，在图像处理领域认为灰度值的范围为$[0,255]$，其中0表示纯黑色$\color{black}{▨}$，255表示纯白色 $\color{white}{▨}$，用8比特进行表示。  
**因此，每一张灰度图像都可以用一个矩阵表示，矩阵的每个位置上的元素表示对应空间上图像的像素点的灰度值。**  

#### 彩色图像  
对于彩色图像，则是将图像拆分为由红绿蓝(Red$\color{red}{▨}$,Green$\color{green}{▨}$,Blue$\color{blue}{▨}$ )这三种光学三原色组成的三个图层，每个图层上的像素值依次表示对应颜色的深度，因此彩色图像中的每一个像素都可以由一个三维坐标$(R,G,B)$进行表示。  
**因此，每一张彩色图像都可以用三个矩阵表示，矩阵的每个位置上的元素表示对应空间上图像的像素点的R/G/B值。**  

#### 视频  
因此每一个视频都可以转化为若干的矩阵时序序列。  
视频是由一张一张的静态图快速播放形成的，一张静态图称为一帧(frame)，比如人眼分辨率的下限为每秒24帧，即视频一秒钟包含24张静态图，如此人眼才会将这些播放的静态图视为“动态的”。因此，每秒24帧的彩色视频中包含24张彩色图。  

## 基础图像处理
通过前文可知，**图像处理的本质是对图像所对应的矩阵进行相关的数学操作**。  
基础的图像处理有叠加、差分、反转、平移、旋转和缩放。  

### 叠加
叠加对应的矩阵操作就是将两个图片所对应的矩阵（以灰度图为例，下同）$I_1,I_2$进行相加:  
$$I_1+I_2$$
相加后的效果为“**亮的更亮、暗的更暗**”，图像对应的像素会比原来的像素值更高。  
将多张拍摄场景相同，但是随机噪点的数量和位置不同的照片通过叠加，可以得到比原来任何一张图片都噪点都要小很多的照片。  

### 差分
图像差分，就是把两幅图像的对应像素值相减，以**削弱图像的相似部分，突出显示图像的变化部分**。  
$$I_1-I_2$$
差分可以用于异常检测中：使用一张正常状态的图片与需要进行异常检测的图片进行差分，可以发现被检测图片中与标准图片不一致的地方。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221205165318.png width=50%>  

### 反转
对图像反转对应的是量化级的最高值减去图像当前对应的像素值，对于8bit灰度图，反转表示为一个全为255的矩阵减去图像对应的矩阵：  
$$[255]-I_1$$
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221205165619.png width=30%>  

### 平移、旋转和缩放
图像的平移、旋转和缩放则是将原图像与一个对应的矩阵相乘，如下图所示：  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221205165805.png width=50%>  

需要注意的是，对于图像的旋转操作会由于图像空间量化误差而造成信息上的损失，如下图所示，某个图像经过旋转后出现了信息丢失，这是因为在空间量化中只认为图形在每个像素中占比超过50%的部分才会有对应的像素值：  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221205170715.png width=50%>  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221205170917.png width=50%>  

## 图像压缩
如果将图像表示为一个灰度值函数，自变量为空间位置$f(x,y)$，图像压缩(compression)技术可以通过对图像编码和解码来实现对信息的压缩，以便将图像信息发送给接收方。接收方利用解压缩过程(decompression)将比特流解码为图像，再使用反映射将图像进行复原。整个过程如下图所示。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221213164630.png width=50%>  

在量化阶段，量化将灰度值转换为可以传输的比特信息，这个过程中通过引入量化误差来实现对于图像的压缩。**量化过程是图像压缩过程中信息损失最多的环节**。   
量化之前的映射过程的**目的是通过使用一些变换函数尽可能地减小原图和复原图像之间的均方差**。经过映射后的图像通过量化和传输时的信息损失更少。    

## JPEG
JPEG(Joint Photographic Experts Group)是一种图像压缩国际标准，其图像压缩和解压缩的过程如下图所示：  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221213201714.png width=50%>  
JPEG会首先将一整个图片分为8px × 8px的子图，然后再分别对每一张子图做相应的处理。  
子图通过前向变换(Forward transform)(主要是离散余弦变换)实现映射，每一张8px × 8px进行量化后会生成仅生成一个元素，然后进行编码。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221213210907.png width=70%>  

{% note info %}  
JPEG标准中子图采用8px × 8px大小与JPEG中采用的离散余弦变换的性质（见后文）有关：  
使用更小的子图会导致分组增多从而导致离散余弦变换的图像质量下降。越大的子图越不容易满足马尔科夫条件，同时更大的子图计算量也更多。  
{% endnote %}  

### 压缩过程
#### 离散余弦变换
离散余弦变换(discret cosine transformation,DST)是JPEG标准中采用的前向变换方法。相比于K-L变换，离散余弦变换的算子是通用算子，与原图独立。但是复原图像的均方差相比于使用K-L变换得到的复原图像较大，不过仍然在可以接受的范围。  
离散余弦变换的公式可以表示为：  
$$T(u,v)=∑_{x=0}^{n-1}∑_{y=0}^{n-1}f(x,y)r(x,y,u,v)$$
其中$f(x,y)$是原图像，$r(x,y,u,v)$称为变换系数(transformation coeffients)。  
相应的，反离散余弦变换(inverse discret cosine transformation)公式为：  
$$F(x,y)=∑_{u=0}^{n-1}∑_{v=0}^{n-1}T(u,v)S(u,v,x,y)$$
对于离散余弦变换及其反变换，它们的变换系数是相同的：  
$$r(x,y,u,v)=S(u,v,x,y)$$
这个变换系数的具体表达式为：  
$$r(x,y,u,v)=α(u)α(v)cos\left[\frac{(2x+1)uπ}{2n}\right]cos\left[\frac{(2y+1)vπ}{2n}\right]$$
其中，  
$$α(u)=\begin{cases}
  \sqrt{\frac{1}{n}},u=0\\
  \sqrt{\frac{2}{n}},u≠0\\
\end{cases}$$

##### 使用离散余弦变换的原因
- 当信号具有接近马尔科夫过程(Markov processes)的统计特性时（这样的条件又被称为马尔科夫条件），离散余弦变换的去相关性接近于K-L变换。**此时离散余项变换的作用相当于K-L变换。**  
- 相比于快速傅里叶变换(fast fourier transformation, FFT)，离散余弦变换可以通过反转信号达到变换后信号是原信号周期的两倍，如此避免了快速傅里叶变换中可能出现的间断点。离散余弦变换后子图之间的间隔更加平滑。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221219202507.png width=50%>   

#### 量化
**量化过程是JPEG标准中信息损失最大的部分**。JPEG中量化的目的是为了大幅度的压缩图像大小，同时保证图像的质量，即重建后的图像仍然保留了原图中的大部分信息。  
**量化过程中对于不同位置的像素使用了不同的量化级和量化阈值**。  

##### 量化级的分配
根据离散余弦变换的性质可知，变换后图像大部分的信息将被集中在左上角，因此，**在量化过程中，图像的左上角将被使用更高的精度（更多的比特）进行量化**，下图展示了JPEG量化过程中为子图中每个像素量化所使用的比特数量的分配。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220134651.png width=20%>  

##### 量化阈值的分配
JPEG的量化过程采用的阈值量化，即在不同的阈值范围内量化值是不同的。简单来说，量化的公式可以表示为：   
$$\hat{T}(u,v)=[\frac{T(u,v)}{C}]_{round}×C$$
其中$[·]_{round}$表示取整，$C$是设定好的阈值。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220140631.png width=20%>  
对于不同位置的像素，JPEG使用了不同的量化阈值。左上角的阈值要小于右下角的阈值，以便更好地捕捉子图中左上角的信息。  

实际上，JPEG的量化过程会事先建立一个8×8的量化表，将变换后的矩阵中各元素除以对应量化表中的元素，并对结果舍入取整（取最接近的整数），以便于执行最后的编码。  
下图展示了JPEG标准中规定的灰度量化表：  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220135737.png width=20%>  

经过量化阶段之后，所有的数据只保留了整数近似值，也就再度损失了一些数据内容。  

#### 霍夫曼编码
JPEG中采用的是霍夫曼编码(Huffman coding)，这种编码方式可以极大地减少信息冗余，增大信息密度。  
简单来说，霍夫曼编码按照每个像素值（灰度值或者RGB值）在图像（子图）中出现的频率来为每个像素值确定其编码的长度：**像素值出现的频率越低，那么其对应编码的长度越长。**  
霍夫曼编码的过程分为两步，当每个像素值的出现频率被确定后，按照频率大小为其排序。接着按照排序结果为每个像素值赋予相应的编码长度和比特值。每一个频率$P_r$对应一种比特长度$L_r$，并且频率$1-n×P_r$（$n$代表具有$P_r$的像素值个数）所对应的比特长度应当为$L_r+\sqrt{n'+1}$($n'$为下一个频率对应的像素值个数)。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220122837.png width=50%>   

下图展示了使用霍夫曼编码的一个例子：  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220130020.png width=50%>  

## 图像增强
### 点处理
点处理是像素点到点的变换，其影响仅限于单个的像素。图像上一个像素值$r(x,y)$,经过处理$s(x,y)=T(r(x,y))$后，得到同一位置的像素$s(x,y)$。    
注意：
1. $(x,y)$表示坐标。
2. 不同的图像处理库坐标系统的原点设置不同，$y$的取值设定也不同。  
3. $T$只能是单调（通常是单调递增）的函数。

点处理的几个特性：  
- 点处理的影响仅限于单个的像素点。  
- 点处理不会改变像素的位置。  

对于图像的点处理：$s=T(r)$，**当且仅当$T(·)$是一个严格单调的函数时，原图像中的像素可以和处理后的图像中的像素一一对应，如此只需要使用$T(·)$的反函数$T^{-1}(·)$就能够将图像从处理后的状态恢复到原图，且恢复过程没有任何损失**。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221133821.png width=50%>  


基本的点处理变换如下表所示。  

| 变换名 | 表达式 | 效果 |
|:-:|:-:|:-:|
|阈值变换<br>thresholding|$s=\begin{cases}0, r≤k\\255,r>k\end{cases}$|高于阈值的像素将会被强化为近白色/白色的像素值，低于阈值的像素值将被弱化为近黑色/黑色的像素值|
|对数变换|$s=clog(1+r)$|扩展低灰度值（突出过曝区域的细节）而压缩高灰度值（突出过暗区域的细节），从而增强图像的清晰度|
|幂变换/伽马变换|$s=cr^γ$|调整图像整体的明暗关系。<br>当$0<γ<1$时，图像整体的暗部被加强；$γ>1$时，图像整体的亮部被加强|
|反转|$s=L-1-r$|像素值进行颠倒：白色变为黑色，黑色变为白色|
|线性分段处理<br>linear piecewise| - |分区域对不同的灰度区域实现不同的映射，进而选择性地增强图像的细节|

### 亮度直方图
亮度直方图(histogram)的横轴是像素值，纵轴是该像素值对应的像素点个数，它反映了图像整体的像素分布情况。  

#### 直方图均衡    
图像在直方图上的分布越均匀，整个图像的明暗表现越好，同时图像的细节也得到更好的表现。  
直方图均衡(historgram equalization)是一种用于增强图像对比度的同时均衡图像亮度的方法，其目的是为了尽可能地将图像像素在直方图上的分布改变为均匀分布。直方图均衡是一种点处理。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221133126.png width=50%>  

定义直方图均衡变换：  
$$s=T(r)=(L-1)\int_0^rp_r(w)dw$$
其离散形式为：  
$$s=T(r)=(L-1)\sum_{w=0}^rp_r(w)$$
使得:  
$$P_s(s)=P_r(r)|\frac{dr}{ds}|=\frac{1}{L-1}$$

证明：当$s=T(r)=(L-1)\int_0^rp_r(w)dw$时，对等式两边求导：  
$$\begin{aligned}
    \frac{ds}{dr}=\frac{dT(r)}{dr}&=\frac{d[(L-1)\int_0^rp_r(w)dw]}{dr}\\
    &=(L-1)\frac{\int_0^rp_r(w)dw}{dr}\\
    &=(L-1)P_r(r)
\end{aligned}$$
带入$P_s(s)=P_r(r)|\frac{dr}{ds}|$，有：  
$$P_s(s)=P_r(r)|\frac{dr}{ds}|=\frac{1}{L-1}$$

#### 直方图匹配
直方图匹配(historgram matching)的是将图像的直方图尽可能地接近设计好的亮度直方图的一种方式。其基本思想是：理论上原图的亮度直方图和设计好的亮度直方图都可以通过直方图均衡得到相同的均匀分布的直方图，因此只需要将原图进行一次直方图均衡，再使用一次设计直方图的反直方图均衡即可得到设计好的直方图。  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221140903.png width=50%>  

直方图匹配的难点是在进行第二次反均衡时，$T_2(·)$的并不是一个严格单调递增的函数，其中有多个像素值被映射为了同一个像素值。  
因此其反函数$T^{-1}_2(·)$在反映射过程中需要将这些原本混合的像素值重新分离，一般采用的方法是将它们映射为与原图更为接近的像素值。  

### 相邻处理
与点处理比较，（Neighborhood Processing）相邻处理的输入值仍然是一个像素值，但是输出值确实一个围绕输入像素值的像素集。（如下图所示）  
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221220151132.png width=30%>   

常见的相邻处理如下表所示：  

| 名称 | 数学原理 | 效果和作用 |
|:-:|:-:|:-|
| 均值滤波<br>average filtering | $MSE(a)=∑_{i}(a-r_i)^2$<br>当$a$为这些像素值的均值时，此时有均方差最小| 图像中的噪点通过模糊化图像的方法移除 |
| 中值滤波<br> median filtering | $MSE(a)=∑abs(a-r_i)$ <br>当$a$为所有像素的中值时有优化函数最小| 除去图像中的椒盐噪声<br>不引入新的像素值，处理后的图像相较于均值滤波更接近原图 |
| 高斯滤波<br> Gaussian filtering| $G(x,y)=\frac{1}{2πσ^2}e^{-\frac{x^2+y^2}{2σ^2}}$ | 图像模糊，使图像呈现一种毛玻璃的质感。<br> 移除高斯噪声 |

### 边缘检测和图像锐化
#### 差分计算及物理意义  

|名称|表达式|二维图示|物理意义|
|:-:|:-:|:-:|:-|
| 一阶差分 |$f(x+1)-f(x)$|<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221144256.png width=100%>|图像沿着$x$方向或者$y$方向上像素值是否发生了变化，并返回这个变化的剧烈程度|
| 二阶差分 |$[f(x+1)-f(x)]-[f(x)-f(x-1)]\\=f(x+1)+f(x-1)-2f(x)$|<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221152524.png width=100%>|发现像素值变化趋势的改变点|

#### 拉普拉斯算子
设:  
$$F=\begin{bmatrix}
    0 & 0 & 0\\
    0 & 1 & 0\\
    0 & 0 & 0\\
\end{bmatrix}$$
定义拉普拉斯算子(Laplacian operator)为基础图像$F$在$x$方向与$y$方向上二阶导的和:  
$$▿F=\frac{d^2F}{dx^2}+\frac{d^2F}{dy^2}=\begin{bmatrix}
    0 & 0 & 0\\
    1 & -2 & 1\\
    0 & 0 & 0\\
\end{bmatrix}+\begin{bmatrix}
    0 & 1 & 0\\
    0 & -2 & 0\\
    0 & 1 & 0\\
\end{bmatrix}=\begin{bmatrix}
    0 & 1 & 0\\
    1 & -4 & 1\\
    0 & 1 & 0\\
\end{bmatrix}$$

图像与这个算子发生卷积后$I\*▿F$，就能够提取出图像的边缘。   
将提取的边缘与原图进行叠加后，原图像中的由边缘检测算子提取到的图像细节被加强，称为图像锐化(sharpened)。  

#### 反锐化遮罩
反锐化遮罩(unsharp marking, USM)算法是另一种边缘提取的方法。  
由于模糊算法会特别地将图像像素变化剧烈的物体边界部分进行模糊处理，那么倘若将模糊后的图像与原图像进行差分，那么差分的结果将会是这些被模糊的边界部分，以此提取出图像中物体的边缘。   
<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20221221151942.png width=50%>  

同样地，将提取到的边缘与原图进行叠加，原图中的边缘将被锐化。  