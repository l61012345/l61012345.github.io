---
title: 10.3. 主成分分析算法的优化
date: 2021/08/21
categories: 
- 机器学习基础课程——吴恩达
- 10. 主成分分析
---
# PCA算法优化
## 主成分数量的选取
$K$称作主成分的数量，通常$K$的选取与如下的两个参数有关：  
平均投影误差的平方：  
$$\frac{1}{m}∑_{i=1}^m|x^{(i)}-x^{(i)}_{approx}|^2$$  
$x_{approx}=U_{reduce}z$，是通过$z$复原后得到的向量。  
反应每一个数据到投影的距离之和。  
数据的方差：  
$$\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2$$  
反应每一个数据到原点的距离之和。  
$K$的选取通常遵循以下规律：  
满足最小的$K$,使得：  
$$\frac{\frac{1}{m}∑_{i=1}^m|x^{(i)}-x^{(i)_{approx}}|^2}{\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2}≤ 0.1(1\%)$$
表示99%的数据中的特征被保留，仅有1%的数据特征被压缩。  
如果希望这个比例小于1%，就意味着原本数据的偏差有99%都保留下来了，如果选择保留95%的偏差，便能非常显著地降低模型中特征的维度了。  
> 理解： 
> 1. 投影误差对应的是被放弃的$n-k$个特征值$λ$之和，而均方值对应的是所有的$n$之和，因此从这一点来看，$\frac{∑_{i=1}^k λ_i}{∑_{i=1}^n λ_i}≥99\%$的说法与此处的解释并无冲突。  
> 2. 1%其实是一个容错的区间，从5%到15%的区间内选取都是比较合理的，取决于具体问题。  


### 实现过程
从$k=1$开始应用PCA，计算出$U_{reduce}$和$z$，然后计算比例是否小于1%。如果不是的话再令$k=2$，如此类推，直到找到可以使得比例小于1%的最小$k$值（原因是各个特征之间通常情况存在某种相关性）。  
这样做的问题在于奇异值分解的过程计算量非常的大。  
实际上，在Octave中应用时，奇异值分解：`svd()`函数会返回三个矩阵U,S,V，其中U即为前文中提到的一个含有$n$个方向向量（也是特征向量）的矩阵（所有的列向量是方向向量/特征向量）。S是一个对角矩阵，对角线上的元素$s_{ii}$为特征值。  
$\frac{\frac{1}{m}∑_{i=1}^m|x^{(i)}-z^{(i)}|^2}{\frac{1}{m}∑_{i=1}^m|x^{(i)}|^2}≤ 0.1(1\%)$可以等价为：  
$$1-\frac{∑_{i=1}^ks_{ii}}{∑_{i=1}^ns_{ii}}≤0.01$$
如此则只需要应用一次`svd()`函数通过返回的特征值矩阵$S$得到所有的特征值，尝试前$k$个特征值，直到找到符合条件的最小$k$即可。  

> 事实上，$k$的选取还与应用PCA的目的有关，如果应用PCA的目的是为了减小计算量、加速算法的学习，则应当按照上述流程选取$k$。如果应用PCA的目的只是为了可视化数据集，那么$k=2$或$k=3$。  

## 重建的压缩表示
PCA是一个数据压缩算法，那么如何将压缩后的数据复原回原来的维度？  
应用公式：
$$x_{approx}=U_{reduce}z$$
可以看出$U_{reduce}$是$n × k$的矩阵，$z$是$k × 1$的向量，根据矩阵乘法的性质可以推导出$x_{approx}$是$n × 1$的向量。重构的数据$x_{approx}$在原始空间中的分布是共低维平面的。  

## 加速监督学习
如果对于高维的数据，通过应用PCA的降维效果能够显著的降低监督学习的计算量。  
对于数据集$(x^{(i)},y^{(i)})$，先抽取所有的数据:$x^{(i)}$，然后应用PCA得到这些数据的低维表示$z^{(i)}$，现在新的数据集变为$(z^{(i)},y^{(i)})$进行训练。同样的对预测的数据$x$也需要将$x$映射到$z$再进行预测。  
> $U_{reduce}$只能通过训练集来进行定义，再将$U_{reduce}$应用到交叉验证集或者是测试集。  

## 不恰当的应用案例
### 使用PCA来防止过拟合
合理性： 由于PCA能够降维、减小数据的特征量，因此认为使用PCA来防止过拟合是合理的，但是并不是一个好的应用。  
由于PCA不关心数据的标签$y$来降维，因此可能会在降维过程中丢失一些非常有用的特征信息。而正则化会考虑数据的标签$y$，因此正则化比PCA更不容易损失有用的信息。  

### 滥用PCA
另一个常见的错误是，默认地将主要成分分析作为学习过程中的一部分。应当先尝试使用原始数据作为机器学习算法的输入，当计算量非常大、计算速度非常慢、硬盘空间不足时，才应该应用PCA对数据进行压缩。  
