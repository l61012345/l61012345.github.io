---
title: 无序变量的基本相关性分析方法和Python实现
date: 2023/1/21
category_bar: true
categories: 
- 论文
- 事件建模和聚类
---
# 无序变量的基本相关性分析方法和Python实现
## 概述
相关性(correlation analysis)是根据数据判断两个变量之间的变化关系是否随机的统计性质。和灵敏度分析不同，相关性检验主要是基于统计数据本身而非数学模型，且只考虑变量之间的两两关系。  
高尔顿(Francis Galton)作为相关性检验的发明者，确定了一套用于描述两个变量相关性的数学语言：以一个指数$ρ$的值表示两个变量的相关性：  
如果$0<ρ≤1$，表明两个变量之间存在正向的相关性，所谓正向指的是两个变量的变化方向一致；如果$ρ=0$，则表明两个变量之间不具有任何相关性；如果$-1≤ρ<0$，表明两个变量之间存在负向的相关性，两个变量的变化方向相反。  

| 范围 | 解释 |
|:-:|:-:|
|$0<ρ≤1$| 两个变量具有正向相关性 |
|$ρ=0$|两个变量不具有任何相关性|
|$-1≤ρ<0$|两个变量具有负向相关性|

所谓等级变量，是指变量具有程度的性质，且使用具有不同高低的等级进行区分的变量，比如肝硬化程度、服务满意度等等。与之相反概念的是无序变量，这样的变量在描述时不使用等级语言。  
常用的两种无序变量的相关性分析是皮尔逊相关性分析(Pearson correlation analysis)和斯皮尔曼相关性分析(Spearman correlation analysis)。  

## 协方差和皮尔逊相关性分析
### 协方差
在统计学上，两个随机变量$X$、$Y$的方差满足如下关系：  
$$D(X±Y)=D(X)+D(Y)±2E[(X-E(X))(Y-E(Y))]$$
其中，
$$\begin{aligned}
    E[(X-E(X))(Y-E(Y))]&=E(XY-XE(Y)-YE(X)+E(X)E(Y))\\
    &=E(XY)-E(X)E(Y)
\end{aligned}$$
当两个随机变量独立时，$E(XY)=E(X)E(Y)$,有$E[(X-E(X))(Y-E(Y))]=0$，$D(X±Y)=D(X)+D(Y)$。  
当两个随机变量不独立时，有$E[(X-E(X))(Y-E(Y))]≠0$。  
因此，$E[(X-E(X))(Y-E(Y))]$可以认为是可以衡量两个随机变量之间在线性代数和统计学上是否具有独立性，换言之即是否具有线性相关性的标志。定义两个随机变量的协方差(covariance):  
$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$$

### 皮尔逊相关分析
皮尔逊相关分析则是对协方差定义的进一步拓展，对两个随机变量的协方差使用各自的方差进行归一化处理，如此将满足高尔顿提出的相关性的数学描述：  
$$ρ=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$
进一步地，如果将$X$、$Y$的期望和方差进一步分解，有：  
$$Cov(X,Y)=∑_{i=1}^n(x_i-\overline{X})(y_i-\overline{Y})$$
同时$D(X)=∑_{i=1}^n(x_i-\overline{X})^2$、$D(Y)=∑_{i=1}^n(y_i-\overline{Y})^2$，定义统计学上的样本皮尔逊相关分析系数：  
$$r=\frac{∑_{i=1}^n(x_i-\overline{X})(y_i-\overline{Y})}{\sqrt{∑_{i=1}^n(x_i-\overline{X})^2}\sqrt{∑_{i=1}^n(y_i-\overline{Y})^2}}$$

其在Python中的实现需要借用`numpy`库实现求和和列表相乘：  
```python
def pearson_correlation(X: 'lists', Y: 'lists')->['float']:
    x = np.array(X)
    y = np.array(Y)
    n = len(X)
    sum_xy = np.sum(np.sum(x * y))
    sum_x = np.sum(np.sum(x))
    sum_y = np.sum(np.sum(y))
    sum_x_square = np.sum(np.sum(x * x))
    sum_y_square = np.sum(np.sum(y * y))
    # pearson coefficient
    pearson = (n * sum_xy - sum_x * sum_y) / np.sqrt(
        (n * sum_x_square - sum_x * sum_x) *
        (n * sum_y_square - sum_y * sum_y))
    return pearson
```

由于皮尔逊相关系数本质上就是归一化的协方差，因此**皮尔逊相关系数只能衡量两个随机变量之间是否具有线性相关性**。  