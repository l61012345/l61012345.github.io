---
title: æ— åºå˜é‡çš„åŸºæœ¬ç›¸å…³æ€§åˆ†ææ–¹æ³•å’ŒPythonå®ç°
date: 2023/1/21
category_bar: true
categories: 
- ç ”ç©¶
- ç³»ç»Ÿå·¥ç¨‹
- ç³»ç»Ÿåˆ†æç†è®º
---
# æ— åºå˜é‡çš„åŸºæœ¬ç›¸å…³æ€§åˆ†ææ–¹æ³•å’ŒPythonå®ç°
## æ¦‚è¿°
ç›¸å…³æ€§(correlation analysis)æ˜¯æ ¹æ®æ•°æ®åˆ¤æ–­ä¸¤ä¸ªå˜é‡ä¹‹é—´çš„å˜åŒ–å…³ç³»æ˜¯å¦éšæœºçš„ç»Ÿè®¡æ€§è´¨ã€‚å’Œçµæ•åº¦åˆ†æä¸åŒï¼Œç›¸å…³æ€§æ£€éªŒä¸»è¦æ˜¯åŸºäºç»Ÿè®¡æ•°æ®æœ¬èº«è€Œéæ•°å­¦æ¨¡å‹ï¼Œä¸”åªè€ƒè™‘å˜é‡ä¹‹é—´çš„ä¸¤ä¸¤å…³ç³»ã€‚  
é«˜å°”é¡¿(Francis Galton)ä½œä¸ºç›¸å…³æ€§æ£€éªŒçš„å‘æ˜è€…ï¼Œç¡®å®šäº†ä¸€å¥—ç”¨äºæè¿°ä¸¤ä¸ªå˜é‡ç›¸å…³æ€§çš„æ•°å­¦è¯­è¨€ï¼šä»¥ä¸€ä¸ªæŒ‡æ•°$Ï$çš„å€¼è¡¨ç¤ºä¸¤ä¸ªå˜é‡çš„ç›¸å…³æ€§ï¼š  
å¦‚æœ$0<Ïâ‰¤1$ï¼Œè¡¨æ˜ä¸¤ä¸ªå˜é‡ä¹‹é—´å­˜åœ¨æ­£å‘çš„ç›¸å…³æ€§ï¼Œæ‰€è°“æ­£å‘æŒ‡çš„æ˜¯ä¸¤ä¸ªå˜é‡çš„å˜åŒ–æ–¹å‘ä¸€è‡´ï¼›å¦‚æœ$Ï=0$ï¼Œåˆ™è¡¨æ˜ä¸¤ä¸ªå˜é‡ä¹‹é—´ä¸å…·æœ‰ä»»ä½•ç›¸å…³æ€§ï¼›å¦‚æœ$-1â‰¤Ï<0$ï¼Œè¡¨æ˜ä¸¤ä¸ªå˜é‡ä¹‹é—´å­˜åœ¨è´Ÿå‘çš„ç›¸å…³æ€§ï¼Œä¸¤ä¸ªå˜é‡çš„å˜åŒ–æ–¹å‘ç›¸åã€‚  

| èŒƒå›´ | è§£é‡Š |
|:-:|:-:|
|$0<Ïâ‰¤1$| ä¸¤ä¸ªå˜é‡å…·æœ‰æ­£å‘ç›¸å…³æ€§ |
|$Ï=0$|ä¸¤ä¸ªå˜é‡ä¸å…·æœ‰ä»»ä½•ç›¸å…³æ€§|
|$-1â‰¤Ï<0$|ä¸¤ä¸ªå˜é‡å…·æœ‰è´Ÿå‘ç›¸å…³æ€§|

æ‰€è°“ç­‰çº§å˜é‡ï¼Œæ˜¯æŒ‡å˜é‡å…·æœ‰ç¨‹åº¦çš„æ€§è´¨ï¼Œä¸”ä½¿ç”¨å…·æœ‰ä¸åŒé«˜ä½çš„ç­‰çº§è¿›è¡ŒåŒºåˆ†çš„å˜é‡ï¼Œæ¯”å¦‚è‚ç¡¬åŒ–ç¨‹åº¦ã€æœåŠ¡æ»¡æ„åº¦ç­‰ç­‰ã€‚ä¸ä¹‹ç›¸åæ¦‚å¿µçš„æ˜¯æ— åºå˜é‡ï¼Œè¿™æ ·çš„å˜é‡åœ¨æè¿°æ—¶ä¸ä½¿ç”¨ç­‰çº§è¯­è¨€ã€‚  
å¸¸ç”¨çš„ä¸¤ç§æ— åºå˜é‡çš„ç›¸å…³æ€§åˆ†ææ˜¯çš®å°”é€Šç›¸å…³æ€§åˆ†æ(Pearson correlation analysis)å’Œæ–¯çš®å°”æ›¼ç›¸å…³æ€§åˆ†æ(Spearman correlation analysis)ã€‚  

## åæ–¹å·®å’Œçš®å°”é€Šç›¸å…³æ€§åˆ†æ
### åæ–¹å·®
åœ¨ç»Ÿè®¡å­¦ä¸Šï¼Œä¸¤ä¸ªéšæœºå˜é‡$X$ã€$Y$çš„æ–¹å·®æ»¡è¶³å¦‚ä¸‹å…³ç³»ï¼š  
$$D(XÂ±Y)=D(X)+D(Y)Â±2E[(X-E(X))(Y-E(Y))]$$
å…¶ä¸­ï¼Œ
$$\begin{aligned}
    E[(X-E(X))(Y-E(Y))]&=E(XY-XE(Y)-YE(X)+E(X)E(Y))\\
    &=E(XY)-E(X)E(Y)
\end{aligned}$$
å½“ä¸¤ä¸ªéšæœºå˜é‡ç‹¬ç«‹æ—¶ï¼Œ$E(XY)=E(X)E(Y)$,æœ‰$E[(X-E(X))(Y-E(Y))]=0$ï¼Œ$D(XÂ±Y)=D(X)+D(Y)$ã€‚  
å½“ä¸¤ä¸ªéšæœºå˜é‡ä¸ç‹¬ç«‹æ—¶ï¼Œæœ‰$E[(X-E(X))(Y-E(Y))]â‰ 0$ã€‚  
å› æ­¤ï¼Œ$E[(X-E(X))(Y-E(Y))]$å¯ä»¥è®¤ä¸ºæ˜¯å¯ä»¥è¡¡é‡ä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´åœ¨çº¿æ€§ä»£æ•°å’Œç»Ÿè®¡å­¦ä¸Šæ˜¯å¦å…·æœ‰ç‹¬ç«‹æ€§ï¼Œæ¢è¨€ä¹‹å³æ˜¯å¦å…·æœ‰çº¿æ€§ç›¸å…³æ€§çš„æ ‡å¿—ã€‚å®šä¹‰ä¸¤ä¸ªéšæœºå˜é‡çš„åæ–¹å·®(covariance):  
$$Cov(X,Y)=E[(X-E(X))(Y-E(Y))]$$

### çš®å°”é€Šç›¸å…³åˆ†æ
çš®å°”é€Šç›¸å…³åˆ†æåˆ™æ˜¯å¯¹åæ–¹å·®å®šä¹‰çš„è¿›ä¸€æ­¥æ‹“å±•ï¼Œå¯¹ä¸¤ä¸ªéšæœºå˜é‡çš„åæ–¹å·®ä½¿ç”¨å„è‡ªçš„æ–¹å·®è¿›è¡Œå½’ä¸€åŒ–å¤„ç†ï¼Œå¦‚æ­¤å°†æ»¡è¶³é«˜å°”é¡¿æå‡ºçš„ç›¸å…³æ€§çš„æ•°å­¦æè¿°ï¼š  
$$Ï=\frac{Cov(X,Y)}{\sqrt{D(X)}\sqrt{D(Y)}}$$
è¿›ä¸€æ­¥åœ°ï¼Œå¦‚æœå°†$X$ã€$Y$çš„æœŸæœ›å’Œæ–¹å·®è¿›ä¸€æ­¥åˆ†è§£ï¼Œæœ‰ï¼š  
$$Cov(X,Y)=âˆ‘_{i=1}^n(x_i-\overline{X})(y_i-\overline{Y})$$
åŒæ—¶$D(X)=âˆ‘_{i=1}^n(x_i-\overline{X})^2$ã€$D(Y)=âˆ‘_{i=1}^n(y_i-\overline{Y})^2$ï¼Œå®šä¹‰ç»Ÿè®¡å­¦ä¸Šçš„æ ·æœ¬çš®å°”é€Šç›¸å…³åˆ†æç³»æ•°ï¼š  
$$r=\frac{âˆ‘_{i=1}^n(x_i-\overline{X})(y_i-\overline{Y})}{\sqrt{âˆ‘_{i=1}^n(x_i-\overline{X})^2}\sqrt{âˆ‘_{i=1}^n(y_i-\overline{Y})^2}}$$

#### ä»£ç å®ç°
å…¶åœ¨Pythonä¸­çš„å®ç°éœ€è¦å€Ÿç”¨`numpy`åº“å®ç°æ±‚å’Œå’Œåˆ—è¡¨ç›¸ä¹˜ï¼š  
```python
def pearson_correlation(X: 'lists', Y: 'lists')->['float']:
    x = np.array(X)
    y = np.array(Y)
    n = len(X)
    sum_xy = np.sum(np.sum(x * y))
    sum_x = np.sum(np.sum(x))
    sum_y = np.sum(np.sum(y))
    sum_x_square = np.sum(np.sum(x * x))
    sum_y_square = np.sum(np.sum(y * y))
    # pearson coefficient
    pearson = (n * sum_xy - sum_x * sum_y) / np.sqrt(
        (n * sum_x_square - sum_x * sum_x) *
        (n * sum_y_square - sum_y * sum_y))
    return pearson
```
å½“ç„¶ï¼Œå¦‚`pandas`ã€`scipy.stats`ä¹‹ç±»çš„åº“ä¸­ä¹Ÿæœ‰ç›¸å…³çš„å‡½æ•°å¯ä»¥å®ç°çš®å°”é€Šç›¸å…³ç³»æ•°ã€‚æ¯”å¦‚`data.corr('pearson')`æˆ–è€…`stats.pearsonr(data.X,data.Y)`ã€‚  


ç”±äºçš®å°”é€Šç›¸å…³ç³»æ•°æœ¬è´¨ä¸Šå°±æ˜¯å½’ä¸€åŒ–çš„åæ–¹å·®ï¼Œå› æ­¤**çš®å°”é€Šç›¸å…³ç³»æ•°åªèƒ½è¡¡é‡ä¸¤ä¸ªéšæœºå˜é‡ä¹‹é—´æ˜¯å¦å…·æœ‰çº¿æ€§ç›¸å…³æ€§**ã€‚  

### æ–¯çš®å°”æ›¼ç›¸å…³æ€§åˆ†æ
ä¸ºäº†è§£å†³çš®å°”é€Šç›¸å…³ç³»æ•°çš„å±€é™æ€§ï¼Œæ–¯çš®å°”æ›¼(C Spearman)å¼•å…¥äº†ç­‰çº§ç›¸å…³çš„æ¦‚å¿µï¼Œå¹¶ä¸”é˜è¿°äº†å…¶ä¼˜ç‚¹ã€‚æ–¯çš®å°”æ›¼ç›¸å…³æ€§åˆ†æä¸­ï¼Œä¸¤ä¸ªéšæœºå˜é‡çš„ç»Ÿè®¡æ ·æœ¬é€šè¿‡å¯¹ç­‰çº§åŒ–å–æ¶ˆäº†æ•°æ®çš„ç›´æ¥ç›¸å…³æ€§ã€‚æ‰€è°“ç­‰çº§åŒ–$R(Â·)$æ˜¯æŒ‡åŸæœ‰çš„æ•°æ®ç‚¹æŒ‰ç…§ç›¸å¯¹å¤§å°ç”±é«˜åˆ°ä½æ’åˆ—ï¼Œå¹¶ç”¨æ’åºåºå·æ›¿æ¢åŸæœ‰çš„ç»Ÿè®¡æ•°æ®ã€‚ç»è¿‡ç­‰çº§åŒ–åçš„éšæœºå˜é‡è¿›è¡Œçš®å°”é€Šç›¸å…³æ€§åˆ†æ:
$$r_s=\frac{âˆ‘_{i=1}^n(R(x_i)-\overline{R(X)})(R(y_i)-\overline{R(Y)})}{\sqrt{âˆ‘_{i=1}^n(R(x_i)-\overline{R(X)})^2}\sqrt{âˆ‘_{i=1}^n(R(y_i)-\overline{R(Y)})^2}}$$
å¦‚æ­¤çš®å°”é€Šç›¸å…³æ€§åˆ†æè¡¡é‡çš„å°±æ˜¯ä¸¤ä¸ªç­‰çº§å˜é‡çš„ç›¸å…³æ€§ã€‚ç”±äºç­‰çº§å˜é‡åªä¼šè¡¨ç¤ºæ•°æ®çš„ç›¸å¯¹å¤§å°ï¼Œå› æ­¤è¿™æ ·çš„ç»“æœæ˜¯çš®å°”é€Šç›¸å…³åˆ†æåªä¼šä½“ç°å‡ºä¸¤ä¸ªéšæœºå˜é‡çš„å•è°ƒç›¸å…³æ€§ã€‚  
å› æ­¤ï¼Œ**æ–¯çš®å°”æ›¼ç›¸å…³æ€§åˆ†æè¡¡é‡äº†ä¸¤ä¸ªéšæœºå˜é‡çš„å•è°ƒç›¸å…³æ€§**ã€‚  

å½“æ‰€æœ‰çš„ç­‰çº§éƒ½æ˜¯æ­£æ•´æ•°æ—¶ï¼Œ$r_s$å¯ä»¥ç®€åŒ–ä¸ºï¼š  
$$ğ‘Ÿ_ğ‘ =1âˆ’\frac{6âˆ‘_{i=1}^nğ‘‘_ğ‘–^2}{ğ‘›(ğ‘›^2âˆ’1)}$$
å…¶ä¸­$d_i$æ˜¯ç¬¬$i$ä¸ªæ ·æœ¬$(x_i,y_i)$çš„ç­‰çº§å·®ï¼š$d_i=R(x_i)-R(y_i)$.  

å¦‚æœå¤šä¸ªæ ·æœ¬å…·æœ‰ç›¸åŒçš„å€¼ï¼š$x_a=x_b=x_c=...x_z$ï¼Œé‚£ä¹ˆè¿™äº›æ ·æœ¬çš„ç­‰çº§å°†è¢«å¹³å‡åŒ–ï¼š  
$$R(x_a)=\frac{R(x_a)+R(x_b)+...+R(x_z)}{N_{same}}$$

#### ä»£ç å®ç°
é¦–å…ˆå°†ä¸¤ä¸ªè¾“å…¥çš„éšæœºå˜é‡æ•°æ®ä»å¤§åˆ°å°è¿›è¡Œæ’åºï¼Œå¹¶æ£€æµ‹æ˜¯å¦å­˜åœ¨å€¼ç›¸åŒçš„æ ·æœ¬æ•°æ®ï¼Œå¦‚æœæœ‰åˆ™å°†è¿™äº›æ ·æœ¬ç‚¹çš„ç­‰çº§å¹³å‡åŒ–ã€‚  
```python
# order two lists
def sort_list(X):
    X_sorted = sorted(X,reverse=True)
    X_d = []
    # exam whether this value is repeated
    for i in X:
        if X_sorted.count(i)==1:
            X_d.append(X_sorted.index(i))
        else:
            # if the value is repeated, the rank will be the average rank for the repeated number
            X_d.append(X_sorted.index(i)/X_sorted.count(i))
    return X_d
```
å¸¦å…¥å…¬å¼ï¼š  
```python
# find the difference of ranks of two data, d , then square and sum
sum_d_square = 0
for j in range(len(X_d)):
    d = X_d[j] - Y_d[j]
    sum_d_square = sum_d_square + d*d
# spearman coefficent 1-[(6*\sum d^2)/(n(n^2-1))]
spearman = 1-(6*sum_d_square/(n*(n*n-1)))
```
å®Œæ•´ä»£ç å¦‚ä¸‹ï¼š  
```python
def spearman_correlation(X:'list',Y:'list'):
    # order two lists
    def sort_list(X):
        X_sorted = sorted(X,reverse=True)
        X_d = []
        # exam whether this value is repeated
        for i in X:
            if X_sorted.count(i)==1:
                X_d.append(X_sorted.index(i))
            else:
                # if the value is repeated, the rank will be the average rank for the repeated number
                X_d.append(X_sorted.index(i)/X_sorted.count(i))
        return X_d

    # exam the length of two list
    if len(X)==len(Y):
        n = len(X)
        X_d = sort_list(X)
        Y_d = sort_list(Y)

        # find the difference of ranks of two data, d , then square and sum
        sum_d_square = 0
        for j in range(len(X_d)):
            d = X_d[j] - Y_d[j]
            sum_d_square = sum_d_square + d*d
        # spearman coefficent 1-[(6*\sum d^2)/(n(n^2-1))]
        spearman = 1-(6*sum_d_square/(n*(n*n-1)))
    else:
        print('Length unequal')
        spearman = None
    return spearman
```
å½“ç„¶ï¼Œå¦‚`pandas`ã€`scipy.stats`ä¹‹ç±»çš„åº“ä¸­ä¹Ÿæœ‰ç›¸å…³çš„å‡½æ•°å¯ä»¥å®ç°æ–¯çš®å°”æ›¼ç›¸å…³ç³»æ•°ï¼Œæ¯”å¦‚`data.corr('spearman')`æˆ–è€…`stats.spearmanr(data.X,data.Y)`ã€‚  

å¤šç»´æ•°æ®è¿˜å¯ä»¥ä½¿ç”¨`seabon.heatmap`å°†ç›¸å…³æ€§æ£€éªŒçš„ç»“æœè¡¨ç¤ºä¸ºçƒ­åŠ›å›¾ï¼Œä¾‹å¦‚ï¼š
```
seaborn.heatmap(hardness_data,vmax=0.3,annot=True,cmap="RdBu_r")
plt.show()
```  

<img src= https://cdn.jsdelivr.net/gh/l61012345/Pic/img/20230121154739.png width=50%>  