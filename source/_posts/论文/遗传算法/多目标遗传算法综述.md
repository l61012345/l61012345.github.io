---
title: 多目标优化遗传算法综述
date: 2023/4/24
category_bar: true
categories:  
- 论文
- 遗传算法
---

# 多目标优化遗传算法综述

> Multi-objective optimization using genetic algorithms: A tutorial. Abdullah Konak, *et al*.  


## 帕累托最优理论
在数学上，多目标优化问题可以被公式化为如下表述：  
如果多目标问题的每一种解都可以使用$n$维空间$X$中的一个的向量进行表示：$\bold{x}=\{x_1,x_2,...,x_n\}$，那么多目标优化就是找到一个解$\bold{x^*}$使得$K$个目标函数(objective function)$z_i(\bold{x})$具有最小值:  
$$z(x^*)=\{z_1(\bold{x^*}),z_2(\bold{x^*}),...,z_n(\bold{x^*})\}$$

同时，搜索空间$X$收到一系列的约束条件(constrain)$g$的限制：$g_j(\bold{x^*})=b_j$，$j=1,...,m$.   

实际情况是，许多约束的满足条件彼此之间会冲突，因此**实际上想要找到一个多目标解使得所有目标函数同时达到最优解几乎是不可能的**。因此，事实上多目标优化是寻找一组最优化的近似解，这个解在每一个目标函数中的结果都在可以接受的范围内，而且没有其他的解可以比这个解至少在一个目标函数中更好。  

### 支配和帕累托最优解
假设优化问题为最小值优化，**如果一个解$\bold{x}$至少在一个目标函数中的结果比另一个解$\bold{y}$好**：$z_i(\bold{x})<z_i(\bold{y}), i=1,2,...,K$，**且在其他目标函数中的结果不比$\bold{y}$差：$z_j(\bold{x})≤z_j(\bold{y}),j=1,2,...,K$，那么称解$\bold{x}$支配(dominate)另一个解$\bold{y}$**($\bold{x}≻\bold{y}$).  
进一步地，如果一个解$\bold{x}$在搜索空间中不被其他任何一个解支配，那么这个解被称为帕累托最优解(Pareto optimal，以下简称帕累托解)或者帕累托效率(Pareto efficiency)。  


{% note info %}  
在搜索空间中存在多个帕累托最优解，比如对于目标函数$f_1(x),f_2(x)$，$[1,2]$和$[2,1]$相互之间不被支配。  
{% endnote %}  

所有的帕累托最优解构成的集合称为帕累托最优解集合(Pareto optimal set)，这些帕累托最优解带入到每一个目标函数中得到的结果所构成的集合称为帕累托前沿(Pareto front).  
  
因此，多目标优化的关键是在于找到帕累托最优解集合。  
但是，随着搜索空间$X$维度的升高，帕累托集合的数量会越来越大。对于大多数问题而言，帕累托解的数量巨大甚至是无穷多的。实际要想找完所有的帕累托最优解是不可能的。并且证明这些解的最优性在计算上也是无法实现的。因此**实际的多目标优化是找到最接近全解的帕累托最优解集合**。要想逼近完整的帕累托最优解集合，最优化算法需要尽可能地达到三个相互制约的目标：  

1. 找到的帕累托前沿的近似需要尽可能地接近多目标问题真正的帕累托前沿。  
2. 找到的帕累托近似最优解集合中，解在搜索空间中的分布是尽可能均匀的，如此近似最优解的集合中的解具有丰富的多样性，不会偏向于任何一个特定的目标函数而是整体地达到近似最优。这样可以让决策者无偏地在这些帕累托解中权衡。  
3. 找到的帕累托前沿的近似需要尽可能的捕捉真正帕累托前沿的分布特性。也就是说，最优化算法需要尽可能的找到帕累托最优解集合中那些可能分布在搜索空间角落的极端帕累托解。  

对于给定的计算和时间限制，第一个目标可以通过将搜索聚焦在帕累托前沿的某一个部分达成；但是相对地，第二个目标要求算法的搜索需要均匀无偏；第三个目标要求算法尽可能地扩展已经找到的帕累托前沿的两侧，继续寻找新的解。  


## 多目标遗传算法
遗传算法(Genetic Algorithm)相比于其他的经典算法在多目标优化问题上的优点主要如下：  
- 由于遗传算法是一种基于群体的搜索优化算法，它可以在一次运行中产生多个帕累托解，而类似于神经网络的算法则需要多次运行才能够生成足够的帕累托解。[^1]  
- 相较于其他算法，遗传算法本身的搜索能力对帕累托前沿的形状不敏感。[^1]  
- 面对不同的目标函数，遗传算法可以通过交叉不断发掘新的帕累托解以延伸已经发现的帕累托前沿近似。  
- 大多数时候，多目标的遗传算法不需要对目标确定优先级(prioritize)、缩放(scale)、或者设置权重(weight)。  


[^1]: C. A. C. Coello, "Evolutionary multi-objective optimization: a historical view of the field," IEEE Computational Intelligence Magazine, vol. 1, no. 1, pp. 28-36, 2006, doi: https://doi.org/10.1109/MCI.2006.1597059.  

综上所述，使用遗传算法对多目标问题进行优化已经成为一种流行的使用方法。第一个多目标遗传算法(Multi-objective GA)是由Schaffer提出的VEGA(Vector Evalutated GA). 之后陆陆续续有更多的遗传算法的改进被应用于多目标优化中，它们的评述在文中总结在本文文末。   

## 多目标遗传算法的设计
### 适应度函数
#### 线性组合和赋权
最经典的一种设计多目标遗传算法适应度函数的方法是将所有的适应度函数进行线性组合，并分别赋予权重$w_i$。如此多目标优化将通过线性组合转化为一种近似于单目标优化问题的求解方式：  
$$min [z] = w_1z_1(\bold{x})+w_2z_2(\bold{x})+...+w_kz_k(\bold{x})$$
通常所有的权重和为1：$∑w_i=1$。这种方法通常需要使用者通过某种方式给出权重$\bold{w_i}=\{w_1,w_2,...,w_k\}$，常见的赋权方式为按照优先级赋权，因此这种方法被称为优先级方法(priori approach)。  
在这种方法下，算法需要使用不同的权重多次运行进行测试，如何设置不同的权重是该方法中的一个重要问题。WBGA中使用了一种自动化赋权的方式：WBGA中，权重与个体的染色体绑定，跟随个体一同被选择和进化。 
另一种基于MOGA的多目标遗传算法RWGA则在选择阶段为每一个个体使用随机生成的不同的权重向量$\bold{w_i}$。使用随机赋权的目的是通过随机的权重可以在一次算法运行中规定不同的搜索方向而不需要添加和设置其他参数。  


{% note info %}  
Procedure RWGA:  
$E$:  external archive to store non-dominated solutions
found during the search so far;  
$n_E$: number of elitist solutions immigrating from $E$ to $P$
in each generation.  

Step 1: Generate a random population.  
Step 2: Assign a fitness value to each solution $x∈P_t$ by performing the following steps:  
- Step 2.1: Generate a random number uk in $[0,1]$ for each objective $k, k=1,...,K$.  
- Step 2.2: Calculate the random weight of each objective $k$ as $w_k=(1/u_k)\sum_{i=1}^Ku_i$.  
- Step 2.3: Calculate the fitness of the solution as $f(\bold{x})=\sum_{i=1}^Kw_kz_k(\bold{x})$.  

Step 3: Calculate the selection probability of each solution $x∈P_t$ as follows: $p(\bold{x})=(f(\bold{x})-f^{min})^{-1}\sum_{\bold{y}∈P_t}(f(\bold{y})-f^{min})$  
where $f^{min}=min\{f(\bold{x})|\bold{x}∈P_t\}$.  
Step 4: Select parents using the selection probabilities calculated in Step 3. Apply crossover on the selected
parent pairs to create $N$ offspring.  Mutate offspring with a predefined mutation rate.   
Copy all offspring to $P_{t+1}$.  
Update $E$ if necessary.  
Step 5: Randomly remove nE solutions from $P_{t+1}$ and add the same number of solutions from $E$ to $P_{t+1}$.  
Step 6: If the stopping condition is not satisfied, set $t=t+1$ and go to Step 2. Otherwise, return to $E$.  

{% endnote %}  

线性组合的主要优点是这种方法非常简单而且易于实现。相对地，线性组合的方式查找对非凸的目标函数性能较差。因此，如果真正的帕累托前沿是非凸函数，按照线性组合并不能完全找到帕累托最优解，而且找到的最优解很难做到均匀分布。  



## 总结：不同的多目标遗传算法以及评述  

| Algorithm | Fitness Assignment | Diversity Mechanism | Elitism | External Population | Advantages | Disadvantages |
|:-:|:-|:-|:-:|:-:|:-|:-|
|VEGA | Each subpopulation is evaluated with respect to a different objective| No | No | No | First MOGA Straightforward implementation | Tend converge to the extreme of each objective |
| MOGA | Pareto ranking Fitness sharing by niching|No | No | Simple extension of single objective GA| Usually slow convergence| Problems related to niche size parameter|
|WBGA| Weighted average of normalized objectives | Niching | No | No | Simple extension of single objective GA | Difficulties in nonconvex|
| NPGA | No fitness assignment, tournament selection | Niche count as tie breaker in tournament selection| No |No |Very simple selection process with tournament selection|- Problems related to niche size parameter <br> - Extra parameter for tournament selection |
| RWGA | Weighted average of normalized objectives |Randomly assigned weights | Yes | Yes | Efficient and easy implement|Difficulties in nonconvex objective function space|
|PESA | No fitness assignment |Cell-based density | Pure elitist | Yes | - Easy to implement Performance depends on <br> - Computationally efficient cell size s| Prior information needed about objective space|
| PAES | Pareto dominance is used to replace a parent if offspring dominates | Cell-based density as tie breaker between offspring and parent | Yes | Yes | - Random mutation hill climbing strategy<br> - Easy to implement Performance depends on | - Not a population based approach <br> - Computationally efficient cell sizes|
NSGA | Ranking based on non-domination sorting |Fitness sharing by niching |No | No | Fast convergence | Problems related to niche size parameter |
|NSGA-II| Ranking based on non-domination sorting|Crowding distance| Yes | No | - Single parameter ($N$) <br> - Well tested <br> - Efficient |Crowding distance works in objective space only|
|SPEA | Ranking based on the external archive of non-dominated solutions| Clustering to truncateexternal population|Yes| Yes|- Well tested <br> - No parameter for clustering | Complex clustering algorithm|
|SPEA-2 | Strength of dominators | Density based on the k-th nearest neighbor|Yes |Yes |- Improved SPEA<br> - Make sure extreme points are preserved | Computationally expensive fitness and density calculation|
| RDGA | The problem reduced to bi-objective problem with solution rank and density as objectives |Forbidden region cell based density|Yes | Yes | - Dynamic cell update <br>- Robust with respect to the number of objectives |More difficult to implement than others |
| DMOEA | Cell-based ranking|Adaptive cell-based density | Yes (implicitly) | No | - Includes efficient techniques to update cell densities<br> - Adaptive approaches to set GA parameter | More difficult to implement than others|
